// Generated from gen/SparkSQL.g4 by ANTLR 4.13.1

import * as antlr from "antlr4ng";
import { Token } from "antlr4ng";

import { SparkSQLListener } from "./SparkSQLListener.js";
import { SparkSQLVisitor } from "./SparkSQLVisitor.js";

// for running tests with parameters, TODO: discuss strategy for typed parameters in CI
// eslint-disable-next-line no-unused-vars
type int = number;


export class SparkSQLParser extends antlr.Parser {
    public static readonly SPACE = 1;
    public static readonly COMMENT_INPUT = 2;
    public static readonly LINE_COMMENT = 3;
    public static readonly KW_ADD = 4;
    public static readonly KW_ADMIN = 5;
    public static readonly KW_AFTER = 6;
    public static readonly KW_ANALYZE = 7;
    public static readonly KW_ASC = 8;
    public static readonly KW_BEFORE = 9;
    public static readonly KW_BYTE = 10;
    public static readonly KW_BYTES = 11;
    public static readonly KW_CACHE = 12;
    public static readonly KW_CASCADE = 13;
    public static readonly KW_CATALOG = 14;
    public static readonly KW_CATALOGS = 15;
    public static readonly KW_CLEAR = 16;
    public static readonly KW_CENTURY = 17;
    public static readonly KW_CHAIN = 18;
    public static readonly KW_CHANGELOG_MODE = 19;
    public static readonly KW_CHARACTERS = 20;
    public static readonly KW_COMMENT = 21;
    public static readonly KW_COMPACT = 22;
    public static readonly KW_COLUMNS = 23;
    public static readonly KW_CONSTRAINTS = 24;
    public static readonly KW_CONSTRUCTOR = 25;
    public static readonly KW_COMPUTE = 26;
    public static readonly KW_CUMULATE = 27;
    public static readonly KW_DATA = 28;
    public static readonly KW_DATABASE = 29;
    public static readonly KW_DATABASES = 30;
    public static readonly KW_DAYS = 31;
    public static readonly KW_DBPROPERTIES = 32;
    public static readonly KW_DECADE = 33;
    public static readonly KW_DEFINED = 34;
    public static readonly KW_DESC = 35;
    public static readonly KW_DESCRIPTOR = 36;
    public static readonly KW_DIV = 37;
    public static readonly KW_ENCODING = 38;
    public static readonly KW_ENFORCED = 39;
    public static readonly KW_ENGINE = 40;
    public static readonly KW_EPOCH = 41;
    public static readonly KW_ERROR = 42;
    public static readonly KW_ESTIMATED_COST = 43;
    public static readonly KW_EXCEPTION = 44;
    public static readonly KW_EXCLUDE = 45;
    public static readonly KW_EXCLUDING = 46;
    public static readonly KW_EXTENDED = 47;
    public static readonly KW_FILTER = 48;
    public static readonly KW_FILE = 49;
    public static readonly KW_FILES = 50;
    public static readonly KW_FINAL = 51;
    public static readonly KW_FIRST = 52;
    public static readonly KW_FOLLOWING = 53;
    public static readonly KW_FORMAT = 54;
    public static readonly KW_FORTRAN = 55;
    public static readonly KW_FOUND = 56;
    public static readonly KW_FRAC_SECOND = 57;
    public static readonly KW_FUNCTIONS = 58;
    public static readonly KW_GENERAL = 59;
    public static readonly KW_GENERATED = 60;
    public static readonly KW_GO = 61;
    public static readonly KW_GOTO = 62;
    public static readonly KW_GRANTED = 63;
    public static readonly KW_HOP = 64;
    public static readonly KW_HOURS = 65;
    public static readonly KW_IF = 66;
    public static readonly KW_IGNORE = 67;
    public static readonly KW_INCLUDE = 68;
    public static readonly KW_INCREMENT = 69;
    public static readonly KW_INPUT = 70;
    public static readonly KW_INVOKER = 71;
    public static readonly KW_JAR = 72;
    public static readonly KW_JARS = 73;
    public static readonly KW_JAVA = 74;
    public static readonly KW_JSON = 75;
    public static readonly KW_JSON_EXECUTION_PLAN = 76;
    public static readonly KW_KEY = 77;
    public static readonly KW_KEYS = 78;
    public static readonly KW_KEY_MEMBER = 79;
    public static readonly KW_KEY_TYPE = 80;
    public static readonly KW_LABEL = 81;
    public static readonly KW_LAST = 82;
    public static readonly KW_LENGTH = 83;
    public static readonly KW_LEVEL = 84;
    public static readonly KW_LIST = 85;
    public static readonly KW_LOAD = 86;
    public static readonly KW_LOCATION = 87;
    public static readonly KW_LONG = 88;
    public static readonly KW_MAP = 89;
    public static readonly KW_MICROSECOND = 90;
    public static readonly KW_MILLENNIUM = 91;
    public static readonly KW_MILLISECOND = 92;
    public static readonly KW_MINUTES = 93;
    public static readonly KW_MINVALUE = 94;
    public static readonly KW_MODIFY = 95;
    public static readonly KW_MODULES = 96;
    public static readonly KW_MONTHS = 97;
    public static readonly KW_NANOSECOND = 98;
    public static readonly KW_NOSCAN = 99;
    public static readonly KW_NULLS = 100;
    public static readonly KW_NUMBER = 101;
    public static readonly KW_OPTION = 102;
    public static readonly KW_OPTIONS = 103;
    public static readonly KW_ORDERING = 104;
    public static readonly KW_OUTPUT = 105;
    public static readonly KW_OVERWRITE = 106;
    public static readonly KW_OVERWRITING = 107;
    public static readonly KW_PARTITIONED = 108;
    public static readonly KW_PARTITIONS = 109;
    public static readonly KW_PASSING = 110;
    public static readonly KW_PAST = 111;
    public static readonly KW_PATH = 112;
    public static readonly KW_PLACING = 113;
    public static readonly KW_PLAN = 114;
    public static readonly KW_PRECEDING = 115;
    public static readonly KW_PRESERVE = 116;
    public static readonly KW_PRIOR = 117;
    public static readonly KW_PRIVILEGES = 118;
    public static readonly KW_PUBLIC = 119;
    public static readonly KW_PYTHON = 120;
    public static readonly KW_PYTHON_FILES = 121;
    public static readonly KW_PYTHON_REQUIREMENTS = 122;
    public static readonly KW_PYTHON_DEPENDENCIES = 123;
    public static readonly KW_PYTHON_JAR = 124;
    public static readonly KW_PYTHON_ARCHIVES = 125;
    public static readonly KW_PYTHON_PARAMETER = 126;
    public static readonly KW_QUARTER = 127;
    public static readonly KW_QUERY = 128;
    public static readonly KW_RAW = 129;
    public static readonly KW_READ = 130;
    public static readonly KW_REAL = 131;
    public static readonly KW_RELATIVE = 132;
    public static readonly KW_REMOVE = 133;
    public static readonly KW_RENAME = 134;
    public static readonly KW_REPLACE = 135;
    public static readonly KW_RESPECT = 136;
    public static readonly KW_RESTART = 137;
    public static readonly KW_RESTRICT = 138;
    public static readonly KW_ROLE = 139;
    public static readonly KW_ROW_COUNT = 140;
    public static readonly KW_SCALA = 141;
    public static readonly KW_SCALAR = 142;
    public static readonly KW_SCALE = 143;
    public static readonly KW_SCHEMA = 144;
    public static readonly KW_SCHEMAS = 145;
    public static readonly KW_SECONDS = 146;
    public static readonly KW_SECTION = 147;
    public static readonly KW_SECURITY = 148;
    public static readonly KW_SELF = 149;
    public static readonly KW_SERVER = 150;
    public static readonly KW_SERVER_NAME = 151;
    public static readonly KW_SESSION = 152;
    public static readonly KW_SETS = 153;
    public static readonly KW_SHORT = 154;
    public static readonly KW_SIMPLE = 155;
    public static readonly KW_SIZE = 156;
    public static readonly KW_SLIDE = 157;
    public static readonly KW_SOURCE = 158;
    public static readonly KW_SPACE = 159;
    public static readonly KW_SERDEPROPERTIES = 160;
    public static readonly KW_STATE = 161;
    public static readonly KW_STATISTICS = 162;
    public static readonly KW_STATEMENT = 163;
    public static readonly KW_STEP = 164;
    public static readonly KW_STRING = 165;
    public static readonly KW_STRUCTURE = 166;
    public static readonly KW_STYLE = 167;
    public static readonly KW_TABLES = 168;
    public static readonly KW_TEMPORARY = 169;
    public static readonly KW_TIMECOL = 170;
    public static readonly KW_FLOOR = 171;
    public static readonly KW_TIMESTAMP_LTZ = 172;
    public static readonly KW_TIMESTAMP_NTZ = 173;
    public static readonly KW_TIMESTAMPADD = 174;
    public static readonly KW_TIMESTAMPDIFF = 175;
    public static readonly KW_TOTIMESTAMP = 176;
    public static readonly KW_TRANSFORM = 177;
    public static readonly KW_TUMBLE = 178;
    public static readonly KW_TYPE = 179;
    public static readonly KW_UNCACHE = 180;
    public static readonly KW_UNDER = 181;
    public static readonly KW_UNBOUNDED = 182;
    public static readonly KW_UNLOAD = 183;
    public static readonly KW_USAGE = 184;
    public static readonly KW_USE = 185;
    public static readonly KW_UTF16 = 186;
    public static readonly KW_UTF32 = 187;
    public static readonly KW_UTF8 = 188;
    public static readonly KW_VERSION = 189;
    public static readonly KW_VIEW = 190;
    public static readonly KW_VIEWS = 191;
    public static readonly KW_VIRTUAL = 192;
    public static readonly KW_WATERMARK = 193;
    public static readonly KW_WATERMARKS = 194;
    public static readonly KW_WEEK = 195;
    public static readonly KW_WEEKS = 196;
    public static readonly KW_WORK = 197;
    public static readonly KW_WRAPPER = 198;
    public static readonly KW_YEARS = 199;
    public static readonly KW_ZONE = 200;
    public static readonly KW_ABS = 201;
    public static readonly KW_ALL = 202;
    public static readonly KW_ALLOW = 203;
    public static readonly KW_ALTER = 204;
    public static readonly KW_AND = 205;
    public static readonly KW_ANY = 206;
    public static readonly KW_ARE = 207;
    public static readonly KW_ARRAY = 208;
    public static readonly KW_AS = 209;
    public static readonly KW_ASYMMETRIC = 210;
    public static readonly KW_AT = 211;
    public static readonly KW_AVG = 212;
    public static readonly KW_BEGIN = 213;
    public static readonly KW_BETWEEN = 214;
    public static readonly KW_BIGINT = 215;
    public static readonly KW_BINARY = 216;
    public static readonly KW_BIT = 217;
    public static readonly KW_BLOB = 218;
    public static readonly KW_BOOLEAN = 219;
    public static readonly KW_BOTH = 220;
    public static readonly KW_BUCKET = 221;
    public static readonly KW_BUCKETS = 222;
    public static readonly KW_BY = 223;
    public static readonly KW_CALL = 224;
    public static readonly KW_CALLED = 225;
    public static readonly KW_CASCADED = 226;
    public static readonly KW_CASE = 227;
    public static readonly KW_CAST = 228;
    public static readonly KW_CEIL = 229;
    public static readonly KW_CHAR = 230;
    public static readonly KW_CHARACTER = 231;
    public static readonly KW_CHECK = 232;
    public static readonly KW_CLOB = 233;
    public static readonly KW_CLOSE = 234;
    public static readonly KW_CLUSTER = 235;
    public static readonly KW_CLUSTERED = 236;
    public static readonly KW_COALESCE = 237;
    public static readonly KW_COLLATE = 238;
    public static readonly KW_COLLECT = 239;
    public static readonly KW_COLUMN = 240;
    public static readonly KW_COMMIT = 241;
    public static readonly KW_CONNECT = 242;
    public static readonly KW_CONSTRAINT = 243;
    public static readonly KW_CONTAINS = 244;
    public static readonly KW_CONVERT = 245;
    public static readonly KW_COUNT = 246;
    public static readonly KW_CURRENT_TIMESTAMP = 247;
    public static readonly KW_CREATE = 248;
    public static readonly KW_CROSS = 249;
    public static readonly KW_CUBE = 250;
    public static readonly KW_CUME_DIST = 251;
    public static readonly KW_CURRENT = 252;
    public static readonly KW_CURSOR = 253;
    public static readonly KW_CYCLE = 254;
    public static readonly KW_COLLECTION = 255;
    public static readonly KW_DATE = 256;
    public static readonly KW_DATETIME = 257;
    public static readonly KW_DAY = 258;
    public static readonly KW_DEC = 259;
    public static readonly KW_DECIMAL = 260;
    public static readonly KW_DECLARE = 261;
    public static readonly KW_DEFAULT = 262;
    public static readonly KW_DEFINE = 263;
    public static readonly KW_DELETE = 264;
    public static readonly KW_DELIMITED = 265;
    public static readonly KW_DESCRIBE = 266;
    public static readonly KW_DENSE_RANK = 267;
    public static readonly KW_DISTINCT = 268;
    public static readonly KW_DIRECTORY = 269;
    public static readonly KW_DISTRIBUTED = 270;
    public static readonly KW_DISTRIBUTE = 271;
    public static readonly KW_DOUBLE = 272;
    public static readonly KW_DROP = 273;
    public static readonly KW_EACH = 274;
    public static readonly KW_ELSE = 275;
    public static readonly KW_END = 276;
    public static readonly KW_EQUALS = 277;
    public static readonly KW_ESCAPE = 278;
    public static readonly KW_ESCAPED = 279;
    public static readonly KW_EXCEPT = 280;
    public static readonly KW_EXECUTE = 281;
    public static readonly KW_EXISTS = 282;
    public static readonly KW_EXPLAIN = 283;
    public static readonly KW_EXPLODE = 284;
    public static readonly KW_EXPLODE_OUTER = 285;
    public static readonly KW_EXTERNAL = 286;
    public static readonly KW_EXTRACT = 287;
    public static readonly KW_FIRST_VALUE = 288;
    public static readonly KW_FALSE = 289;
    public static readonly KW_FLOAT = 290;
    public static readonly KW_FIELDS = 291;
    public static readonly KW_FOR = 292;
    public static readonly KW_FROM = 293;
    public static readonly KW_FROM_UNIXTIME = 294;
    public static readonly KW_FULL = 295;
    public static readonly KW_FUNCTION = 296;
    public static readonly KW_GLOBAL = 297;
    public static readonly KW_GRANT = 298;
    public static readonly KW_GROUP = 299;
    public static readonly KW_GROUPING = 300;
    public static readonly KW_GROUPS = 301;
    public static readonly KW_HASH = 302;
    public static readonly KW_HAVING = 303;
    public static readonly KW_HOUR = 304;
    public static readonly KW_IMPORT = 305;
    public static readonly KW_IN = 306;
    public static readonly KW_INCLUDING = 307;
    public static readonly KW_INPUTFORMAT = 308;
    public static readonly KW_INNER = 309;
    public static readonly KW_INOUT = 310;
    public static readonly KW_INSERT = 311;
    public static readonly KW_INT = 312;
    public static readonly KW_INTEGER = 313;
    public static readonly KW_INTERSECT = 314;
    public static readonly KW_INTERVAL = 315;
    public static readonly KW_INTO = 316;
    public static readonly KW_INPATH = 317;
    public static readonly KW_INLINE = 318;
    public static readonly KW_INLINE_OUTER = 319;
    public static readonly KW_ITEMS = 320;
    public static readonly KW_IS = 321;
    public static readonly KW_JOIN = 322;
    public static readonly KW_JSON_TUPLE = 323;
    public static readonly KW_LAG = 324;
    public static readonly KW_LANGUAGE = 325;
    public static readonly KW_LATERAL = 326;
    public static readonly KW_LAST_VALUE = 327;
    public static readonly KW_LEAD = 328;
    public static readonly KW_LEADING = 329;
    public static readonly KW_LEFT = 330;
    public static readonly KW_LIKE = 331;
    public static readonly KW_LINES = 332;
    public static readonly KW_LIMIT = 333;
    public static readonly KW_LOCAL = 334;
    public static readonly KW_LOCALTIMESTAMP = 335;
    public static readonly KW_MATCH = 336;
    public static readonly KW_MATCH_RECOGNIZE = 337;
    public static readonly KW_MEASURES = 338;
    public static readonly KW_MERGE = 339;
    public static readonly KW_METADATA = 340;
    public static readonly KW_MINUS = 341;
    public static readonly KW_MINUTE = 342;
    public static readonly KW_MODIFIES = 343;
    public static readonly KW_MODULE = 344;
    public static readonly KW_MONTH = 345;
    public static readonly KW_MULTISET = 346;
    public static readonly KW_NATURAL = 347;
    public static readonly KW_NEXT = 348;
    public static readonly KW_NO = 349;
    public static readonly KW_NONE = 350;
    public static readonly KW_NOT = 351;
    public static readonly KW_NTILE = 352;
    public static readonly KW_NTH_VALUE = 353;
    public static readonly KW_NULL = 354;
    public static readonly KW_NUMERIC = 355;
    public static readonly KW_OF = 356;
    public static readonly KW_OFFSET = 357;
    public static readonly KW_ON = 358;
    public static readonly KW_ONE = 359;
    public static readonly KW_OR = 360;
    public static readonly KW_ORDER = 361;
    public static readonly KW_OUT = 362;
    public static readonly KW_OUTER = 363;
    public static readonly KW_OUTPUTFORMAT = 364;
    public static readonly KW_OVER = 365;
    public static readonly KW_OVERLAY = 366;
    public static readonly KW_PARSE_URL = 367;
    public static readonly KW_PARTITION = 368;
    public static readonly KW_PATTERN = 369;
    public static readonly KW_PER = 370;
    public static readonly KW_PERCENT = 371;
    public static readonly KW_PERCENT_RANK = 372;
    public static readonly KW_PERCENTILE_CONT = 373;
    public static readonly KW_PERCENTILE_DISC = 374;
    public static readonly KW_PERIOD = 375;
    public static readonly KW_PIVOT = 376;
    public static readonly KW_POSITION = 377;
    public static readonly KW_POWER = 378;
    public static readonly KW_POSEXPLODE = 379;
    public static readonly KW_POSEXPLODE_OUTER = 380;
    public static readonly KW_PRIMARY = 381;
    public static readonly KW_PURGE = 382;
    public static readonly KW_RANGE = 383;
    public static readonly KW_RECORDWRITER = 384;
    public static readonly KW_ROW_NUMBER = 385;
    public static readonly KW_RANK = 386;
    public static readonly KW_REGEXP = 387;
    public static readonly KW_RESET = 388;
    public static readonly KW_REVOKE = 389;
    public static readonly KW_REPAIR = 390;
    public static readonly KW_RIGHT = 391;
    public static readonly KW_RLIKE = 392;
    public static readonly KW_ROLLBACK = 393;
    public static readonly KW_ROLLUP = 394;
    public static readonly KW_ROW = 395;
    public static readonly KW_ROWS = 396;
    public static readonly KW_SECOND = 397;
    public static readonly KW_SELECT = 398;
    public static readonly KW_SET = 399;
    public static readonly KW_SERDE = 400;
    public static readonly KW_SHOW = 401;
    public static readonly KW_SIMILAR = 402;
    public static readonly KW_SKIP = 403;
    public static readonly KW_STORED = 404;
    public static readonly KW_SORTED = 405;
    public static readonly KW_SMALLINT = 406;
    public static readonly KW_STACK = 407;
    public static readonly KW_START = 408;
    public static readonly KW_STATIC = 409;
    public static readonly KW_STRUCT = 410;
    public static readonly KW_SORT = 411;
    public static readonly KW_SUBSTRING = 412;
    public static readonly KW_SUM = 413;
    public static readonly KW_SYMMETRIC = 414;
    public static readonly KW_SYSTEM = 415;
    public static readonly KW_SYSTEM_TIME = 416;
    public static readonly KW_SYSTEM_USER = 417;
    public static readonly KW_TABLE = 418;
    public static readonly KW_TBLPROPERTIES = 419;
    public static readonly KW_TABLESAMPLE = 420;
    public static readonly KW_TERMINATED = 421;
    public static readonly KW_THEN = 422;
    public static readonly KW_TIME = 423;
    public static readonly KW_TIMESTAMP = 424;
    public static readonly KW_TIMESTAMP_3 = 425;
    public static readonly KW_TIMESTAMP_6 = 426;
    public static readonly KW_TIMESTAMP_9 = 427;
    public static readonly KW_TINYINT = 428;
    public static readonly KW_TO = 429;
    public static readonly KW_TRAILING = 430;
    public static readonly KW_TRUE = 431;
    public static readonly KW_TRUNCATE = 432;
    public static readonly KW_UNION = 433;
    public static readonly KW_UNIQUE = 434;
    public static readonly KW_UNKNOWN = 435;
    public static readonly KW_UNSET = 436;
    public static readonly KW_UNPIVOT = 437;
    public static readonly KW_UPPER = 438;
    public static readonly KW_UPSERT = 439;
    public static readonly KW_USER = 440;
    public static readonly KW_USING = 441;
    public static readonly KW_VALUE = 442;
    public static readonly KW_VALUES = 443;
    public static readonly KW_VARBINARY = 444;
    public static readonly KW_VARCHAR = 445;
    public static readonly KW_WHEN = 446;
    public static readonly KW_WHERE = 447;
    public static readonly KW_WINDOW = 448;
    public static readonly KW_WITH = 449;
    public static readonly KW_WITHIN = 450;
    public static readonly KW_WITHOUT = 451;
    public static readonly KW_YEAR = 452;
    public static readonly KW_MATERIALIZED = 453;
    public static readonly KW_FRESHNESS = 454;
    public static readonly KW_REFRESH_MODE = 455;
    public static readonly KW_RECOVER = 456;
    public static readonly KW_CONTINUOUS = 457;
    public static readonly KW_SUSPEND = 458;
    public static readonly KW_RESUME = 459;
    public static readonly KW_REFRESH = 460;
    public static readonly BIT_NOT_OP = 461;
    public static readonly BIT_OR_OP = 462;
    public static readonly BIT_AND_OP = 463;
    public static readonly BIT_XOR_OP = 464;
    public static readonly EQUAL_SYMBOL = 465;
    public static readonly GREATER_SYMBOL = 466;
    public static readonly LESS_SYMBOL = 467;
    public static readonly EXCLAMATION_SYMBOL = 468;
    public static readonly DOT = 469;
    public static readonly LS_BRACKET = 470;
    public static readonly RS_BRACKET = 471;
    public static readonly LR_BRACKET = 472;
    public static readonly RR_BRACKET = 473;
    public static readonly LB_BRACKET = 474;
    public static readonly RB_BRACKET = 475;
    public static readonly COMMA = 476;
    public static readonly SEMICOLON = 477;
    public static readonly AT_SIGN = 478;
    public static readonly DOLLAR = 479;
    public static readonly SINGLE_QUOTE_SYMB = 480;
    public static readonly DOUBLE_QUOTE_SYMB = 481;
    public static readonly REVERSE_QUOTE_SYMB = 482;
    public static readonly COLON_SYMB = 483;
    public static readonly ASTERISK_SIGN = 484;
    public static readonly UNDERLINE_SIGN = 485;
    public static readonly HYPNEN_SIGN = 486;
    public static readonly ADD_SIGN = 487;
    public static readonly PENCENT_SIGN = 488;
    public static readonly DOUBLE_VERTICAL_SIGN = 489;
    public static readonly DOUBLE_HYPNEN_SIGN = 490;
    public static readonly SLASH_SIGN = 491;
    public static readonly QUESTION_MARK_SIGN = 492;
    public static readonly DOUBLE_RIGHT_ARROW = 493;
    public static readonly STRING_LITERAL = 494;
    public static readonly DIG_LITERAL = 495;
    public static readonly REAL_LITERAL = 496;
    public static readonly ID_LITERAL = 497;
    public static readonly RULE_statement = 0;
    public static readonly RULE_sqlStatements = 1;
    public static readonly RULE_sqlStatement = 2;
    public static readonly RULE_emptyStatement = 3;
    public static readonly RULE_createStatement = 4;
    public static readonly RULE_dmlStatement = 5;
    public static readonly RULE_createTable = 6;
    public static readonly RULE_simpleCreateTable = 7;
    public static readonly RULE_simpleCreateTableNoSortElement = 8;
    public static readonly RULE_location = 9;
    public static readonly RULE_sortedBy = 10;
    public static readonly RULE_usingCreate = 11;
    public static readonly RULE_tblProperties = 12;
    public static readonly RULE_defaultColumnUsing = 13;
    public static readonly RULE_defaultColumnUsingNoSortElement = 14;
    public static readonly RULE_columnUsing = 15;
    public static readonly RULE_columnUsingNoSortElement = 16;
    public static readonly RULE_usingByQuery = 17;
    public static readonly RULE_usingByQueryNoSortElement = 18;
    public static readonly RULE_intoBuckets = 19;
    public static readonly RULE_hiveFormatpartitionDefinition = 20;
    public static readonly RULE_rowFormatSerde = 21;
    public static readonly RULE_fieldsTerminatedBy = 22;
    public static readonly RULE_storedAs = 23;
    public static readonly RULE_storedAsInputformat = 24;
    public static readonly RULE_outputformat = 25;
    public static readonly RULE_rowFormatDelimted = 26;
    public static readonly RULE_columnsBody = 27;
    public static readonly RULE_createCustomSerde = 28;
    public static readonly RULE_createCustomSerdeNoSortElement = 29;
    public static readonly RULE_createCustomSerdeExternal = 30;
    public static readonly RULE_createCustomSerdeExternalNoSortElement = 31;
    public static readonly RULE_createTableAsSelect = 32;
    public static readonly RULE_createMaterializedTableAsSelect = 33;
    public static readonly RULE_createMaterializedTableAsSelectNoSortElement = 34;
    public static readonly RULE_usingClause = 35;
    public static readonly RULE_jarFileName = 36;
    public static readonly RULE_filePath = 37;
    public static readonly RULE_ifExistsPart = 38;
    public static readonly RULE_columnPosition = 39;
    public static readonly RULE_renameDefinition = 40;
    public static readonly RULE_setKeyValueDefinition = 41;
    public static readonly RULE_addConstraint = 42;
    public static readonly RULE_dropConstraint = 43;
    public static readonly RULE_addUnique = 44;
    public static readonly RULE_notForced = 45;
    public static readonly RULE_insertStatement = 46;
    public static readonly RULE_insertSimpleStatement = 47;
    public static readonly RULE_insertPartitionDefinition = 48;
    public static readonly RULE_queryStatement = 49;
    public static readonly RULE_withClause = 50;
    public static readonly RULE_valuesCaluse = 51;
    public static readonly RULE_inlineBody = 52;
    public static readonly RULE_withItem = 53;
    public static readonly RULE_withItemName = 54;
    public static readonly RULE_selectStatement = 55;
    public static readonly RULE_selectClause = 56;
    public static readonly RULE_projectItemDefinition = 57;
    public static readonly RULE_filterPart = 58;
    public static readonly RULE_overWindowItem = 59;
    public static readonly RULE_overClause = 60;
    public static readonly RULE_windowFunctioPart = 61;
    public static readonly RULE_windowFunctionName = 62;
    public static readonly RULE_analyticFunction = 63;
    public static readonly RULE_rangkingFunction = 64;
    public static readonly RULE_fromClause = 65;
    public static readonly RULE_windowFrameForWindowsQuery = 66;
    public static readonly RULE_frameExpession = 67;
    public static readonly RULE_tableExpression = 68;
    public static readonly RULE_tvfClause = 69;
    public static readonly RULE_rangeClause = 70;
    public static readonly RULE_viewReference = 71;
    public static readonly RULE_pivotReference = 72;
    public static readonly RULE_tableReference = 73;
    public static readonly RULE_tablePrimary = 74;
    public static readonly RULE_funtionBody = 75;
    public static readonly RULE_unpivotBody = 76;
    public static readonly RULE_pivotBody = 77;
    public static readonly RULE_expressionAsAlias = 78;
    public static readonly RULE_expressionAsAliasList = 79;
    public static readonly RULE_systemTimePeriod = 80;
    public static readonly RULE_dateTimeExpression = 81;
    public static readonly RULE_inlineDataValueClause = 82;
    public static readonly RULE_windowTVFClause = 83;
    public static readonly RULE_windowTVFExpression = 84;
    public static readonly RULE_windowTVFName = 85;
    public static readonly RULE_rowFormatDelimited = 86;
    public static readonly RULE_hiveSerde = 87;
    public static readonly RULE_usingAsColumnPart = 88;
    public static readonly RULE_hiveSerdePart = 89;
    public static readonly RULE_tableCanHasKeyPropertyList = 90;
    public static readonly RULE_sparkRecordWriterPart = 91;
    public static readonly RULE_windowTVFParam = 92;
    public static readonly RULE_timeIntervalParamName = 93;
    public static readonly RULE_columnDescriptor = 94;
    public static readonly RULE_joinCondition = 95;
    public static readonly RULE_whereClause = 96;
    public static readonly RULE_samplingQueries = 97;
    public static readonly RULE_someByClause = 98;
    public static readonly RULE_clusterByClause = 99;
    public static readonly RULE_clusteredByClause = 100;
    public static readonly RULE_distributeByClause = 101;
    public static readonly RULE_groupByClause = 102;
    public static readonly RULE_groupItemDefinition = 103;
    public static readonly RULE_groupingSets = 104;
    public static readonly RULE_groupingSetsNotionName = 105;
    public static readonly RULE_groupWindowFunction = 106;
    public static readonly RULE_groupWindowFunctionName = 107;
    public static readonly RULE_timeAttrColumn = 108;
    public static readonly RULE_havingClause = 109;
    public static readonly RULE_windowClause = 110;
    public static readonly RULE_namedWindow = 111;
    public static readonly RULE_windowSpec = 112;
    public static readonly RULE_matchRecognizeClause = 113;
    public static readonly RULE_orderByCaluse = 114;
    public static readonly RULE_sortByCaluse = 115;
    public static readonly RULE_orderItemDefinition = 116;
    public static readonly RULE_limitClause = 117;
    public static readonly RULE_offsetClause = 118;
    public static readonly RULE_partitionByClause = 119;
    public static readonly RULE_quantifiers = 120;
    public static readonly RULE_measuresClause = 121;
    public static readonly RULE_patternDefinition = 122;
    public static readonly RULE_patternVariable = 123;
    public static readonly RULE_outputMode = 124;
    public static readonly RULE_afterMatchStrategy = 125;
    public static readonly RULE_patternVariablesDefinition = 126;
    public static readonly RULE_windowFrame = 127;
    public static readonly RULE_frameBound = 128;
    public static readonly RULE_withinClause = 129;
    public static readonly RULE_selfDefinitionClause = 130;
    public static readonly RULE_partitionDefinition = 131;
    public static readonly RULE_transformList = 132;
    public static readonly RULE_transform = 133;
    public static readonly RULE_transformArgument = 134;
    public static readonly RULE_likeDefinition = 135;
    public static readonly RULE_distribution = 136;
    public static readonly RULE_using = 137;
    public static readonly RULE_likeOption = 138;
    public static readonly RULE_columnOptionDefinition = 139;
    public static readonly RULE_physicalColumnDefinitionList = 140;
    public static readonly RULE_physicalColumnDefinition = 141;
    public static readonly RULE_computedColumnExpression = 142;
    public static readonly RULE_watermarkDefinition = 143;
    public static readonly RULE_tableConstraint = 144;
    public static readonly RULE_constraintName = 145;
    public static readonly RULE_valuesDefinition = 146;
    public static readonly RULE_valuesRowDefinition = 147;
    public static readonly RULE_lengthOneDimension = 148;
    public static readonly RULE_lengthTwoOptionalDimension = 149;
    public static readonly RULE_lengthTwoStringDimension = 150;
    public static readonly RULE_lengthOneTypeDimension = 151;
    public static readonly RULE_mapTypeDimension = 152;
    public static readonly RULE_rowTypeDimension = 153;
    public static readonly RULE_structTypeDimension = 154;
    public static readonly RULE_columnConstraint = 155;
    public static readonly RULE_commentSpec = 156;
    public static readonly RULE_metadataColumnDefinition = 157;
    public static readonly RULE_metadataKey = 158;
    public static readonly RULE_computedColumnDefinition = 159;
    public static readonly RULE_columnName = 160;
    public static readonly RULE_columnNameList = 161;
    public static readonly RULE_columnType = 162;
    public static readonly RULE_expression = 163;
    public static readonly RULE_booleanExpression = 164;
    public static readonly RULE_predicate = 165;
    public static readonly RULE_likePredicate = 166;
    public static readonly RULE_valueExpression = 167;
    public static readonly RULE_primaryExpression = 168;
    public static readonly RULE_complexDataTypeExpression = 169;
    public static readonly RULE_arrayExpression = 170;
    public static readonly RULE_structExpression = 171;
    public static readonly RULE_rowExpression = 172;
    public static readonly RULE_mapExpression = 173;
    public static readonly RULE_dataTypeExpression = 174;
    public static readonly RULE_sqlSimpleType = 175;
    public static readonly RULE_functionName = 176;
    public static readonly RULE_functionParam = 177;
    public static readonly RULE_filterClause = 178;
    public static readonly RULE_correlationName = 179;
    public static readonly RULE_qualifiedName = 180;
    public static readonly RULE_timeIntervalExpression = 181;
    public static readonly RULE_errorCapturingMultiUnitsInterval = 182;
    public static readonly RULE_multiUnitsInterval = 183;
    public static readonly RULE_errorCapturingUnitToUnitInterval = 184;
    public static readonly RULE_unitToUnitInterval = 185;
    public static readonly RULE_intervalValue = 186;
    public static readonly RULE_columnAlias = 187;
    public static readonly RULE_tableAlias = 188;
    public static readonly RULE_anyAlias = 189;
    public static readonly RULE_errorCapturingIdentifier = 190;
    public static readonly RULE_errorCapturingIdentifierExtra = 191;
    public static readonly RULE_identifierList = 192;
    public static readonly RULE_identifierSeq = 193;
    public static readonly RULE_identifier = 194;
    public static readonly RULE_unquotedAnyString = 195;
    public static readonly RULE_refVar = 196;
    public static readonly RULE_unquotedIdentifier = 197;
    public static readonly RULE_whenClause = 198;
    public static readonly RULE_catalogPath = 199;
    public static readonly RULE_databasePath = 200;
    public static readonly RULE_databasePathCreate = 201;
    public static readonly RULE_tablePathCreate = 202;
    public static readonly RULE_tablePath = 203;
    public static readonly RULE_anonymousWindowsName = 204;
    public static readonly RULE_uid = 205;
    public static readonly RULE_withOption = 206;
    public static readonly RULE_ifNotExists = 207;
    public static readonly RULE_ifExists = 208;
    public static readonly RULE_tablePropertyList = 209;
    public static readonly RULE_tableProperty = 210;
    public static readonly RULE_tablePropertyKey = 211;
    public static readonly RULE_propertyName = 212;
    public static readonly RULE_tablePropertyValue = 213;
    public static readonly RULE_comparisonOperator = 214;
    public static readonly RULE_constant = 215;
    public static readonly RULE_timePointLiteral = 216;
    public static readonly RULE_stringLiteral = 217;
    public static readonly RULE_decimalLiteral = 218;
    public static readonly RULE_booleanLiteral = 219;
    public static readonly RULE_setQuantifier = 220;
    public static readonly RULE_timePointUnit = 221;
    public static readonly RULE_timeIntervalUnit = 222;
    public static readonly RULE_reservedKeywordsUsedAsFuncParam = 223;
    public static readonly RULE_reservedKeywordsUsedAsFuncName = 224;
    public static readonly RULE_nonReservedKeywords = 225;
    public static readonly RULE_selectStatementPlus = 226;

    public static readonly literalNames = [
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, "'~'", 
        "'|'", "'&'", "'^'", "'='", "'>'", "'<'", "'!'", "'.'", "'['", "']'", 
        "'('", "')'", "'{'", "'}'", "','", "';'", "'@'", "'$'", "'''", "'\"'", 
        "'`'", "':'", "'*'", "'_'", "'-'", "'+'", "'%'", null, null, "'/'", 
        "'?'"
    ];

    public static readonly symbolicNames = [
        null, "SPACE", "COMMENT_INPUT", "LINE_COMMENT", "KW_ADD", "KW_ADMIN", 
        "KW_AFTER", "KW_ANALYZE", "KW_ASC", "KW_BEFORE", "KW_BYTE", "KW_BYTES", 
        "KW_CACHE", "KW_CASCADE", "KW_CATALOG", "KW_CATALOGS", "KW_CLEAR", 
        "KW_CENTURY", "KW_CHAIN", "KW_CHANGELOG_MODE", "KW_CHARACTERS", 
        "KW_COMMENT", "KW_COMPACT", "KW_COLUMNS", "KW_CONSTRAINTS", "KW_CONSTRUCTOR", 
        "KW_COMPUTE", "KW_CUMULATE", "KW_DATA", "KW_DATABASE", "KW_DATABASES", 
        "KW_DAYS", "KW_DBPROPERTIES", "KW_DECADE", "KW_DEFINED", "KW_DESC", 
        "KW_DESCRIPTOR", "KW_DIV", "KW_ENCODING", "KW_ENFORCED", "KW_ENGINE", 
        "KW_EPOCH", "KW_ERROR", "KW_ESTIMATED_COST", "KW_EXCEPTION", "KW_EXCLUDE", 
        "KW_EXCLUDING", "KW_EXTENDED", "KW_FILTER", "KW_FILE", "KW_FILES", 
        "KW_FINAL", "KW_FIRST", "KW_FOLLOWING", "KW_FORMAT", "KW_FORTRAN", 
        "KW_FOUND", "KW_FRAC_SECOND", "KW_FUNCTIONS", "KW_GENERAL", "KW_GENERATED", 
        "KW_GO", "KW_GOTO", "KW_GRANTED", "KW_HOP", "KW_HOURS", "KW_IF", 
        "KW_IGNORE", "KW_INCLUDE", "KW_INCREMENT", "KW_INPUT", "KW_INVOKER", 
        "KW_JAR", "KW_JARS", "KW_JAVA", "KW_JSON", "KW_JSON_EXECUTION_PLAN", 
        "KW_KEY", "KW_KEYS", "KW_KEY_MEMBER", "KW_KEY_TYPE", "KW_LABEL", 
        "KW_LAST", "KW_LENGTH", "KW_LEVEL", "KW_LIST", "KW_LOAD", "KW_LOCATION", 
        "KW_LONG", "KW_MAP", "KW_MICROSECOND", "KW_MILLENNIUM", "KW_MILLISECOND", 
        "KW_MINUTES", "KW_MINVALUE", "KW_MODIFY", "KW_MODULES", "KW_MONTHS", 
        "KW_NANOSECOND", "KW_NOSCAN", "KW_NULLS", "KW_NUMBER", "KW_OPTION", 
        "KW_OPTIONS", "KW_ORDERING", "KW_OUTPUT", "KW_OVERWRITE", "KW_OVERWRITING", 
        "KW_PARTITIONED", "KW_PARTITIONS", "KW_PASSING", "KW_PAST", "KW_PATH", 
        "KW_PLACING", "KW_PLAN", "KW_PRECEDING", "KW_PRESERVE", "KW_PRIOR", 
        "KW_PRIVILEGES", "KW_PUBLIC", "KW_PYTHON", "KW_PYTHON_FILES", "KW_PYTHON_REQUIREMENTS", 
        "KW_PYTHON_DEPENDENCIES", "KW_PYTHON_JAR", "KW_PYTHON_ARCHIVES", 
        "KW_PYTHON_PARAMETER", "KW_QUARTER", "KW_QUERY", "KW_RAW", "KW_READ", 
        "KW_REAL", "KW_RELATIVE", "KW_REMOVE", "KW_RENAME", "KW_REPLACE", 
        "KW_RESPECT", "KW_RESTART", "KW_RESTRICT", "KW_ROLE", "KW_ROW_COUNT", 
        "KW_SCALA", "KW_SCALAR", "KW_SCALE", "KW_SCHEMA", "KW_SCHEMAS", 
        "KW_SECONDS", "KW_SECTION", "KW_SECURITY", "KW_SELF", "KW_SERVER", 
        "KW_SERVER_NAME", "KW_SESSION", "KW_SETS", "KW_SHORT", "KW_SIMPLE", 
        "KW_SIZE", "KW_SLIDE", "KW_SOURCE", "KW_SPACE", "KW_SERDEPROPERTIES", 
        "KW_STATE", "KW_STATISTICS", "KW_STATEMENT", "KW_STEP", "KW_STRING", 
        "KW_STRUCTURE", "KW_STYLE", "KW_TABLES", "KW_TEMPORARY", "KW_TIMECOL", 
        "KW_FLOOR", "KW_TIMESTAMP_LTZ", "KW_TIMESTAMP_NTZ", "KW_TIMESTAMPADD", 
        "KW_TIMESTAMPDIFF", "KW_TOTIMESTAMP", "KW_TRANSFORM", "KW_TUMBLE", 
        "KW_TYPE", "KW_UNCACHE", "KW_UNDER", "KW_UNBOUNDED", "KW_UNLOAD", 
        "KW_USAGE", "KW_USE", "KW_UTF16", "KW_UTF32", "KW_UTF8", "KW_VERSION", 
        "KW_VIEW", "KW_VIEWS", "KW_VIRTUAL", "KW_WATERMARK", "KW_WATERMARKS", 
        "KW_WEEK", "KW_WEEKS", "KW_WORK", "KW_WRAPPER", "KW_YEARS", "KW_ZONE", 
        "KW_ABS", "KW_ALL", "KW_ALLOW", "KW_ALTER", "KW_AND", "KW_ANY", 
        "KW_ARE", "KW_ARRAY", "KW_AS", "KW_ASYMMETRIC", "KW_AT", "KW_AVG", 
        "KW_BEGIN", "KW_BETWEEN", "KW_BIGINT", "KW_BINARY", "KW_BIT", "KW_BLOB", 
        "KW_BOOLEAN", "KW_BOTH", "KW_BUCKET", "KW_BUCKETS", "KW_BY", "KW_CALL", 
        "KW_CALLED", "KW_CASCADED", "KW_CASE", "KW_CAST", "KW_CEIL", "KW_CHAR", 
        "KW_CHARACTER", "KW_CHECK", "KW_CLOB", "KW_CLOSE", "KW_CLUSTER", 
        "KW_CLUSTERED", "KW_COALESCE", "KW_COLLATE", "KW_COLLECT", "KW_COLUMN", 
        "KW_COMMIT", "KW_CONNECT", "KW_CONSTRAINT", "KW_CONTAINS", "KW_CONVERT", 
        "KW_COUNT", "KW_CURRENT_TIMESTAMP", "KW_CREATE", "KW_CROSS", "KW_CUBE", 
        "KW_CUME_DIST", "KW_CURRENT", "KW_CURSOR", "KW_CYCLE", "KW_COLLECTION", 
        "KW_DATE", "KW_DATETIME", "KW_DAY", "KW_DEC", "KW_DECIMAL", "KW_DECLARE", 
        "KW_DEFAULT", "KW_DEFINE", "KW_DELETE", "KW_DELIMITED", "KW_DESCRIBE", 
        "KW_DENSE_RANK", "KW_DISTINCT", "KW_DIRECTORY", "KW_DISTRIBUTED", 
        "KW_DISTRIBUTE", "KW_DOUBLE", "KW_DROP", "KW_EACH", "KW_ELSE", "KW_END", 
        "KW_EQUALS", "KW_ESCAPE", "KW_ESCAPED", "KW_EXCEPT", "KW_EXECUTE", 
        "KW_EXISTS", "KW_EXPLAIN", "KW_EXPLODE", "KW_EXPLODE_OUTER", "KW_EXTERNAL", 
        "KW_EXTRACT", "KW_FIRST_VALUE", "KW_FALSE", "KW_FLOAT", "KW_FIELDS", 
        "KW_FOR", "KW_FROM", "KW_FROM_UNIXTIME", "KW_FULL", "KW_FUNCTION", 
        "KW_GLOBAL", "KW_GRANT", "KW_GROUP", "KW_GROUPING", "KW_GROUPS", 
        "KW_HASH", "KW_HAVING", "KW_HOUR", "KW_IMPORT", "KW_IN", "KW_INCLUDING", 
        "KW_INPUTFORMAT", "KW_INNER", "KW_INOUT", "KW_INSERT", "KW_INT", 
        "KW_INTEGER", "KW_INTERSECT", "KW_INTERVAL", "KW_INTO", "KW_INPATH", 
        "KW_INLINE", "KW_INLINE_OUTER", "KW_ITEMS", "KW_IS", "KW_JOIN", 
        "KW_JSON_TUPLE", "KW_LAG", "KW_LANGUAGE", "KW_LATERAL", "KW_LAST_VALUE", 
        "KW_LEAD", "KW_LEADING", "KW_LEFT", "KW_LIKE", "KW_LINES", "KW_LIMIT", 
        "KW_LOCAL", "KW_LOCALTIMESTAMP", "KW_MATCH", "KW_MATCH_RECOGNIZE", 
        "KW_MEASURES", "KW_MERGE", "KW_METADATA", "KW_MINUS", "KW_MINUTE", 
        "KW_MODIFIES", "KW_MODULE", "KW_MONTH", "KW_MULTISET", "KW_NATURAL", 
        "KW_NEXT", "KW_NO", "KW_NONE", "KW_NOT", "KW_NTILE", "KW_NTH_VALUE", 
        "KW_NULL", "KW_NUMERIC", "KW_OF", "KW_OFFSET", "KW_ON", "KW_ONE", 
        "KW_OR", "KW_ORDER", "KW_OUT", "KW_OUTER", "KW_OUTPUTFORMAT", "KW_OVER", 
        "KW_OVERLAY", "KW_PARSE_URL", "KW_PARTITION", "KW_PATTERN", "KW_PER", 
        "KW_PERCENT", "KW_PERCENT_RANK", "KW_PERCENTILE_CONT", "KW_PERCENTILE_DISC", 
        "KW_PERIOD", "KW_PIVOT", "KW_POSITION", "KW_POWER", "KW_POSEXPLODE", 
        "KW_POSEXPLODE_OUTER", "KW_PRIMARY", "KW_PURGE", "KW_RANGE", "KW_RECORDWRITER", 
        "KW_ROW_NUMBER", "KW_RANK", "KW_REGEXP", "KW_RESET", "KW_REVOKE", 
        "KW_REPAIR", "KW_RIGHT", "KW_RLIKE", "KW_ROLLBACK", "KW_ROLLUP", 
        "KW_ROW", "KW_ROWS", "KW_SECOND", "KW_SELECT", "KW_SET", "KW_SERDE", 
        "KW_SHOW", "KW_SIMILAR", "KW_SKIP", "KW_STORED", "KW_SORTED", "KW_SMALLINT", 
        "KW_STACK", "KW_START", "KW_STATIC", "KW_STRUCT", "KW_SORT", "KW_SUBSTRING", 
        "KW_SUM", "KW_SYMMETRIC", "KW_SYSTEM", "KW_SYSTEM_TIME", "KW_SYSTEM_USER", 
        "KW_TABLE", "KW_TBLPROPERTIES", "KW_TABLESAMPLE", "KW_TERMINATED", 
        "KW_THEN", "KW_TIME", "KW_TIMESTAMP", "KW_TIMESTAMP_3", "KW_TIMESTAMP_6", 
        "KW_TIMESTAMP_9", "KW_TINYINT", "KW_TO", "KW_TRAILING", "KW_TRUE", 
        "KW_TRUNCATE", "KW_UNION", "KW_UNIQUE", "KW_UNKNOWN", "KW_UNSET", 
        "KW_UNPIVOT", "KW_UPPER", "KW_UPSERT", "KW_USER", "KW_USING", "KW_VALUE", 
        "KW_VALUES", "KW_VARBINARY", "KW_VARCHAR", "KW_WHEN", "KW_WHERE", 
        "KW_WINDOW", "KW_WITH", "KW_WITHIN", "KW_WITHOUT", "KW_YEAR", "KW_MATERIALIZED", 
        "KW_FRESHNESS", "KW_REFRESH_MODE", "KW_RECOVER", "KW_CONTINUOUS", 
        "KW_SUSPEND", "KW_RESUME", "KW_REFRESH", "BIT_NOT_OP", "BIT_OR_OP", 
        "BIT_AND_OP", "BIT_XOR_OP", "EQUAL_SYMBOL", "GREATER_SYMBOL", "LESS_SYMBOL", 
        "EXCLAMATION_SYMBOL", "DOT", "LS_BRACKET", "RS_BRACKET", "LR_BRACKET", 
        "RR_BRACKET", "LB_BRACKET", "RB_BRACKET", "COMMA", "SEMICOLON", 
        "AT_SIGN", "DOLLAR", "SINGLE_QUOTE_SYMB", "DOUBLE_QUOTE_SYMB", "REVERSE_QUOTE_SYMB", 
        "COLON_SYMB", "ASTERISK_SIGN", "UNDERLINE_SIGN", "HYPNEN_SIGN", 
        "ADD_SIGN", "PENCENT_SIGN", "DOUBLE_VERTICAL_SIGN", "DOUBLE_HYPNEN_SIGN", 
        "SLASH_SIGN", "QUESTION_MARK_SIGN", "DOUBLE_RIGHT_ARROW", "STRING_LITERAL", 
        "DIG_LITERAL", "REAL_LITERAL", "ID_LITERAL"
    ];
    public static readonly ruleNames = [
        "statement", "sqlStatements", "sqlStatement", "emptyStatement", 
        "createStatement", "dmlStatement", "createTable", "simpleCreateTable", 
        "simpleCreateTableNoSortElement", "location", "sortedBy", "usingCreate", 
        "tblProperties", "defaultColumnUsing", "defaultColumnUsingNoSortElement", 
        "columnUsing", "columnUsingNoSortElement", "usingByQuery", "usingByQueryNoSortElement", 
        "intoBuckets", "hiveFormatpartitionDefinition", "rowFormatSerde", 
        "fieldsTerminatedBy", "storedAs", "storedAsInputformat", "outputformat", 
        "rowFormatDelimted", "columnsBody", "createCustomSerde", "createCustomSerdeNoSortElement", 
        "createCustomSerdeExternal", "createCustomSerdeExternalNoSortElement", 
        "createTableAsSelect", "createMaterializedTableAsSelect", "createMaterializedTableAsSelectNoSortElement", 
        "usingClause", "jarFileName", "filePath", "ifExistsPart", "columnPosition", 
        "renameDefinition", "setKeyValueDefinition", "addConstraint", "dropConstraint", 
        "addUnique", "notForced", "insertStatement", "insertSimpleStatement", 
        "insertPartitionDefinition", "queryStatement", "withClause", "valuesCaluse", 
        "inlineBody", "withItem", "withItemName", "selectStatement", "selectClause", 
        "projectItemDefinition", "filterPart", "overWindowItem", "overClause", 
        "windowFunctioPart", "windowFunctionName", "analyticFunction", "rangkingFunction", 
        "fromClause", "windowFrameForWindowsQuery", "frameExpession", "tableExpression", 
        "tvfClause", "rangeClause", "viewReference", "pivotReference", "tableReference", 
        "tablePrimary", "funtionBody", "unpivotBody", "pivotBody", "expressionAsAlias", 
        "expressionAsAliasList", "systemTimePeriod", "dateTimeExpression", 
        "inlineDataValueClause", "windowTVFClause", "windowTVFExpression", 
        "windowTVFName", "rowFormatDelimited", "hiveSerde", "usingAsColumnPart", 
        "hiveSerdePart", "tableCanHasKeyPropertyList", "sparkRecordWriterPart", 
        "windowTVFParam", "timeIntervalParamName", "columnDescriptor", "joinCondition", 
        "whereClause", "samplingQueries", "someByClause", "clusterByClause", 
        "clusteredByClause", "distributeByClause", "groupByClause", "groupItemDefinition", 
        "groupingSets", "groupingSetsNotionName", "groupWindowFunction", 
        "groupWindowFunctionName", "timeAttrColumn", "havingClause", "windowClause", 
        "namedWindow", "windowSpec", "matchRecognizeClause", "orderByCaluse", 
        "sortByCaluse", "orderItemDefinition", "limitClause", "offsetClause", 
        "partitionByClause", "quantifiers", "measuresClause", "patternDefinition", 
        "patternVariable", "outputMode", "afterMatchStrategy", "patternVariablesDefinition", 
        "windowFrame", "frameBound", "withinClause", "selfDefinitionClause", 
        "partitionDefinition", "transformList", "transform", "transformArgument", 
        "likeDefinition", "distribution", "using", "likeOption", "columnOptionDefinition", 
        "physicalColumnDefinitionList", "physicalColumnDefinition", "computedColumnExpression", 
        "watermarkDefinition", "tableConstraint", "constraintName", "valuesDefinition", 
        "valuesRowDefinition", "lengthOneDimension", "lengthTwoOptionalDimension", 
        "lengthTwoStringDimension", "lengthOneTypeDimension", "mapTypeDimension", 
        "rowTypeDimension", "structTypeDimension", "columnConstraint", "commentSpec", 
        "metadataColumnDefinition", "metadataKey", "computedColumnDefinition", 
        "columnName", "columnNameList", "columnType", "expression", "booleanExpression", 
        "predicate", "likePredicate", "valueExpression", "primaryExpression", 
        "complexDataTypeExpression", "arrayExpression", "structExpression", 
        "rowExpression", "mapExpression", "dataTypeExpression", "sqlSimpleType", 
        "functionName", "functionParam", "filterClause", "correlationName", 
        "qualifiedName", "timeIntervalExpression", "errorCapturingMultiUnitsInterval", 
        "multiUnitsInterval", "errorCapturingUnitToUnitInterval", "unitToUnitInterval", 
        "intervalValue", "columnAlias", "tableAlias", "anyAlias", "errorCapturingIdentifier", 
        "errorCapturingIdentifierExtra", "identifierList", "identifierSeq", 
        "identifier", "unquotedAnyString", "refVar", "unquotedIdentifier", 
        "whenClause", "catalogPath", "databasePath", "databasePathCreate", 
        "tablePathCreate", "tablePath", "anonymousWindowsName", "uid", "withOption", 
        "ifNotExists", "ifExists", "tablePropertyList", "tableProperty", 
        "tablePropertyKey", "propertyName", "tablePropertyValue", "comparisonOperator", 
        "constant", "timePointLiteral", "stringLiteral", "decimalLiteral", 
        "booleanLiteral", "setQuantifier", "timePointUnit", "timeIntervalUnit", 
        "reservedKeywordsUsedAsFuncParam", "reservedKeywordsUsedAsFuncName", 
        "nonReservedKeywords", "selectStatementPlus",
    ];

    public get grammarFileName(): string { return "SparkSQL.g4"; }
    public get literalNames(): (string | null)[] { return SparkSQLParser.literalNames; }
    public get symbolicNames(): (string | null)[] { return SparkSQLParser.symbolicNames; }
    public get ruleNames(): string[] { return SparkSQLParser.ruleNames; }
    public get serializedATN(): number[] { return SparkSQLParser._serializedATN; }

    protected createFailedPredicateException(predicate?: string, message?: string): antlr.FailedPredicateException {
        return new antlr.FailedPredicateException(this, predicate, message);
    }

    public constructor(input: antlr.TokenStream) {
        super(input);
        this.interpreter = new antlr.ParserATNSimulator(this, SparkSQLParser._ATN, SparkSQLParser.decisionsToDFA, new antlr.PredictionContextCache());
    }
    public statement(): StatementContext {
        let localContext = new StatementContext(this.context, this.state);
        this.enterRule(localContext, 0, SparkSQLParser.RULE_statement);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 454;
            this.sqlStatements();
            this.state = 455;
            this.match(SparkSQLParser.EOF);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public sqlStatements(): SqlStatementsContext {
        let localContext = new SqlStatementsContext(this.context, this.state);
        this.enterRule(localContext, 2, SparkSQLParser.RULE_sqlStatements);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 461;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 248 || ((((_la - 281)) & ~0x1F) === 0 && ((1 << (_la - 281)) & 1073745921) !== 0) || _la === 398 || ((((_la - 449)) & ~0x1F) === 0 && ((1 << (_la - 449)) & 276824065) !== 0)) {
                {
                this.state = 459;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 0, this.context) ) {
                case 1:
                    {
                    this.state = 457;
                    this.sqlStatement();
                    }
                    break;
                case 2:
                    {
                    this.state = 458;
                    this.emptyStatement();
                    }
                    break;
                }
                }
                this.state = 463;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public sqlStatement(): SqlStatementContext {
        let localContext = new SqlStatementContext(this.context, this.state);
        this.enterRule(localContext, 4, SparkSQLParser.RULE_sqlStatement);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 466;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.KW_EXECUTE:
            case SparkSQLParser.KW_FROM:
            case SparkSQLParser.KW_INSERT:
            case SparkSQLParser.KW_SELECT:
            case SparkSQLParser.KW_WITH:
            case SparkSQLParser.LR_BRACKET:
            case SparkSQLParser.SEMICOLON:
                {
                this.state = 464;
                this.dmlStatement();
                }
                break;
            case SparkSQLParser.KW_CREATE:
                {
                this.state = 465;
                this.createStatement();
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
            this.state = 468;
            this.match(SparkSQLParser.SEMICOLON);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public emptyStatement(): EmptyStatementContext {
        let localContext = new EmptyStatementContext(this.context, this.state);
        this.enterRule(localContext, 6, SparkSQLParser.RULE_emptyStatement);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 470;
            this.match(SparkSQLParser.SEMICOLON);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public createStatement(): CreateStatementContext {
        let localContext = new CreateStatementContext(this.context, this.state);
        this.enterRule(localContext, 8, SparkSQLParser.RULE_createStatement);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 472;
            this.createTable();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public dmlStatement(): DmlStatementContext {
        let localContext = new DmlStatementContext(this.context, this.state);
        this.enterRule(localContext, 10, SparkSQLParser.RULE_dmlStatement);
        try {
            this.state = 476;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.KW_FROM:
            case SparkSQLParser.KW_SELECT:
            case SparkSQLParser.KW_WITH:
            case SparkSQLParser.LR_BRACKET:
            case SparkSQLParser.SEMICOLON:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 474;
                this.queryStatement(0);
                }
                break;
            case SparkSQLParser.KW_EXECUTE:
            case SparkSQLParser.KW_INSERT:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 475;
                this.insertStatement();
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public createTable(): CreateTableContext {
        let localContext = new CreateTableContext(this.context, this.state);
        this.enterRule(localContext, 12, SparkSQLParser.RULE_createTable);
        try {
            this.state = 484;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 4, this.context) ) {
            case 1:
                localContext = new SimpleContext(localContext);
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 478;
                this.simpleCreateTable();
                }
                break;
            case 2:
                localContext = new AsSelectContext(localContext);
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 479;
                this.createTableAsSelect();
                }
                break;
            case 3:
                localContext = new MaterializedContext(localContext);
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 480;
                this.createMaterializedTableAsSelect();
                }
                break;
            case 4:
                localContext = new CustomSerdeContext(localContext);
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 481;
                this.createCustomSerde();
                }
                break;
            case 5:
                localContext = new CustomSerdeExternalContext(localContext);
                this.enterOuterAlt(localContext, 5);
                {
                this.state = 482;
                this.createCustomSerdeExternal();
                }
                break;
            case 6:
                localContext = new Using_createContext(localContext);
                this.enterOuterAlt(localContext, 6);
                {
                this.state = 483;
                this.usingCreate();
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public simpleCreateTable(): SimpleCreateTableContext {
        let localContext = new SimpleCreateTableContext(this.context, this.state);
        this.enterRule(localContext, 14, SparkSQLParser.RULE_simpleCreateTable);
        let _la: number;
        try {
            let alternative: number;
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 486;
            this.match(SparkSQLParser.KW_CREATE);
            this.state = 488;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 169) {
                {
                this.state = 487;
                this.match(SparkSQLParser.KW_TEMPORARY);
                }
            }

            this.state = 490;
            this.match(SparkSQLParser.KW_TABLE);
            this.state = 492;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 6, this.context) ) {
            case 1:
                {
                this.state = 491;
                this.ifNotExists();
                }
                break;
            }
            this.state = 494;
            this.tablePathCreate();
            this.state = 498;
            this.errorHandler.sync(this);
            alternative = this.interpreter.adaptivePredict(this.tokenStream, 7, this.context);
            while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {
                if (alternative === 1) {
                    {
                    {
                    this.state = 495;
                    this.simpleCreateTableNoSortElement();
                    }
                    }
                }
                this.state = 500;
                this.errorHandler.sync(this);
                alternative = this.interpreter.adaptivePredict(this.tokenStream, 7, this.context);
            }
            this.state = 504;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.LR_BRACKET:
                {
                this.state = 501;
                this.columnsBody();
                }
                break;
            case SparkSQLParser.KW_LIKE:
                {
                {
                this.state = 502;
                this.match(SparkSQLParser.KW_LIKE);
                this.state = 503;
                this.tablePath();
                }
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
            this.state = 509;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 87 || _la === 108 || _la === 235 || _la === 236 || ((((_la - 270)) & ~0x1F) === 0 && ((1 << (_la - 270)) & 538968067) !== 0) || ((((_la - 316)) & ~0x1F) === 0 && ((1 << (_la - 316)) & 98305) !== 0) || _la === 354 || ((((_la - 395)) & ~0x1F) === 0 && ((1 << (_la - 395)) & 16778753) !== 0) || _la === 441 || _la === 449) {
                {
                {
                this.state = 506;
                this.simpleCreateTableNoSortElement();
                }
                }
                this.state = 511;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public simpleCreateTableNoSortElement(): SimpleCreateTableNoSortElementContext {
        let localContext = new SimpleCreateTableNoSortElementContext(this.context, this.state);
        this.enterRule(localContext, 16, SparkSQLParser.RULE_simpleCreateTableNoSortElement);
        try {
            this.state = 526;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 10, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 512;
                this.partitionDefinition();
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 513;
                this.withOption();
                }
                break;
            case 3:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 514;
                this.likeDefinition();
                }
                break;
            case 4:
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 515;
                this.distribution();
                }
                break;
            case 5:
                this.enterOuterAlt(localContext, 5);
                {
                this.state = 516;
                this.someByClause();
                }
                break;
            case 6:
                this.enterOuterAlt(localContext, 6);
                {
                this.state = 517;
                this.intoBuckets();
                }
                break;
            case 7:
                this.enterOuterAlt(localContext, 7);
                {
                this.state = 518;
                this.storedAs();
                }
                break;
            case 8:
                this.enterOuterAlt(localContext, 8);
                {
                this.state = 519;
                this.hiveFormatpartitionDefinition();
                }
                break;
            case 9:
                this.enterOuterAlt(localContext, 9);
                {
                this.state = 520;
                this.sortedBy();
                }
                break;
            case 10:
                this.enterOuterAlt(localContext, 10);
                {
                this.state = 521;
                this.rowFormatDelimited();
                }
                break;
            case 11:
                this.enterOuterAlt(localContext, 11);
                {
                this.state = 522;
                this.fieldsTerminatedBy();
                }
                break;
            case 12:
                this.enterOuterAlt(localContext, 12);
                {
                this.state = 523;
                this.using();
                }
                break;
            case 13:
                this.enterOuterAlt(localContext, 13);
                {
                this.state = 524;
                this.location();
                }
                break;
            case 14:
                this.enterOuterAlt(localContext, 14);
                {
                this.state = 525;
                this.tblProperties();
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public location(): LocationContext {
        let localContext = new LocationContext(this.context, this.state);
        this.enterRule(localContext, 18, SparkSQLParser.RULE_location);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 528;
            this.match(SparkSQLParser.KW_LOCATION);
            this.state = 529;
            this.filePath();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public sortedBy(): SortedByContext {
        let localContext = new SortedByContext(this.context, this.state);
        this.enterRule(localContext, 20, SparkSQLParser.RULE_sortedBy);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 531;
            this.match(SparkSQLParser.KW_SORTED);
            this.state = 532;
            this.match(SparkSQLParser.KW_BY);
            this.state = 533;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 534;
            this.identifier();
            this.state = 536;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 8 || _la === 35) {
                {
                this.state = 535;
                _la = this.tokenStream.LA(1);
                if(!(_la === 8 || _la === 35)) {
                this.errorHandler.recoverInline(this);
                }
                else {
                    this.errorHandler.reportMatch(this);
                    this.consume();
                }
                }
            }

            this.state = 538;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public usingCreate(): UsingCreateContext {
        let localContext = new UsingCreateContext(this.context, this.state);
        this.enterRule(localContext, 22, SparkSQLParser.RULE_usingCreate);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 540;
            this.match(SparkSQLParser.KW_CREATE);
            this.state = 541;
            this.match(SparkSQLParser.KW_TABLE);
            this.state = 543;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 12, this.context) ) {
            case 1:
                {
                this.state = 542;
                this.ifNotExists();
                }
                break;
            }
            this.state = 545;
            this.tablePathCreate();
            this.state = 549;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 13, this.context) ) {
            case 1:
                {
                this.state = 546;
                this.columnUsing();
                }
                break;
            case 2:
                {
                this.state = 547;
                this.usingByQuery();
                }
                break;
            case 3:
                {
                this.state = 548;
                this.defaultColumnUsing();
                }
                break;
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public tblProperties(): TblPropertiesContext {
        let localContext = new TblPropertiesContext(this.context, this.state);
        this.enterRule(localContext, 24, SparkSQLParser.RULE_tblProperties);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 551;
            this.match(SparkSQLParser.KW_TBLPROPERTIES);
            this.state = 552;
            this.tablePropertyList();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public defaultColumnUsing(): DefaultColumnUsingContext {
        let localContext = new DefaultColumnUsingContext(this.context, this.state);
        this.enterRule(localContext, 26, SparkSQLParser.RULE_defaultColumnUsing);
        let _la: number;
        try {
            let alternative: number;
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 554;
            this.using();
            this.state = 558;
            this.errorHandler.sync(this);
            alternative = this.interpreter.adaptivePredict(this.tokenStream, 14, this.context);
            while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {
                if (alternative === 1) {
                    {
                    {
                    this.state = 555;
                    this.defaultColumnUsingNoSortElement();
                    }
                    }
                }
                this.state = 560;
                this.errorHandler.sync(this);
                alternative = this.interpreter.adaptivePredict(this.tokenStream, 14, this.context);
            }
            {
            this.state = 562;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 209) {
                {
                this.state = 561;
                this.match(SparkSQLParser.KW_AS);
                }
            }

            this.state = 564;
            this.queryStatement(0);
            }
            this.state = 569;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 21 || _la === 103 || _la === 108 || _la === 235 || _la === 236 || _la === 271 || _la === 299 || _la === 316 || _la === 419 || _la === 449) {
                {
                {
                this.state = 566;
                this.defaultColumnUsingNoSortElement();
                }
                }
                this.state = 571;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public defaultColumnUsingNoSortElement(): DefaultColumnUsingNoSortElementContext {
        let localContext = new DefaultColumnUsingNoSortElementContext(this.context, this.state);
        this.enterRule(localContext, 28, SparkSQLParser.RULE_defaultColumnUsingNoSortElement);
        try {
            this.state = 585;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.KW_PARTITIONED:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 572;
                this.partitionDefinition();
                }
                break;
            case SparkSQLParser.KW_OPTIONS:
                this.enterOuterAlt(localContext, 2);
                {
                {
                this.state = 573;
                this.match(SparkSQLParser.KW_OPTIONS);
                this.state = 574;
                this.tablePropertyList();
                }
                }
                break;
            case SparkSQLParser.KW_TBLPROPERTIES:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 575;
                this.tblProperties();
                }
                break;
            case SparkSQLParser.KW_CLUSTER:
            case SparkSQLParser.KW_CLUSTERED:
            case SparkSQLParser.KW_DISTRIBUTE:
            case SparkSQLParser.KW_GROUP:
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 576;
                this.someByClause();
                }
                break;
            case SparkSQLParser.KW_INTO:
                this.enterOuterAlt(localContext, 5);
                {
                this.state = 577;
                this.intoBuckets();
                }
                break;
            case SparkSQLParser.KW_WITH:
                this.enterOuterAlt(localContext, 6);
                {
                {
                this.state = 578;
                this.match(SparkSQLParser.KW_WITH);
                this.state = 579;
                this.tableAlias();
                this.state = 580;
                this.match(SparkSQLParser.LB_BRACKET);
                this.state = 581;
                this.queryStatement(0);
                this.state = 582;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                }
                break;
            case SparkSQLParser.KW_COMMENT:
                this.enterOuterAlt(localContext, 7);
                {
                this.state = 584;
                this.commentSpec();
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public columnUsing(): ColumnUsingContext {
        let localContext = new ColumnUsingContext(this.context, this.state);
        this.enterRule(localContext, 30, SparkSQLParser.RULE_columnUsing);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            {
            this.state = 587;
            this.columnsBody();
            this.state = 588;
            this.using();
            }
            this.state = 593;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 21 || _la === 103 || _la === 108 || _la === 235 || _la === 236 || _la === 271 || _la === 299 || _la === 316 || _la === 419) {
                {
                {
                this.state = 590;
                this.columnUsingNoSortElement();
                }
                }
                this.state = 595;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public columnUsingNoSortElement(): ColumnUsingNoSortElementContext {
        let localContext = new ColumnUsingNoSortElementContext(this.context, this.state);
        this.enterRule(localContext, 32, SparkSQLParser.RULE_columnUsingNoSortElement);
        try {
            this.state = 603;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.KW_PARTITIONED:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 596;
                this.partitionDefinition();
                }
                break;
            case SparkSQLParser.KW_OPTIONS:
                this.enterOuterAlt(localContext, 2);
                {
                {
                this.state = 597;
                this.match(SparkSQLParser.KW_OPTIONS);
                this.state = 598;
                this.tablePropertyList();
                }
                }
                break;
            case SparkSQLParser.KW_TBLPROPERTIES:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 599;
                this.tblProperties();
                }
                break;
            case SparkSQLParser.KW_CLUSTER:
            case SparkSQLParser.KW_CLUSTERED:
            case SparkSQLParser.KW_DISTRIBUTE:
            case SparkSQLParser.KW_GROUP:
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 600;
                this.someByClause();
                }
                break;
            case SparkSQLParser.KW_INTO:
                this.enterOuterAlt(localContext, 5);
                {
                this.state = 601;
                this.intoBuckets();
                }
                break;
            case SparkSQLParser.KW_COMMENT:
                this.enterOuterAlt(localContext, 6);
                {
                this.state = 602;
                this.commentSpec();
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public usingByQuery(): UsingByQueryContext {
        let localContext = new UsingByQueryContext(this.context, this.state);
        this.enterRule(localContext, 34, SparkSQLParser.RULE_usingByQuery);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            {
            this.state = 605;
            this.using();
            this.state = 606;
            this.match(SparkSQLParser.KW_AS);
            this.state = 607;
            this.queryStatement(0);
            }
            this.state = 612;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 21 || _la === 103 || _la === 108 || _la === 235 || _la === 236 || _la === 271 || _la === 299 || _la === 316 || _la === 419) {
                {
                {
                this.state = 609;
                this.usingByQueryNoSortElement();
                }
                }
                this.state = 614;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public usingByQueryNoSortElement(): UsingByQueryNoSortElementContext {
        let localContext = new UsingByQueryNoSortElementContext(this.context, this.state);
        this.enterRule(localContext, 36, SparkSQLParser.RULE_usingByQueryNoSortElement);
        try {
            this.state = 622;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.KW_PARTITIONED:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 615;
                this.partitionDefinition();
                }
                break;
            case SparkSQLParser.KW_OPTIONS:
                this.enterOuterAlt(localContext, 2);
                {
                {
                this.state = 616;
                this.match(SparkSQLParser.KW_OPTIONS);
                this.state = 617;
                this.tablePropertyList();
                }
                }
                break;
            case SparkSQLParser.KW_TBLPROPERTIES:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 618;
                this.tblProperties();
                }
                break;
            case SparkSQLParser.KW_CLUSTER:
            case SparkSQLParser.KW_CLUSTERED:
            case SparkSQLParser.KW_DISTRIBUTE:
            case SparkSQLParser.KW_GROUP:
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 619;
                this.someByClause();
                }
                break;
            case SparkSQLParser.KW_INTO:
                this.enterOuterAlt(localContext, 5);
                {
                this.state = 620;
                this.intoBuckets();
                }
                break;
            case SparkSQLParser.KW_COMMENT:
                this.enterOuterAlt(localContext, 6);
                {
                this.state = 621;
                this.commentSpec();
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public intoBuckets(): IntoBucketsContext {
        let localContext = new IntoBucketsContext(this.context, this.state);
        this.enterRule(localContext, 38, SparkSQLParser.RULE_intoBuckets);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 624;
            this.match(SparkSQLParser.KW_INTO);
            this.state = 625;
            this.match(SparkSQLParser.DIG_LITERAL);
            this.state = 626;
            this.match(SparkSQLParser.KW_BUCKETS);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public hiveFormatpartitionDefinition(): HiveFormatpartitionDefinitionContext {
        let localContext = new HiveFormatpartitionDefinitionContext(this.context, this.state);
        this.enterRule(localContext, 40, SparkSQLParser.RULE_hiveFormatpartitionDefinition);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 628;
            this.match(SparkSQLParser.KW_PARTITIONED);
            this.state = 629;
            this.match(SparkSQLParser.KW_BY);
            this.state = 630;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 631;
            this.match(SparkSQLParser.ID_LITERAL);
            this.state = 633;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 10 || _la === 88 || _la === 131 || _la === 154 || _la === 172 || _la === 173 || _la === 215 || _la === 219 || ((((_la - 256)) & ~0x1F) === 0 && ((1 << (_la - 256)) & 65553) !== 0) || ((((_la - 290)) & ~0x1F) === 0 && ((1 << (_la - 290)) & 12582913) !== 0) || _la === 355 || ((((_la - 406)) & ~0x1F) === 0 && ((1 << (_la - 406)) & 4587521) !== 0)) {
                {
                this.state = 632;
                this.sqlSimpleType();
                }
            }

            this.state = 642;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 476) {
                {
                {
                this.state = 635;
                this.match(SparkSQLParser.COMMA);
                this.state = 636;
                this.match(SparkSQLParser.ID_LITERAL);
                this.state = 638;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 10 || _la === 88 || _la === 131 || _la === 154 || _la === 172 || _la === 173 || _la === 215 || _la === 219 || ((((_la - 256)) & ~0x1F) === 0 && ((1 << (_la - 256)) & 65553) !== 0) || ((((_la - 290)) & ~0x1F) === 0 && ((1 << (_la - 290)) & 12582913) !== 0) || _la === 355 || ((((_la - 406)) & ~0x1F) === 0 && ((1 << (_la - 406)) & 4587521) !== 0)) {
                    {
                    this.state = 637;
                    this.sqlSimpleType();
                    }
                }

                }
                }
                this.state = 644;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 645;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public rowFormatSerde(): RowFormatSerdeContext {
        let localContext = new RowFormatSerdeContext(this.context, this.state);
        this.enterRule(localContext, 42, SparkSQLParser.RULE_rowFormatSerde);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 647;
            this.match(SparkSQLParser.KW_ROW);
            this.state = 648;
            this.match(SparkSQLParser.KW_FORMAT);
            this.state = 649;
            this.match(SparkSQLParser.KW_SERDE);
            this.state = 650;
            this.stringLiteral();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public fieldsTerminatedBy(): FieldsTerminatedByContext {
        let localContext = new FieldsTerminatedByContext(this.context, this.state);
        this.enterRule(localContext, 44, SparkSQLParser.RULE_fieldsTerminatedBy);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 652;
            this.match(SparkSQLParser.KW_FIELDS);
            this.state = 653;
            this.match(SparkSQLParser.KW_TERMINATED);
            this.state = 654;
            this.match(SparkSQLParser.KW_BY);
            this.state = 655;
            this.stringLiteral();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public storedAs(): StoredAsContext {
        let localContext = new StoredAsContext(this.context, this.state);
        this.enterRule(localContext, 46, SparkSQLParser.RULE_storedAs);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 657;
            this.match(SparkSQLParser.KW_STORED);
            this.state = 658;
            this.match(SparkSQLParser.KW_AS);
            this.state = 660;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 25, this.context) ) {
            case 1:
                {
                this.state = 659;
                this.identifier();
                }
                break;
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public storedAsInputformat(): StoredAsInputformatContext {
        let localContext = new StoredAsInputformatContext(this.context, this.state);
        this.enterRule(localContext, 48, SparkSQLParser.RULE_storedAsInputformat);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 662;
            this.match(SparkSQLParser.KW_STORED);
            this.state = 663;
            this.match(SparkSQLParser.KW_AS);
            this.state = 664;
            this.match(SparkSQLParser.KW_INPUTFORMAT);
            this.state = 666;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if ((((_la) & ~0x1F) === 0 && ((1 << _la) & 4294896624) !== 0) || ((((_la - 33)) & ~0x1F) === 0 && ((1 << (_la - 33)) & 4294803199) !== 0) || ((((_la - 65)) & ~0x1F) === 0 && ((1 << (_la - 65)) & 4281327607) !== 0) || ((((_la - 97)) & ~0x1F) === 0 && ((1 << (_la - 97)) & 2147483643) !== 0) || ((((_la - 129)) & ~0x1F) === 0 && ((1 << (_la - 129)) & 2113863675) !== 0) || ((((_la - 161)) & ~0x1F) === 0 && ((1 << (_la - 161)) & 4292341757) !== 0) || ((((_la - 193)) & ~0x1F) === 0 && ((1 << (_la - 193)) & 247) !== 0) || _la === 335 || ((((_la - 479)) & ~0x1F) === 0 && ((1 << (_la - 479)) & 360449) !== 0)) {
                {
                this.state = 665;
                this.identifier();
                }
            }

            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public outputformat(): OutputformatContext {
        let localContext = new OutputformatContext(this.context, this.state);
        this.enterRule(localContext, 50, SparkSQLParser.RULE_outputformat);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 668;
            this.match(SparkSQLParser.KW_OUTPUTFORMAT);
            this.state = 670;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if ((((_la) & ~0x1F) === 0 && ((1 << _la) & 4294896624) !== 0) || ((((_la - 33)) & ~0x1F) === 0 && ((1 << (_la - 33)) & 4294803199) !== 0) || ((((_la - 65)) & ~0x1F) === 0 && ((1 << (_la - 65)) & 4281327607) !== 0) || ((((_la - 97)) & ~0x1F) === 0 && ((1 << (_la - 97)) & 2147483643) !== 0) || ((((_la - 129)) & ~0x1F) === 0 && ((1 << (_la - 129)) & 2113863675) !== 0) || ((((_la - 161)) & ~0x1F) === 0 && ((1 << (_la - 161)) & 4292341757) !== 0) || ((((_la - 193)) & ~0x1F) === 0 && ((1 << (_la - 193)) & 247) !== 0) || _la === 335 || ((((_la - 479)) & ~0x1F) === 0 && ((1 << (_la - 479)) & 360449) !== 0)) {
                {
                this.state = 669;
                this.identifier();
                }
            }

            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public rowFormatDelimted(): RowFormatDelimtedContext {
        let localContext = new RowFormatDelimtedContext(this.context, this.state);
        this.enterRule(localContext, 52, SparkSQLParser.RULE_rowFormatDelimted);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 672;
            this.match(SparkSQLParser.KW_ROW);
            this.state = 673;
            this.match(SparkSQLParser.KW_FORMAT);
            this.state = 674;
            this.match(SparkSQLParser.KW_DELIMITED);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public columnsBody(): ColumnsBodyContext {
        let localContext = new ColumnsBodyContext(this.context, this.state);
        this.enterRule(localContext, 54, SparkSQLParser.RULE_columnsBody);
        let _la: number;
        try {
            let alternative: number;
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 676;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 677;
            this.columnOptionDefinition();
            this.state = 679;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 21) {
                {
                this.state = 678;
                this.commentSpec();
                }
            }

            this.state = 688;
            this.errorHandler.sync(this);
            alternative = this.interpreter.adaptivePredict(this.tokenStream, 30, this.context);
            while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {
                if (alternative === 1) {
                    {
                    {
                    this.state = 681;
                    this.match(SparkSQLParser.COMMA);
                    this.state = 682;
                    this.columnOptionDefinition();
                    this.state = 684;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                    if (_la === 21) {
                        {
                        this.state = 683;
                        this.commentSpec();
                        }
                    }

                    }
                    }
                }
                this.state = 690;
                this.errorHandler.sync(this);
                alternative = this.interpreter.adaptivePredict(this.tokenStream, 30, this.context);
            }
            this.state = 696;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 32, this.context) ) {
            case 1:
                {
                this.state = 691;
                this.match(SparkSQLParser.COMMA);
                this.state = 692;
                this.watermarkDefinition();
                this.state = 694;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 21) {
                    {
                    this.state = 693;
                    this.commentSpec();
                    }
                }

                }
                break;
            }
            this.state = 703;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 34, this.context) ) {
            case 1:
                {
                this.state = 698;
                this.match(SparkSQLParser.COMMA);
                this.state = 699;
                this.tableConstraint();
                this.state = 701;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 21) {
                    {
                    this.state = 700;
                    this.commentSpec();
                    }
                }

                }
                break;
            }
            this.state = 710;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 476) {
                {
                this.state = 705;
                this.match(SparkSQLParser.COMMA);
                this.state = 706;
                this.selfDefinitionClause();
                this.state = 708;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 21) {
                    {
                    this.state = 707;
                    this.commentSpec();
                    }
                }

                }
            }

            this.state = 712;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public createCustomSerde(): CreateCustomSerdeContext {
        let localContext = new CreateCustomSerdeContext(this.context, this.state);
        this.enterRule(localContext, 56, SparkSQLParser.RULE_createCustomSerde);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 714;
            this.match(SparkSQLParser.KW_CREATE);
            this.state = 716;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 169) {
                {
                this.state = 715;
                this.match(SparkSQLParser.KW_TEMPORARY);
                }
            }

            this.state = 718;
            this.match(SparkSQLParser.KW_TABLE);
            this.state = 720;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 38, this.context) ) {
            case 1:
                {
                this.state = 719;
                this.ifNotExists();
                }
                break;
            }
            this.state = 722;
            this.tablePathCreate();
            this.state = 726;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 21 || _la === 108 || _la === 270 || _la === 331 || _la === 449 || _la === 472) {
                {
                {
                this.state = 723;
                this.createCustomSerdeNoSortElement();
                }
                }
                this.state = 728;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 729;
            this.match(SparkSQLParser.KW_ROW);
            this.state = 730;
            this.match(SparkSQLParser.KW_FORMAT);
            this.state = 731;
            this.match(SparkSQLParser.KW_SERDE);
            this.state = 732;
            this.tablePropertyKey();
            this.state = 736;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 21 || _la === 108 || _la === 270 || _la === 331 || _la === 449 || _la === 472) {
                {
                {
                this.state = 733;
                this.createCustomSerdeNoSortElement();
                }
                }
                this.state = 738;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 739;
            this.match(SparkSQLParser.KW_SORTED);
            this.state = 740;
            this.match(SparkSQLParser.KW_AS);
            this.state = 741;
            this.match(SparkSQLParser.KW_INPUTFORMAT);
            this.state = 742;
            this.tablePropertyKey();
            this.state = 746;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 21 || _la === 108 || _la === 270 || _la === 331 || _la === 449 || _la === 472) {
                {
                {
                this.state = 743;
                this.createCustomSerdeNoSortElement();
                }
                }
                this.state = 748;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 749;
            this.match(SparkSQLParser.KW_OUTPUTFORMAT);
            this.state = 750;
            this.tablePropertyKey();
            this.state = 754;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 21 || _la === 108 || _la === 270 || _la === 331 || _la === 449 || _la === 472) {
                {
                {
                this.state = 751;
                this.createCustomSerdeNoSortElement();
                }
                }
                this.state = 756;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 757;
            this.tblProperties();
            this.state = 761;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 21 || _la === 108 || _la === 270 || _la === 331 || _la === 449 || _la === 472) {
                {
                {
                this.state = 758;
                this.createCustomSerdeNoSortElement();
                }
                }
                this.state = 763;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public createCustomSerdeNoSortElement(): CreateCustomSerdeNoSortElementContext {
        let localContext = new CreateCustomSerdeNoSortElementContext(this.context, this.state);
        this.enterRule(localContext, 58, SparkSQLParser.RULE_createCustomSerdeNoSortElement);
        try {
            this.state = 770;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.LR_BRACKET:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 764;
                this.columnsBody();
                }
                break;
            case SparkSQLParser.KW_COMMENT:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 765;
                this.commentSpec();
                }
                break;
            case SparkSQLParser.KW_PARTITIONED:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 766;
                this.partitionDefinition();
                }
                break;
            case SparkSQLParser.KW_WITH:
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 767;
                this.withOption();
                }
                break;
            case SparkSQLParser.KW_LIKE:
                this.enterOuterAlt(localContext, 5);
                {
                this.state = 768;
                this.likeDefinition();
                }
                break;
            case SparkSQLParser.KW_DISTRIBUTED:
                this.enterOuterAlt(localContext, 6);
                {
                this.state = 769;
                this.distribution();
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public createCustomSerdeExternal(): CreateCustomSerdeExternalContext {
        let localContext = new CreateCustomSerdeExternalContext(this.context, this.state);
        this.enterRule(localContext, 60, SparkSQLParser.RULE_createCustomSerdeExternal);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 772;
            this.match(SparkSQLParser.KW_CREATE);
            this.state = 773;
            this.match(SparkSQLParser.KW_EXTERNAL);
            this.state = 774;
            this.match(SparkSQLParser.KW_TABLE);
            this.state = 776;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 45, this.context) ) {
            case 1:
                {
                this.state = 775;
                this.ifNotExists();
                }
                break;
            }
            this.state = 778;
            this.tablePathCreate();
            this.state = 782;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 21 || _la === 108 || _la === 270 || _la === 331 || _la === 419 || _la === 449) {
                {
                {
                this.state = 779;
                this.createCustomSerdeExternalNoSortElement();
                }
                }
                this.state = 784;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 785;
            this.columnsBody();
            this.state = 789;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 21 || _la === 108 || _la === 270 || _la === 331 || _la === 419 || _la === 449) {
                {
                {
                this.state = 786;
                this.createCustomSerdeExternalNoSortElement();
                }
                }
                this.state = 791;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 792;
            this.match(SparkSQLParser.KW_ROW);
            this.state = 793;
            this.match(SparkSQLParser.KW_FORMAT);
            this.state = 794;
            this.match(SparkSQLParser.KW_SERDE);
            this.state = 795;
            this.tablePropertyKey();
            this.state = 799;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 21 || _la === 108 || _la === 270 || _la === 331 || _la === 419 || _la === 449) {
                {
                {
                this.state = 796;
                this.createCustomSerdeExternalNoSortElement();
                }
                }
                this.state = 801;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 802;
            this.match(SparkSQLParser.KW_SORTED);
            this.state = 803;
            this.match(SparkSQLParser.KW_AS);
            this.state = 804;
            this.match(SparkSQLParser.KW_INPUTFORMAT);
            this.state = 805;
            this.tablePropertyKey();
            this.state = 809;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 21 || _la === 108 || _la === 270 || _la === 331 || _la === 419 || _la === 449) {
                {
                {
                this.state = 806;
                this.createCustomSerdeExternalNoSortElement();
                }
                }
                this.state = 811;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 812;
            this.match(SparkSQLParser.KW_OUTPUTFORMAT);
            this.state = 813;
            this.tablePropertyKey();
            this.state = 817;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 21 || _la === 108 || _la === 270 || _la === 331 || _la === 419 || _la === 449) {
                {
                {
                this.state = 814;
                this.createCustomSerdeExternalNoSortElement();
                }
                }
                this.state = 819;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 820;
            this.match(SparkSQLParser.KW_LOCATION);
            this.state = 821;
            this.filePath();
            this.state = 825;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 21 || _la === 108 || _la === 270 || _la === 331 || _la === 419 || _la === 449) {
                {
                {
                this.state = 822;
                this.createCustomSerdeExternalNoSortElement();
                }
                }
                this.state = 827;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public createCustomSerdeExternalNoSortElement(): CreateCustomSerdeExternalNoSortElementContext {
        let localContext = new CreateCustomSerdeExternalNoSortElementContext(this.context, this.state);
        this.enterRule(localContext, 62, SparkSQLParser.RULE_createCustomSerdeExternalNoSortElement);
        try {
            this.state = 834;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.KW_COMMENT:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 828;
                this.commentSpec();
                }
                break;
            case SparkSQLParser.KW_PARTITIONED:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 829;
                this.partitionDefinition();
                }
                break;
            case SparkSQLParser.KW_WITH:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 830;
                this.withOption();
                }
                break;
            case SparkSQLParser.KW_LIKE:
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 831;
                this.likeDefinition();
                }
                break;
            case SparkSQLParser.KW_DISTRIBUTED:
                this.enterOuterAlt(localContext, 5);
                {
                this.state = 832;
                this.distribution();
                }
                break;
            case SparkSQLParser.KW_TBLPROPERTIES:
                this.enterOuterAlt(localContext, 6);
                {
                this.state = 833;
                this.tblProperties();
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public createTableAsSelect(): CreateTableAsSelectContext {
        let localContext = new CreateTableAsSelectContext(this.context, this.state);
        this.enterRule(localContext, 64, SparkSQLParser.RULE_createTableAsSelect);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 836;
            this.match(SparkSQLParser.KW_CREATE);
            this.state = 837;
            this.match(SparkSQLParser.KW_TABLE);
            this.state = 839;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 53, this.context) ) {
            case 1:
                {
                this.state = 838;
                this.ifNotExists();
                }
                break;
            }
            this.state = 841;
            this.tablePathCreate();
            this.state = 842;
            this.withOption();
            this.state = 845;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 209) {
                {
                this.state = 843;
                this.match(SparkSQLParser.KW_AS);
                this.state = 844;
                this.queryStatement(0);
                }
            }

            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public createMaterializedTableAsSelect(): CreateMaterializedTableAsSelectContext {
        let localContext = new CreateMaterializedTableAsSelectContext(this.context, this.state);
        this.enterRule(localContext, 66, SparkSQLParser.RULE_createMaterializedTableAsSelect);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 847;
            this.match(SparkSQLParser.KW_CREATE);
            this.state = 848;
            this.match(SparkSQLParser.KW_MATERIALIZED);
            this.state = 849;
            this.match(SparkSQLParser.KW_TABLE);
            this.state = 850;
            this.tablePathCreate();
            this.state = 854;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 108 || _la === 209 || _la === 449 || _la === 455) {
                {
                {
                this.state = 851;
                this.createMaterializedTableAsSelectNoSortElement();
                }
                }
                this.state = 856;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 857;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 858;
            this.match(SparkSQLParser.KW_PRIMARY);
            this.state = 859;
            this.match(SparkSQLParser.KW_KEY);
            this.state = 860;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 861;
            this.identifier();
            this.state = 866;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 476) {
                {
                {
                this.state = 862;
                this.match(SparkSQLParser.COMMA);
                this.state = 863;
                this.identifier();
                }
                }
                this.state = 868;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 869;
            this.match(SparkSQLParser.RR_BRACKET);
            this.state = 872;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 351) {
                {
                this.state = 870;
                this.match(SparkSQLParser.KW_NOT);
                this.state = 871;
                this.match(SparkSQLParser.KW_ENFORCED);
                }
            }

            this.state = 874;
            this.match(SparkSQLParser.RR_BRACKET);
            this.state = 878;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 108 || _la === 209 || _la === 449 || _la === 455) {
                {
                {
                this.state = 875;
                this.createMaterializedTableAsSelectNoSortElement();
                }
                }
                this.state = 880;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            {
            this.state = 881;
            this.match(SparkSQLParser.KW_FRESHNESS);
            this.state = 882;
            this.match(SparkSQLParser.EQUAL_SYMBOL);
            this.state = 883;
            this.match(SparkSQLParser.KW_INTERVAL);
            this.state = 884;
            this.identifier();
            this.state = 885;
            _la = this.tokenStream.LA(1);
            if(!(_la === 258 || _la === 304 || _la === 342 || _la === 397)) {
            this.errorHandler.recoverInline(this);
            }
            else {
                this.errorHandler.reportMatch(this);
                this.consume();
            }
            }
            this.state = 890;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 108 || _la === 209 || _la === 449 || _la === 455) {
                {
                {
                this.state = 887;
                this.createMaterializedTableAsSelectNoSortElement();
                }
                }
                this.state = 892;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public createMaterializedTableAsSelectNoSortElement(): CreateMaterializedTableAsSelectNoSortElementContext {
        let localContext = new CreateMaterializedTableAsSelectNoSortElementContext(this.context, this.state);
        this.enterRule(localContext, 68, SparkSQLParser.RULE_createMaterializedTableAsSelectNoSortElement);
        let _la: number;
        try {
            this.state = 900;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.KW_PARTITIONED:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 893;
                this.partitionDefinition();
                }
                break;
            case SparkSQLParser.KW_WITH:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 894;
                this.withOption();
                }
                break;
            case SparkSQLParser.KW_REFRESH_MODE:
                this.enterOuterAlt(localContext, 3);
                {
                {
                this.state = 895;
                this.match(SparkSQLParser.KW_REFRESH_MODE);
                this.state = 896;
                this.match(SparkSQLParser.EQUAL_SYMBOL);
                this.state = 897;
                _la = this.tokenStream.LA(1);
                if(!(_la === 295 || _la === 457)) {
                this.errorHandler.recoverInline(this);
                }
                else {
                    this.errorHandler.reportMatch(this);
                    this.consume();
                }
                }
                }
                break;
            case SparkSQLParser.KW_AS:
                this.enterOuterAlt(localContext, 4);
                {
                {
                this.state = 898;
                this.match(SparkSQLParser.KW_AS);
                this.state = 899;
                this.queryStatement(0);
                }
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public usingClause(): UsingClauseContext {
        let localContext = new UsingClauseContext(this.context, this.state);
        this.enterRule(localContext, 70, SparkSQLParser.RULE_usingClause);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 902;
            this.match(SparkSQLParser.KW_USING);
            this.state = 903;
            this.match(SparkSQLParser.KW_JAR);
            this.state = 904;
            this.jarFileName();
            this.state = 910;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 476) {
                {
                {
                this.state = 905;
                this.match(SparkSQLParser.COMMA);
                this.state = 906;
                this.match(SparkSQLParser.KW_JAR);
                this.state = 907;
                this.jarFileName();
                }
                }
                this.state = 912;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public jarFileName(): JarFileNameContext {
        let localContext = new JarFileNameContext(this.context, this.state);
        this.enterRule(localContext, 72, SparkSQLParser.RULE_jarFileName);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 913;
            this.filePath();
            this.state = 916;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 469) {
                {
                this.state = 914;
                this.match(SparkSQLParser.DOT);
                this.state = 915;
                this.match(SparkSQLParser.KW_JAR);
                }
            }

            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public filePath(): FilePathContext {
        let localContext = new FilePathContext(this.context, this.state);
        this.enterRule(localContext, 74, SparkSQLParser.RULE_filePath);
        let _la: number;
        try {
            this.state = 927;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.STRING_LITERAL:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 918;
                this.match(SparkSQLParser.STRING_LITERAL);
                }
                break;
            case SparkSQLParser.SLASH_SIGN:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 923;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                do {
                    {
                    {
                    this.state = 919;
                    this.match(SparkSQLParser.SLASH_SIGN);
                    this.state = 921;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                    if (_la === 497) {
                        {
                        this.state = 920;
                        this.match(SparkSQLParser.ID_LITERAL);
                        }
                    }

                    }
                    }
                    this.state = 925;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                } while (_la === 491);
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public ifExistsPart(): IfExistsPartContext {
        let localContext = new IfExistsPartContext(this.context, this.state);
        this.enterRule(localContext, 76, SparkSQLParser.RULE_ifExistsPart);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 929;
            this.match(SparkSQLParser.KW_IF);
            this.state = 931;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 351) {
                {
                this.state = 930;
                this.match(SparkSQLParser.KW_NOT);
                }
            }

            this.state = 933;
            this.match(SparkSQLParser.KW_EXISTS);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public columnPosition(): ColumnPositionContext {
        let localContext = new ColumnPositionContext(this.context, this.state);
        this.enterRule(localContext, 78, SparkSQLParser.RULE_columnPosition);
        let _la: number;
        try {
            this.state = 938;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.KW_FIRST:
            case SparkSQLParser.KW_LAST:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 935;
                _la = this.tokenStream.LA(1);
                if(!(_la === 52 || _la === 82)) {
                this.errorHandler.recoverInline(this);
                }
                else {
                    this.errorHandler.reportMatch(this);
                    this.consume();
                }
                }
                break;
            case SparkSQLParser.KW_AFTER:
            case SparkSQLParser.KW_BEFORE:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 936;
                _la = this.tokenStream.LA(1);
                if(!(_la === 6 || _la === 9)) {
                this.errorHandler.recoverInline(this);
                }
                else {
                    this.errorHandler.reportMatch(this);
                    this.consume();
                }
                this.state = 937;
                this.uid();
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public renameDefinition(): RenameDefinitionContext {
        let localContext = new RenameDefinitionContext(this.context, this.state);
        this.enterRule(localContext, 80, SparkSQLParser.RULE_renameDefinition);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 940;
            this.match(SparkSQLParser.KW_RENAME);
            this.state = 942;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if ((((_la) & ~0x1F) === 0 && ((1 << _la) & 4294896624) !== 0) || ((((_la - 33)) & ~0x1F) === 0 && ((1 << (_la - 33)) & 4294803199) !== 0) || ((((_la - 65)) & ~0x1F) === 0 && ((1 << (_la - 65)) & 4281327607) !== 0) || ((((_la - 97)) & ~0x1F) === 0 && ((1 << (_la - 97)) & 2147483643) !== 0) || ((((_la - 129)) & ~0x1F) === 0 && ((1 << (_la - 129)) & 2113863675) !== 0) || ((((_la - 161)) & ~0x1F) === 0 && ((1 << (_la - 161)) & 4292341757) !== 0) || ((((_la - 193)) & ~0x1F) === 0 && ((1 << (_la - 193)) & 247) !== 0) || _la === 335 || ((((_la - 479)) & ~0x1F) === 0 && ((1 << (_la - 479)) & 360449) !== 0)) {
                {
                this.state = 941;
                this.uid();
                }
            }

            this.state = 944;
            this.match(SparkSQLParser.KW_TO);
            this.state = 945;
            this.uid();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public setKeyValueDefinition(): SetKeyValueDefinitionContext {
        let localContext = new SetKeyValueDefinitionContext(this.context, this.state);
        this.enterRule(localContext, 82, SparkSQLParser.RULE_setKeyValueDefinition);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 947;
            this.match(SparkSQLParser.KW_SET);
            this.state = 948;
            this.tablePropertyList();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public addConstraint(): AddConstraintContext {
        let localContext = new AddConstraintContext(this.context, this.state);
        this.enterRule(localContext, 84, SparkSQLParser.RULE_addConstraint);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 950;
            this.match(SparkSQLParser.KW_ADD);
            this.state = 951;
            this.match(SparkSQLParser.KW_CONSTRAINT);
            this.state = 952;
            this.constraintName();
            this.state = 953;
            this.match(SparkSQLParser.KW_PRIMARY);
            this.state = 954;
            this.match(SparkSQLParser.KW_KEY);
            this.state = 955;
            this.columnNameList();
            this.state = 957;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 351) {
                {
                this.state = 956;
                this.notForced();
                }
            }

            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public dropConstraint(): DropConstraintContext {
        let localContext = new DropConstraintContext(this.context, this.state);
        this.enterRule(localContext, 86, SparkSQLParser.RULE_dropConstraint);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 959;
            this.match(SparkSQLParser.KW_DROP);
            this.state = 960;
            this.match(SparkSQLParser.KW_CONSTRAINT);
            this.state = 961;
            this.constraintName();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public addUnique(): AddUniqueContext {
        let localContext = new AddUniqueContext(this.context, this.state);
        this.enterRule(localContext, 88, SparkSQLParser.RULE_addUnique);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 963;
            this.match(SparkSQLParser.KW_ADD);
            this.state = 964;
            this.match(SparkSQLParser.KW_UNIQUE);
            this.state = 965;
            this.columnNameList();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public notForced(): NotForcedContext {
        let localContext = new NotForcedContext(this.context, this.state);
        this.enterRule(localContext, 90, SparkSQLParser.RULE_notForced);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 967;
            this.match(SparkSQLParser.KW_NOT);
            this.state = 968;
            this.match(SparkSQLParser.KW_ENFORCED);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public insertStatement(): InsertStatementContext {
        let localContext = new InsertStatementContext(this.context, this.state);
        this.enterRule(localContext, 92, SparkSQLParser.RULE_insertStatement);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 971;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 281) {
                {
                this.state = 970;
                this.match(SparkSQLParser.KW_EXECUTE);
                }
            }

            this.state = 973;
            this.insertSimpleStatement();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public insertSimpleStatement(): InsertSimpleStatementContext {
        let localContext = new InsertSimpleStatementContext(this.context, this.state);
        this.enterRule(localContext, 94, SparkSQLParser.RULE_insertSimpleStatement);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 975;
            this.match(SparkSQLParser.KW_INSERT);
            this.state = 976;
            _la = this.tokenStream.LA(1);
            if(!(_la === 106 || _la === 316)) {
            this.errorHandler.recoverInline(this);
            }
            else {
                this.errorHandler.reportMatch(this);
                this.consume();
            }
            this.state = 978;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 418) {
                {
                this.state = 977;
                this.match(SparkSQLParser.KW_TABLE);
                }
            }

            this.state = 980;
            this.tablePath();
            this.state = 982;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 368) {
                {
                this.state = 981;
                this.insertPartitionDefinition();
                }
            }

            this.state = 985;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 73, this.context) ) {
            case 1:
                {
                this.state = 984;
                this.columnNameList();
                }
                break;
            }
            this.state = 995;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.KW_FROM:
            case SparkSQLParser.KW_SELECT:
            case SparkSQLParser.KW_WITH:
            case SparkSQLParser.LR_BRACKET:
            case SparkSQLParser.SEMICOLON:
                {
                this.state = 987;
                this.queryStatement(0);
                }
                break;
            case SparkSQLParser.KW_VALUES:
                {
                this.state = 988;
                this.valuesDefinition();
                }
                break;
            case SparkSQLParser.KW_REPLACE:
                {
                {
                this.state = 989;
                this.match(SparkSQLParser.KW_REPLACE);
                this.state = 990;
                this.whereClause();
                this.state = 991;
                this.selectStatement();
                }
                }
                break;
            case SparkSQLParser.KW_TABLE:
                {
                {
                this.state = 993;
                this.match(SparkSQLParser.KW_TABLE);
                this.state = 994;
                this.tablePath();
                }
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public insertPartitionDefinition(): InsertPartitionDefinitionContext {
        let localContext = new InsertPartitionDefinitionContext(this.context, this.state);
        this.enterRule(localContext, 96, SparkSQLParser.RULE_insertPartitionDefinition);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 997;
            this.match(SparkSQLParser.KW_PARTITION);
            this.state = 998;
            this.tablePropertyList();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }

    public queryStatement(): QueryStatementContext;
    public queryStatement(_p: number): QueryStatementContext;
    public queryStatement(_p?: number): QueryStatementContext {
        if (_p === undefined) {
            _p = 0;
        }

        let parentContext = this.context;
        let parentState = this.state;
        let localContext = new QueryStatementContext(this.context, parentState);
        let previousContext = localContext;
        let _startState = 98;
        this.enterRecursionRule(localContext, 98, SparkSQLParser.RULE_queryStatement, _p);
        let _la: number;
        try {
            let alternative: number;
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1024;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.KW_WITH:
                {
                this.state = 1001;
                this.withClause();
                this.state = 1002;
                this.queryStatement(4);
                }
                break;
            case SparkSQLParser.LR_BRACKET:
                {
                this.state = 1004;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 1005;
                this.queryStatement(0);
                this.state = 1006;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case SparkSQLParser.KW_FROM:
            case SparkSQLParser.KW_SELECT:
            case SparkSQLParser.SEMICOLON:
                {
                this.state = 1010;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 75, this.context) ) {
                case 1:
                    {
                    this.state = 1008;
                    this.selectClause();
                    }
                    break;
                case 2:
                    {
                    this.state = 1009;
                    this.selectStatement();
                    }
                    break;
                }
                this.state = 1013;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 76, this.context) ) {
                case 1:
                    {
                    this.state = 1012;
                    this.sortByCaluse();
                    }
                    break;
                }
                this.state = 1016;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 77, this.context) ) {
                case 1:
                    {
                    this.state = 1015;
                    this.orderByCaluse();
                    }
                    break;
                }
                this.state = 1019;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 78, this.context) ) {
                case 1:
                    {
                    this.state = 1018;
                    this.limitClause();
                    }
                    break;
                }
                this.state = 1022;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 79, this.context) ) {
                case 1:
                    {
                    this.state = 1021;
                    this.offsetClause();
                    }
                    break;
                }
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
            this.context!.stop = this.tokenStream.LT(-1);
            this.state = 1046;
            this.errorHandler.sync(this);
            alternative = this.interpreter.adaptivePredict(this.tokenStream, 86, this.context);
            while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {
                if (alternative === 1) {
                    if (this.parseListeners != null) {
                        this.triggerExitRuleEvent();
                    }
                    previousContext = localContext;
                    {
                    {
                    localContext = new QueryStatementContext(parentContext, parentState);
                    localContext._left = previousContext;
                    this.pushNewRecursionContext(localContext, _startState, SparkSQLParser.RULE_queryStatement);
                    this.state = 1026;
                    if (!(this.precpred(this.context, 2))) {
                        throw this.createFailedPredicateException("this.precpred(this.context, 2)");
                    }
                    this.state = 1027;
                    localContext._operator = this.tokenStream.LT(1);
                    _la = this.tokenStream.LA(1);
                    if(!(_la === 280 || _la === 314 || _la === 341 || _la === 433)) {
                        localContext._operator = this.errorHandler.recoverInline(this);
                    }
                    else {
                        this.errorHandler.reportMatch(this);
                        this.consume();
                    }
                    this.state = 1029;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                    if (_la === 202 || _la === 268) {
                        {
                        this.state = 1028;
                        _la = this.tokenStream.LA(1);
                        if(!(_la === 202 || _la === 268)) {
                        this.errorHandler.recoverInline(this);
                        }
                        else {
                            this.errorHandler.reportMatch(this);
                            this.consume();
                        }
                        }
                    }

                    this.state = 1031;
                    localContext._right = this.queryStatement(0);
                    this.state = 1033;
                    this.errorHandler.sync(this);
                    switch (this.interpreter.adaptivePredict(this.tokenStream, 82, this.context) ) {
                    case 1:
                        {
                        this.state = 1032;
                        this.sortByCaluse();
                        }
                        break;
                    }
                    this.state = 1036;
                    this.errorHandler.sync(this);
                    switch (this.interpreter.adaptivePredict(this.tokenStream, 83, this.context) ) {
                    case 1:
                        {
                        this.state = 1035;
                        this.orderByCaluse();
                        }
                        break;
                    }
                    this.state = 1039;
                    this.errorHandler.sync(this);
                    switch (this.interpreter.adaptivePredict(this.tokenStream, 84, this.context) ) {
                    case 1:
                        {
                        this.state = 1038;
                        this.limitClause();
                        }
                        break;
                    }
                    this.state = 1042;
                    this.errorHandler.sync(this);
                    switch (this.interpreter.adaptivePredict(this.tokenStream, 85, this.context) ) {
                    case 1:
                        {
                        this.state = 1041;
                        this.offsetClause();
                        }
                        break;
                    }
                    }
                    }
                }
                this.state = 1048;
                this.errorHandler.sync(this);
                alternative = this.interpreter.adaptivePredict(this.tokenStream, 86, this.context);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.unrollRecursionContexts(parentContext);
        }
        return localContext;
    }
    public withClause(): WithClauseContext {
        let localContext = new WithClauseContext(this.context, this.state);
        this.enterRule(localContext, 100, SparkSQLParser.RULE_withClause);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1049;
            this.match(SparkSQLParser.KW_WITH);
            this.state = 1050;
            this.withItem();
            this.state = 1055;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 476) {
                {
                {
                this.state = 1051;
                this.match(SparkSQLParser.COMMA);
                this.state = 1052;
                this.withItem();
                }
                }
                this.state = 1057;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public valuesCaluse(): ValuesCaluseContext {
        let localContext = new ValuesCaluseContext(this.context, this.state);
        this.enterRule(localContext, 102, SparkSQLParser.RULE_valuesCaluse);
        try {
            let alternative: number;
            this.enterOuterAlt(localContext, 1);
            {
            {
            this.state = 1058;
            this.match(SparkSQLParser.KW_VALUES);
            this.state = 1059;
            this.inlineBody();
            this.state = 1067;
            this.errorHandler.sync(this);
            alternative = this.interpreter.adaptivePredict(this.tokenStream, 89, this.context);
            while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {
                if (alternative === 1) {
                    {
                    {
                    this.state = 1062;
                    this.errorHandler.sync(this);
                    switch (this.tokenStream.LA(1)) {
                    case SparkSQLParser.COMMA:
                        {
                        this.state = 1060;
                        this.match(SparkSQLParser.COMMA);
                        }
                        break;
                    case SparkSQLParser.KW_ADD:
                    case SparkSQLParser.KW_ADMIN:
                    case SparkSQLParser.KW_AFTER:
                    case SparkSQLParser.KW_ANALYZE:
                    case SparkSQLParser.KW_ASC:
                    case SparkSQLParser.KW_BEFORE:
                    case SparkSQLParser.KW_BYTES:
                    case SparkSQLParser.KW_CASCADE:
                    case SparkSQLParser.KW_CATALOG:
                    case SparkSQLParser.KW_CATALOGS:
                    case SparkSQLParser.KW_CENTURY:
                    case SparkSQLParser.KW_CHAIN:
                    case SparkSQLParser.KW_CHANGELOG_MODE:
                    case SparkSQLParser.KW_CHARACTERS:
                    case SparkSQLParser.KW_COMMENT:
                    case SparkSQLParser.KW_COMPACT:
                    case SparkSQLParser.KW_COLUMNS:
                    case SparkSQLParser.KW_CONSTRAINTS:
                    case SparkSQLParser.KW_CONSTRUCTOR:
                    case SparkSQLParser.KW_COMPUTE:
                    case SparkSQLParser.KW_CUMULATE:
                    case SparkSQLParser.KW_DATA:
                    case SparkSQLParser.KW_DATABASE:
                    case SparkSQLParser.KW_DATABASES:
                    case SparkSQLParser.KW_DAYS:
                    case SparkSQLParser.KW_DECADE:
                    case SparkSQLParser.KW_DEFINED:
                    case SparkSQLParser.KW_DESC:
                    case SparkSQLParser.KW_DESCRIPTOR:
                    case SparkSQLParser.KW_DIV:
                    case SparkSQLParser.KW_ENCODING:
                    case SparkSQLParser.KW_ENFORCED:
                    case SparkSQLParser.KW_ENGINE:
                    case SparkSQLParser.KW_ERROR:
                    case SparkSQLParser.KW_ESTIMATED_COST:
                    case SparkSQLParser.KW_EXCEPTION:
                    case SparkSQLParser.KW_EXCLUDE:
                    case SparkSQLParser.KW_EXCLUDING:
                    case SparkSQLParser.KW_EXTENDED:
                    case SparkSQLParser.KW_FILE:
                    case SparkSQLParser.KW_FINAL:
                    case SparkSQLParser.KW_FIRST:
                    case SparkSQLParser.KW_FOLLOWING:
                    case SparkSQLParser.KW_FORMAT:
                    case SparkSQLParser.KW_FORTRAN:
                    case SparkSQLParser.KW_FOUND:
                    case SparkSQLParser.KW_FRAC_SECOND:
                    case SparkSQLParser.KW_FUNCTIONS:
                    case SparkSQLParser.KW_GENERAL:
                    case SparkSQLParser.KW_GENERATED:
                    case SparkSQLParser.KW_GO:
                    case SparkSQLParser.KW_GOTO:
                    case SparkSQLParser.KW_GRANTED:
                    case SparkSQLParser.KW_HOP:
                    case SparkSQLParser.KW_HOURS:
                    case SparkSQLParser.KW_IF:
                    case SparkSQLParser.KW_IGNORE:
                    case SparkSQLParser.KW_INCREMENT:
                    case SparkSQLParser.KW_INPUT:
                    case SparkSQLParser.KW_INVOKER:
                    case SparkSQLParser.KW_JAR:
                    case SparkSQLParser.KW_JARS:
                    case SparkSQLParser.KW_JAVA:
                    case SparkSQLParser.KW_JSON:
                    case SparkSQLParser.KW_JSON_EXECUTION_PLAN:
                    case SparkSQLParser.KW_KEY:
                    case SparkSQLParser.KW_KEY_MEMBER:
                    case SparkSQLParser.KW_KEY_TYPE:
                    case SparkSQLParser.KW_LABEL:
                    case SparkSQLParser.KW_LAST:
                    case SparkSQLParser.KW_LENGTH:
                    case SparkSQLParser.KW_LEVEL:
                    case SparkSQLParser.KW_LOAD:
                    case SparkSQLParser.KW_MAP:
                    case SparkSQLParser.KW_MICROSECOND:
                    case SparkSQLParser.KW_MILLENNIUM:
                    case SparkSQLParser.KW_MILLISECOND:
                    case SparkSQLParser.KW_MINUTES:
                    case SparkSQLParser.KW_MINVALUE:
                    case SparkSQLParser.KW_MODIFY:
                    case SparkSQLParser.KW_MODULES:
                    case SparkSQLParser.KW_MONTHS:
                    case SparkSQLParser.KW_NANOSECOND:
                    case SparkSQLParser.KW_NULLS:
                    case SparkSQLParser.KW_NUMBER:
                    case SparkSQLParser.KW_OPTION:
                    case SparkSQLParser.KW_OPTIONS:
                    case SparkSQLParser.KW_ORDERING:
                    case SparkSQLParser.KW_OUTPUT:
                    case SparkSQLParser.KW_OVERWRITE:
                    case SparkSQLParser.KW_OVERWRITING:
                    case SparkSQLParser.KW_PARTITIONED:
                    case SparkSQLParser.KW_PARTITIONS:
                    case SparkSQLParser.KW_PASSING:
                    case SparkSQLParser.KW_PAST:
                    case SparkSQLParser.KW_PATH:
                    case SparkSQLParser.KW_PLACING:
                    case SparkSQLParser.KW_PLAN:
                    case SparkSQLParser.KW_PRECEDING:
                    case SparkSQLParser.KW_PRESERVE:
                    case SparkSQLParser.KW_PRIOR:
                    case SparkSQLParser.KW_PRIVILEGES:
                    case SparkSQLParser.KW_PUBLIC:
                    case SparkSQLParser.KW_PYTHON:
                    case SparkSQLParser.KW_PYTHON_FILES:
                    case SparkSQLParser.KW_PYTHON_REQUIREMENTS:
                    case SparkSQLParser.KW_PYTHON_DEPENDENCIES:
                    case SparkSQLParser.KW_PYTHON_JAR:
                    case SparkSQLParser.KW_PYTHON_ARCHIVES:
                    case SparkSQLParser.KW_PYTHON_PARAMETER:
                    case SparkSQLParser.KW_QUARTER:
                    case SparkSQLParser.KW_RAW:
                    case SparkSQLParser.KW_READ:
                    case SparkSQLParser.KW_RELATIVE:
                    case SparkSQLParser.KW_REMOVE:
                    case SparkSQLParser.KW_RENAME:
                    case SparkSQLParser.KW_REPLACE:
                    case SparkSQLParser.KW_RESPECT:
                    case SparkSQLParser.KW_RESTART:
                    case SparkSQLParser.KW_RESTRICT:
                    case SparkSQLParser.KW_ROLE:
                    case SparkSQLParser.KW_ROW_COUNT:
                    case SparkSQLParser.KW_SCALA:
                    case SparkSQLParser.KW_SCALAR:
                    case SparkSQLParser.KW_SCALE:
                    case SparkSQLParser.KW_SCHEMA:
                    case SparkSQLParser.KW_SECONDS:
                    case SparkSQLParser.KW_SECTION:
                    case SparkSQLParser.KW_SECURITY:
                    case SparkSQLParser.KW_SELF:
                    case SparkSQLParser.KW_SERVER:
                    case SparkSQLParser.KW_SERVER_NAME:
                    case SparkSQLParser.KW_SESSION:
                    case SparkSQLParser.KW_SETS:
                    case SparkSQLParser.KW_SIMPLE:
                    case SparkSQLParser.KW_SIZE:
                    case SparkSQLParser.KW_SLIDE:
                    case SparkSQLParser.KW_SOURCE:
                    case SparkSQLParser.KW_SPACE:
                    case SparkSQLParser.KW_STATE:
                    case SparkSQLParser.KW_STATEMENT:
                    case SparkSQLParser.KW_STEP:
                    case SparkSQLParser.KW_STRING:
                    case SparkSQLParser.KW_STRUCTURE:
                    case SparkSQLParser.KW_STYLE:
                    case SparkSQLParser.KW_TABLES:
                    case SparkSQLParser.KW_TEMPORARY:
                    case SparkSQLParser.KW_TIMECOL:
                    case SparkSQLParser.KW_FLOOR:
                    case SparkSQLParser.KW_TIMESTAMP_LTZ:
                    case SparkSQLParser.KW_TIMESTAMPADD:
                    case SparkSQLParser.KW_TIMESTAMPDIFF:
                    case SparkSQLParser.KW_TOTIMESTAMP:
                    case SparkSQLParser.KW_TRANSFORM:
                    case SparkSQLParser.KW_TUMBLE:
                    case SparkSQLParser.KW_TYPE:
                    case SparkSQLParser.KW_UNDER:
                    case SparkSQLParser.KW_UNLOAD:
                    case SparkSQLParser.KW_USAGE:
                    case SparkSQLParser.KW_USE:
                    case SparkSQLParser.KW_UTF16:
                    case SparkSQLParser.KW_UTF32:
                    case SparkSQLParser.KW_UTF8:
                    case SparkSQLParser.KW_VERSION:
                    case SparkSQLParser.KW_VIEW:
                    case SparkSQLParser.KW_VIEWS:
                    case SparkSQLParser.KW_VIRTUAL:
                    case SparkSQLParser.KW_WATERMARK:
                    case SparkSQLParser.KW_WATERMARKS:
                    case SparkSQLParser.KW_WEEK:
                    case SparkSQLParser.KW_WORK:
                    case SparkSQLParser.KW_WRAPPER:
                    case SparkSQLParser.KW_YEARS:
                    case SparkSQLParser.KW_ZONE:
                    case SparkSQLParser.KW_AS:
                    case SparkSQLParser.KW_LOCALTIMESTAMP:
                    case SparkSQLParser.DOLLAR:
                    case SparkSQLParser.STRING_LITERAL:
                    case SparkSQLParser.DIG_LITERAL:
                    case SparkSQLParser.ID_LITERAL:
                        {
                        this.state = 1061;
                        this.tableAlias();
                        }
                        break;
                    default:
                        throw new antlr.NoViableAltException(this);
                    }
                    this.state = 1064;
                    this.inlineBody();
                    }
                    }
                }
                this.state = 1069;
                this.errorHandler.sync(this);
                alternative = this.interpreter.adaptivePredict(this.tokenStream, 89, this.context);
            }
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public inlineBody(): InlineBodyContext {
        let localContext = new InlineBodyContext(this.context, this.state);
        this.enterRule(localContext, 104, SparkSQLParser.RULE_inlineBody);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1070;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 1071;
            this.expression();
            this.state = 1076;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 476) {
                {
                {
                this.state = 1072;
                this.match(SparkSQLParser.COMMA);
                this.state = 1073;
                this.expression();
                }
                }
                this.state = 1078;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 1079;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public withItem(): WithItemContext {
        let localContext = new WithItemContext(this.context, this.state);
        this.enterRule(localContext, 106, SparkSQLParser.RULE_withItem);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1081;
            this.withItemName();
            this.state = 1093;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 472) {
                {
                this.state = 1082;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 1083;
                this.columnName();
                this.state = 1088;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                while (_la === 476) {
                    {
                    {
                    this.state = 1084;
                    this.match(SparkSQLParser.COMMA);
                    this.state = 1085;
                    this.columnName();
                    }
                    }
                    this.state = 1090;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                }
                this.state = 1091;
                this.match(SparkSQLParser.RR_BRACKET);
                }
            }

            this.state = 1095;
            this.match(SparkSQLParser.KW_AS);
            this.state = 1096;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 1097;
            this.queryStatement(0);
            this.state = 1098;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public withItemName(): WithItemNameContext {
        let localContext = new WithItemNameContext(this.context, this.state);
        this.enterRule(localContext, 108, SparkSQLParser.RULE_withItemName);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1100;
            this.identifier();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public selectStatement(): SelectStatementContext {
        let localContext = new SelectStatementContext(this.context, this.state);
        this.enterRule(localContext, 110, SparkSQLParser.RULE_selectStatement);
        try {
            this.state = 1139;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 101, this.context) ) {
            case 1:
                localContext = new CommonSelectContext(localContext);
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 1102;
                this.selectClause();
                this.state = 1103;
                this.fromClause();
                this.state = 1105;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 93, this.context) ) {
                case 1:
                    {
                    this.state = 1104;
                    this.whereClause();
                    }
                    break;
                }
                this.state = 1108;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 94, this.context) ) {
                case 1:
                    {
                    this.state = 1107;
                    this.someByClause();
                    }
                    break;
                }
                this.state = 1111;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 95, this.context) ) {
                case 1:
                    {
                    this.state = 1110;
                    this.havingClause();
                    }
                    break;
                }
                this.state = 1114;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 96, this.context) ) {
                case 1:
                    {
                    this.state = 1113;
                    this.windowClause();
                    }
                    break;
                }
                }
                break;
            case 2:
                localContext = new SparkStyleSelectContext(localContext);
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 1116;
                this.fromClause();
                this.state = 1117;
                this.selectClause();
                this.state = 1119;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 97, this.context) ) {
                case 1:
                    {
                    this.state = 1118;
                    this.whereClause();
                    }
                    break;
                }
                this.state = 1122;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 98, this.context) ) {
                case 1:
                    {
                    this.state = 1121;
                    this.someByClause();
                    }
                    break;
                }
                this.state = 1125;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 99, this.context) ) {
                case 1:
                    {
                    this.state = 1124;
                    this.havingClause();
                    }
                    break;
                }
                this.state = 1128;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 100, this.context) ) {
                case 1:
                    {
                    this.state = 1127;
                    this.windowClause();
                    }
                    break;
                }
                }
                break;
            case 3:
                localContext = new MatchRecognizeSelectContext(localContext);
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 1130;
                this.selectClause();
                this.state = 1131;
                this.fromClause();
                this.state = 1132;
                this.matchRecognizeClause();
                }
                break;
            case 4:
                localContext = new TableSampleContext(localContext);
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 1134;
                this.selectClause();
                this.state = 1135;
                this.fromClause();
                this.state = 1136;
                this.samplingQueries();
                }
                break;
            case 5:
                localContext = new SelectPlusContext(localContext);
                this.enterOuterAlt(localContext, 5);
                {
                this.state = 1138;
                this.selectStatementPlus();
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public selectClause(): SelectClauseContext {
        let localContext = new SelectClauseContext(this.context, this.state);
        this.enterRule(localContext, 112, SparkSQLParser.RULE_selectClause);
        let _la: number;
        try {
            let alternative: number;
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1141;
            this.match(SparkSQLParser.KW_SELECT);
            this.state = 1143;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 202 || _la === 268) {
                {
                this.state = 1142;
                this.setQuantifier();
                }
            }

            this.state = 1145;
            this.projectItemDefinition();
            this.state = 1150;
            this.errorHandler.sync(this);
            alternative = this.interpreter.adaptivePredict(this.tokenStream, 103, this.context);
            while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {
                if (alternative === 1) {
                    {
                    {
                    this.state = 1146;
                    this.match(SparkSQLParser.COMMA);
                    this.state = 1147;
                    this.projectItemDefinition();
                    }
                    }
                }
                this.state = 1152;
                this.errorHandler.sync(this);
                alternative = this.interpreter.adaptivePredict(this.tokenStream, 103, this.context);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public projectItemDefinition(): ProjectItemDefinitionContext {
        let localContext = new ProjectItemDefinitionContext(this.context, this.state);
        this.enterRule(localContext, 114, SparkSQLParser.RULE_projectItemDefinition);
        let _la: number;
        try {
            this.state = 1165;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 107, this.context) ) {
            case 1:
                localContext = new WindowsProrjectItemContext(localContext);
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 1153;
                this.overWindowItem();
                this.state = 1158;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 105, this.context) ) {
                case 1:
                    {
                    this.state = 1155;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                    if (_la === 209) {
                        {
                        this.state = 1154;
                        this.match(SparkSQLParser.KW_AS);
                        }
                    }

                    this.state = 1157;
                    this.identifier();
                    }
                    break;
                }
                }
                break;
            case 2:
                localContext = new ExpressionProjectItemContext(localContext);
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 1160;
                this.expression();
                this.state = 1163;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 106, this.context) ) {
                case 1:
                    {
                    this.state = 1161;
                    this.match(SparkSQLParser.KW_AS);
                    this.state = 1162;
                    this.expression();
                    }
                    break;
                }
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public filterPart(): FilterPartContext {
        let localContext = new FilterPartContext(this.context, this.state);
        this.enterRule(localContext, 116, SparkSQLParser.RULE_filterPart);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1167;
            this.match(SparkSQLParser.KW_FILTER);
            this.state = 1168;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 1169;
            this.whereClause();
            this.state = 1170;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public overWindowItem(): OverWindowItemContext {
        let localContext = new OverWindowItemContext(this.context, this.state);
        this.enterRule(localContext, 118, SparkSQLParser.RULE_overWindowItem);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1172;
            this.windowFunctioPart();
            this.state = 1175;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 67 || _la === 136) {
                {
                this.state = 1173;
                _la = this.tokenStream.LA(1);
                if(!(_la === 67 || _la === 136)) {
                this.errorHandler.recoverInline(this);
                }
                else {
                    this.errorHandler.reportMatch(this);
                    this.consume();
                }
                this.state = 1174;
                this.match(SparkSQLParser.KW_NULLS);
                }
            }

            this.state = 1177;
            this.match(SparkSQLParser.KW_OVER);
            this.state = 1179;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 109, this.context) ) {
            case 1:
                {
                this.state = 1178;
                this.anonymousWindowsName();
                }
                break;
            }
            this.state = 1191;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 112, this.context) ) {
            case 1:
                {
                this.state = 1181;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 1183;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 271 || _la === 368) {
                    {
                    this.state = 1182;
                    this.overClause();
                    }
                }

                this.state = 1185;
                this.orderByCaluse();
                this.state = 1187;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 383 || _la === 396) {
                    {
                    this.state = 1186;
                    this.windowFrameForWindowsQuery();
                    }
                }

                this.state = 1189;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public overClause(): OverClauseContext {
        let localContext = new OverClauseContext(this.context, this.state);
        this.enterRule(localContext, 120, SparkSQLParser.RULE_overClause);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1193;
            _la = this.tokenStream.LA(1);
            if(!(_la === 271 || _la === 368)) {
            this.errorHandler.recoverInline(this);
            }
            else {
                this.errorHandler.reportMatch(this);
                this.consume();
            }
            this.state = 1194;
            this.match(SparkSQLParser.KW_BY);
            this.state = 1195;
            this.columnName();
            this.state = 1200;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 476) {
                {
                {
                this.state = 1196;
                this.match(SparkSQLParser.COMMA);
                this.state = 1197;
                this.columnName();
                }
                }
                this.state = 1202;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 1205;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 465) {
                {
                this.state = 1203;
                this.match(SparkSQLParser.EQUAL_SYMBOL);
                this.state = 1204;
                this.expression();
                }
            }

            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public windowFunctioPart(): WindowFunctioPartContext {
        let localContext = new WindowFunctioPartContext(this.context, this.state);
        this.enterRule(localContext, 122, SparkSQLParser.RULE_windowFunctioPart);
        let _la: number;
        try {
            this.state = 1222;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 117, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 1207;
                this.windowFunctionName();
                this.state = 1208;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 1217;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if ((((_la) & ~0x1F) === 0 && ((1 << _la) & 4294896624) !== 0) || ((((_la - 33)) & ~0x1F) === 0 && ((1 << (_la - 33)) & 4294836223) !== 0) || ((((_la - 65)) & ~0x1F) === 0 && ((1 << (_la - 65)) & 4281327607) !== 0) || ((((_la - 97)) & ~0x1F) === 0 && ((1 << (_la - 97)) & 2147483643) !== 0) || ((((_la - 129)) & ~0x1F) === 0 && ((1 << (_la - 129)) & 2113863675) !== 0) || ((((_la - 161)) & ~0x1F) === 0 && ((1 << (_la - 161)) & 4292341757) !== 0) || ((((_la - 193)) & ~0x1F) === 0 && ((1 << (_la - 193)) & 134775807) !== 0) || ((((_la - 227)) & ~0x1F) === 0 && ((1 << (_la - 227)) & 2685932551) !== 0) || ((((_la - 268)) & ~0x1F) === 0 && ((1 << (_la - 268)) & 70336513) !== 0) || ((((_la - 300)) & ~0x1F) === 0 && ((1 << (_la - 300)) & 2030075921) !== 0) || ((((_la - 335)) & ~0x1F) === 0 && ((1 << (_la - 335)) & 2148205697) !== 0) || ((((_la - 372)) & ~0x1F) === 0 && ((1 << (_la - 372)) & 42494055) !== 0) || ((((_la - 410)) & ~0x1F) === 0 && ((1 << (_la - 410)) & 276029453) !== 0) || ((((_la - 452)) & ~0x1F) === 0 && ((1 << (_la - 452)) & 135266817) !== 0) || ((((_la - 484)) & ~0x1F) === 0 && ((1 << (_la - 484)) & 15373) !== 0)) {
                    {
                    this.state = 1209;
                    this.functionParam();
                    this.state = 1214;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                    while (_la === 476) {
                        {
                        {
                        this.state = 1210;
                        this.match(SparkSQLParser.COMMA);
                        this.state = 1211;
                        this.functionParam();
                        }
                        }
                        this.state = 1216;
                        this.errorHandler.sync(this);
                        _la = this.tokenStream.LA(1);
                    }
                    }
                }

                this.state = 1219;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 1221;
                this.primaryExpression(0);
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public windowFunctionName(): WindowFunctionNameContext {
        let localContext = new WindowFunctionNameContext(this.context, this.state);
        this.enterRule(localContext, 124, SparkSQLParser.RULE_windowFunctionName);
        try {
            this.state = 1226;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.KW_DENSE_RANK:
            case SparkSQLParser.KW_NTILE:
            case SparkSQLParser.KW_PERCENT_RANK:
            case SparkSQLParser.KW_RANK:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 1224;
                this.rangkingFunction();
                }
                break;
            case SparkSQLParser.KW_CUME_DIST:
            case SparkSQLParser.KW_FIRST_VALUE:
            case SparkSQLParser.KW_LAG:
            case SparkSQLParser.KW_LAST_VALUE:
            case SparkSQLParser.KW_LEAD:
            case SparkSQLParser.KW_NTH_VALUE:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 1225;
                this.analyticFunction();
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public analyticFunction(): AnalyticFunctionContext {
        let localContext = new AnalyticFunctionContext(this.context, this.state);
        this.enterRule(localContext, 126, SparkSQLParser.RULE_analyticFunction);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1228;
            _la = this.tokenStream.LA(1);
            if(!(_la === 251 || _la === 288 || ((((_la - 324)) & ~0x1F) === 0 && ((1 << (_la - 324)) & 536870937) !== 0))) {
            this.errorHandler.recoverInline(this);
            }
            else {
                this.errorHandler.reportMatch(this);
                this.consume();
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public rangkingFunction(): RangkingFunctionContext {
        let localContext = new RangkingFunctionContext(this.context, this.state);
        this.enterRule(localContext, 128, SparkSQLParser.RULE_rangkingFunction);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1230;
            _la = this.tokenStream.LA(1);
            if(!(_la === 267 || _la === 352 || _la === 372 || _la === 386)) {
            this.errorHandler.recoverInline(this);
            }
            else {
                this.errorHandler.reportMatch(this);
                this.consume();
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public fromClause(): FromClauseContext {
        let localContext = new FromClauseContext(this.context, this.state);
        this.enterRule(localContext, 130, SparkSQLParser.RULE_fromClause);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1232;
            this.match(SparkSQLParser.KW_FROM);
            this.state = 1233;
            this.tableExpression(0);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public windowFrameForWindowsQuery(): WindowFrameForWindowsQueryContext {
        let localContext = new WindowFrameForWindowsQueryContext(this.context, this.state);
        this.enterRule(localContext, 132, SparkSQLParser.RULE_windowFrameForWindowsQuery);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1235;
            _la = this.tokenStream.LA(1);
            if(!(_la === 383 || _la === 396)) {
            this.errorHandler.recoverInline(this);
            }
            else {
                this.errorHandler.reportMatch(this);
                this.consume();
            }
            this.state = 1242;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.KW_ADD:
            case SparkSQLParser.KW_ADMIN:
            case SparkSQLParser.KW_AFTER:
            case SparkSQLParser.KW_ANALYZE:
            case SparkSQLParser.KW_ASC:
            case SparkSQLParser.KW_BEFORE:
            case SparkSQLParser.KW_BYTES:
            case SparkSQLParser.KW_CASCADE:
            case SparkSQLParser.KW_CATALOG:
            case SparkSQLParser.KW_CATALOGS:
            case SparkSQLParser.KW_CENTURY:
            case SparkSQLParser.KW_CHAIN:
            case SparkSQLParser.KW_CHANGELOG_MODE:
            case SparkSQLParser.KW_CHARACTERS:
            case SparkSQLParser.KW_COMMENT:
            case SparkSQLParser.KW_COMPACT:
            case SparkSQLParser.KW_COLUMNS:
            case SparkSQLParser.KW_CONSTRAINTS:
            case SparkSQLParser.KW_CONSTRUCTOR:
            case SparkSQLParser.KW_COMPUTE:
            case SparkSQLParser.KW_CUMULATE:
            case SparkSQLParser.KW_DATA:
            case SparkSQLParser.KW_DATABASE:
            case SparkSQLParser.KW_DATABASES:
            case SparkSQLParser.KW_DAYS:
            case SparkSQLParser.KW_DECADE:
            case SparkSQLParser.KW_DEFINED:
            case SparkSQLParser.KW_DESC:
            case SparkSQLParser.KW_DESCRIPTOR:
            case SparkSQLParser.KW_DIV:
            case SparkSQLParser.KW_ENCODING:
            case SparkSQLParser.KW_ENFORCED:
            case SparkSQLParser.KW_ENGINE:
            case SparkSQLParser.KW_ERROR:
            case SparkSQLParser.KW_ESTIMATED_COST:
            case SparkSQLParser.KW_EXCEPTION:
            case SparkSQLParser.KW_EXCLUDE:
            case SparkSQLParser.KW_EXCLUDING:
            case SparkSQLParser.KW_EXTENDED:
            case SparkSQLParser.KW_FILE:
            case SparkSQLParser.KW_FINAL:
            case SparkSQLParser.KW_FIRST:
            case SparkSQLParser.KW_FOLLOWING:
            case SparkSQLParser.KW_FORMAT:
            case SparkSQLParser.KW_FORTRAN:
            case SparkSQLParser.KW_FOUND:
            case SparkSQLParser.KW_FRAC_SECOND:
            case SparkSQLParser.KW_FUNCTIONS:
            case SparkSQLParser.KW_GENERAL:
            case SparkSQLParser.KW_GENERATED:
            case SparkSQLParser.KW_GO:
            case SparkSQLParser.KW_GOTO:
            case SparkSQLParser.KW_GRANTED:
            case SparkSQLParser.KW_HOP:
            case SparkSQLParser.KW_HOURS:
            case SparkSQLParser.KW_IF:
            case SparkSQLParser.KW_IGNORE:
            case SparkSQLParser.KW_INCREMENT:
            case SparkSQLParser.KW_INPUT:
            case SparkSQLParser.KW_INVOKER:
            case SparkSQLParser.KW_JAR:
            case SparkSQLParser.KW_JARS:
            case SparkSQLParser.KW_JAVA:
            case SparkSQLParser.KW_JSON:
            case SparkSQLParser.KW_JSON_EXECUTION_PLAN:
            case SparkSQLParser.KW_KEY:
            case SparkSQLParser.KW_KEY_MEMBER:
            case SparkSQLParser.KW_KEY_TYPE:
            case SparkSQLParser.KW_LABEL:
            case SparkSQLParser.KW_LAST:
            case SparkSQLParser.KW_LENGTH:
            case SparkSQLParser.KW_LEVEL:
            case SparkSQLParser.KW_LOAD:
            case SparkSQLParser.KW_MAP:
            case SparkSQLParser.KW_MICROSECOND:
            case SparkSQLParser.KW_MILLENNIUM:
            case SparkSQLParser.KW_MILLISECOND:
            case SparkSQLParser.KW_MINUTES:
            case SparkSQLParser.KW_MINVALUE:
            case SparkSQLParser.KW_MODIFY:
            case SparkSQLParser.KW_MODULES:
            case SparkSQLParser.KW_MONTHS:
            case SparkSQLParser.KW_NANOSECOND:
            case SparkSQLParser.KW_NULLS:
            case SparkSQLParser.KW_NUMBER:
            case SparkSQLParser.KW_OPTION:
            case SparkSQLParser.KW_OPTIONS:
            case SparkSQLParser.KW_ORDERING:
            case SparkSQLParser.KW_OUTPUT:
            case SparkSQLParser.KW_OVERWRITE:
            case SparkSQLParser.KW_OVERWRITING:
            case SparkSQLParser.KW_PARTITIONED:
            case SparkSQLParser.KW_PARTITIONS:
            case SparkSQLParser.KW_PASSING:
            case SparkSQLParser.KW_PAST:
            case SparkSQLParser.KW_PATH:
            case SparkSQLParser.KW_PLACING:
            case SparkSQLParser.KW_PLAN:
            case SparkSQLParser.KW_PRECEDING:
            case SparkSQLParser.KW_PRESERVE:
            case SparkSQLParser.KW_PRIOR:
            case SparkSQLParser.KW_PRIVILEGES:
            case SparkSQLParser.KW_PUBLIC:
            case SparkSQLParser.KW_PYTHON:
            case SparkSQLParser.KW_PYTHON_FILES:
            case SparkSQLParser.KW_PYTHON_REQUIREMENTS:
            case SparkSQLParser.KW_PYTHON_DEPENDENCIES:
            case SparkSQLParser.KW_PYTHON_JAR:
            case SparkSQLParser.KW_PYTHON_ARCHIVES:
            case SparkSQLParser.KW_PYTHON_PARAMETER:
            case SparkSQLParser.KW_QUARTER:
            case SparkSQLParser.KW_RAW:
            case SparkSQLParser.KW_READ:
            case SparkSQLParser.KW_RELATIVE:
            case SparkSQLParser.KW_REMOVE:
            case SparkSQLParser.KW_RENAME:
            case SparkSQLParser.KW_REPLACE:
            case SparkSQLParser.KW_RESPECT:
            case SparkSQLParser.KW_RESTART:
            case SparkSQLParser.KW_RESTRICT:
            case SparkSQLParser.KW_ROLE:
            case SparkSQLParser.KW_ROW_COUNT:
            case SparkSQLParser.KW_SCALA:
            case SparkSQLParser.KW_SCALAR:
            case SparkSQLParser.KW_SCALE:
            case SparkSQLParser.KW_SCHEMA:
            case SparkSQLParser.KW_SECONDS:
            case SparkSQLParser.KW_SECTION:
            case SparkSQLParser.KW_SECURITY:
            case SparkSQLParser.KW_SELF:
            case SparkSQLParser.KW_SERVER:
            case SparkSQLParser.KW_SERVER_NAME:
            case SparkSQLParser.KW_SESSION:
            case SparkSQLParser.KW_SETS:
            case SparkSQLParser.KW_SIMPLE:
            case SparkSQLParser.KW_SIZE:
            case SparkSQLParser.KW_SLIDE:
            case SparkSQLParser.KW_SOURCE:
            case SparkSQLParser.KW_SPACE:
            case SparkSQLParser.KW_STATE:
            case SparkSQLParser.KW_STATEMENT:
            case SparkSQLParser.KW_STEP:
            case SparkSQLParser.KW_STRING:
            case SparkSQLParser.KW_STRUCTURE:
            case SparkSQLParser.KW_STYLE:
            case SparkSQLParser.KW_TABLES:
            case SparkSQLParser.KW_TEMPORARY:
            case SparkSQLParser.KW_TIMECOL:
            case SparkSQLParser.KW_FLOOR:
            case SparkSQLParser.KW_TIMESTAMP_LTZ:
            case SparkSQLParser.KW_TIMESTAMPADD:
            case SparkSQLParser.KW_TIMESTAMPDIFF:
            case SparkSQLParser.KW_TOTIMESTAMP:
            case SparkSQLParser.KW_TRANSFORM:
            case SparkSQLParser.KW_TUMBLE:
            case SparkSQLParser.KW_TYPE:
            case SparkSQLParser.KW_UNDER:
            case SparkSQLParser.KW_UNBOUNDED:
            case SparkSQLParser.KW_UNLOAD:
            case SparkSQLParser.KW_USAGE:
            case SparkSQLParser.KW_USE:
            case SparkSQLParser.KW_UTF16:
            case SparkSQLParser.KW_UTF32:
            case SparkSQLParser.KW_UTF8:
            case SparkSQLParser.KW_VERSION:
            case SparkSQLParser.KW_VIEW:
            case SparkSQLParser.KW_VIEWS:
            case SparkSQLParser.KW_VIRTUAL:
            case SparkSQLParser.KW_WATERMARK:
            case SparkSQLParser.KW_WATERMARKS:
            case SparkSQLParser.KW_WEEK:
            case SparkSQLParser.KW_WORK:
            case SparkSQLParser.KW_WRAPPER:
            case SparkSQLParser.KW_YEARS:
            case SparkSQLParser.KW_ZONE:
            case SparkSQLParser.KW_ABS:
            case SparkSQLParser.KW_ARRAY:
            case SparkSQLParser.KW_AVG:
            case SparkSQLParser.KW_CASE:
            case SparkSQLParser.KW_CAST:
            case SparkSQLParser.KW_CEIL:
            case SparkSQLParser.KW_COALESCE:
            case SparkSQLParser.KW_COLLECT:
            case SparkSQLParser.KW_COUNT:
            case SparkSQLParser.KW_CURRENT_TIMESTAMP:
            case SparkSQLParser.KW_CURRENT:
            case SparkSQLParser.KW_DATE:
            case SparkSQLParser.KW_DAY:
            case SparkSQLParser.KW_EXISTS:
            case SparkSQLParser.KW_EXPLODE:
            case SparkSQLParser.KW_FIRST_VALUE:
            case SparkSQLParser.KW_FALSE:
            case SparkSQLParser.KW_FROM_UNIXTIME:
            case SparkSQLParser.KW_GROUPING:
            case SparkSQLParser.KW_HOUR:
            case SparkSQLParser.KW_INTERVAL:
            case SparkSQLParser.KW_LAG:
            case SparkSQLParser.KW_LAST_VALUE:
            case SparkSQLParser.KW_LEAD:
            case SparkSQLParser.KW_LEFT:
            case SparkSQLParser.KW_LOCALTIMESTAMP:
            case SparkSQLParser.KW_MINUTE:
            case SparkSQLParser.KW_MONTH:
            case SparkSQLParser.KW_NOT:
            case SparkSQLParser.KW_NTILE:
            case SparkSQLParser.KW_NULL:
            case SparkSQLParser.KW_OVERLAY:
            case SparkSQLParser.KW_PERCENT_RANK:
            case SparkSQLParser.KW_PERCENTILE_CONT:
            case SparkSQLParser.KW_PERCENTILE_DISC:
            case SparkSQLParser.KW_POSITION:
            case SparkSQLParser.KW_POWER:
            case SparkSQLParser.KW_RANGE:
            case SparkSQLParser.KW_ROW_NUMBER:
            case SparkSQLParser.KW_RANK:
            case SparkSQLParser.KW_RIGHT:
            case SparkSQLParser.KW_ROW:
            case SparkSQLParser.KW_SECOND:
            case SparkSQLParser.KW_STRUCT:
            case SparkSQLParser.KW_SUBSTRING:
            case SparkSQLParser.KW_SUM:
            case SparkSQLParser.KW_TIME:
            case SparkSQLParser.KW_TIMESTAMP:
            case SparkSQLParser.KW_TIMESTAMP_3:
            case SparkSQLParser.KW_TIMESTAMP_6:
            case SparkSQLParser.KW_TIMESTAMP_9:
            case SparkSQLParser.KW_TRUE:
            case SparkSQLParser.KW_TRUNCATE:
            case SparkSQLParser.KW_UPPER:
            case SparkSQLParser.KW_YEAR:
            case SparkSQLParser.BIT_NOT_OP:
            case SparkSQLParser.LR_BRACKET:
            case SparkSQLParser.DOLLAR:
            case SparkSQLParser.ASTERISK_SIGN:
            case SparkSQLParser.HYPNEN_SIGN:
            case SparkSQLParser.ADD_SIGN:
            case SparkSQLParser.STRING_LITERAL:
            case SparkSQLParser.DIG_LITERAL:
            case SparkSQLParser.REAL_LITERAL:
            case SparkSQLParser.ID_LITERAL:
                {
                this.state = 1236;
                this.frameExpession();
                }
                break;
            case SparkSQLParser.KW_BETWEEN:
                {
                {
                this.state = 1237;
                this.match(SparkSQLParser.KW_BETWEEN);
                this.state = 1238;
                this.frameExpession();
                this.state = 1239;
                this.match(SparkSQLParser.KW_AND);
                this.state = 1240;
                this.frameExpession();
                }
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public frameExpession(): FrameExpessionContext {
        let localContext = new FrameExpessionContext(this.context, this.state);
        this.enterRule(localContext, 134, SparkSQLParser.RULE_frameExpession);
        try {
            this.state = 1256;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 120, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 1244;
                this.match(SparkSQLParser.KW_UNBOUNDED);
                this.state = 1245;
                this.match(SparkSQLParser.KW_PRECEDING);
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 1246;
                this.expression();
                this.state = 1247;
                this.match(SparkSQLParser.KW_PRECEDING);
                }
                break;
            case 3:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 1249;
                this.match(SparkSQLParser.KW_CURRENT);
                this.state = 1250;
                this.match(SparkSQLParser.KW_ROW);
                }
                break;
            case 4:
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 1251;
                this.expression();
                this.state = 1252;
                this.match(SparkSQLParser.KW_FOLLOWING);
                }
                break;
            case 5:
                this.enterOuterAlt(localContext, 5);
                {
                this.state = 1254;
                this.match(SparkSQLParser.KW_UNBOUNDED);
                this.state = 1255;
                this.match(SparkSQLParser.KW_FOLLOWING);
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }

    public tableExpression(): TableExpressionContext;
    public tableExpression(_p: number): TableExpressionContext;
    public tableExpression(_p?: number): TableExpressionContext {
        if (_p === undefined) {
            _p = 0;
        }

        let parentContext = this.context;
        let parentState = this.state;
        let localContext = new TableExpressionContext(this.context, parentState);
        let previousContext = localContext;
        let _startState = 136;
        this.enterRecursionRule(localContext, 136, SparkSQLParser.RULE_tableExpression, _p);
        let _la: number;
        try {
            let alternative: number;
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1288;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 126, this.context) ) {
            case 1:
                {
                this.state = 1259;
                this.tableReference();
                this.state = 1264;
                this.errorHandler.sync(this);
                alternative = this.interpreter.adaptivePredict(this.tokenStream, 121, this.context);
                while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {
                    if (alternative === 1) {
                        {
                        {
                        this.state = 1260;
                        this.match(SparkSQLParser.COMMA);
                        this.state = 1261;
                        this.tableReference();
                        }
                        }
                    }
                    this.state = 1266;
                    this.errorHandler.sync(this);
                    alternative = this.interpreter.adaptivePredict(this.tokenStream, 121, this.context);
                }
                }
                break;
            case 2:
                {
                this.state = 1267;
                this.tableReference();
                this.state = 1268;
                this.pivotReference();
                this.state = 1270;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 122, this.context) ) {
                case 1:
                    {
                    this.state = 1269;
                    this.tableAlias();
                    }
                    break;
                }
                }
                break;
            case 3:
                {
                this.state = 1272;
                this.tableReference();
                this.state = 1276;
                this.errorHandler.sync(this);
                alternative = this.interpreter.adaptivePredict(this.tokenStream, 123, this.context);
                while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {
                    if (alternative === 1) {
                        {
                        {
                        this.state = 1273;
                        this.viewReference();
                        }
                        }
                    }
                    this.state = 1278;
                    this.errorHandler.sync(this);
                    alternative = this.interpreter.adaptivePredict(this.tokenStream, 123, this.context);
                }
                this.state = 1280;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 124, this.context) ) {
                case 1:
                    {
                    this.state = 1279;
                    this.tableAlias();
                    }
                    break;
                }
                }
                break;
            case 4:
                {
                this.state = 1282;
                this.valuesCaluse();
                }
                break;
            case 5:
                {
                this.state = 1283;
                this.tvfClause();
                this.state = 1285;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 125, this.context) ) {
                case 1:
                    {
                    this.state = 1284;
                    this.tableAlias();
                    }
                    break;
                }
                }
                break;
            case 6:
                {
                this.state = 1287;
                this.windowTVFClause();
                }
                break;
            }
            this.context!.stop = this.tokenStream.LT(-1);
            this.state = 1318;
            this.errorHandler.sync(this);
            alternative = this.interpreter.adaptivePredict(this.tokenStream, 133, this.context);
            while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {
                if (alternative === 1) {
                    if (this.parseListeners != null) {
                        this.triggerExitRuleEvent();
                    }
                    previousContext = localContext;
                    {
                    this.state = 1316;
                    this.errorHandler.sync(this);
                    switch (this.interpreter.adaptivePredict(this.tokenStream, 132, this.context) ) {
                    case 1:
                        {
                        localContext = new TableExpressionContext(parentContext, parentState);
                        this.pushNewRecursionContext(localContext, _startState, SparkSQLParser.RULE_tableExpression);
                        this.state = 1290;
                        if (!(this.precpred(this.context, 4))) {
                            throw this.createFailedPredicateException("this.precpred(this.context, 4)");
                        }
                        this.state = 1291;
                        this.match(SparkSQLParser.KW_CROSS);
                        this.state = 1292;
                        this.match(SparkSQLParser.KW_JOIN);
                        this.state = 1293;
                        this.tableExpression(5);
                        }
                        break;
                    case 2:
                        {
                        localContext = new TableExpressionContext(parentContext, parentState);
                        this.pushNewRecursionContext(localContext, _startState, SparkSQLParser.RULE_tableExpression);
                        this.state = 1294;
                        if (!(this.precpred(this.context, 5))) {
                            throw this.createFailedPredicateException("this.precpred(this.context, 5)");
                        }
                        this.state = 1296;
                        this.errorHandler.sync(this);
                        _la = this.tokenStream.LA(1);
                        if (_la === 347) {
                            {
                            this.state = 1295;
                            this.match(SparkSQLParser.KW_NATURAL);
                            }
                        }

                        this.state = 1299;
                        this.errorHandler.sync(this);
                        _la = this.tokenStream.LA(1);
                        if (_la === 295 || _la === 309 || _la === 330 || _la === 391) {
                            {
                            this.state = 1298;
                            _la = this.tokenStream.LA(1);
                            if(!(_la === 295 || _la === 309 || _la === 330 || _la === 391)) {
                            this.errorHandler.recoverInline(this);
                            }
                            else {
                                this.errorHandler.reportMatch(this);
                                this.consume();
                            }
                            }
                        }

                        this.state = 1302;
                        this.errorHandler.sync(this);
                        _la = this.tokenStream.LA(1);
                        if (_la === 363) {
                            {
                            this.state = 1301;
                            this.match(SparkSQLParser.KW_OUTER);
                            }
                        }

                        this.state = 1304;
                        this.match(SparkSQLParser.KW_JOIN);
                        this.state = 1305;
                        this.tableExpression(0);
                        this.state = 1307;
                        this.errorHandler.sync(this);
                        switch (this.interpreter.adaptivePredict(this.tokenStream, 130, this.context) ) {
                        case 1:
                            {
                            this.state = 1306;
                            this.joinCondition();
                            }
                            break;
                        }
                        this.state = 1313;
                        this.errorHandler.sync(this);
                        alternative = this.interpreter.adaptivePredict(this.tokenStream, 131, this.context);
                        while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {
                            if (alternative === 1) {
                                {
                                {
                                this.state = 1309;
                                this.match(SparkSQLParser.COMMA);
                                this.state = 1310;
                                this.tableReference();
                                }
                                }
                            }
                            this.state = 1315;
                            this.errorHandler.sync(this);
                            alternative = this.interpreter.adaptivePredict(this.tokenStream, 131, this.context);
                        }
                        }
                        break;
                    }
                    }
                }
                this.state = 1320;
                this.errorHandler.sync(this);
                alternative = this.interpreter.adaptivePredict(this.tokenStream, 133, this.context);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.unrollRecursionContexts(parentContext);
        }
        return localContext;
    }
    public tvfClause(): TvfClauseContext {
        let localContext = new TvfClauseContext(this.context, this.state);
        this.enterRule(localContext, 138, SparkSQLParser.RULE_tvfClause);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1321;
            this.rangeClause();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public rangeClause(): RangeClauseContext {
        let localContext = new RangeClauseContext(this.context, this.state);
        this.enterRule(localContext, 140, SparkSQLParser.RULE_rangeClause);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1323;
            this.match(SparkSQLParser.KW_RANGE);
            this.state = 1324;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 1325;
            this.expression();
            this.state = 1330;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 476) {
                {
                {
                this.state = 1326;
                this.match(SparkSQLParser.COMMA);
                this.state = 1327;
                this.expression();
                }
                }
                this.state = 1332;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 1333;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public viewReference(): ViewReferenceContext {
        let localContext = new ViewReferenceContext(this.context, this.state);
        this.enterRule(localContext, 142, SparkSQLParser.RULE_viewReference);
        let _la: number;
        try {
            let alternative: number;
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1335;
            this.match(SparkSQLParser.KW_LATERAL);
            this.state = 1336;
            this.match(SparkSQLParser.KW_VIEW);
            this.state = 1338;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 363) {
                {
                this.state = 1337;
                this.match(SparkSQLParser.KW_OUTER);
                }
            }

            this.state = 1340;
            this.funtionBody();
            this.state = 1342;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 136, this.context) ) {
            case 1:
                {
                this.state = 1341;
                this.tableAlias();
                }
                break;
            }
            this.state = 1344;
            this.match(SparkSQLParser.KW_AS);
            this.state = 1345;
            this.columnAlias();
            this.state = 1350;
            this.errorHandler.sync(this);
            alternative = this.interpreter.adaptivePredict(this.tokenStream, 137, this.context);
            while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {
                if (alternative === 1) {
                    {
                    {
                    this.state = 1346;
                    this.match(SparkSQLParser.COMMA);
                    this.state = 1347;
                    this.columnAlias();
                    }
                    }
                }
                this.state = 1352;
                this.errorHandler.sync(this);
                alternative = this.interpreter.adaptivePredict(this.tokenStream, 137, this.context);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public pivotReference(): PivotReferenceContext {
        let localContext = new PivotReferenceContext(this.context, this.state);
        this.enterRule(localContext, 144, SparkSQLParser.RULE_pivotReference);
        let _la: number;
        try {
            this.state = 1367;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.KW_PIVOT:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 1353;
                this.match(SparkSQLParser.KW_PIVOT);
                this.state = 1354;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 1355;
                this.pivotBody();
                this.state = 1356;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case SparkSQLParser.KW_UNPIVOT:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 1358;
                this.match(SparkSQLParser.KW_UNPIVOT);
                this.state = 1361;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 45 || _la === 68) {
                    {
                    this.state = 1359;
                    _la = this.tokenStream.LA(1);
                    if(!(_la === 45 || _la === 68)) {
                    this.errorHandler.recoverInline(this);
                    }
                    else {
                        this.errorHandler.reportMatch(this);
                        this.consume();
                    }
                    this.state = 1360;
                    this.match(SparkSQLParser.KW_NULLS);
                    }
                }

                this.state = 1363;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 1364;
                this.unpivotBody();
                this.state = 1365;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public tableReference(): TableReferenceContext {
        let localContext = new TableReferenceContext(this.context, this.state);
        this.enterRule(localContext, 146, SparkSQLParser.RULE_tableReference);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1369;
            this.tablePrimary();
            this.state = 1371;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 140, this.context) ) {
            case 1:
                {
                this.state = 1370;
                this.tableAlias();
                }
                break;
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public tablePrimary(): TablePrimaryContext {
        let localContext = new TablePrimaryContext(this.context, this.state);
        this.enterRule(localContext, 148, SparkSQLParser.RULE_tablePrimary);
        let _la: number;
        try {
            this.state = 1414;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 146, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 1374;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 418) {
                    {
                    this.state = 1373;
                    this.match(SparkSQLParser.KW_TABLE);
                    }
                }

                this.state = 1376;
                this.tablePath();
                this.state = 1378;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 142, this.context) ) {
                case 1:
                    {
                    this.state = 1377;
                    this.systemTimePeriod();
                    }
                    break;
                }
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 1380;
                this.match(SparkSQLParser.KW_LATERAL);
                this.state = 1381;
                this.match(SparkSQLParser.KW_TABLE);
                this.state = 1384;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 143, this.context) ) {
                case 1:
                    {
                    this.state = 1382;
                    this.funtionBody();
                    }
                    break;
                case 2:
                    {
                    this.state = 1383;
                    this.complexDataTypeExpression();
                    }
                    break;
                }
                }
                break;
            case 3:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 1386;
                this.match(SparkSQLParser.KW_LATERAL);
                this.state = 1387;
                this.match(SparkSQLParser.KW_TABLE);
                this.state = 1388;
                this.match(SparkSQLParser.KW_EXPLODE);
                this.state = 1389;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 1392;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 144, this.context) ) {
                case 1:
                    {
                    this.state = 1390;
                    this.funtionBody();
                    }
                    break;
                case 2:
                    {
                    this.state = 1391;
                    this.complexDataTypeExpression();
                    }
                    break;
                }
                this.state = 1394;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case 4:
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 1396;
                this.match(SparkSQLParser.KW_LATERAL);
                this.state = 1397;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 1398;
                this.queryStatement(0);
                this.state = 1399;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case 5:
                this.enterOuterAlt(localContext, 5);
                {
                this.state = 1401;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 1405;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                while (_la === 293 || _la === 398 || ((((_la - 449)) & ~0x1F) === 0 && ((1 << (_la - 449)) & 276824065) !== 0)) {
                    {
                    {
                    this.state = 1402;
                    this.queryStatement(0);
                    }
                    }
                    this.state = 1407;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                }
                this.state = 1408;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case 6:
                this.enterOuterAlt(localContext, 6);
                {
                this.state = 1409;
                this.match(SparkSQLParser.KW_UNSET);
                this.state = 1410;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 1411;
                this.expression();
                this.state = 1412;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public funtionBody(): FuntionBodyContext {
        let localContext = new FuntionBodyContext(this.context, this.state);
        this.enterRule(localContext, 150, SparkSQLParser.RULE_funtionBody);
        let _la: number;
        try {
            let alternative: number;
            this.state = 1463;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 154, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 1416;
                this.functionName();
                this.state = 1417;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 1420;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 147, this.context) ) {
                case 1:
                    {
                    this.state = 1418;
                    this.funtionBody();
                    }
                    break;
                case 2:
                    {
                    this.state = 1419;
                    this.functionParam();
                    }
                    break;
                }
                this.state = 1429;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                while (_la === 476) {
                    {
                    {
                    this.state = 1422;
                    this.match(SparkSQLParser.COMMA);
                    this.state = 1425;
                    this.errorHandler.sync(this);
                    switch (this.interpreter.adaptivePredict(this.tokenStream, 148, this.context) ) {
                    case 1:
                        {
                        this.state = 1423;
                        this.funtionBody();
                        }
                        break;
                    case 2:
                        {
                        this.state = 1424;
                        this.functionParam();
                        }
                        break;
                    }
                    }
                    }
                    this.state = 1431;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                }
                this.state = 1432;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 1434;
                this.functionName();
                this.state = 1435;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 1438;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 150, this.context) ) {
                case 1:
                    {
                    this.state = 1436;
                    this.funtionBody();
                    }
                    break;
                case 2:
                    {
                    this.state = 1437;
                    this.functionParam();
                    }
                    break;
                }
                this.state = 1447;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                while (_la === 476) {
                    {
                    {
                    this.state = 1440;
                    this.match(SparkSQLParser.COMMA);
                    this.state = 1443;
                    this.errorHandler.sync(this);
                    switch (this.interpreter.adaptivePredict(this.tokenStream, 151, this.context) ) {
                    case 1:
                        {
                        this.state = 1441;
                        this.funtionBody();
                        }
                        break;
                    case 2:
                        {
                        this.state = 1442;
                        this.functionParam();
                        }
                        break;
                    }
                    }
                    }
                    this.state = 1449;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                }
                this.state = 1450;
                this.match(SparkSQLParser.RR_BRACKET);
                this.state = 1451;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 1452;
                this.match(SparkSQLParser.KW_AS);
                this.state = 1453;
                this.tableAlias();
                this.state = 1454;
                this.match(SparkSQLParser.RR_BRACKET);
                this.state = 1455;
                this.projectItemDefinition();
                this.state = 1460;
                this.errorHandler.sync(this);
                alternative = this.interpreter.adaptivePredict(this.tokenStream, 153, this.context);
                while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {
                    if (alternative === 1) {
                        {
                        {
                        this.state = 1456;
                        this.match(SparkSQLParser.COMMA);
                        this.state = 1457;
                        this.projectItemDefinition();
                        }
                        }
                    }
                    this.state = 1462;
                    this.errorHandler.sync(this);
                    alternative = this.interpreter.adaptivePredict(this.tokenStream, 153, this.context);
                }
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public unpivotBody(): UnpivotBodyContext {
        let localContext = new UnpivotBodyContext(this.context, this.state);
        this.enterRule(localContext, 152, SparkSQLParser.RULE_unpivotBody);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1467;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 155, this.context) ) {
            case 1:
                {
                this.state = 1465;
                this.columnName();
                }
                break;
            case 2:
                {
                this.state = 1466;
                this.columnNameList();
                }
                break;
            }
            this.state = 1469;
            this.match(SparkSQLParser.KW_FOR);
            this.state = 1470;
            this.columnName();
            this.state = 1471;
            this.match(SparkSQLParser.KW_IN);
            this.state = 1472;
            this.expressionAsAliasList();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public pivotBody(): PivotBodyContext {
        let localContext = new PivotBodyContext(this.context, this.state);
        this.enterRule(localContext, 154, SparkSQLParser.RULE_pivotBody);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1474;
            this.expressionAsAlias();
            {
            this.state = 1475;
            this.match(SparkSQLParser.COMMA);
            this.state = 1476;
            this.expressionAsAlias();
            }
            this.state = 1478;
            this.match(SparkSQLParser.KW_FOR);
            this.state = 1481;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 156, this.context) ) {
            case 1:
                {
                this.state = 1479;
                this.columnName();
                }
                break;
            case 2:
                {
                this.state = 1480;
                this.columnNameList();
                }
                break;
            }
            this.state = 1483;
            this.match(SparkSQLParser.KW_IN);
            this.state = 1484;
            this.expressionAsAliasList();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public expressionAsAlias(): ExpressionAsAliasContext {
        let localContext = new ExpressionAsAliasContext(this.context, this.state);
        this.enterRule(localContext, 156, SparkSQLParser.RULE_expressionAsAlias);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1486;
            this.expression();
            this.state = 1489;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 209) {
                {
                this.state = 1487;
                this.match(SparkSQLParser.KW_AS);
                this.state = 1488;
                this.columnAlias();
                }
            }

            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public expressionAsAliasList(): ExpressionAsAliasListContext {
        let localContext = new ExpressionAsAliasListContext(this.context, this.state);
        this.enterRule(localContext, 158, SparkSQLParser.RULE_expressionAsAliasList);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1491;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 1492;
            this.expressionAsAlias();
            this.state = 1497;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 476) {
                {
                {
                this.state = 1493;
                this.match(SparkSQLParser.COMMA);
                this.state = 1494;
                this.expressionAsAlias();
                }
                }
                this.state = 1499;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 1500;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public systemTimePeriod(): SystemTimePeriodContext {
        let localContext = new SystemTimePeriodContext(this.context, this.state);
        this.enterRule(localContext, 160, SparkSQLParser.RULE_systemTimePeriod);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1502;
            this.match(SparkSQLParser.KW_FOR);
            this.state = 1503;
            this.match(SparkSQLParser.KW_SYSTEM_TIME);
            this.state = 1504;
            this.match(SparkSQLParser.KW_AS);
            this.state = 1505;
            this.match(SparkSQLParser.KW_OF);
            this.state = 1506;
            this.dateTimeExpression();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public dateTimeExpression(): DateTimeExpressionContext {
        let localContext = new DateTimeExpressionContext(this.context, this.state);
        this.enterRule(localContext, 162, SparkSQLParser.RULE_dateTimeExpression);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1508;
            this.expression();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public inlineDataValueClause(): InlineDataValueClauseContext {
        let localContext = new InlineDataValueClauseContext(this.context, this.state);
        this.enterRule(localContext, 164, SparkSQLParser.RULE_inlineDataValueClause);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1510;
            this.expression();
            this.state = 1515;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 476) {
                {
                {
                this.state = 1511;
                this.match(SparkSQLParser.COMMA);
                this.state = 1512;
                this.expression();
                }
                }
                this.state = 1517;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 1519;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if ((((_la) & ~0x1F) === 0 && ((1 << _la) & 4294896624) !== 0) || ((((_la - 33)) & ~0x1F) === 0 && ((1 << (_la - 33)) & 4294803199) !== 0) || ((((_la - 65)) & ~0x1F) === 0 && ((1 << (_la - 65)) & 4281327607) !== 0) || ((((_la - 97)) & ~0x1F) === 0 && ((1 << (_la - 97)) & 2147483643) !== 0) || ((((_la - 129)) & ~0x1F) === 0 && ((1 << (_la - 129)) & 2113863675) !== 0) || ((((_la - 161)) & ~0x1F) === 0 && ((1 << (_la - 161)) & 4292341757) !== 0) || ((((_la - 193)) & ~0x1F) === 0 && ((1 << (_la - 193)) & 65783) !== 0) || _la === 335 || ((((_la - 479)) & ~0x1F) === 0 && ((1 << (_la - 479)) & 360449) !== 0)) {
                {
                this.state = 1518;
                this.tableAlias();
                }
            }

            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public windowTVFClause(): WindowTVFClauseContext {
        let localContext = new WindowTVFClauseContext(this.context, this.state);
        this.enterRule(localContext, 166, SparkSQLParser.RULE_windowTVFClause);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1521;
            this.match(SparkSQLParser.KW_TABLE);
            this.state = 1522;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 1523;
            this.windowTVFExpression();
            this.state = 1524;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public windowTVFExpression(): WindowTVFExpressionContext {
        let localContext = new WindowTVFExpressionContext(this.context, this.state);
        this.enterRule(localContext, 168, SparkSQLParser.RULE_windowTVFExpression);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1526;
            this.windowTVFName();
            this.state = 1527;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 1528;
            this.windowTVFParam();
            this.state = 1533;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 476) {
                {
                {
                this.state = 1529;
                this.match(SparkSQLParser.COMMA);
                this.state = 1530;
                this.windowTVFParam();
                }
                }
                this.state = 1535;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 1536;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public windowTVFName(): WindowTVFNameContext {
        let localContext = new WindowTVFNameContext(this.context, this.state);
        this.enterRule(localContext, 170, SparkSQLParser.RULE_windowTVFName);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1538;
            _la = this.tokenStream.LA(1);
            if(!(_la === 27 || _la === 64 || _la === 178)) {
            this.errorHandler.recoverInline(this);
            }
            else {
                this.errorHandler.reportMatch(this);
                this.consume();
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public rowFormatDelimited(): RowFormatDelimitedContext {
        let localContext = new RowFormatDelimitedContext(this.context, this.state);
        this.enterRule(localContext, 172, SparkSQLParser.RULE_rowFormatDelimited);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1540;
            this.sparkRecordWriterPart();
            this.state = 1541;
            this.usingAsColumnPart();
            this.state = 1542;
            this.sparkRecordWriterPart();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public hiveSerde(): HiveSerdeContext {
        let localContext = new HiveSerdeContext(this.context, this.state);
        this.enterRule(localContext, 174, SparkSQLParser.RULE_hiveSerde);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1544;
            this.hiveSerdePart();
            this.state = 1545;
            this.usingAsColumnPart();
            this.state = 1546;
            this.hiveSerdePart();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public usingAsColumnPart(): UsingAsColumnPartContext {
        let localContext = new UsingAsColumnPartContext(this.context, this.state);
        this.enterRule(localContext, 176, SparkSQLParser.RULE_usingAsColumnPart);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1548;
            this.match(SparkSQLParser.KW_USING);
            this.state = 1549;
            this.stringLiteral();
            this.state = 1550;
            this.match(SparkSQLParser.KW_AS);
            {
            this.state = 1553;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 162, this.context) ) {
            case 1:
                {
                this.state = 1551;
                this.columnNameList();
                }
                break;
            case 2:
                {
                this.state = 1552;
                this.physicalColumnDefinitionList();
                }
                break;
            }
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public hiveSerdePart(): HiveSerdePartContext {
        let localContext = new HiveSerdePartContext(this.context, this.state);
        this.enterRule(localContext, 178, SparkSQLParser.RULE_hiveSerdePart);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1559;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 395) {
                {
                this.state = 1555;
                this.match(SparkSQLParser.KW_ROW);
                this.state = 1556;
                this.match(SparkSQLParser.KW_FORMAT);
                this.state = 1557;
                this.match(SparkSQLParser.KW_SERDE);
                this.state = 1558;
                this.stringLiteral();
                }
            }

            this.state = 1564;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 449) {
                {
                this.state = 1561;
                this.match(SparkSQLParser.KW_WITH);
                this.state = 1562;
                this.match(SparkSQLParser.KW_SERDEPROPERTIES);
                this.state = 1563;
                this.tableCanHasKeyPropertyList();
                }
            }

            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public tableCanHasKeyPropertyList(): TableCanHasKeyPropertyListContext {
        let localContext = new TableCanHasKeyPropertyListContext(this.context, this.state);
        this.enterRule(localContext, 180, SparkSQLParser.RULE_tableCanHasKeyPropertyList);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1566;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 1569;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 165, this.context) ) {
            case 1:
                {
                this.state = 1567;
                this.tableProperty();
                }
                break;
            case 2:
                {
                this.state = 1568;
                this.tablePropertyKey();
                }
                break;
            }
            this.state = 1578;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 476) {
                {
                {
                this.state = 1571;
                this.match(SparkSQLParser.COMMA);
                this.state = 1574;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 166, this.context) ) {
                case 1:
                    {
                    this.state = 1572;
                    this.tableProperty();
                    }
                    break;
                case 2:
                    {
                    this.state = 1573;
                    this.tablePropertyKey();
                    }
                    break;
                }
                }
                }
                this.state = 1580;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 1581;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public sparkRecordWriterPart(): SparkRecordWriterPartContext {
        let localContext = new SparkRecordWriterPartContext(this.context, this.state);
        this.enterRule(localContext, 182, SparkSQLParser.RULE_sparkRecordWriterPart);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1584;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 168, this.context) ) {
            case 1:
                {
                this.state = 1583;
                this.rowFormatDelimted();
                }
                break;
            }
            this.state = 1587;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 169, this.context) ) {
            case 1:
                {
                this.state = 1586;
                this.fieldsTerminatedBy();
                }
                break;
            }
            this.state = 1593;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 170, this.context) ) {
            case 1:
                {
                this.state = 1589;
                this.match(SparkSQLParser.KW_LINES);
                this.state = 1590;
                this.match(SparkSQLParser.KW_TERMINATED);
                this.state = 1591;
                this.match(SparkSQLParser.KW_BY);
                this.state = 1592;
                this.stringLiteral();
                }
                break;
            }
            this.state = 1599;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 171, this.context) ) {
            case 1:
                {
                this.state = 1595;
                this.match(SparkSQLParser.KW_NULL);
                this.state = 1596;
                this.match(SparkSQLParser.KW_DEFINED);
                this.state = 1597;
                this.match(SparkSQLParser.KW_AS);
                this.state = 1598;
                this.stringLiteral();
                }
                break;
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public windowTVFParam(): WindowTVFParamContext {
        let localContext = new WindowTVFParamContext(this.context, this.state);
        this.enterRule(localContext, 184, SparkSQLParser.RULE_windowTVFParam);
        try {
            this.state = 1616;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 172, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 1601;
                this.match(SparkSQLParser.KW_TABLE);
                this.state = 1602;
                this.timeAttrColumn();
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 1603;
                this.columnDescriptor();
                }
                break;
            case 3:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 1604;
                this.timeIntervalExpression();
                }
                break;
            case 4:
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 1605;
                this.match(SparkSQLParser.KW_DATA);
                this.state = 1606;
                this.match(SparkSQLParser.DOUBLE_RIGHT_ARROW);
                this.state = 1607;
                this.match(SparkSQLParser.KW_TABLE);
                this.state = 1608;
                this.timeAttrColumn();
                }
                break;
            case 5:
                this.enterOuterAlt(localContext, 5);
                {
                this.state = 1609;
                this.match(SparkSQLParser.KW_TIMECOL);
                this.state = 1610;
                this.match(SparkSQLParser.DOUBLE_RIGHT_ARROW);
                this.state = 1611;
                this.columnDescriptor();
                }
                break;
            case 6:
                this.enterOuterAlt(localContext, 6);
                {
                this.state = 1612;
                this.timeIntervalParamName();
                this.state = 1613;
                this.match(SparkSQLParser.DOUBLE_RIGHT_ARROW);
                this.state = 1614;
                this.timeIntervalExpression();
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public timeIntervalParamName(): TimeIntervalParamNameContext {
        let localContext = new TimeIntervalParamNameContext(this.context, this.state);
        this.enterRule(localContext, 186, SparkSQLParser.RULE_timeIntervalParamName);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1618;
            _la = this.tokenStream.LA(1);
            if(!(_la === 28 || ((((_la - 156)) & ~0x1F) === 0 && ((1 << (_la - 156)) & 16643) !== 0) || _la === 357)) {
            this.errorHandler.recoverInline(this);
            }
            else {
                this.errorHandler.reportMatch(this);
                this.consume();
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public columnDescriptor(): ColumnDescriptorContext {
        let localContext = new ColumnDescriptorContext(this.context, this.state);
        this.enterRule(localContext, 188, SparkSQLParser.RULE_columnDescriptor);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1620;
            this.match(SparkSQLParser.KW_DESCRIPTOR);
            this.state = 1621;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 1622;
            this.uid();
            this.state = 1623;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public joinCondition(): JoinConditionContext {
        let localContext = new JoinConditionContext(this.context, this.state);
        this.enterRule(localContext, 190, SparkSQLParser.RULE_joinCondition);
        let _la: number;
        try {
            this.state = 1639;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.KW_ON:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 1625;
                this.match(SparkSQLParser.KW_ON);
                this.state = 1626;
                this.booleanExpression(0);
                }
                break;
            case SparkSQLParser.KW_USING:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 1627;
                this.match(SparkSQLParser.KW_USING);
                this.state = 1628;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 1629;
                this.uid();
                this.state = 1634;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                while (_la === 476) {
                    {
                    {
                    this.state = 1630;
                    this.match(SparkSQLParser.COMMA);
                    this.state = 1631;
                    this.uid();
                    }
                    }
                    this.state = 1636;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                }
                this.state = 1637;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public whereClause(): WhereClauseContext {
        let localContext = new WhereClauseContext(this.context, this.state);
        this.enterRule(localContext, 192, SparkSQLParser.RULE_whereClause);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1641;
            this.match(SparkSQLParser.KW_WHERE);
            this.state = 1642;
            this.booleanExpression(0);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public samplingQueries(): SamplingQueriesContext {
        let localContext = new SamplingQueriesContext(this.context, this.state);
        this.enterRule(localContext, 194, SparkSQLParser.RULE_samplingQueries);
        try {
            this.state = 1675;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 179, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 1644;
                this.match(SparkSQLParser.KW_TABLESAMPLE);
                this.state = 1645;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 1649;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 175, this.context) ) {
                case 1:
                    {
                    this.state = 1646;
                    this.decimalLiteral();
                    }
                    break;
                case 2:
                    {
                    this.state = 1647;
                    this.match(SparkSQLParser.DIG_LITERAL);
                    }
                    break;
                case 3:
                    {
                    this.state = 1648;
                    this.expression();
                    }
                    break;
                }
                this.state = 1651;
                this.match(SparkSQLParser.KW_PERCENT);
                this.state = 1652;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 1653;
                this.match(SparkSQLParser.KW_TABLESAMPLE);
                this.state = 1654;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 1657;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 176, this.context) ) {
                case 1:
                    {
                    this.state = 1655;
                    this.match(SparkSQLParser.DIG_LITERAL);
                    }
                    break;
                case 2:
                    {
                    this.state = 1656;
                    this.expression();
                    }
                    break;
                }
                this.state = 1659;
                this.match(SparkSQLParser.KW_ROWS);
                this.state = 1660;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case 3:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 1661;
                this.match(SparkSQLParser.KW_TABLESAMPLE);
                this.state = 1662;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 1663;
                this.match(SparkSQLParser.KW_BUCKET);
                this.state = 1666;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 177, this.context) ) {
                case 1:
                    {
                    this.state = 1664;
                    this.match(SparkSQLParser.DIG_LITERAL);
                    }
                    break;
                case 2:
                    {
                    this.state = 1665;
                    this.expression();
                    }
                    break;
                }
                this.state = 1668;
                this.match(SparkSQLParser.KW_OUT);
                this.state = 1669;
                this.match(SparkSQLParser.KW_OF);
                this.state = 1672;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 178, this.context) ) {
                case 1:
                    {
                    this.state = 1670;
                    this.match(SparkSQLParser.DIG_LITERAL);
                    }
                    break;
                case 2:
                    {
                    this.state = 1671;
                    this.expression();
                    }
                    break;
                }
                this.state = 1674;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public someByClause(): SomeByClauseContext {
        let localContext = new SomeByClauseContext(this.context, this.state);
        this.enterRule(localContext, 196, SparkSQLParser.RULE_someByClause);
        try {
            this.state = 1681;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.KW_CLUSTERED:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 1677;
                this.clusteredByClause();
                }
                break;
            case SparkSQLParser.KW_CLUSTER:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 1678;
                this.clusterByClause();
                }
                break;
            case SparkSQLParser.KW_DISTRIBUTE:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 1679;
                this.distributeByClause();
                }
                break;
            case SparkSQLParser.KW_GROUP:
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 1680;
                this.groupByClause();
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public clusterByClause(): ClusterByClauseContext {
        let localContext = new ClusterByClauseContext(this.context, this.state);
        this.enterRule(localContext, 198, SparkSQLParser.RULE_clusterByClause);
        try {
            let alternative: number;
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1683;
            this.match(SparkSQLParser.KW_CLUSTER);
            this.state = 1684;
            this.match(SparkSQLParser.KW_BY);
            this.state = 1685;
            this.groupItemDefinition();
            this.state = 1690;
            this.errorHandler.sync(this);
            alternative = this.interpreter.adaptivePredict(this.tokenStream, 181, this.context);
            while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {
                if (alternative === 1) {
                    {
                    {
                    this.state = 1686;
                    this.match(SparkSQLParser.COMMA);
                    this.state = 1687;
                    this.groupItemDefinition();
                    }
                    }
                }
                this.state = 1692;
                this.errorHandler.sync(this);
                alternative = this.interpreter.adaptivePredict(this.tokenStream, 181, this.context);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public clusteredByClause(): ClusteredByClauseContext {
        let localContext = new ClusteredByClauseContext(this.context, this.state);
        this.enterRule(localContext, 200, SparkSQLParser.RULE_clusteredByClause);
        try {
            let alternative: number;
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1693;
            this.match(SparkSQLParser.KW_CLUSTERED);
            this.state = 1694;
            this.match(SparkSQLParser.KW_BY);
            this.state = 1695;
            this.groupItemDefinition();
            this.state = 1700;
            this.errorHandler.sync(this);
            alternative = this.interpreter.adaptivePredict(this.tokenStream, 182, this.context);
            while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {
                if (alternative === 1) {
                    {
                    {
                    this.state = 1696;
                    this.match(SparkSQLParser.COMMA);
                    this.state = 1697;
                    this.groupItemDefinition();
                    }
                    }
                }
                this.state = 1702;
                this.errorHandler.sync(this);
                alternative = this.interpreter.adaptivePredict(this.tokenStream, 182, this.context);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public distributeByClause(): DistributeByClauseContext {
        let localContext = new DistributeByClauseContext(this.context, this.state);
        this.enterRule(localContext, 202, SparkSQLParser.RULE_distributeByClause);
        try {
            let alternative: number;
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1703;
            this.match(SparkSQLParser.KW_DISTRIBUTE);
            this.state = 1704;
            this.match(SparkSQLParser.KW_BY);
            this.state = 1705;
            this.groupItemDefinition();
            this.state = 1710;
            this.errorHandler.sync(this);
            alternative = this.interpreter.adaptivePredict(this.tokenStream, 183, this.context);
            while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {
                if (alternative === 1) {
                    {
                    {
                    this.state = 1706;
                    this.match(SparkSQLParser.COMMA);
                    this.state = 1707;
                    this.groupItemDefinition();
                    }
                    }
                }
                this.state = 1712;
                this.errorHandler.sync(this);
                alternative = this.interpreter.adaptivePredict(this.tokenStream, 183, this.context);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public groupByClause(): GroupByClauseContext {
        let localContext = new GroupByClauseContext(this.context, this.state);
        this.enterRule(localContext, 204, SparkSQLParser.RULE_groupByClause);
        try {
            let alternative: number;
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1713;
            this.match(SparkSQLParser.KW_GROUP);
            this.state = 1714;
            this.match(SparkSQLParser.KW_BY);
            this.state = 1715;
            this.groupItemDefinition();
            this.state = 1720;
            this.errorHandler.sync(this);
            alternative = this.interpreter.adaptivePredict(this.tokenStream, 184, this.context);
            while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {
                if (alternative === 1) {
                    {
                    {
                    this.state = 1716;
                    this.match(SparkSQLParser.COMMA);
                    this.state = 1717;
                    this.groupItemDefinition();
                    }
                    }
                }
                this.state = 1722;
                this.errorHandler.sync(this);
                alternative = this.interpreter.adaptivePredict(this.tokenStream, 184, this.context);
            }
            this.state = 1725;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 185, this.context) ) {
            case 1:
                {
                this.state = 1723;
                this.match(SparkSQLParser.KW_WITH);
                this.state = 1724;
                this.groupingSetsNotionName();
                }
                break;
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public groupItemDefinition(): GroupItemDefinitionContext {
        let localContext = new GroupItemDefinitionContext(this.context, this.state);
        this.enterRule(localContext, 206, SparkSQLParser.RULE_groupItemDefinition);
        let _la: number;
        try {
            let alternative: number;
            this.state = 1773;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 190, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 1727;
                this.expression();
                this.state = 1732;
                this.errorHandler.sync(this);
                alternative = this.interpreter.adaptivePredict(this.tokenStream, 186, this.context);
                while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {
                    if (alternative === 1) {
                        {
                        {
                        this.state = 1728;
                        this.match(SparkSQLParser.COMMA);
                        this.state = 1729;
                        this.expression();
                        }
                        }
                    }
                    this.state = 1734;
                    this.errorHandler.sync(this);
                    alternative = this.interpreter.adaptivePredict(this.tokenStream, 186, this.context);
                }
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 1735;
                this.groupWindowFunction();
                }
                break;
            case 3:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 1736;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 1737;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case 4:
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 1738;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 1739;
                this.expression();
                this.state = 1744;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                while (_la === 476) {
                    {
                    {
                    this.state = 1740;
                    this.match(SparkSQLParser.COMMA);
                    this.state = 1741;
                    this.expression();
                    }
                    }
                    this.state = 1746;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                }
                this.state = 1747;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case 5:
                this.enterOuterAlt(localContext, 5);
                {
                this.state = 1749;
                this.groupingSetsNotionName();
                this.state = 1750;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 1751;
                this.expression();
                this.state = 1756;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                while (_la === 476) {
                    {
                    {
                    this.state = 1752;
                    this.match(SparkSQLParser.COMMA);
                    this.state = 1753;
                    this.expression();
                    }
                    }
                    this.state = 1758;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                }
                this.state = 1759;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case 6:
                this.enterOuterAlt(localContext, 6);
                {
                this.state = 1761;
                this.groupingSets();
                this.state = 1762;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 1763;
                this.groupItemDefinition();
                this.state = 1768;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                while (_la === 476) {
                    {
                    {
                    this.state = 1764;
                    this.match(SparkSQLParser.COMMA);
                    this.state = 1765;
                    this.groupItemDefinition();
                    }
                    }
                    this.state = 1770;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                }
                this.state = 1771;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public groupingSets(): GroupingSetsContext {
        let localContext = new GroupingSetsContext(this.context, this.state);
        this.enterRule(localContext, 208, SparkSQLParser.RULE_groupingSets);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1775;
            this.match(SparkSQLParser.KW_GROUPING);
            this.state = 1776;
            this.match(SparkSQLParser.KW_SETS);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public groupingSetsNotionName(): GroupingSetsNotionNameContext {
        let localContext = new GroupingSetsNotionNameContext(this.context, this.state);
        this.enterRule(localContext, 210, SparkSQLParser.RULE_groupingSetsNotionName);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1778;
            _la = this.tokenStream.LA(1);
            if(!(_la === 250 || _la === 394)) {
            this.errorHandler.recoverInline(this);
            }
            else {
                this.errorHandler.reportMatch(this);
                this.consume();
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public groupWindowFunction(): GroupWindowFunctionContext {
        let localContext = new GroupWindowFunctionContext(this.context, this.state);
        this.enterRule(localContext, 212, SparkSQLParser.RULE_groupWindowFunction);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1780;
            this.groupWindowFunctionName();
            this.state = 1781;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 1782;
            this.timeAttrColumn();
            this.state = 1783;
            this.match(SparkSQLParser.COMMA);
            this.state = 1784;
            this.timeIntervalExpression();
            this.state = 1785;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public groupWindowFunctionName(): GroupWindowFunctionNameContext {
        let localContext = new GroupWindowFunctionNameContext(this.context, this.state);
        this.enterRule(localContext, 214, SparkSQLParser.RULE_groupWindowFunctionName);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1787;
            _la = this.tokenStream.LA(1);
            if(!(_la === 64 || _la === 152 || _la === 178)) {
            this.errorHandler.recoverInline(this);
            }
            else {
                this.errorHandler.reportMatch(this);
                this.consume();
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public timeAttrColumn(): TimeAttrColumnContext {
        let localContext = new TimeAttrColumnContext(this.context, this.state);
        this.enterRule(localContext, 216, SparkSQLParser.RULE_timeAttrColumn);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1789;
            this.uid();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public havingClause(): HavingClauseContext {
        let localContext = new HavingClauseContext(this.context, this.state);
        this.enterRule(localContext, 218, SparkSQLParser.RULE_havingClause);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1791;
            this.match(SparkSQLParser.KW_HAVING);
            this.state = 1792;
            this.booleanExpression(0);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public windowClause(): WindowClauseContext {
        let localContext = new WindowClauseContext(this.context, this.state);
        this.enterRule(localContext, 220, SparkSQLParser.RULE_windowClause);
        try {
            let alternative: number;
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1794;
            this.match(SparkSQLParser.KW_WINDOW);
            this.state = 1795;
            this.namedWindow();
            this.state = 1800;
            this.errorHandler.sync(this);
            alternative = this.interpreter.adaptivePredict(this.tokenStream, 191, this.context);
            while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {
                if (alternative === 1) {
                    {
                    {
                    this.state = 1796;
                    this.match(SparkSQLParser.COMMA);
                    this.state = 1797;
                    this.namedWindow();
                    }
                    }
                }
                this.state = 1802;
                this.errorHandler.sync(this);
                alternative = this.interpreter.adaptivePredict(this.tokenStream, 191, this.context);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public namedWindow(): NamedWindowContext {
        let localContext = new NamedWindowContext(this.context, this.state);
        this.enterRule(localContext, 222, SparkSQLParser.RULE_namedWindow);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1803;
            localContext._name = this.errorCapturingIdentifier();
            this.state = 1804;
            this.match(SparkSQLParser.KW_AS);
            this.state = 1805;
            this.windowSpec();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public windowSpec(): WindowSpecContext {
        let localContext = new WindowSpecContext(this.context, this.state);
        this.enterRule(localContext, 224, SparkSQLParser.RULE_windowSpec);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1808;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if ((((_la) & ~0x1F) === 0 && ((1 << _la) & 4294896624) !== 0) || ((((_la - 33)) & ~0x1F) === 0 && ((1 << (_la - 33)) & 4294803199) !== 0) || ((((_la - 65)) & ~0x1F) === 0 && ((1 << (_la - 65)) & 4281327607) !== 0) || ((((_la - 97)) & ~0x1F) === 0 && ((1 << (_la - 97)) & 2147483643) !== 0) || ((((_la - 129)) & ~0x1F) === 0 && ((1 << (_la - 129)) & 2113863675) !== 0) || ((((_la - 161)) & ~0x1F) === 0 && ((1 << (_la - 161)) & 4292341757) !== 0) || ((((_la - 193)) & ~0x1F) === 0 && ((1 << (_la - 193)) & 247) !== 0) || _la === 335 || ((((_la - 479)) & ~0x1F) === 0 && ((1 << (_la - 479)) & 360449) !== 0)) {
                {
                this.state = 1807;
                localContext._name = this.errorCapturingIdentifier();
                }
            }

            this.state = 1810;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 1812;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 368) {
                {
                this.state = 1811;
                this.partitionByClause();
                }
            }

            this.state = 1815;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 411) {
                {
                this.state = 1814;
                this.sortByCaluse();
                }
            }

            this.state = 1818;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 361) {
                {
                this.state = 1817;
                this.orderByCaluse();
                }
            }

            this.state = 1821;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 383 || _la === 396) {
                {
                this.state = 1820;
                this.windowFrame();
                }
            }

            this.state = 1823;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public matchRecognizeClause(): MatchRecognizeClauseContext {
        let localContext = new MatchRecognizeClauseContext(this.context, this.state);
        this.enterRule(localContext, 226, SparkSQLParser.RULE_matchRecognizeClause);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1825;
            this.match(SparkSQLParser.KW_MATCH_RECOGNIZE);
            this.state = 1826;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 1828;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 368) {
                {
                this.state = 1827;
                this.partitionByClause();
                }
            }

            this.state = 1831;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 411) {
                {
                this.state = 1830;
                this.sortByCaluse();
                }
            }

            this.state = 1834;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 361) {
                {
                this.state = 1833;
                this.orderByCaluse();
                }
            }

            this.state = 1837;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 338) {
                {
                this.state = 1836;
                this.measuresClause();
                }
            }

            this.state = 1840;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 202 || _la === 359) {
                {
                this.state = 1839;
                this.outputMode();
                }
            }

            this.state = 1843;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 6) {
                {
                this.state = 1842;
                this.afterMatchStrategy();
                }
            }

            this.state = 1846;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 369) {
                {
                this.state = 1845;
                this.patternDefinition();
                }
            }

            this.state = 1848;
            this.patternVariablesDefinition();
            this.state = 1849;
            this.match(SparkSQLParser.RR_BRACKET);
            this.state = 1854;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 205, this.context) ) {
            case 1:
                {
                this.state = 1851;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 209) {
                    {
                    this.state = 1850;
                    this.match(SparkSQLParser.KW_AS);
                    }
                }

                this.state = 1853;
                this.identifier();
                }
                break;
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public orderByCaluse(): OrderByCaluseContext {
        let localContext = new OrderByCaluseContext(this.context, this.state);
        this.enterRule(localContext, 228, SparkSQLParser.RULE_orderByCaluse);
        try {
            let alternative: number;
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1856;
            this.match(SparkSQLParser.KW_ORDER);
            this.state = 1857;
            this.match(SparkSQLParser.KW_BY);
            this.state = 1858;
            this.orderItemDefinition();
            this.state = 1863;
            this.errorHandler.sync(this);
            alternative = this.interpreter.adaptivePredict(this.tokenStream, 206, this.context);
            while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {
                if (alternative === 1) {
                    {
                    {
                    this.state = 1859;
                    this.match(SparkSQLParser.COMMA);
                    this.state = 1860;
                    this.orderItemDefinition();
                    }
                    }
                }
                this.state = 1865;
                this.errorHandler.sync(this);
                alternative = this.interpreter.adaptivePredict(this.tokenStream, 206, this.context);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public sortByCaluse(): SortByCaluseContext {
        let localContext = new SortByCaluseContext(this.context, this.state);
        this.enterRule(localContext, 230, SparkSQLParser.RULE_sortByCaluse);
        try {
            let alternative: number;
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1866;
            this.match(SparkSQLParser.KW_SORT);
            this.state = 1867;
            this.match(SparkSQLParser.KW_BY);
            this.state = 1868;
            this.orderItemDefinition();
            this.state = 1873;
            this.errorHandler.sync(this);
            alternative = this.interpreter.adaptivePredict(this.tokenStream, 207, this.context);
            while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {
                if (alternative === 1) {
                    {
                    {
                    this.state = 1869;
                    this.match(SparkSQLParser.COMMA);
                    this.state = 1870;
                    this.orderItemDefinition();
                    }
                    }
                }
                this.state = 1875;
                this.errorHandler.sync(this);
                alternative = this.interpreter.adaptivePredict(this.tokenStream, 207, this.context);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public orderItemDefinition(): OrderItemDefinitionContext {
        let localContext = new OrderItemDefinitionContext(this.context, this.state);
        this.enterRule(localContext, 232, SparkSQLParser.RULE_orderItemDefinition);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1876;
            this.expression();
            this.state = 1878;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 208, this.context) ) {
            case 1:
                {
                this.state = 1877;
                localContext._ordering = this.tokenStream.LT(1);
                _la = this.tokenStream.LA(1);
                if(!(_la === 8 || _la === 35)) {
                    localContext._ordering = this.errorHandler.recoverInline(this);
                }
                else {
                    this.errorHandler.reportMatch(this);
                    this.consume();
                }
                }
                break;
            }
            this.state = 1882;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 209, this.context) ) {
            case 1:
                {
                this.state = 1880;
                this.match(SparkSQLParser.KW_NULLS);
                this.state = 1881;
                localContext._nullOrder = this.tokenStream.LT(1);
                _la = this.tokenStream.LA(1);
                if(!(_la === 52 || _la === 82)) {
                    localContext._nullOrder = this.errorHandler.recoverInline(this);
                }
                else {
                    this.errorHandler.reportMatch(this);
                    this.consume();
                }
                }
                break;
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public limitClause(): LimitClauseContext {
        let localContext = new LimitClauseContext(this.context, this.state);
        this.enterRule(localContext, 234, SparkSQLParser.RULE_limitClause);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1884;
            this.match(SparkSQLParser.KW_LIMIT);
            this.state = 1887;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.KW_ALL:
                {
                this.state = 1885;
                this.match(SparkSQLParser.KW_ALL);
                }
                break;
            case SparkSQLParser.KW_ADD:
            case SparkSQLParser.KW_ADMIN:
            case SparkSQLParser.KW_AFTER:
            case SparkSQLParser.KW_ANALYZE:
            case SparkSQLParser.KW_ASC:
            case SparkSQLParser.KW_BEFORE:
            case SparkSQLParser.KW_BYTES:
            case SparkSQLParser.KW_CASCADE:
            case SparkSQLParser.KW_CATALOG:
            case SparkSQLParser.KW_CATALOGS:
            case SparkSQLParser.KW_CENTURY:
            case SparkSQLParser.KW_CHAIN:
            case SparkSQLParser.KW_CHANGELOG_MODE:
            case SparkSQLParser.KW_CHARACTERS:
            case SparkSQLParser.KW_COMMENT:
            case SparkSQLParser.KW_COMPACT:
            case SparkSQLParser.KW_COLUMNS:
            case SparkSQLParser.KW_CONSTRAINTS:
            case SparkSQLParser.KW_CONSTRUCTOR:
            case SparkSQLParser.KW_COMPUTE:
            case SparkSQLParser.KW_CUMULATE:
            case SparkSQLParser.KW_DATA:
            case SparkSQLParser.KW_DATABASE:
            case SparkSQLParser.KW_DATABASES:
            case SparkSQLParser.KW_DAYS:
            case SparkSQLParser.KW_DECADE:
            case SparkSQLParser.KW_DEFINED:
            case SparkSQLParser.KW_DESC:
            case SparkSQLParser.KW_DESCRIPTOR:
            case SparkSQLParser.KW_DIV:
            case SparkSQLParser.KW_ENCODING:
            case SparkSQLParser.KW_ENFORCED:
            case SparkSQLParser.KW_ENGINE:
            case SparkSQLParser.KW_ERROR:
            case SparkSQLParser.KW_ESTIMATED_COST:
            case SparkSQLParser.KW_EXCEPTION:
            case SparkSQLParser.KW_EXCLUDE:
            case SparkSQLParser.KW_EXCLUDING:
            case SparkSQLParser.KW_EXTENDED:
            case SparkSQLParser.KW_FILE:
            case SparkSQLParser.KW_FINAL:
            case SparkSQLParser.KW_FIRST:
            case SparkSQLParser.KW_FOLLOWING:
            case SparkSQLParser.KW_FORMAT:
            case SparkSQLParser.KW_FORTRAN:
            case SparkSQLParser.KW_FOUND:
            case SparkSQLParser.KW_FRAC_SECOND:
            case SparkSQLParser.KW_FUNCTIONS:
            case SparkSQLParser.KW_GENERAL:
            case SparkSQLParser.KW_GENERATED:
            case SparkSQLParser.KW_GO:
            case SparkSQLParser.KW_GOTO:
            case SparkSQLParser.KW_GRANTED:
            case SparkSQLParser.KW_HOP:
            case SparkSQLParser.KW_HOURS:
            case SparkSQLParser.KW_IF:
            case SparkSQLParser.KW_IGNORE:
            case SparkSQLParser.KW_INCREMENT:
            case SparkSQLParser.KW_INPUT:
            case SparkSQLParser.KW_INVOKER:
            case SparkSQLParser.KW_JAR:
            case SparkSQLParser.KW_JARS:
            case SparkSQLParser.KW_JAVA:
            case SparkSQLParser.KW_JSON:
            case SparkSQLParser.KW_JSON_EXECUTION_PLAN:
            case SparkSQLParser.KW_KEY:
            case SparkSQLParser.KW_KEY_MEMBER:
            case SparkSQLParser.KW_KEY_TYPE:
            case SparkSQLParser.KW_LABEL:
            case SparkSQLParser.KW_LAST:
            case SparkSQLParser.KW_LENGTH:
            case SparkSQLParser.KW_LEVEL:
            case SparkSQLParser.KW_LOAD:
            case SparkSQLParser.KW_MAP:
            case SparkSQLParser.KW_MICROSECOND:
            case SparkSQLParser.KW_MILLENNIUM:
            case SparkSQLParser.KW_MILLISECOND:
            case SparkSQLParser.KW_MINUTES:
            case SparkSQLParser.KW_MINVALUE:
            case SparkSQLParser.KW_MODIFY:
            case SparkSQLParser.KW_MODULES:
            case SparkSQLParser.KW_MONTHS:
            case SparkSQLParser.KW_NANOSECOND:
            case SparkSQLParser.KW_NULLS:
            case SparkSQLParser.KW_NUMBER:
            case SparkSQLParser.KW_OPTION:
            case SparkSQLParser.KW_OPTIONS:
            case SparkSQLParser.KW_ORDERING:
            case SparkSQLParser.KW_OUTPUT:
            case SparkSQLParser.KW_OVERWRITE:
            case SparkSQLParser.KW_OVERWRITING:
            case SparkSQLParser.KW_PARTITIONED:
            case SparkSQLParser.KW_PARTITIONS:
            case SparkSQLParser.KW_PASSING:
            case SparkSQLParser.KW_PAST:
            case SparkSQLParser.KW_PATH:
            case SparkSQLParser.KW_PLACING:
            case SparkSQLParser.KW_PLAN:
            case SparkSQLParser.KW_PRECEDING:
            case SparkSQLParser.KW_PRESERVE:
            case SparkSQLParser.KW_PRIOR:
            case SparkSQLParser.KW_PRIVILEGES:
            case SparkSQLParser.KW_PUBLIC:
            case SparkSQLParser.KW_PYTHON:
            case SparkSQLParser.KW_PYTHON_FILES:
            case SparkSQLParser.KW_PYTHON_REQUIREMENTS:
            case SparkSQLParser.KW_PYTHON_DEPENDENCIES:
            case SparkSQLParser.KW_PYTHON_JAR:
            case SparkSQLParser.KW_PYTHON_ARCHIVES:
            case SparkSQLParser.KW_PYTHON_PARAMETER:
            case SparkSQLParser.KW_QUARTER:
            case SparkSQLParser.KW_RAW:
            case SparkSQLParser.KW_READ:
            case SparkSQLParser.KW_RELATIVE:
            case SparkSQLParser.KW_REMOVE:
            case SparkSQLParser.KW_RENAME:
            case SparkSQLParser.KW_REPLACE:
            case SparkSQLParser.KW_RESPECT:
            case SparkSQLParser.KW_RESTART:
            case SparkSQLParser.KW_RESTRICT:
            case SparkSQLParser.KW_ROLE:
            case SparkSQLParser.KW_ROW_COUNT:
            case SparkSQLParser.KW_SCALA:
            case SparkSQLParser.KW_SCALAR:
            case SparkSQLParser.KW_SCALE:
            case SparkSQLParser.KW_SCHEMA:
            case SparkSQLParser.KW_SECONDS:
            case SparkSQLParser.KW_SECTION:
            case SparkSQLParser.KW_SECURITY:
            case SparkSQLParser.KW_SELF:
            case SparkSQLParser.KW_SERVER:
            case SparkSQLParser.KW_SERVER_NAME:
            case SparkSQLParser.KW_SESSION:
            case SparkSQLParser.KW_SETS:
            case SparkSQLParser.KW_SIMPLE:
            case SparkSQLParser.KW_SIZE:
            case SparkSQLParser.KW_SLIDE:
            case SparkSQLParser.KW_SOURCE:
            case SparkSQLParser.KW_SPACE:
            case SparkSQLParser.KW_STATE:
            case SparkSQLParser.KW_STATEMENT:
            case SparkSQLParser.KW_STEP:
            case SparkSQLParser.KW_STRING:
            case SparkSQLParser.KW_STRUCTURE:
            case SparkSQLParser.KW_STYLE:
            case SparkSQLParser.KW_TABLES:
            case SparkSQLParser.KW_TEMPORARY:
            case SparkSQLParser.KW_TIMECOL:
            case SparkSQLParser.KW_FLOOR:
            case SparkSQLParser.KW_TIMESTAMP_LTZ:
            case SparkSQLParser.KW_TIMESTAMPADD:
            case SparkSQLParser.KW_TIMESTAMPDIFF:
            case SparkSQLParser.KW_TOTIMESTAMP:
            case SparkSQLParser.KW_TRANSFORM:
            case SparkSQLParser.KW_TUMBLE:
            case SparkSQLParser.KW_TYPE:
            case SparkSQLParser.KW_UNDER:
            case SparkSQLParser.KW_UNLOAD:
            case SparkSQLParser.KW_USAGE:
            case SparkSQLParser.KW_USE:
            case SparkSQLParser.KW_UTF16:
            case SparkSQLParser.KW_UTF32:
            case SparkSQLParser.KW_UTF8:
            case SparkSQLParser.KW_VERSION:
            case SparkSQLParser.KW_VIEW:
            case SparkSQLParser.KW_VIEWS:
            case SparkSQLParser.KW_VIRTUAL:
            case SparkSQLParser.KW_WATERMARK:
            case SparkSQLParser.KW_WATERMARKS:
            case SparkSQLParser.KW_WEEK:
            case SparkSQLParser.KW_WORK:
            case SparkSQLParser.KW_WRAPPER:
            case SparkSQLParser.KW_YEARS:
            case SparkSQLParser.KW_ZONE:
            case SparkSQLParser.KW_ABS:
            case SparkSQLParser.KW_ARRAY:
            case SparkSQLParser.KW_AVG:
            case SparkSQLParser.KW_CASE:
            case SparkSQLParser.KW_CAST:
            case SparkSQLParser.KW_CEIL:
            case SparkSQLParser.KW_COALESCE:
            case SparkSQLParser.KW_COLLECT:
            case SparkSQLParser.KW_COUNT:
            case SparkSQLParser.KW_CURRENT_TIMESTAMP:
            case SparkSQLParser.KW_DATE:
            case SparkSQLParser.KW_DAY:
            case SparkSQLParser.KW_EXISTS:
            case SparkSQLParser.KW_EXPLODE:
            case SparkSQLParser.KW_FIRST_VALUE:
            case SparkSQLParser.KW_FALSE:
            case SparkSQLParser.KW_FROM_UNIXTIME:
            case SparkSQLParser.KW_GROUPING:
            case SparkSQLParser.KW_HOUR:
            case SparkSQLParser.KW_INTERVAL:
            case SparkSQLParser.KW_LAG:
            case SparkSQLParser.KW_LAST_VALUE:
            case SparkSQLParser.KW_LEAD:
            case SparkSQLParser.KW_LEFT:
            case SparkSQLParser.KW_LOCALTIMESTAMP:
            case SparkSQLParser.KW_MINUTE:
            case SparkSQLParser.KW_MONTH:
            case SparkSQLParser.KW_NOT:
            case SparkSQLParser.KW_NTILE:
            case SparkSQLParser.KW_NULL:
            case SparkSQLParser.KW_OVERLAY:
            case SparkSQLParser.KW_PERCENT_RANK:
            case SparkSQLParser.KW_PERCENTILE_CONT:
            case SparkSQLParser.KW_PERCENTILE_DISC:
            case SparkSQLParser.KW_POSITION:
            case SparkSQLParser.KW_POWER:
            case SparkSQLParser.KW_RANGE:
            case SparkSQLParser.KW_ROW_NUMBER:
            case SparkSQLParser.KW_RANK:
            case SparkSQLParser.KW_RIGHT:
            case SparkSQLParser.KW_ROW:
            case SparkSQLParser.KW_SECOND:
            case SparkSQLParser.KW_STRUCT:
            case SparkSQLParser.KW_SUBSTRING:
            case SparkSQLParser.KW_SUM:
            case SparkSQLParser.KW_TIME:
            case SparkSQLParser.KW_TIMESTAMP:
            case SparkSQLParser.KW_TIMESTAMP_3:
            case SparkSQLParser.KW_TIMESTAMP_6:
            case SparkSQLParser.KW_TIMESTAMP_9:
            case SparkSQLParser.KW_TRUE:
            case SparkSQLParser.KW_TRUNCATE:
            case SparkSQLParser.KW_UPPER:
            case SparkSQLParser.KW_YEAR:
            case SparkSQLParser.BIT_NOT_OP:
            case SparkSQLParser.LR_BRACKET:
            case SparkSQLParser.DOLLAR:
            case SparkSQLParser.ASTERISK_SIGN:
            case SparkSQLParser.HYPNEN_SIGN:
            case SparkSQLParser.ADD_SIGN:
            case SparkSQLParser.STRING_LITERAL:
            case SparkSQLParser.DIG_LITERAL:
            case SparkSQLParser.REAL_LITERAL:
            case SparkSQLParser.ID_LITERAL:
                {
                this.state = 1886;
                localContext._limit = this.expression();
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public offsetClause(): OffsetClauseContext {
        let localContext = new OffsetClauseContext(this.context, this.state);
        this.enterRule(localContext, 236, SparkSQLParser.RULE_offsetClause);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1889;
            this.match(SparkSQLParser.KW_OFFSET);
            this.state = 1892;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 211, this.context) ) {
            case 1:
                {
                this.state = 1890;
                this.match(SparkSQLParser.DIG_LITERAL);
                }
                break;
            case 2:
                {
                this.state = 1891;
                this.expression();
                }
                break;
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public partitionByClause(): PartitionByClauseContext {
        let localContext = new PartitionByClauseContext(this.context, this.state);
        this.enterRule(localContext, 238, SparkSQLParser.RULE_partitionByClause);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1894;
            this.match(SparkSQLParser.KW_PARTITION);
            this.state = 1895;
            this.match(SparkSQLParser.KW_BY);
            this.state = 1896;
            this.expression();
            this.state = 1901;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 476) {
                {
                {
                this.state = 1897;
                this.match(SparkSQLParser.COMMA);
                this.state = 1898;
                this.expression();
                }
                }
                this.state = 1903;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public quantifiers(): QuantifiersContext {
        let localContext = new QuantifiersContext(this.context, this.state);
        this.enterRule(localContext, 240, SparkSQLParser.RULE_quantifiers);
        try {
            this.state = 1920;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 213, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                {
                this.state = 1904;
                this.match(SparkSQLParser.ASTERISK_SIGN);
                }
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                {
                this.state = 1905;
                this.match(SparkSQLParser.ADD_SIGN);
                }
                }
                break;
            case 3:
                this.enterOuterAlt(localContext, 3);
                {
                {
                this.state = 1906;
                this.match(SparkSQLParser.QUESTION_MARK_SIGN);
                }
                }
                break;
            case 4:
                this.enterOuterAlt(localContext, 4);
                {
                {
                this.state = 1907;
                this.match(SparkSQLParser.LB_BRACKET);
                this.state = 1908;
                this.match(SparkSQLParser.DIG_LITERAL);
                this.state = 1909;
                this.match(SparkSQLParser.COMMA);
                this.state = 1910;
                this.match(SparkSQLParser.DIG_LITERAL);
                this.state = 1911;
                this.match(SparkSQLParser.RB_BRACKET);
                }
                }
                break;
            case 5:
                this.enterOuterAlt(localContext, 5);
                {
                {
                this.state = 1912;
                this.match(SparkSQLParser.LB_BRACKET);
                this.state = 1913;
                this.match(SparkSQLParser.DIG_LITERAL);
                this.state = 1914;
                this.match(SparkSQLParser.COMMA);
                this.state = 1915;
                this.match(SparkSQLParser.RB_BRACKET);
                }
                }
                break;
            case 6:
                this.enterOuterAlt(localContext, 6);
                {
                {
                this.state = 1916;
                this.match(SparkSQLParser.LB_BRACKET);
                this.state = 1917;
                this.match(SparkSQLParser.COMMA);
                this.state = 1918;
                this.match(SparkSQLParser.DIG_LITERAL);
                this.state = 1919;
                this.match(SparkSQLParser.RB_BRACKET);
                }
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public measuresClause(): MeasuresClauseContext {
        let localContext = new MeasuresClauseContext(this.context, this.state);
        this.enterRule(localContext, 242, SparkSQLParser.RULE_measuresClause);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1922;
            this.match(SparkSQLParser.KW_MEASURES);
            this.state = 1923;
            this.projectItemDefinition();
            this.state = 1928;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 476) {
                {
                {
                this.state = 1924;
                this.match(SparkSQLParser.COMMA);
                this.state = 1925;
                this.projectItemDefinition();
                }
                }
                this.state = 1930;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public patternDefinition(): PatternDefinitionContext {
        let localContext = new PatternDefinitionContext(this.context, this.state);
        this.enterRule(localContext, 244, SparkSQLParser.RULE_patternDefinition);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1931;
            this.match(SparkSQLParser.KW_PATTERN);
            this.state = 1932;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 1934;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            do {
                {
                {
                this.state = 1933;
                this.patternVariable();
                }
                }
                this.state = 1936;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            } while (_la === 495 || _la === 497);
            this.state = 1938;
            this.match(SparkSQLParser.RR_BRACKET);
            this.state = 1940;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 450) {
                {
                this.state = 1939;
                this.withinClause();
                }
            }

            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public patternVariable(): PatternVariableContext {
        let localContext = new PatternVariableContext(this.context, this.state);
        this.enterRule(localContext, 246, SparkSQLParser.RULE_patternVariable);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1942;
            this.unquotedIdentifier();
            this.state = 1944;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (((((_la - 474)) & ~0x1F) === 0 && ((1 << (_la - 474)) & 271361) !== 0)) {
                {
                this.state = 1943;
                this.quantifiers();
                }
            }

            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public outputMode(): OutputModeContext {
        let localContext = new OutputModeContext(this.context, this.state);
        this.enterRule(localContext, 248, SparkSQLParser.RULE_outputMode);
        try {
            this.state = 1954;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.KW_ALL:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 1946;
                this.match(SparkSQLParser.KW_ALL);
                this.state = 1947;
                this.match(SparkSQLParser.KW_ROWS);
                this.state = 1948;
                this.match(SparkSQLParser.KW_PER);
                this.state = 1949;
                this.match(SparkSQLParser.KW_MATCH);
                }
                break;
            case SparkSQLParser.KW_ONE:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 1950;
                this.match(SparkSQLParser.KW_ONE);
                this.state = 1951;
                this.match(SparkSQLParser.KW_ROW);
                this.state = 1952;
                this.match(SparkSQLParser.KW_PER);
                this.state = 1953;
                this.match(SparkSQLParser.KW_MATCH);
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public afterMatchStrategy(): AfterMatchStrategyContext {
        let localContext = new AfterMatchStrategyContext(this.context, this.state);
        this.enterRule(localContext, 250, SparkSQLParser.RULE_afterMatchStrategy);
        try {
            this.state = 1980;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 219, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 1956;
                this.match(SparkSQLParser.KW_AFTER);
                this.state = 1957;
                this.match(SparkSQLParser.KW_MATCH);
                this.state = 1958;
                this.match(SparkSQLParser.KW_SKIP);
                this.state = 1959;
                this.match(SparkSQLParser.KW_PAST);
                this.state = 1960;
                this.match(SparkSQLParser.KW_LAST);
                this.state = 1961;
                this.match(SparkSQLParser.KW_ROW);
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 1962;
                this.match(SparkSQLParser.KW_AFTER);
                this.state = 1963;
                this.match(SparkSQLParser.KW_MATCH);
                this.state = 1964;
                this.match(SparkSQLParser.KW_SKIP);
                this.state = 1965;
                this.match(SparkSQLParser.KW_TO);
                this.state = 1966;
                this.match(SparkSQLParser.KW_NEXT);
                this.state = 1967;
                this.match(SparkSQLParser.KW_ROW);
                }
                break;
            case 3:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 1968;
                this.match(SparkSQLParser.KW_AFTER);
                this.state = 1969;
                this.match(SparkSQLParser.KW_MATCH);
                this.state = 1970;
                this.match(SparkSQLParser.KW_SKIP);
                this.state = 1971;
                this.match(SparkSQLParser.KW_TO);
                this.state = 1972;
                this.match(SparkSQLParser.KW_LAST);
                this.state = 1973;
                this.unquotedIdentifier();
                }
                break;
            case 4:
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 1974;
                this.match(SparkSQLParser.KW_AFTER);
                this.state = 1975;
                this.match(SparkSQLParser.KW_MATCH);
                this.state = 1976;
                this.match(SparkSQLParser.KW_SKIP);
                this.state = 1977;
                this.match(SparkSQLParser.KW_TO);
                this.state = 1978;
                this.match(SparkSQLParser.KW_FIRST);
                this.state = 1979;
                this.unquotedIdentifier();
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public patternVariablesDefinition(): PatternVariablesDefinitionContext {
        let localContext = new PatternVariablesDefinitionContext(this.context, this.state);
        this.enterRule(localContext, 252, SparkSQLParser.RULE_patternVariablesDefinition);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1982;
            this.match(SparkSQLParser.KW_DEFINE);
            this.state = 1983;
            this.projectItemDefinition();
            this.state = 1988;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 476) {
                {
                {
                this.state = 1984;
                this.match(SparkSQLParser.COMMA);
                this.state = 1985;
                this.projectItemDefinition();
                }
                }
                this.state = 1990;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public windowFrame(): WindowFrameContext {
        let localContext = new WindowFrameContext(this.context, this.state);
        this.enterRule(localContext, 254, SparkSQLParser.RULE_windowFrame);
        try {
            this.state = 2000;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.KW_RANGE:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 1991;
                this.match(SparkSQLParser.KW_RANGE);
                this.state = 1992;
                this.match(SparkSQLParser.KW_BETWEEN);
                this.state = 1993;
                this.timeIntervalExpression();
                this.state = 1994;
                this.frameBound();
                }
                break;
            case SparkSQLParser.KW_ROWS:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 1996;
                this.match(SparkSQLParser.KW_ROWS);
                this.state = 1997;
                this.match(SparkSQLParser.KW_BETWEEN);
                this.state = 1998;
                this.match(SparkSQLParser.DIG_LITERAL);
                this.state = 1999;
                this.frameBound();
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public frameBound(): FrameBoundContext {
        let localContext = new FrameBoundContext(this.context, this.state);
        this.enterRule(localContext, 256, SparkSQLParser.RULE_frameBound);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2002;
            this.match(SparkSQLParser.KW_PRECEDING);
            this.state = 2003;
            this.match(SparkSQLParser.KW_AND);
            this.state = 2004;
            this.match(SparkSQLParser.KW_CURRENT);
            this.state = 2005;
            this.match(SparkSQLParser.KW_ROW);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public withinClause(): WithinClauseContext {
        let localContext = new WithinClauseContext(this.context, this.state);
        this.enterRule(localContext, 258, SparkSQLParser.RULE_withinClause);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2007;
            this.match(SparkSQLParser.KW_WITHIN);
            this.state = 2008;
            this.timeIntervalExpression();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public selfDefinitionClause(): SelfDefinitionClauseContext {
        let localContext = new SelfDefinitionClauseContext(this.context, this.state);
        this.enterRule(localContext, 260, SparkSQLParser.RULE_selfDefinitionClause);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2010;
            this.match(SparkSQLParser.KW_PERIOD);
            this.state = 2011;
            this.match(SparkSQLParser.KW_FOR);
            this.state = 2012;
            this.match(SparkSQLParser.KW_SYSTEM_TIME);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public partitionDefinition(): PartitionDefinitionContext {
        let localContext = new PartitionDefinitionContext(this.context, this.state);
        this.enterRule(localContext, 262, SparkSQLParser.RULE_partitionDefinition);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2014;
            this.match(SparkSQLParser.KW_PARTITIONED);
            this.state = 2015;
            this.match(SparkSQLParser.KW_BY);
            this.state = 2016;
            this.transformList();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public transformList(): TransformListContext {
        let localContext = new TransformListContext(this.context, this.state);
        this.enterRule(localContext, 264, SparkSQLParser.RULE_transformList);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2018;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 2019;
            this.transform();
            this.state = 2021;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if ((((_la) & ~0x1F) === 0 && ((1 << _la) & 4294897648) !== 0) || ((((_la - 33)) & ~0x1F) === 0 && ((1 << (_la - 33)) & 4294803199) !== 0) || ((((_la - 65)) & ~0x1F) === 0 && ((1 << (_la - 65)) & 4289716215) !== 0) || ((((_la - 97)) & ~0x1F) === 0 && ((1 << (_la - 97)) & 2147483643) !== 0) || ((((_la - 129)) & ~0x1F) === 0 && ((1 << (_la - 129)) & 2147418111) !== 0) || ((((_la - 161)) & ~0x1F) === 0 && ((1 << (_la - 161)) & 4292345853) !== 0) || ((((_la - 193)) & ~0x1F) === 0 && ((1 << (_la - 193)) & 71401719) !== 0) || ((((_la - 256)) & ~0x1F) === 0 && ((1 << (_la - 256)) & 65557) !== 0) || ((((_la - 289)) & ~0x1F) === 0 && ((1 << (_la - 289)) & 92307459) !== 0) || ((((_la - 335)) & ~0x1F) === 0 && ((1 << (_la - 335)) & 1639553) !== 0) || ((((_la - 395)) & ~0x1F) === 0 && ((1 << (_la - 395)) & 805341189) !== 0) || ((((_la - 428)) & ~0x1F) === 0 && ((1 << (_la - 428)) & 16777225) !== 0) || ((((_la - 479)) & ~0x1F) === 0 && ((1 << (_la - 479)) & 491649) !== 0)) {
                {
                this.state = 2020;
                this.dataTypeExpression();
                }
            }

            this.state = 2030;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 476) {
                {
                {
                this.state = 2023;
                this.match(SparkSQLParser.COMMA);
                this.state = 2024;
                this.transform();
                this.state = 2026;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if ((((_la) & ~0x1F) === 0 && ((1 << _la) & 4294897648) !== 0) || ((((_la - 33)) & ~0x1F) === 0 && ((1 << (_la - 33)) & 4294803199) !== 0) || ((((_la - 65)) & ~0x1F) === 0 && ((1 << (_la - 65)) & 4289716215) !== 0) || ((((_la - 97)) & ~0x1F) === 0 && ((1 << (_la - 97)) & 2147483643) !== 0) || ((((_la - 129)) & ~0x1F) === 0 && ((1 << (_la - 129)) & 2147418111) !== 0) || ((((_la - 161)) & ~0x1F) === 0 && ((1 << (_la - 161)) & 4292345853) !== 0) || ((((_la - 193)) & ~0x1F) === 0 && ((1 << (_la - 193)) & 71401719) !== 0) || ((((_la - 256)) & ~0x1F) === 0 && ((1 << (_la - 256)) & 65557) !== 0) || ((((_la - 289)) & ~0x1F) === 0 && ((1 << (_la - 289)) & 92307459) !== 0) || ((((_la - 335)) & ~0x1F) === 0 && ((1 << (_la - 335)) & 1639553) !== 0) || ((((_la - 395)) & ~0x1F) === 0 && ((1 << (_la - 395)) & 805341189) !== 0) || ((((_la - 428)) & ~0x1F) === 0 && ((1 << (_la - 428)) & 16777225) !== 0) || ((((_la - 479)) & ~0x1F) === 0 && ((1 << (_la - 479)) & 491649) !== 0)) {
                    {
                    this.state = 2025;
                    this.dataTypeExpression();
                    }
                }

                }
                }
                this.state = 2032;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 2033;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public transform(): TransformContext {
        let localContext = new TransformContext(this.context, this.state);
        this.enterRule(localContext, 266, SparkSQLParser.RULE_transform);
        let _la: number;
        try {
            this.state = 2048;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 226, this.context) ) {
            case 1:
                localContext = new IdentityTransformContext(localContext);
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 2035;
                this.qualifiedName();
                }
                break;
            case 2:
                localContext = new ApplyTransformContext(localContext);
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 2036;
                (localContext as ApplyTransformContext)._transformName = this.identifier();
                this.state = 2037;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 2038;
                this.transformArgument();
                this.state = 2043;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                while (_la === 476) {
                    {
                    {
                    this.state = 2039;
                    this.match(SparkSQLParser.COMMA);
                    this.state = 2040;
                    this.transformArgument();
                    }
                    }
                    this.state = 2045;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                }
                this.state = 2046;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public transformArgument(): TransformArgumentContext {
        let localContext = new TransformArgumentContext(this.context, this.state);
        this.enterRule(localContext, 268, SparkSQLParser.RULE_transformArgument);
        try {
            this.state = 2052;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 227, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 2050;
                this.qualifiedName();
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 2051;
                this.constant();
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public likeDefinition(): LikeDefinitionContext {
        let localContext = new LikeDefinitionContext(this.context, this.state);
        this.enterRule(localContext, 270, SparkSQLParser.RULE_likeDefinition);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2054;
            this.match(SparkSQLParser.KW_LIKE);
            this.state = 2055;
            this.tablePath();
            this.state = 2064;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 229, this.context) ) {
            case 1:
                {
                this.state = 2056;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 2060;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                while (_la === 46 || _la === 107 || _la === 307) {
                    {
                    {
                    this.state = 2057;
                    this.likeOption();
                    }
                    }
                    this.state = 2062;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                }
                this.state = 2063;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public distribution(): DistributionContext {
        let localContext = new DistributionContext(this.context, this.state);
        this.enterRule(localContext, 272, SparkSQLParser.RULE_distribution);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2066;
            this.match(SparkSQLParser.KW_DISTRIBUTED);
            this.state = 2075;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 223) {
                {
                this.state = 2067;
                this.match(SparkSQLParser.KW_BY);
                this.state = 2069;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 302) {
                    {
                    this.state = 2068;
                    this.match(SparkSQLParser.KW_HASH);
                    }
                }

                this.state = 2071;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 2072;
                this.identifier();
                this.state = 2073;
                this.match(SparkSQLParser.RR_BRACKET);
                }
            }

            this.state = 2078;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 232, this.context) ) {
            case 1:
                {
                this.state = 2077;
                this.intoBuckets();
                }
                break;
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public using(): UsingContext {
        let localContext = new UsingContext(this.context, this.state);
        this.enterRule(localContext, 274, SparkSQLParser.RULE_using);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2080;
            this.match(SparkSQLParser.KW_USING);
            this.state = 2081;
            this.match(SparkSQLParser.ID_LITERAL);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public likeOption(): LikeOptionContext {
        let localContext = new LikeOptionContext(this.context, this.state);
        this.enterRule(localContext, 276, SparkSQLParser.RULE_likeOption);
        let _la: number;
        try {
            this.state = 2087;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 233, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                {
                this.state = 2083;
                _la = this.tokenStream.LA(1);
                if(!(_la === 46 || _la === 307)) {
                this.errorHandler.recoverInline(this);
                }
                else {
                    this.errorHandler.reportMatch(this);
                    this.consume();
                }
                this.state = 2084;
                _la = this.tokenStream.LA(1);
                if(!(_la === 24 || _la === 109 || _la === 202)) {
                this.errorHandler.recoverInline(this);
                }
                else {
                    this.errorHandler.reportMatch(this);
                    this.consume();
                }
                }
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                {
                this.state = 2085;
                _la = this.tokenStream.LA(1);
                if(!(_la === 46 || _la === 107 || _la === 307)) {
                this.errorHandler.recoverInline(this);
                }
                else {
                    this.errorHandler.reportMatch(this);
                    this.consume();
                }
                this.state = 2086;
                _la = this.tokenStream.LA(1);
                if(!(_la === 60 || _la === 103 || _la === 194)) {
                this.errorHandler.recoverInline(this);
                }
                else {
                    this.errorHandler.reportMatch(this);
                    this.consume();
                }
                }
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public columnOptionDefinition(): ColumnOptionDefinitionContext {
        let localContext = new ColumnOptionDefinitionContext(this.context, this.state);
        this.enterRule(localContext, 278, SparkSQLParser.RULE_columnOptionDefinition);
        try {
            this.state = 2092;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 234, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 2089;
                this.physicalColumnDefinition();
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 2090;
                this.metadataColumnDefinition();
                }
                break;
            case 3:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 2091;
                this.computedColumnDefinition();
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public physicalColumnDefinitionList(): PhysicalColumnDefinitionListContext {
        let localContext = new PhysicalColumnDefinitionListContext(this.context, this.state);
        this.enterRule(localContext, 280, SparkSQLParser.RULE_physicalColumnDefinitionList);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2094;
            this.match(SparkSQLParser.LR_BRACKET);
            {
            this.state = 2095;
            this.physicalColumnDefinition();
            }
            this.state = 2100;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 476) {
                {
                {
                this.state = 2096;
                this.match(SparkSQLParser.COMMA);
                this.state = 2097;
                this.physicalColumnDefinition();
                }
                }
                this.state = 2102;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 2103;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public physicalColumnDefinition(): PhysicalColumnDefinitionContext {
        let localContext = new PhysicalColumnDefinitionContext(this.context, this.state);
        this.enterRule(localContext, 282, SparkSQLParser.RULE_physicalColumnDefinition);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2105;
            this.columnName();
            this.state = 2106;
            this.columnType();
            this.state = 2108;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 243 || ((((_la - 351)) & ~0x1F) === 0 && ((1 << (_la - 351)) & 1073741833) !== 0)) {
                {
                this.state = 2107;
                this.columnConstraint();
                }
            }

            this.state = 2111;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 237, this.context) ) {
            case 1:
                {
                this.state = 2110;
                this.commentSpec();
                }
                break;
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public computedColumnExpression(): ComputedColumnExpressionContext {
        let localContext = new ComputedColumnExpressionContext(this.context, this.state);
        this.enterRule(localContext, 284, SparkSQLParser.RULE_computedColumnExpression);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2113;
            this.expression();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public watermarkDefinition(): WatermarkDefinitionContext {
        let localContext = new WatermarkDefinitionContext(this.context, this.state);
        this.enterRule(localContext, 286, SparkSQLParser.RULE_watermarkDefinition);
        try {
            this.state = 2130;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 239, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 2115;
                this.match(SparkSQLParser.KW_WATERMARK);
                this.state = 2116;
                this.match(SparkSQLParser.KW_FOR);
                this.state = 2117;
                this.expression();
                this.state = 2118;
                this.match(SparkSQLParser.KW_AS);
                this.state = 2119;
                this.expression();
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 2121;
                this.match(SparkSQLParser.KW_WATERMARK);
                this.state = 2122;
                this.match(SparkSQLParser.KW_FOR);
                this.state = 2125;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 238, this.context) ) {
                case 1:
                    {
                    this.state = 2123;
                    this.uid();
                    }
                    break;
                case 2:
                    {
                    this.state = 2124;
                    this.expression();
                    }
                    break;
                }
                this.state = 2127;
                this.match(SparkSQLParser.KW_AS);
                this.state = 2128;
                this.uid();
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public tableConstraint(): TableConstraintContext {
        let localContext = new TableConstraintContext(this.context, this.state);
        this.enterRule(localContext, 288, SparkSQLParser.RULE_tableConstraint);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2134;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 243) {
                {
                this.state = 2132;
                this.match(SparkSQLParser.KW_CONSTRAINT);
                this.state = 2133;
                this.constraintName();
                }
            }

            this.state = 2136;
            this.match(SparkSQLParser.KW_PRIMARY);
            this.state = 2137;
            this.match(SparkSQLParser.KW_KEY);
            this.state = 2138;
            this.columnNameList();
            this.state = 2139;
            this.match(SparkSQLParser.KW_NOT);
            this.state = 2140;
            this.match(SparkSQLParser.KW_ENFORCED);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public constraintName(): ConstraintNameContext {
        let localContext = new ConstraintNameContext(this.context, this.state);
        this.enterRule(localContext, 290, SparkSQLParser.RULE_constraintName);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2142;
            this.identifier();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public valuesDefinition(): ValuesDefinitionContext {
        let localContext = new ValuesDefinitionContext(this.context, this.state);
        this.enterRule(localContext, 292, SparkSQLParser.RULE_valuesDefinition);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2144;
            this.match(SparkSQLParser.KW_VALUES);
            this.state = 2145;
            this.valuesRowDefinition();
            this.state = 2150;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 476) {
                {
                {
                this.state = 2146;
                this.match(SparkSQLParser.COMMA);
                this.state = 2147;
                this.valuesRowDefinition();
                }
                }
                this.state = 2152;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public valuesRowDefinition(): ValuesRowDefinitionContext {
        let localContext = new ValuesRowDefinitionContext(this.context, this.state);
        this.enterRule(localContext, 294, SparkSQLParser.RULE_valuesRowDefinition);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2153;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 2154;
            this.constant();
            this.state = 2159;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 476) {
                {
                {
                this.state = 2155;
                this.match(SparkSQLParser.COMMA);
                this.state = 2156;
                this.constant();
                }
                }
                this.state = 2161;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 2162;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public lengthOneDimension(): LengthOneDimensionContext {
        let localContext = new LengthOneDimensionContext(this.context, this.state);
        this.enterRule(localContext, 296, SparkSQLParser.RULE_lengthOneDimension);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2164;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 2165;
            this.decimalLiteral();
            this.state = 2166;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public lengthTwoOptionalDimension(): LengthTwoOptionalDimensionContext {
        let localContext = new LengthTwoOptionalDimensionContext(this.context, this.state);
        this.enterRule(localContext, 298, SparkSQLParser.RULE_lengthTwoOptionalDimension);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2168;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 2169;
            this.decimalLiteral();
            this.state = 2172;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 476) {
                {
                this.state = 2170;
                this.match(SparkSQLParser.COMMA);
                this.state = 2171;
                this.decimalLiteral();
                }
            }

            this.state = 2174;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public lengthTwoStringDimension(): LengthTwoStringDimensionContext {
        let localContext = new LengthTwoStringDimensionContext(this.context, this.state);
        this.enterRule(localContext, 300, SparkSQLParser.RULE_lengthTwoStringDimension);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2176;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 2177;
            this.stringLiteral();
            this.state = 2180;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 476) {
                {
                this.state = 2178;
                this.match(SparkSQLParser.COMMA);
                this.state = 2179;
                this.stringLiteral();
                }
            }

            this.state = 2182;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public lengthOneTypeDimension(): LengthOneTypeDimensionContext {
        let localContext = new LengthOneTypeDimensionContext(this.context, this.state);
        this.enterRule(localContext, 302, SparkSQLParser.RULE_lengthOneTypeDimension);
        let _la: number;
        try {
            localContext = new LengthSymbolsTypeDimensionContext(localContext);
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2184;
            this.match(SparkSQLParser.LESS_SYMBOL);
            this.state = 2185;
            this.columnType();
            this.state = 2190;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 476) {
                {
                {
                this.state = 2186;
                this.match(SparkSQLParser.COMMA);
                this.state = 2187;
                this.columnType();
                }
                }
                this.state = 2192;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 2193;
            this.match(SparkSQLParser.GREATER_SYMBOL);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public mapTypeDimension(): MapTypeDimensionContext {
        let localContext = new MapTypeDimensionContext(this.context, this.state);
        this.enterRule(localContext, 304, SparkSQLParser.RULE_mapTypeDimension);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2195;
            this.match(SparkSQLParser.LESS_SYMBOL);
            this.state = 2196;
            this.columnType();
            {
            this.state = 2197;
            this.match(SparkSQLParser.COMMA);
            this.state = 2198;
            this.columnType();
            }
            this.state = 2200;
            this.match(SparkSQLParser.GREATER_SYMBOL);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public rowTypeDimension(): RowTypeDimensionContext {
        let localContext = new RowTypeDimensionContext(this.context, this.state);
        this.enterRule(localContext, 306, SparkSQLParser.RULE_rowTypeDimension);
        let _la: number;
        try {
            localContext = new RowSymbolsTypeDimensionContext(localContext);
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2202;
            this.match(SparkSQLParser.LESS_SYMBOL);
            this.state = 2203;
            this.columnName();
            this.state = 2204;
            this.columnType();
            this.state = 2211;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 476) {
                {
                {
                this.state = 2205;
                this.match(SparkSQLParser.COMMA);
                this.state = 2206;
                this.columnName();
                this.state = 2207;
                this.columnType();
                }
                }
                this.state = 2213;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 2214;
            this.match(SparkSQLParser.GREATER_SYMBOL);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public structTypeDimension(): StructTypeDimensionContext {
        let localContext = new StructTypeDimensionContext(this.context, this.state);
        this.enterRule(localContext, 308, SparkSQLParser.RULE_structTypeDimension);
        let _la: number;
        try {
            localContext = new StructSymbolsTypeDimensionContext(localContext);
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2216;
            this.match(SparkSQLParser.LESS_SYMBOL);
            this.state = 2217;
            this.columnName();
            this.state = 2218;
            this.match(SparkSQLParser.COLON_SYMB);
            this.state = 2219;
            this.columnType();
            this.state = 2227;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 476) {
                {
                {
                this.state = 2220;
                this.match(SparkSQLParser.COMMA);
                this.state = 2221;
                this.columnName();
                this.state = 2222;
                this.match(SparkSQLParser.COLON_SYMB);
                this.state = 2223;
                this.columnType();
                }
                }
                this.state = 2229;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 2230;
            this.match(SparkSQLParser.GREATER_SYMBOL);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public columnConstraint(): ColumnConstraintContext {
        let localContext = new ColumnConstraintContext(this.context, this.state);
        this.enterRule(localContext, 310, SparkSQLParser.RULE_columnConstraint);
        let _la: number;
        try {
            this.state = 2246;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.KW_CONSTRAINT:
            case SparkSQLParser.KW_PRIMARY:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 2234;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 243) {
                    {
                    this.state = 2232;
                    this.match(SparkSQLParser.KW_CONSTRAINT);
                    this.state = 2233;
                    this.constraintName();
                    }
                }

                this.state = 2236;
                this.match(SparkSQLParser.KW_PRIMARY);
                this.state = 2237;
                this.match(SparkSQLParser.KW_KEY);
                this.state = 2240;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 351) {
                    {
                    this.state = 2238;
                    this.match(SparkSQLParser.KW_NOT);
                    this.state = 2239;
                    this.match(SparkSQLParser.KW_ENFORCED);
                    }
                }

                }
                break;
            case SparkSQLParser.KW_NOT:
            case SparkSQLParser.KW_NULL:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 2243;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 351) {
                    {
                    this.state = 2242;
                    this.match(SparkSQLParser.KW_NOT);
                    }
                }

                this.state = 2245;
                this.match(SparkSQLParser.KW_NULL);
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public commentSpec(): CommentSpecContext {
        let localContext = new CommentSpecContext(this.context, this.state);
        this.enterRule(localContext, 312, SparkSQLParser.RULE_commentSpec);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2248;
            this.match(SparkSQLParser.KW_COMMENT);
            this.state = 2249;
            this.propertyName();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public metadataColumnDefinition(): MetadataColumnDefinitionContext {
        let localContext = new MetadataColumnDefinitionContext(this.context, this.state);
        this.enterRule(localContext, 314, SparkSQLParser.RULE_metadataColumnDefinition);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2251;
            this.columnName();
            this.state = 2252;
            this.columnType();
            this.state = 2253;
            this.match(SparkSQLParser.KW_METADATA);
            this.state = 2256;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 293) {
                {
                this.state = 2254;
                this.match(SparkSQLParser.KW_FROM);
                this.state = 2255;
                this.metadataKey();
                }
            }

            this.state = 2259;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 192) {
                {
                this.state = 2258;
                this.match(SparkSQLParser.KW_VIRTUAL);
                }
            }

            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public metadataKey(): MetadataKeyContext {
        let localContext = new MetadataKeyContext(this.context, this.state);
        this.enterRule(localContext, 316, SparkSQLParser.RULE_metadataKey);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2261;
            this.match(SparkSQLParser.STRING_LITERAL);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public computedColumnDefinition(): ComputedColumnDefinitionContext {
        let localContext = new ComputedColumnDefinitionContext(this.context, this.state);
        this.enterRule(localContext, 318, SparkSQLParser.RULE_computedColumnDefinition);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2263;
            this.columnName();
            this.state = 2264;
            this.match(SparkSQLParser.KW_AS);
            this.state = 2265;
            this.computedColumnExpression();
            this.state = 2267;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 254, this.context) ) {
            case 1:
                {
                this.state = 2266;
                this.commentSpec();
                }
                break;
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public columnName(): ColumnNameContext {
        let localContext = new ColumnNameContext(this.context, this.state);
        this.enterRule(localContext, 320, SparkSQLParser.RULE_columnName);
        try {
            this.state = 2271;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 255, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 2269;
                this.uid();
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 2270;
                this.expression();
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public columnNameList(): ColumnNameListContext {
        let localContext = new ColumnNameListContext(this.context, this.state);
        this.enterRule(localContext, 322, SparkSQLParser.RULE_columnNameList);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2273;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 2274;
            this.columnName();
            this.state = 2276;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 21) {
                {
                this.state = 2275;
                this.commentSpec();
                }
            }

            this.state = 2285;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 476) {
                {
                {
                this.state = 2278;
                this.match(SparkSQLParser.COMMA);
                this.state = 2279;
                this.columnName();
                this.state = 2281;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 21) {
                    {
                    this.state = 2280;
                    this.commentSpec();
                    }
                }

                }
                }
                this.state = 2287;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 2288;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public columnType(): ColumnTypeContext {
        let localContext = new ColumnTypeContext(this.context, this.state);
        this.enterRule(localContext, 324, SparkSQLParser.RULE_columnType);
        let _la: number;
        try {
            this.state = 2365;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.KW_BOOLEAN:
            case SparkSQLParser.KW_DATE:
            case SparkSQLParser.KW_NULL:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 2290;
                localContext._typeName = this.tokenStream.LT(1);
                _la = this.tokenStream.LA(1);
                if(!(_la === 219 || _la === 256 || _la === 354)) {
                    localContext._typeName = this.errorHandler.recoverInline(this);
                }
                else {
                    this.errorHandler.reportMatch(this);
                    this.consume();
                }
                }
                break;
            case SparkSQLParser.KW_BYTES:
            case SparkSQLParser.KW_STRING:
            case SparkSQLParser.KW_TIMESTAMP_LTZ:
            case SparkSQLParser.KW_BIGINT:
            case SparkSQLParser.KW_BINARY:
            case SparkSQLParser.KW_CHAR:
            case SparkSQLParser.KW_DATETIME:
            case SparkSQLParser.KW_INT:
            case SparkSQLParser.KW_INTEGER:
            case SparkSQLParser.KW_SMALLINT:
            case SparkSQLParser.KW_TIME:
            case SparkSQLParser.KW_TINYINT:
            case SparkSQLParser.KW_VARBINARY:
            case SparkSQLParser.KW_VARCHAR:
                this.enterOuterAlt(localContext, 2);
                {
                {
                this.state = 2291;
                localContext._typeName = this.tokenStream.LT(1);
                _la = this.tokenStream.LA(1);
                if(!(_la === 11 || _la === 165 || _la === 172 || ((((_la - 215)) & ~0x1F) === 0 && ((1 << (_la - 215)) & 32771) !== 0) || _la === 257 || _la === 312 || _la === 313 || ((((_la - 406)) & ~0x1F) === 0 && ((1 << (_la - 406)) & 4325377) !== 0) || _la === 444 || _la === 445)) {
                    localContext._typeName = this.errorHandler.recoverInline(this);
                }
                else {
                    this.errorHandler.reportMatch(this);
                    this.consume();
                }
                this.state = 2293;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 472) {
                    {
                    this.state = 2292;
                    this.lengthOneDimension();
                    }
                }

                }
                }
                break;
            case SparkSQLParser.KW_TIMESTAMP:
                this.enterOuterAlt(localContext, 3);
                {
                {
                this.state = 2295;
                localContext._typeName = this.match(SparkSQLParser.KW_TIMESTAMP);
                this.state = 2297;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 472) {
                    {
                    this.state = 2296;
                    this.lengthOneDimension();
                    }
                }

                this.state = 2305;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 449 || _la === 451) {
                    {
                    this.state = 2299;
                    _la = this.tokenStream.LA(1);
                    if(!(_la === 449 || _la === 451)) {
                    this.errorHandler.recoverInline(this);
                    }
                    else {
                        this.errorHandler.reportMatch(this);
                        this.consume();
                    }
                    this.state = 2301;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                    if (_la === 334) {
                        {
                        this.state = 2300;
                        this.match(SparkSQLParser.KW_LOCAL);
                        }
                    }

                    this.state = 2303;
                    this.match(SparkSQLParser.KW_TIME);
                    this.state = 2304;
                    this.match(SparkSQLParser.KW_ZONE);
                    }
                }

                }
                }
                break;
            case SparkSQLParser.KW_TIMESTAMP_3:
                this.enterOuterAlt(localContext, 4);
                {
                {
                this.state = 2307;
                localContext._typeName = this.match(SparkSQLParser.KW_TIMESTAMP_3);
                this.state = 2309;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 472) {
                    {
                    this.state = 2308;
                    this.lengthOneDimension();
                    }
                }

                this.state = 2317;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 449 || _la === 451) {
                    {
                    this.state = 2311;
                    _la = this.tokenStream.LA(1);
                    if(!(_la === 449 || _la === 451)) {
                    this.errorHandler.recoverInline(this);
                    }
                    else {
                        this.errorHandler.reportMatch(this);
                        this.consume();
                    }
                    this.state = 2313;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                    if (_la === 334) {
                        {
                        this.state = 2312;
                        this.match(SparkSQLParser.KW_LOCAL);
                        }
                    }

                    this.state = 2315;
                    this.match(SparkSQLParser.KW_TIME);
                    this.state = 2316;
                    this.match(SparkSQLParser.KW_ZONE);
                    }
                }

                }
                }
                break;
            case SparkSQLParser.KW_TIMESTAMP_6:
                this.enterOuterAlt(localContext, 5);
                {
                {
                this.state = 2319;
                localContext._typeName = this.match(SparkSQLParser.KW_TIMESTAMP_6);
                this.state = 2321;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 472) {
                    {
                    this.state = 2320;
                    this.lengthOneDimension();
                    }
                }

                this.state = 2329;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 449 || _la === 451) {
                    {
                    this.state = 2323;
                    _la = this.tokenStream.LA(1);
                    if(!(_la === 449 || _la === 451)) {
                    this.errorHandler.recoverInline(this);
                    }
                    else {
                        this.errorHandler.reportMatch(this);
                        this.consume();
                    }
                    this.state = 2325;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                    if (_la === 334) {
                        {
                        this.state = 2324;
                        this.match(SparkSQLParser.KW_LOCAL);
                        }
                    }

                    this.state = 2327;
                    this.match(SparkSQLParser.KW_TIME);
                    this.state = 2328;
                    this.match(SparkSQLParser.KW_ZONE);
                    }
                }

                }
                }
                break;
            case SparkSQLParser.KW_TIMESTAMP_9:
                this.enterOuterAlt(localContext, 6);
                {
                {
                this.state = 2331;
                localContext._typeName = this.match(SparkSQLParser.KW_TIMESTAMP_9);
                this.state = 2333;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 472) {
                    {
                    this.state = 2332;
                    this.lengthOneDimension();
                    }
                }

                this.state = 2341;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 449 || _la === 451) {
                    {
                    this.state = 2335;
                    _la = this.tokenStream.LA(1);
                    if(!(_la === 449 || _la === 451)) {
                    this.errorHandler.recoverInline(this);
                    }
                    else {
                        this.errorHandler.reportMatch(this);
                        this.consume();
                    }
                    this.state = 2337;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                    if (_la === 334) {
                        {
                        this.state = 2336;
                        this.match(SparkSQLParser.KW_LOCAL);
                        }
                    }

                    this.state = 2339;
                    this.match(SparkSQLParser.KW_TIME);
                    this.state = 2340;
                    this.match(SparkSQLParser.KW_ZONE);
                    }
                }

                }
                }
                break;
            case SparkSQLParser.KW_DEC:
            case SparkSQLParser.KW_DECIMAL:
            case SparkSQLParser.KW_DOUBLE:
            case SparkSQLParser.KW_FLOAT:
            case SparkSQLParser.KW_NUMERIC:
                this.enterOuterAlt(localContext, 7);
                {
                {
                this.state = 2343;
                localContext._typeName = this.tokenStream.LT(1);
                _la = this.tokenStream.LA(1);
                if(!(((((_la - 259)) & ~0x1F) === 0 && ((1 << (_la - 259)) & 2147491843) !== 0) || _la === 355)) {
                    localContext._typeName = this.errorHandler.recoverInline(this);
                }
                else {
                    this.errorHandler.reportMatch(this);
                    this.consume();
                }
                this.state = 2345;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 472) {
                    {
                    this.state = 2344;
                    this.lengthTwoOptionalDimension();
                    }
                }

                }
                }
                break;
            case SparkSQLParser.KW_ARRAY:
            case SparkSQLParser.KW_MULTISET:
                this.enterOuterAlt(localContext, 8);
                {
                {
                this.state = 2347;
                localContext._type_ = this.tokenStream.LT(1);
                _la = this.tokenStream.LA(1);
                if(!(_la === 208 || _la === 346)) {
                    localContext._type_ = this.errorHandler.recoverInline(this);
                }
                else {
                    this.errorHandler.reportMatch(this);
                    this.consume();
                }
                this.state = 2349;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 467) {
                    {
                    this.state = 2348;
                    this.lengthOneTypeDimension();
                    }
                }

                }
                }
                break;
            case SparkSQLParser.KW_MAP:
                this.enterOuterAlt(localContext, 9);
                {
                {
                this.state = 2351;
                localContext._type_ = this.match(SparkSQLParser.KW_MAP);
                this.state = 2353;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 467) {
                    {
                    this.state = 2352;
                    this.mapTypeDimension();
                    }
                }

                }
                }
                break;
            case SparkSQLParser.KW_ROW:
                this.enterOuterAlt(localContext, 10);
                {
                {
                this.state = 2355;
                localContext._type_ = this.match(SparkSQLParser.KW_ROW);
                this.state = 2357;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 467) {
                    {
                    this.state = 2356;
                    this.rowTypeDimension();
                    }
                }

                }
                }
                break;
            case SparkSQLParser.KW_STRUCT:
                this.enterOuterAlt(localContext, 11);
                {
                {
                this.state = 2359;
                localContext._type_ = this.match(SparkSQLParser.KW_STRUCT);
                this.state = 2360;
                this.structTypeDimension();
                }
                }
                break;
            case SparkSQLParser.KW_RAW:
                this.enterOuterAlt(localContext, 12);
                {
                {
                this.state = 2361;
                localContext._type_ = this.match(SparkSQLParser.KW_RAW);
                this.state = 2363;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 472) {
                    {
                    this.state = 2362;
                    this.lengthTwoStringDimension();
                    }
                }

                }
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public expression(): ExpressionContext {
        let localContext = new ExpressionContext(this.context, this.state);
        this.enterRule(localContext, 326, SparkSQLParser.RULE_expression);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2367;
            this.booleanExpression(0);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }

    public booleanExpression(): BooleanExpressionContext;
    public booleanExpression(_p: number): BooleanExpressionContext;
    public booleanExpression(_p?: number): BooleanExpressionContext {
        if (_p === undefined) {
            _p = 0;
        }

        let parentContext = this.context;
        let parentState = this.state;
        let localContext = new BooleanExpressionContext(this.context, parentState);
        let previousContext = localContext;
        let _startState = 328;
        this.enterRecursionRule(localContext, 328, SparkSQLParser.RULE_booleanExpression, _p);
        let _la: number;
        try {
            let alternative: number;
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2381;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 279, this.context) ) {
            case 1:
                {
                localContext = new LogicalNotContext(localContext);
                this.context = localContext;
                previousContext = localContext;

                this.state = 2370;
                this.match(SparkSQLParser.KW_NOT);
                this.state = 2371;
                this.booleanExpression(6);
                }
                break;
            case 2:
                {
                localContext = new ExistsContext(localContext);
                this.context = localContext;
                previousContext = localContext;
                this.state = 2372;
                this.match(SparkSQLParser.KW_EXISTS);
                this.state = 2373;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 2374;
                this.queryStatement(0);
                this.state = 2375;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case 3:
                {
                localContext = new PredicatedContext(localContext);
                this.context = localContext;
                previousContext = localContext;
                this.state = 2377;
                this.valueExpression(0);
                this.state = 2379;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 278, this.context) ) {
                case 1:
                    {
                    this.state = 2378;
                    this.predicate();
                    }
                    break;
                }
                }
                break;
            }
            this.context!.stop = this.tokenStream.LT(-1);
            this.state = 2397;
            this.errorHandler.sync(this);
            alternative = this.interpreter.adaptivePredict(this.tokenStream, 282, this.context);
            while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {
                if (alternative === 1) {
                    if (this.parseListeners != null) {
                        this.triggerExitRuleEvent();
                    }
                    previousContext = localContext;
                    {
                    this.state = 2395;
                    this.errorHandler.sync(this);
                    switch (this.interpreter.adaptivePredict(this.tokenStream, 281, this.context) ) {
                    case 1:
                        {
                        localContext = new LogicalBinaryContext(new BooleanExpressionContext(parentContext, parentState));
                        (localContext as LogicalBinaryContext)._left = previousContext;
                        this.pushNewRecursionContext(localContext, _startState, SparkSQLParser.RULE_booleanExpression);
                        this.state = 2383;
                        if (!(this.precpred(this.context, 3))) {
                            throw this.createFailedPredicateException("this.precpred(this.context, 3)");
                        }
                        this.state = 2384;
                        (localContext as LogicalBinaryContext)._operator = this.match(SparkSQLParser.KW_AND);
                        this.state = 2385;
                        (localContext as LogicalBinaryContext)._right = this.booleanExpression(4);
                        }
                        break;
                    case 2:
                        {
                        localContext = new LogicalBinaryContext(new BooleanExpressionContext(parentContext, parentState));
                        (localContext as LogicalBinaryContext)._left = previousContext;
                        this.pushNewRecursionContext(localContext, _startState, SparkSQLParser.RULE_booleanExpression);
                        this.state = 2386;
                        if (!(this.precpred(this.context, 2))) {
                            throw this.createFailedPredicateException("this.precpred(this.context, 2)");
                        }
                        this.state = 2387;
                        (localContext as LogicalBinaryContext)._operator = this.match(SparkSQLParser.KW_OR);
                        this.state = 2388;
                        (localContext as LogicalBinaryContext)._right = this.booleanExpression(3);
                        }
                        break;
                    case 3:
                        {
                        localContext = new LogicalNestedContext(new BooleanExpressionContext(parentContext, parentState));
                        this.pushNewRecursionContext(localContext, _startState, SparkSQLParser.RULE_booleanExpression);
                        this.state = 2389;
                        if (!(this.precpred(this.context, 1))) {
                            throw this.createFailedPredicateException("this.precpred(this.context, 1)");
                        }
                        this.state = 2390;
                        this.match(SparkSQLParser.KW_IS);
                        this.state = 2392;
                        this.errorHandler.sync(this);
                        _la = this.tokenStream.LA(1);
                        if (_la === 351) {
                            {
                            this.state = 2391;
                            this.match(SparkSQLParser.KW_NOT);
                            }
                        }

                        this.state = 2394;
                        (localContext as LogicalNestedContext)._kind = this.tokenStream.LT(1);
                        _la = this.tokenStream.LA(1);
                        if(!(_la === 289 || _la === 354 || _la === 431 || _la === 435)) {
                            (localContext as LogicalNestedContext)._kind = this.errorHandler.recoverInline(this);
                        }
                        else {
                            this.errorHandler.reportMatch(this);
                            this.consume();
                        }
                        }
                        break;
                    }
                    }
                }
                this.state = 2399;
                this.errorHandler.sync(this);
                alternative = this.interpreter.adaptivePredict(this.tokenStream, 282, this.context);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.unrollRecursionContexts(parentContext);
        }
        return localContext;
    }
    public predicate(): PredicateContext {
        let localContext = new PredicateContext(this.context, this.state);
        this.enterRule(localContext, 330, SparkSQLParser.RULE_predicate);
        let _la: number;
        try {
            this.state = 2467;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 293, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 2401;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 351) {
                    {
                    this.state = 2400;
                    this.match(SparkSQLParser.KW_NOT);
                    }
                }

                this.state = 2403;
                localContext._kind = this.match(SparkSQLParser.KW_BETWEEN);
                this.state = 2405;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 210 || _la === 414) {
                    {
                    this.state = 2404;
                    _la = this.tokenStream.LA(1);
                    if(!(_la === 210 || _la === 414)) {
                    this.errorHandler.recoverInline(this);
                    }
                    else {
                        this.errorHandler.reportMatch(this);
                        this.consume();
                    }
                    }
                }

                this.state = 2407;
                localContext._lower = this.valueExpression(0);
                this.state = 2408;
                this.match(SparkSQLParser.KW_AND);
                this.state = 2409;
                localContext._upper = this.valueExpression(0);
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 2412;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 351) {
                    {
                    this.state = 2411;
                    this.match(SparkSQLParser.KW_NOT);
                    }
                }

                this.state = 2414;
                localContext._kind = this.match(SparkSQLParser.KW_IN);
                this.state = 2415;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 2416;
                this.expression();
                this.state = 2421;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                while (_la === 476) {
                    {
                    {
                    this.state = 2417;
                    this.match(SparkSQLParser.COMMA);
                    this.state = 2418;
                    this.expression();
                    }
                    }
                    this.state = 2423;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                }
                this.state = 2424;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case 3:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 2427;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 351) {
                    {
                    this.state = 2426;
                    this.match(SparkSQLParser.KW_NOT);
                    }
                }

                this.state = 2429;
                localContext._kind = this.match(SparkSQLParser.KW_IN);
                this.state = 2430;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 2431;
                this.queryStatement(0);
                this.state = 2432;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case 4:
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 2434;
                localContext._kind = this.match(SparkSQLParser.KW_EXISTS);
                this.state = 2435;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 2436;
                this.queryStatement(0);
                this.state = 2437;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case 5:
                this.enterOuterAlt(localContext, 5);
                {
                this.state = 2440;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 351) {
                    {
                    this.state = 2439;
                    this.match(SparkSQLParser.KW_NOT);
                    }
                }

                this.state = 2442;
                localContext._kind = this.match(SparkSQLParser.KW_RLIKE);
                this.state = 2443;
                localContext._pattern = this.valueExpression(0);
                }
                break;
            case 6:
                this.enterOuterAlt(localContext, 6);
                {
                this.state = 2444;
                this.likePredicate();
                }
                break;
            case 7:
                this.enterOuterAlt(localContext, 7);
                {
                this.state = 2445;
                this.match(SparkSQLParser.KW_IS);
                this.state = 2447;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 351) {
                    {
                    this.state = 2446;
                    this.match(SparkSQLParser.KW_NOT);
                    }
                }

                this.state = 2449;
                localContext._kind = this.tokenStream.LT(1);
                _la = this.tokenStream.LA(1);
                if(!(_la === 289 || _la === 354 || _la === 431 || _la === 435)) {
                    localContext._kind = this.errorHandler.recoverInline(this);
                }
                else {
                    this.errorHandler.reportMatch(this);
                    this.consume();
                }
                }
                break;
            case 8:
                this.enterOuterAlt(localContext, 8);
                {
                this.state = 2450;
                this.match(SparkSQLParser.KW_IS);
                this.state = 2452;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 351) {
                    {
                    this.state = 2451;
                    this.match(SparkSQLParser.KW_NOT);
                    }
                }

                this.state = 2454;
                localContext._kind = this.match(SparkSQLParser.KW_DISTINCT);
                this.state = 2455;
                this.match(SparkSQLParser.KW_FROM);
                this.state = 2456;
                localContext._right = this.valueExpression(0);
                }
                break;
            case 9:
                this.enterOuterAlt(localContext, 9);
                {
                this.state = 2458;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 351) {
                    {
                    this.state = 2457;
                    this.match(SparkSQLParser.KW_NOT);
                    }
                }

                this.state = 2460;
                localContext._kind = this.match(SparkSQLParser.KW_SIMILAR);
                this.state = 2461;
                this.match(SparkSQLParser.KW_TO);
                this.state = 2462;
                localContext._right = this.valueExpression(0);
                this.state = 2465;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 292, this.context) ) {
                case 1:
                    {
                    this.state = 2463;
                    this.match(SparkSQLParser.KW_ESCAPE);
                    this.state = 2464;
                    this.stringLiteral();
                    }
                    break;
                }
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public likePredicate(): LikePredicateContext {
        let localContext = new LikePredicateContext(this.context, this.state);
        this.enterRule(localContext, 332, SparkSQLParser.RULE_likePredicate);
        let _la: number;
        try {
            this.state = 2507;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 301, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 2470;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 351) {
                    {
                    this.state = 2469;
                    this.match(SparkSQLParser.KW_NOT);
                    }
                }

                this.state = 2472;
                localContext._kind = this.match(SparkSQLParser.KW_LIKE);
                this.state = 2473;
                localContext._quantifier = this.tokenStream.LT(1);
                _la = this.tokenStream.LA(1);
                if(!(_la === 202 || _la === 206)) {
                    localContext._quantifier = this.errorHandler.recoverInline(this);
                }
                else {
                    this.errorHandler.reportMatch(this);
                    this.consume();
                }
                this.state = 2487;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 296, this.context) ) {
                case 1:
                    {
                    this.state = 2474;
                    this.match(SparkSQLParser.LR_BRACKET);
                    this.state = 2475;
                    this.match(SparkSQLParser.RR_BRACKET);
                    }
                    break;
                case 2:
                    {
                    this.state = 2476;
                    this.match(SparkSQLParser.LR_BRACKET);
                    this.state = 2477;
                    this.expression();
                    this.state = 2482;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                    while (_la === 476) {
                        {
                        {
                        this.state = 2478;
                        this.match(SparkSQLParser.COMMA);
                        this.state = 2479;
                        this.expression();
                        }
                        }
                        this.state = 2484;
                        this.errorHandler.sync(this);
                        _la = this.tokenStream.LA(1);
                    }
                    this.state = 2485;
                    this.match(SparkSQLParser.RR_BRACKET);
                    }
                    break;
                }
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 2490;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 351) {
                    {
                    this.state = 2489;
                    this.match(SparkSQLParser.KW_NOT);
                    }
                }

                this.state = 2492;
                localContext._kind = this.tokenStream.LT(1);
                _la = this.tokenStream.LA(1);
                if(!(_la === 331 || _la === 392)) {
                    localContext._kind = this.errorHandler.recoverInline(this);
                }
                else {
                    this.errorHandler.reportMatch(this);
                    this.consume();
                }
                this.state = 2493;
                localContext._pattern = this.valueExpression(0);
                this.state = 2496;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 298, this.context) ) {
                case 1:
                    {
                    this.state = 2494;
                    this.match(SparkSQLParser.KW_ESCAPE);
                    this.state = 2495;
                    this.stringLiteral();
                    }
                    break;
                }
                }
                break;
            case 3:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 2499;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 351) {
                    {
                    this.state = 2498;
                    this.match(SparkSQLParser.KW_NOT);
                    }
                }

                this.state = 2501;
                _la = this.tokenStream.LA(1);
                if(!(_la === 387 || _la === 392)) {
                this.errorHandler.recoverInline(this);
                }
                else {
                    this.errorHandler.reportMatch(this);
                    this.consume();
                }
                this.state = 2502;
                this.stringLiteral();
                this.state = 2505;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 300, this.context) ) {
                case 1:
                    {
                    this.state = 2503;
                    this.match(SparkSQLParser.KW_ESCAPE);
                    this.state = 2504;
                    this.stringLiteral();
                    }
                    break;
                }
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }

    public valueExpression(): ValueExpressionContext;
    public valueExpression(_p: number): ValueExpressionContext;
    public valueExpression(_p?: number): ValueExpressionContext {
        if (_p === undefined) {
            _p = 0;
        }

        let parentContext = this.context;
        let parentState = this.state;
        let localContext = new ValueExpressionContext(this.context, parentState);
        let previousContext = localContext;
        let _startState = 334;
        this.enterRecursionRule(localContext, 334, SparkSQLParser.RULE_valueExpression, _p);
        let _la: number;
        try {
            let alternative: number;
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2513;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 302, this.context) ) {
            case 1:
                {
                localContext = new ValueExpressionDefaultContext(localContext);
                this.context = localContext;
                previousContext = localContext;

                this.state = 2510;
                this.primaryExpression(0);
                }
                break;
            case 2:
                {
                localContext = new ArithmeticUnaryContext(localContext);
                this.context = localContext;
                previousContext = localContext;
                this.state = 2511;
                (localContext as ArithmeticUnaryContext)._operator = this.tokenStream.LT(1);
                _la = this.tokenStream.LA(1);
                if(!(((((_la - 461)) & ~0x1F) === 0 && ((1 << (_la - 461)) & 100663297) !== 0))) {
                    (localContext as ArithmeticUnaryContext)._operator = this.errorHandler.recoverInline(this);
                }
                else {
                    this.errorHandler.reportMatch(this);
                    this.consume();
                }
                this.state = 2512;
                this.valueExpression(7);
                }
                break;
            }
            this.context!.stop = this.tokenStream.LT(-1);
            this.state = 2536;
            this.errorHandler.sync(this);
            alternative = this.interpreter.adaptivePredict(this.tokenStream, 304, this.context);
            while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {
                if (alternative === 1) {
                    if (this.parseListeners != null) {
                        this.triggerExitRuleEvent();
                    }
                    previousContext = localContext;
                    {
                    this.state = 2534;
                    this.errorHandler.sync(this);
                    switch (this.interpreter.adaptivePredict(this.tokenStream, 303, this.context) ) {
                    case 1:
                        {
                        localContext = new ArithmeticBinaryContext(new ValueExpressionContext(parentContext, parentState));
                        (localContext as ArithmeticBinaryContext)._left = previousContext;
                        this.pushNewRecursionContext(localContext, _startState, SparkSQLParser.RULE_valueExpression);
                        this.state = 2515;
                        if (!(this.precpred(this.context, 6))) {
                            throw this.createFailedPredicateException("this.precpred(this.context, 6)");
                        }
                        this.state = 2516;
                        (localContext as ArithmeticBinaryContext)._operator = this.tokenStream.LT(1);
                        _la = this.tokenStream.LA(1);
                        if(!(_la === 37 || ((((_la - 484)) & ~0x1F) === 0 && ((1 << (_la - 484)) & 145) !== 0))) {
                            (localContext as ArithmeticBinaryContext)._operator = this.errorHandler.recoverInline(this);
                        }
                        else {
                            this.errorHandler.reportMatch(this);
                            this.consume();
                        }
                        this.state = 2517;
                        (localContext as ArithmeticBinaryContext)._right = this.valueExpression(7);
                        }
                        break;
                    case 2:
                        {
                        localContext = new ArithmeticBinaryContext(new ValueExpressionContext(parentContext, parentState));
                        (localContext as ArithmeticBinaryContext)._left = previousContext;
                        this.pushNewRecursionContext(localContext, _startState, SparkSQLParser.RULE_valueExpression);
                        this.state = 2518;
                        if (!(this.precpred(this.context, 5))) {
                            throw this.createFailedPredicateException("this.precpred(this.context, 5)");
                        }
                        this.state = 2519;
                        (localContext as ArithmeticBinaryContext)._operator = this.tokenStream.LT(1);
                        _la = this.tokenStream.LA(1);
                        if(!(((((_la - 486)) & ~0x1F) === 0 && ((1 << (_la - 486)) & 11) !== 0))) {
                            (localContext as ArithmeticBinaryContext)._operator = this.errorHandler.recoverInline(this);
                        }
                        else {
                            this.errorHandler.reportMatch(this);
                            this.consume();
                        }
                        this.state = 2520;
                        (localContext as ArithmeticBinaryContext)._right = this.valueExpression(6);
                        }
                        break;
                    case 3:
                        {
                        localContext = new ArithmeticBinaryContext(new ValueExpressionContext(parentContext, parentState));
                        (localContext as ArithmeticBinaryContext)._left = previousContext;
                        this.pushNewRecursionContext(localContext, _startState, SparkSQLParser.RULE_valueExpression);
                        this.state = 2521;
                        if (!(this.precpred(this.context, 4))) {
                            throw this.createFailedPredicateException("this.precpred(this.context, 4)");
                        }
                        this.state = 2522;
                        (localContext as ArithmeticBinaryContext)._operator = this.match(SparkSQLParser.BIT_AND_OP);
                        this.state = 2523;
                        (localContext as ArithmeticBinaryContext)._right = this.valueExpression(5);
                        }
                        break;
                    case 4:
                        {
                        localContext = new ArithmeticBinaryContext(new ValueExpressionContext(parentContext, parentState));
                        (localContext as ArithmeticBinaryContext)._left = previousContext;
                        this.pushNewRecursionContext(localContext, _startState, SparkSQLParser.RULE_valueExpression);
                        this.state = 2524;
                        if (!(this.precpred(this.context, 3))) {
                            throw this.createFailedPredicateException("this.precpred(this.context, 3)");
                        }
                        this.state = 2525;
                        (localContext as ArithmeticBinaryContext)._operator = this.match(SparkSQLParser.BIT_XOR_OP);
                        this.state = 2526;
                        (localContext as ArithmeticBinaryContext)._right = this.valueExpression(4);
                        }
                        break;
                    case 5:
                        {
                        localContext = new OrContext(new ValueExpressionContext(parentContext, parentState));
                        (localContext as OrContext)._left = previousContext;
                        this.pushNewRecursionContext(localContext, _startState, SparkSQLParser.RULE_valueExpression);
                        this.state = 2527;
                        if (!(this.precpred(this.context, 2))) {
                            throw this.createFailedPredicateException("this.precpred(this.context, 2)");
                        }
                        this.state = 2528;
                        (localContext as OrContext)._operator = this.match(SparkSQLParser.BIT_OR_OP);
                        this.state = 2529;
                        (localContext as OrContext)._right = this.valueExpression(3);
                        }
                        break;
                    case 6:
                        {
                        localContext = new ComparisonContext(new ValueExpressionContext(parentContext, parentState));
                        (localContext as ComparisonContext)._left = previousContext;
                        this.pushNewRecursionContext(localContext, _startState, SparkSQLParser.RULE_valueExpression);
                        this.state = 2530;
                        if (!(this.precpred(this.context, 1))) {
                            throw this.createFailedPredicateException("this.precpred(this.context, 1)");
                        }
                        this.state = 2531;
                        (localContext as ComparisonContext)._operator = this.comparisonOperator();
                        this.state = 2532;
                        (localContext as ComparisonContext)._right = this.valueExpression(2);
                        }
                        break;
                    }
                    }
                }
                this.state = 2538;
                this.errorHandler.sync(this);
                alternative = this.interpreter.adaptivePredict(this.tokenStream, 304, this.context);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.unrollRecursionContexts(parentContext);
        }
        return localContext;
    }

    public primaryExpression(): PrimaryExpressionContext;
    public primaryExpression(_p: number): PrimaryExpressionContext;
    public primaryExpression(_p?: number): PrimaryExpressionContext {
        if (_p === undefined) {
            _p = 0;
        }

        let parentContext = this.context;
        let parentState = this.state;
        let localContext = new PrimaryExpressionContext(this.context, parentState);
        let previousContext = localContext;
        let _startState = 336;
        this.enterRecursionRule(localContext, 336, SparkSQLParser.RULE_primaryExpression, _p);
        let _la: number;
        try {
            let alternative: number;
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2671;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 318, this.context) ) {
            case 1:
                {
                localContext = new SearchedCaseContext(localContext);
                this.context = localContext;
                previousContext = localContext;

                this.state = 2540;
                this.match(SparkSQLParser.KW_CASE);
                this.state = 2542;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                do {
                    {
                    {
                    this.state = 2541;
                    this.whenClause();
                    }
                    }
                    this.state = 2544;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                } while (_la === 446);
                this.state = 2548;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 275) {
                    {
                    this.state = 2546;
                    this.match(SparkSQLParser.KW_ELSE);
                    this.state = 2547;
                    (localContext as SearchedCaseContext)._elseExpression = this.expression();
                    }
                }

                this.state = 2550;
                this.match(SparkSQLParser.KW_END);
                }
                break;
            case 2:
                {
                localContext = new SimpleCaseContext(localContext);
                this.context = localContext;
                previousContext = localContext;
                this.state = 2552;
                this.match(SparkSQLParser.KW_CASE);
                this.state = 2553;
                (localContext as SimpleCaseContext)._value = this.expression();
                this.state = 2555;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                do {
                    {
                    {
                    this.state = 2554;
                    this.whenClause();
                    }
                    }
                    this.state = 2557;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                } while (_la === 446);
                this.state = 2561;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 275) {
                    {
                    this.state = 2559;
                    this.match(SparkSQLParser.KW_ELSE);
                    this.state = 2560;
                    (localContext as SimpleCaseContext)._elseExpression = this.expression();
                    }
                }

                this.state = 2563;
                this.match(SparkSQLParser.KW_END);
                }
                break;
            case 3:
                {
                localContext = new CastContext(localContext);
                this.context = localContext;
                previousContext = localContext;
                this.state = 2565;
                this.match(SparkSQLParser.KW_CAST);
                this.state = 2566;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 2567;
                this.expression();
                this.state = 2568;
                this.match(SparkSQLParser.KW_AS);
                this.state = 2569;
                this.columnType();
                this.state = 2570;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case 4:
                {
                localContext = new FirstContext(localContext);
                this.context = localContext;
                previousContext = localContext;
                this.state = 2572;
                this.match(SparkSQLParser.KW_FIRST);
                this.state = 2573;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 2574;
                this.expression();
                this.state = 2577;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 67) {
                    {
                    this.state = 2575;
                    this.match(SparkSQLParser.KW_IGNORE);
                    this.state = 2576;
                    this.match(SparkSQLParser.KW_NULLS);
                    }
                }

                this.state = 2579;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case 5:
                {
                localContext = new LastContext(localContext);
                this.context = localContext;
                previousContext = localContext;
                this.state = 2581;
                this.match(SparkSQLParser.KW_LAST);
                this.state = 2582;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 2583;
                this.expression();
                this.state = 2586;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 67) {
                    {
                    this.state = 2584;
                    this.match(SparkSQLParser.KW_IGNORE);
                    this.state = 2585;
                    this.match(SparkSQLParser.KW_NULLS);
                    }
                }

                this.state = 2588;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case 6:
                {
                localContext = new PositionContext(localContext);
                this.context = localContext;
                previousContext = localContext;
                this.state = 2590;
                this.match(SparkSQLParser.KW_POSITION);
                this.state = 2591;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 2592;
                (localContext as PositionContext)._substr = this.valueExpression(0);
                this.state = 2593;
                this.match(SparkSQLParser.KW_IN);
                this.state = 2594;
                (localContext as PositionContext)._str = this.valueExpression(0);
                this.state = 2595;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case 7:
                {
                localContext = new ConstantDefaultContext(localContext);
                this.context = localContext;
                previousContext = localContext;
                this.state = 2597;
                this.constant();
                }
                break;
            case 8:
                {
                localContext = new StarContext(localContext);
                this.context = localContext;
                previousContext = localContext;
                this.state = 2598;
                this.match(SparkSQLParser.ASTERISK_SIGN);
                }
                break;
            case 9:
                {
                localContext = new StarContext(localContext);
                this.context = localContext;
                previousContext = localContext;
                this.state = 2599;
                this.uid();
                this.state = 2600;
                this.match(SparkSQLParser.DOT);
                this.state = 2601;
                this.match(SparkSQLParser.ASTERISK_SIGN);
                }
                break;
            case 10:
                {
                localContext = new SubqueryExpressionContext(localContext);
                this.context = localContext;
                previousContext = localContext;
                this.state = 2603;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 2604;
                this.queryStatement(0);
                this.state = 2605;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case 11:
                {
                localContext = new ValuesContext(localContext);
                this.context = localContext;
                previousContext = localContext;
                this.state = 2607;
                this.match(SparkSQLParser.LR_BRACKET);
                {
                this.state = 2608;
                this.functionParam();
                this.state = 2613;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                while (_la === 476) {
                    {
                    {
                    this.state = 2609;
                    this.match(SparkSQLParser.COMMA);
                    this.state = 2610;
                    this.functionParam();
                    }
                    }
                    this.state = 2615;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                }
                }
                this.state = 2616;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case 12:
                {
                localContext = new FunctionCallContext(localContext);
                this.context = localContext;
                previousContext = localContext;
                this.state = 2618;
                this.functionName();
                this.state = 2619;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 2631;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if ((((_la) & ~0x1F) === 0 && ((1 << _la) & 4294896624) !== 0) || ((((_la - 33)) & ~0x1F) === 0 && ((1 << (_la - 33)) & 4294836223) !== 0) || ((((_la - 65)) & ~0x1F) === 0 && ((1 << (_la - 65)) & 4281327607) !== 0) || ((((_la - 97)) & ~0x1F) === 0 && ((1 << (_la - 97)) & 2147483643) !== 0) || ((((_la - 129)) & ~0x1F) === 0 && ((1 << (_la - 129)) & 2113863675) !== 0) || ((((_la - 161)) & ~0x1F) === 0 && ((1 << (_la - 161)) & 4292341757) !== 0) || ((((_la - 193)) & ~0x1F) === 0 && ((1 << (_la - 193)) & 134775807) !== 0) || ((((_la - 227)) & ~0x1F) === 0 && ((1 << (_la - 227)) & 2685932551) !== 0) || ((((_la - 268)) & ~0x1F) === 0 && ((1 << (_la - 268)) & 70336513) !== 0) || ((((_la - 300)) & ~0x1F) === 0 && ((1 << (_la - 300)) & 2030075921) !== 0) || ((((_la - 335)) & ~0x1F) === 0 && ((1 << (_la - 335)) & 2148205697) !== 0) || ((((_la - 372)) & ~0x1F) === 0 && ((1 << (_la - 372)) & 42494055) !== 0) || ((((_la - 410)) & ~0x1F) === 0 && ((1 << (_la - 410)) & 276029453) !== 0) || ((((_la - 452)) & ~0x1F) === 0 && ((1 << (_la - 452)) & 135266817) !== 0) || ((((_la - 484)) & ~0x1F) === 0 && ((1 << (_la - 484)) & 15373) !== 0)) {
                    {
                    this.state = 2621;
                    this.errorHandler.sync(this);
                    switch (this.interpreter.adaptivePredict(this.tokenStream, 312, this.context) ) {
                    case 1:
                        {
                        this.state = 2620;
                        this.setQuantifier();
                        }
                        break;
                    }
                    this.state = 2623;
                    this.functionParam();
                    this.state = 2628;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                    while (_la === 476) {
                        {
                        {
                        this.state = 2624;
                        this.match(SparkSQLParser.COMMA);
                        this.state = 2625;
                        this.functionParam();
                        }
                        }
                        this.state = 2630;
                        this.errorHandler.sync(this);
                        _la = this.tokenStream.LA(1);
                    }
                    }
                }

                this.state = 2633;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case 13:
                {
                localContext = new FunctionCallContext(localContext);
                this.context = localContext;
                previousContext = localContext;
                this.state = 2635;
                this.functionName();
                this.state = 2636;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 2637;
                this.functionParam();
                this.state = 2638;
                this.match(SparkSQLParser.KW_TO);
                this.state = 2639;
                this.functionParam();
                this.state = 2640;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case 14:
                {
                localContext = new FunctionCallFilterContext(localContext);
                this.context = localContext;
                previousContext = localContext;
                this.state = 2642;
                this.functionName();
                this.state = 2643;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 2645;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 315, this.context) ) {
                case 1:
                    {
                    this.state = 2644;
                    this.setQuantifier();
                    }
                    break;
                }
                this.state = 2647;
                this.functionParam();
                this.state = 2648;
                this.match(SparkSQLParser.RR_BRACKET);
                this.state = 2650;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 316, this.context) ) {
                case 1:
                    {
                    this.state = 2649;
                    this.filterClause();
                    }
                    break;
                }
                }
                break;
            case 15:
                {
                localContext = new AggregateFunctionsContext(localContext);
                this.context = localContext;
                previousContext = localContext;
                this.state = 2652;
                this.funtionBody();
                this.state = 2653;
                this.filterPart();
                }
                break;
            case 16:
                {
                localContext = new OrderSetAggregateFunctionsContext(localContext);
                this.context = localContext;
                previousContext = localContext;
                this.state = 2655;
                this.funtionBody();
                this.state = 2656;
                this.match(SparkSQLParser.KW_WITHIN);
                this.state = 2657;
                this.match(SparkSQLParser.KW_GROUP);
                this.state = 2658;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 2659;
                this.orderByCaluse();
                this.state = 2660;
                this.match(SparkSQLParser.RR_BRACKET);
                this.state = 2662;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 317, this.context) ) {
                case 1:
                    {
                    this.state = 2661;
                    this.filterPart();
                    }
                    break;
                }
                }
                break;
            case 17:
                {
                localContext = new ColumnReferenceContext(localContext);
                this.context = localContext;
                previousContext = localContext;
                this.state = 2664;
                this.identifier();
                }
                break;
            case 18:
                {
                localContext = new UidForColumnNameContext(localContext);
                this.context = localContext;
                previousContext = localContext;
                this.state = 2665;
                this.uid();
                }
                break;
            case 19:
                {
                localContext = new ParenthesizedExpressionContext(localContext);
                this.context = localContext;
                previousContext = localContext;
                this.state = 2666;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 2667;
                this.expression();
                this.state = 2668;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case 20:
                {
                localContext = new ComplexDataTypeFieldExpressionContext(localContext);
                this.context = localContext;
                previousContext = localContext;
                this.state = 2670;
                this.complexDataTypeExpression();
                }
                break;
            }
            this.context!.stop = this.tokenStream.LT(-1);
            this.state = 2680;
            this.errorHandler.sync(this);
            alternative = this.interpreter.adaptivePredict(this.tokenStream, 319, this.context);
            while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {
                if (alternative === 1) {
                    if (this.parseListeners != null) {
                        this.triggerExitRuleEvent();
                    }
                    previousContext = localContext;
                    {
                    {
                    localContext = new SubscriptContext(new PrimaryExpressionContext(parentContext, parentState));
                    (localContext as SubscriptContext)._value = previousContext;
                    this.pushNewRecursionContext(localContext, _startState, SparkSQLParser.RULE_primaryExpression);
                    this.state = 2673;
                    if (!(this.precpred(this.context, 5))) {
                        throw this.createFailedPredicateException("this.precpred(this.context, 5)");
                    }
                    this.state = 2674;
                    this.match(SparkSQLParser.LS_BRACKET);
                    this.state = 2675;
                    (localContext as SubscriptContext)._index = this.valueExpression(0);
                    this.state = 2676;
                    this.match(SparkSQLParser.RS_BRACKET);
                    }
                    }
                }
                this.state = 2682;
                this.errorHandler.sync(this);
                alternative = this.interpreter.adaptivePredict(this.tokenStream, 319, this.context);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.unrollRecursionContexts(parentContext);
        }
        return localContext;
    }
    public complexDataTypeExpression(): ComplexDataTypeExpressionContext {
        let localContext = new ComplexDataTypeExpressionContext(this.context, this.state);
        this.enterRule(localContext, 338, SparkSQLParser.RULE_complexDataTypeExpression);
        try {
            this.state = 2687;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.KW_ARRAY:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 2683;
                this.arrayExpression();
                }
                break;
            case SparkSQLParser.KW_ROW:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 2684;
                this.rowExpression();
                }
                break;
            case SparkSQLParser.KW_MAP:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 2685;
                this.mapExpression();
                }
                break;
            case SparkSQLParser.KW_STRUCT:
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 2686;
                this.structExpression();
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public arrayExpression(): ArrayExpressionContext {
        let localContext = new ArrayExpressionContext(this.context, this.state);
        this.enterRule(localContext, 340, SparkSQLParser.RULE_arrayExpression);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2689;
            this.match(SparkSQLParser.KW_ARRAY);
            this.state = 2690;
            this.match(SparkSQLParser.LS_BRACKET);
            this.state = 2691;
            this.dataTypeExpression();
            this.state = 2696;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 476) {
                {
                {
                this.state = 2692;
                this.match(SparkSQLParser.COMMA);
                this.state = 2693;
                this.dataTypeExpression();
                }
                }
                this.state = 2698;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 2699;
            this.match(SparkSQLParser.RS_BRACKET);
            this.state = 2700;
            this.match(SparkSQLParser.KW_ARRAY);
            this.state = 2701;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 2702;
            this.dataTypeExpression();
            this.state = 2707;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 476) {
                {
                {
                this.state = 2703;
                this.match(SparkSQLParser.COMMA);
                this.state = 2704;
                this.dataTypeExpression();
                }
                }
                this.state = 2709;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 2710;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public structExpression(): StructExpressionContext {
        let localContext = new StructExpressionContext(this.context, this.state);
        this.enterRule(localContext, 342, SparkSQLParser.RULE_structExpression);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2712;
            this.match(SparkSQLParser.KW_STRUCT);
            this.state = 2713;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 2714;
            this.dataTypeExpression();
            this.state = 2719;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 476) {
                {
                {
                this.state = 2715;
                this.match(SparkSQLParser.COMMA);
                this.state = 2716;
                this.dataTypeExpression();
                }
                }
                this.state = 2721;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 2722;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public rowExpression(): RowExpressionContext {
        let localContext = new RowExpressionContext(this.context, this.state);
        this.enterRule(localContext, 344, SparkSQLParser.RULE_rowExpression);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2724;
            this.match(SparkSQLParser.KW_ROW);
            this.state = 2725;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 2726;
            this.dataTypeExpression();
            this.state = 2731;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 476) {
                {
                {
                this.state = 2727;
                this.match(SparkSQLParser.COMMA);
                this.state = 2728;
                this.dataTypeExpression();
                }
                }
                this.state = 2733;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 2734;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public mapExpression(): MapExpressionContext {
        let localContext = new MapExpressionContext(this.context, this.state);
        this.enterRule(localContext, 346, SparkSQLParser.RULE_mapExpression);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2736;
            this.match(SparkSQLParser.KW_MAP);
            this.state = 2737;
            this.match(SparkSQLParser.LS_BRACKET);
            this.state = 2738;
            this.dataTypeExpression();
            this.state = 2739;
            this.match(SparkSQLParser.COMMA);
            this.state = 2740;
            this.dataTypeExpression();
            this.state = 2741;
            this.match(SparkSQLParser.RS_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public dataTypeExpression(): DataTypeExpressionContext {
        let localContext = new DataTypeExpressionContext(this.context, this.state);
        this.enterRule(localContext, 348, SparkSQLParser.RULE_dataTypeExpression);
        try {
            this.state = 2747;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 325, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 2743;
                this.columnAlias();
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 2744;
                this.constant();
                }
                break;
            case 3:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 2745;
                this.complexDataTypeExpression();
                }
                break;
            case 4:
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 2746;
                this.sqlSimpleType();
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public sqlSimpleType(): SqlSimpleTypeContext {
        let localContext = new SqlSimpleTypeContext(this.context, this.state);
        this.enterRule(localContext, 350, SparkSQLParser.RULE_sqlSimpleType);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2749;
            _la = this.tokenStream.LA(1);
            if(!(_la === 10 || _la === 88 || _la === 131 || _la === 154 || _la === 172 || _la === 173 || _la === 215 || _la === 219 || ((((_la - 256)) & ~0x1F) === 0 && ((1 << (_la - 256)) & 65553) !== 0) || ((((_la - 290)) & ~0x1F) === 0 && ((1 << (_la - 290)) & 12582913) !== 0) || _la === 355 || ((((_la - 406)) & ~0x1F) === 0 && ((1 << (_la - 406)) & 4587521) !== 0))) {
            this.errorHandler.recoverInline(this);
            }
            else {
                this.errorHandler.reportMatch(this);
                this.consume();
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public functionName(): FunctionNameContext {
        let localContext = new FunctionNameContext(this.context, this.state);
        this.enterRule(localContext, 352, SparkSQLParser.RULE_functionName);
        try {
            this.state = 2754;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 326, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 2751;
                this.nonReservedKeywords();
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 2752;
                this.uid();
                }
                break;
            case 3:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 2753;
                this.reservedKeywordsUsedAsFuncName();
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public functionParam(): FunctionParamContext {
        let localContext = new FunctionParamContext(this.context, this.state);
        this.enterRule(localContext, 354, SparkSQLParser.RULE_functionParam);
        try {
            this.state = 2762;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 327, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 2756;
                this.reservedKeywordsUsedAsFuncParam();
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 2757;
                this.timeIntervalUnit();
                }
                break;
            case 3:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 2758;
                this.timePointUnit();
                }
                break;
            case 4:
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 2759;
                this.expression();
                }
                break;
            case 5:
                this.enterOuterAlt(localContext, 5);
                {
                this.state = 2760;
                this.filterClause();
                }
                break;
            case 6:
                this.enterOuterAlt(localContext, 6);
                {
                this.state = 2761;
                this.constant();
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public filterClause(): FilterClauseContext {
        let localContext = new FilterClauseContext(this.context, this.state);
        this.enterRule(localContext, 356, SparkSQLParser.RULE_filterClause);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2764;
            this.match(SparkSQLParser.KW_FILTER);
            this.state = 2765;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 2766;
            this.match(SparkSQLParser.KW_WHERE);
            this.state = 2767;
            this.booleanExpression(0);
            this.state = 2768;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public correlationName(): CorrelationNameContext {
        let localContext = new CorrelationNameContext(this.context, this.state);
        this.enterRule(localContext, 358, SparkSQLParser.RULE_correlationName);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2770;
            this.identifier();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public qualifiedName(): QualifiedNameContext {
        let localContext = new QualifiedNameContext(this.context, this.state);
        this.enterRule(localContext, 360, SparkSQLParser.RULE_qualifiedName);
        try {
            this.state = 2775;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 328, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 2772;
                this.identifier();
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 2773;
                this.uid();
                }
                break;
            case 3:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 2774;
                this.unquotedAnyString();
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public timeIntervalExpression(): TimeIntervalExpressionContext {
        let localContext = new TimeIntervalExpressionContext(this.context, this.state);
        this.enterRule(localContext, 362, SparkSQLParser.RULE_timeIntervalExpression);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2777;
            this.match(SparkSQLParser.KW_INTERVAL);
            this.state = 2780;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 329, this.context) ) {
            case 1:
                {
                this.state = 2778;
                this.errorCapturingMultiUnitsInterval();
                }
                break;
            case 2:
                {
                this.state = 2779;
                this.errorCapturingUnitToUnitInterval();
                }
                break;
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public errorCapturingMultiUnitsInterval(): ErrorCapturingMultiUnitsIntervalContext {
        let localContext = new ErrorCapturingMultiUnitsIntervalContext(this.context, this.state);
        this.enterRule(localContext, 364, SparkSQLParser.RULE_errorCapturingMultiUnitsInterval);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2782;
            this.multiUnitsInterval();
            this.state = 2784;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 330, this.context) ) {
            case 1:
                {
                this.state = 2783;
                this.unitToUnitInterval();
                }
                break;
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public multiUnitsInterval(): MultiUnitsIntervalContext {
        let localContext = new MultiUnitsIntervalContext(this.context, this.state);
        this.enterRule(localContext, 366, SparkSQLParser.RULE_multiUnitsInterval);
        try {
            let alternative: number;
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2789;
            this.errorHandler.sync(this);
            alternative = 1;
            do {
                switch (alternative) {
                case 1:
                    {
                    {
                    this.state = 2786;
                    this.intervalValue();
                    this.state = 2787;
                    this.timeIntervalUnit();
                    }
                    }
                    break;
                default:
                    throw new antlr.NoViableAltException(this);
                }
                this.state = 2791;
                this.errorHandler.sync(this);
                alternative = this.interpreter.adaptivePredict(this.tokenStream, 331, this.context);
            } while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public errorCapturingUnitToUnitInterval(): ErrorCapturingUnitToUnitIntervalContext {
        let localContext = new ErrorCapturingUnitToUnitIntervalContext(this.context, this.state);
        this.enterRule(localContext, 368, SparkSQLParser.RULE_errorCapturingUnitToUnitInterval);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2793;
            localContext._body = this.unitToUnitInterval();
            this.state = 2796;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 332, this.context) ) {
            case 1:
                {
                this.state = 2794;
                localContext._error1 = this.multiUnitsInterval();
                }
                break;
            case 2:
                {
                this.state = 2795;
                localContext._error2 = this.unitToUnitInterval();
                }
                break;
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public unitToUnitInterval(): UnitToUnitIntervalContext {
        let localContext = new UnitToUnitIntervalContext(this.context, this.state);
        this.enterRule(localContext, 370, SparkSQLParser.RULE_unitToUnitInterval);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2798;
            localContext._value = this.intervalValue();
            this.state = 2799;
            localContext._from_ = this.timeIntervalUnit();
            this.state = 2800;
            this.match(SparkSQLParser.KW_TO);
            this.state = 2801;
            localContext._to = this.timeIntervalUnit();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public intervalValue(): IntervalValueContext {
        let localContext = new IntervalValueContext(this.context, this.state);
        this.enterRule(localContext, 372, SparkSQLParser.RULE_intervalValue);
        let _la: number;
        try {
            this.state = 2808;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.HYPNEN_SIGN:
            case SparkSQLParser.ADD_SIGN:
            case SparkSQLParser.DIG_LITERAL:
            case SparkSQLParser.REAL_LITERAL:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 2804;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 486 || _la === 487) {
                    {
                    this.state = 2803;
                    _la = this.tokenStream.LA(1);
                    if(!(_la === 486 || _la === 487)) {
                    this.errorHandler.recoverInline(this);
                    }
                    else {
                        this.errorHandler.reportMatch(this);
                        this.consume();
                    }
                    }
                }

                this.state = 2806;
                _la = this.tokenStream.LA(1);
                if(!(_la === 495 || _la === 496)) {
                this.errorHandler.recoverInline(this);
                }
                else {
                    this.errorHandler.reportMatch(this);
                    this.consume();
                }
                }
                break;
            case SparkSQLParser.STRING_LITERAL:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 2807;
                this.match(SparkSQLParser.STRING_LITERAL);
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public columnAlias(): ColumnAliasContext {
        let localContext = new ColumnAliasContext(this.context, this.state);
        this.enterRule(localContext, 374, SparkSQLParser.RULE_columnAlias);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2810;
            this.anyAlias();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public tableAlias(): TableAliasContext {
        let localContext = new TableAliasContext(this.context, this.state);
        this.enterRule(localContext, 376, SparkSQLParser.RULE_tableAlias);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2812;
            this.anyAlias();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public anyAlias(): AnyAliasContext {
        let localContext = new AnyAliasContext(this.context, this.state);
        this.enterRule(localContext, 378, SparkSQLParser.RULE_anyAlias);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2815;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 209) {
                {
                this.state = 2814;
                this.match(SparkSQLParser.KW_AS);
                }
            }

            this.state = 2817;
            this.identifier();
            this.state = 2819;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 336, this.context) ) {
            case 1:
                {
                this.state = 2818;
                this.identifierList();
                }
                break;
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public errorCapturingIdentifier(): ErrorCapturingIdentifierContext {
        let localContext = new ErrorCapturingIdentifierContext(this.context, this.state);
        this.enterRule(localContext, 380, SparkSQLParser.RULE_errorCapturingIdentifier);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2821;
            this.identifier();
            this.state = 2822;
            this.errorCapturingIdentifierExtra();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public errorCapturingIdentifierExtra(): ErrorCapturingIdentifierExtraContext {
        let localContext = new ErrorCapturingIdentifierExtraContext(this.context, this.state);
        this.enterRule(localContext, 382, SparkSQLParser.RULE_errorCapturingIdentifierExtra);
        let _la: number;
        try {
            localContext = new ErrorIdentContext(localContext);
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2828;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 341) {
                {
                {
                this.state = 2824;
                this.match(SparkSQLParser.KW_MINUS);
                this.state = 2825;
                this.identifier();
                }
                }
                this.state = 2830;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public identifierList(): IdentifierListContext {
        let localContext = new IdentifierListContext(this.context, this.state);
        this.enterRule(localContext, 384, SparkSQLParser.RULE_identifierList);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2831;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 2832;
            this.identifierSeq();
            this.state = 2833;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public identifierSeq(): IdentifierSeqContext {
        let localContext = new IdentifierSeqContext(this.context, this.state);
        this.enterRule(localContext, 386, SparkSQLParser.RULE_identifierSeq);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2835;
            this.identifier();
            this.state = 2840;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 476) {
                {
                {
                this.state = 2836;
                this.match(SparkSQLParser.COMMA);
                this.state = 2837;
                this.identifier();
                }
                }
                this.state = 2842;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public identifier(): IdentifierContext {
        let localContext = new IdentifierContext(this.context, this.state);
        this.enterRule(localContext, 388, SparkSQLParser.RULE_identifier);
        try {
            this.state = 2847;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.DIG_LITERAL:
            case SparkSQLParser.ID_LITERAL:
                localContext = new UnquotedIdentifierAlternativeContext(localContext);
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 2843;
                this.unquotedIdentifier();
                }
                break;
            case SparkSQLParser.STRING_LITERAL:
                localContext = new QuotedIdentifierAlternativeContext(localContext);
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 2844;
                this.match(SparkSQLParser.STRING_LITERAL);
                }
                break;
            case SparkSQLParser.KW_ADD:
            case SparkSQLParser.KW_ADMIN:
            case SparkSQLParser.KW_AFTER:
            case SparkSQLParser.KW_ANALYZE:
            case SparkSQLParser.KW_ASC:
            case SparkSQLParser.KW_BEFORE:
            case SparkSQLParser.KW_BYTES:
            case SparkSQLParser.KW_CASCADE:
            case SparkSQLParser.KW_CATALOG:
            case SparkSQLParser.KW_CATALOGS:
            case SparkSQLParser.KW_CENTURY:
            case SparkSQLParser.KW_CHAIN:
            case SparkSQLParser.KW_CHANGELOG_MODE:
            case SparkSQLParser.KW_CHARACTERS:
            case SparkSQLParser.KW_COMMENT:
            case SparkSQLParser.KW_COMPACT:
            case SparkSQLParser.KW_COLUMNS:
            case SparkSQLParser.KW_CONSTRAINTS:
            case SparkSQLParser.KW_CONSTRUCTOR:
            case SparkSQLParser.KW_COMPUTE:
            case SparkSQLParser.KW_CUMULATE:
            case SparkSQLParser.KW_DATA:
            case SparkSQLParser.KW_DATABASE:
            case SparkSQLParser.KW_DATABASES:
            case SparkSQLParser.KW_DAYS:
            case SparkSQLParser.KW_DECADE:
            case SparkSQLParser.KW_DEFINED:
            case SparkSQLParser.KW_DESC:
            case SparkSQLParser.KW_DESCRIPTOR:
            case SparkSQLParser.KW_DIV:
            case SparkSQLParser.KW_ENCODING:
            case SparkSQLParser.KW_ENFORCED:
            case SparkSQLParser.KW_ENGINE:
            case SparkSQLParser.KW_ERROR:
            case SparkSQLParser.KW_ESTIMATED_COST:
            case SparkSQLParser.KW_EXCEPTION:
            case SparkSQLParser.KW_EXCLUDE:
            case SparkSQLParser.KW_EXCLUDING:
            case SparkSQLParser.KW_EXTENDED:
            case SparkSQLParser.KW_FILE:
            case SparkSQLParser.KW_FINAL:
            case SparkSQLParser.KW_FIRST:
            case SparkSQLParser.KW_FOLLOWING:
            case SparkSQLParser.KW_FORMAT:
            case SparkSQLParser.KW_FORTRAN:
            case SparkSQLParser.KW_FOUND:
            case SparkSQLParser.KW_FRAC_SECOND:
            case SparkSQLParser.KW_FUNCTIONS:
            case SparkSQLParser.KW_GENERAL:
            case SparkSQLParser.KW_GENERATED:
            case SparkSQLParser.KW_GO:
            case SparkSQLParser.KW_GOTO:
            case SparkSQLParser.KW_GRANTED:
            case SparkSQLParser.KW_HOP:
            case SparkSQLParser.KW_HOURS:
            case SparkSQLParser.KW_IF:
            case SparkSQLParser.KW_IGNORE:
            case SparkSQLParser.KW_INCREMENT:
            case SparkSQLParser.KW_INPUT:
            case SparkSQLParser.KW_INVOKER:
            case SparkSQLParser.KW_JAR:
            case SparkSQLParser.KW_JARS:
            case SparkSQLParser.KW_JAVA:
            case SparkSQLParser.KW_JSON:
            case SparkSQLParser.KW_JSON_EXECUTION_PLAN:
            case SparkSQLParser.KW_KEY:
            case SparkSQLParser.KW_KEY_MEMBER:
            case SparkSQLParser.KW_KEY_TYPE:
            case SparkSQLParser.KW_LABEL:
            case SparkSQLParser.KW_LAST:
            case SparkSQLParser.KW_LENGTH:
            case SparkSQLParser.KW_LEVEL:
            case SparkSQLParser.KW_LOAD:
            case SparkSQLParser.KW_MAP:
            case SparkSQLParser.KW_MICROSECOND:
            case SparkSQLParser.KW_MILLENNIUM:
            case SparkSQLParser.KW_MILLISECOND:
            case SparkSQLParser.KW_MINUTES:
            case SparkSQLParser.KW_MINVALUE:
            case SparkSQLParser.KW_MODIFY:
            case SparkSQLParser.KW_MODULES:
            case SparkSQLParser.KW_MONTHS:
            case SparkSQLParser.KW_NANOSECOND:
            case SparkSQLParser.KW_NULLS:
            case SparkSQLParser.KW_NUMBER:
            case SparkSQLParser.KW_OPTION:
            case SparkSQLParser.KW_OPTIONS:
            case SparkSQLParser.KW_ORDERING:
            case SparkSQLParser.KW_OUTPUT:
            case SparkSQLParser.KW_OVERWRITE:
            case SparkSQLParser.KW_OVERWRITING:
            case SparkSQLParser.KW_PARTITIONED:
            case SparkSQLParser.KW_PARTITIONS:
            case SparkSQLParser.KW_PASSING:
            case SparkSQLParser.KW_PAST:
            case SparkSQLParser.KW_PATH:
            case SparkSQLParser.KW_PLACING:
            case SparkSQLParser.KW_PLAN:
            case SparkSQLParser.KW_PRECEDING:
            case SparkSQLParser.KW_PRESERVE:
            case SparkSQLParser.KW_PRIOR:
            case SparkSQLParser.KW_PRIVILEGES:
            case SparkSQLParser.KW_PUBLIC:
            case SparkSQLParser.KW_PYTHON:
            case SparkSQLParser.KW_PYTHON_FILES:
            case SparkSQLParser.KW_PYTHON_REQUIREMENTS:
            case SparkSQLParser.KW_PYTHON_DEPENDENCIES:
            case SparkSQLParser.KW_PYTHON_JAR:
            case SparkSQLParser.KW_PYTHON_ARCHIVES:
            case SparkSQLParser.KW_PYTHON_PARAMETER:
            case SparkSQLParser.KW_QUARTER:
            case SparkSQLParser.KW_RAW:
            case SparkSQLParser.KW_READ:
            case SparkSQLParser.KW_RELATIVE:
            case SparkSQLParser.KW_REMOVE:
            case SparkSQLParser.KW_RENAME:
            case SparkSQLParser.KW_REPLACE:
            case SparkSQLParser.KW_RESPECT:
            case SparkSQLParser.KW_RESTART:
            case SparkSQLParser.KW_RESTRICT:
            case SparkSQLParser.KW_ROLE:
            case SparkSQLParser.KW_ROW_COUNT:
            case SparkSQLParser.KW_SCALA:
            case SparkSQLParser.KW_SCALAR:
            case SparkSQLParser.KW_SCALE:
            case SparkSQLParser.KW_SCHEMA:
            case SparkSQLParser.KW_SECONDS:
            case SparkSQLParser.KW_SECTION:
            case SparkSQLParser.KW_SECURITY:
            case SparkSQLParser.KW_SELF:
            case SparkSQLParser.KW_SERVER:
            case SparkSQLParser.KW_SERVER_NAME:
            case SparkSQLParser.KW_SESSION:
            case SparkSQLParser.KW_SETS:
            case SparkSQLParser.KW_SIMPLE:
            case SparkSQLParser.KW_SIZE:
            case SparkSQLParser.KW_SLIDE:
            case SparkSQLParser.KW_SOURCE:
            case SparkSQLParser.KW_SPACE:
            case SparkSQLParser.KW_STATE:
            case SparkSQLParser.KW_STATEMENT:
            case SparkSQLParser.KW_STEP:
            case SparkSQLParser.KW_STRING:
            case SparkSQLParser.KW_STRUCTURE:
            case SparkSQLParser.KW_STYLE:
            case SparkSQLParser.KW_TABLES:
            case SparkSQLParser.KW_TEMPORARY:
            case SparkSQLParser.KW_TIMECOL:
            case SparkSQLParser.KW_FLOOR:
            case SparkSQLParser.KW_TIMESTAMP_LTZ:
            case SparkSQLParser.KW_TIMESTAMPADD:
            case SparkSQLParser.KW_TIMESTAMPDIFF:
            case SparkSQLParser.KW_TOTIMESTAMP:
            case SparkSQLParser.KW_TRANSFORM:
            case SparkSQLParser.KW_TUMBLE:
            case SparkSQLParser.KW_TYPE:
            case SparkSQLParser.KW_UNDER:
            case SparkSQLParser.KW_UNLOAD:
            case SparkSQLParser.KW_USAGE:
            case SparkSQLParser.KW_USE:
            case SparkSQLParser.KW_UTF16:
            case SparkSQLParser.KW_UTF32:
            case SparkSQLParser.KW_UTF8:
            case SparkSQLParser.KW_VERSION:
            case SparkSQLParser.KW_VIEW:
            case SparkSQLParser.KW_VIEWS:
            case SparkSQLParser.KW_VIRTUAL:
            case SparkSQLParser.KW_WATERMARK:
            case SparkSQLParser.KW_WATERMARKS:
            case SparkSQLParser.KW_WEEK:
            case SparkSQLParser.KW_WORK:
            case SparkSQLParser.KW_WRAPPER:
            case SparkSQLParser.KW_YEARS:
            case SparkSQLParser.KW_ZONE:
            case SparkSQLParser.KW_LOCALTIMESTAMP:
                localContext = new NonReservedKeywordsAlternativeContext(localContext);
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 2845;
                this.nonReservedKeywords();
                }
                break;
            case SparkSQLParser.DOLLAR:
                localContext = new UrefVarAlternativeContext(localContext);
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 2846;
                this.refVar();
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public unquotedAnyString(): UnquotedAnyStringContext {
        let localContext = new UnquotedAnyStringContext(this.context, this.state);
        this.enterRule(localContext, 390, SparkSQLParser.RULE_unquotedAnyString);
        try {
            this.state = 2853;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 340, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 2849;
                this.unquotedIdentifier();
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 2850;
                this.reservedKeywordsUsedAsFuncParam();
                }
                break;
            case 3:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 2851;
                this.nonReservedKeywords();
                }
                break;
            case 4:
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 2852;
                this.reservedKeywordsUsedAsFuncName();
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public refVar(): RefVarContext {
        let localContext = new RefVarContext(this.context, this.state);
        this.enterRule(localContext, 392, SparkSQLParser.RULE_refVar);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2855;
            this.match(SparkSQLParser.DOLLAR);
            this.state = 2856;
            this.match(SparkSQLParser.LB_BRACKET);
            this.state = 2857;
            this.unquotedIdentifier();
            this.state = 2858;
            this.match(SparkSQLParser.RB_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public unquotedIdentifier(): UnquotedIdentifierContext {
        let localContext = new UnquotedIdentifierContext(this.context, this.state);
        this.enterRule(localContext, 394, SparkSQLParser.RULE_unquotedIdentifier);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2860;
            _la = this.tokenStream.LA(1);
            if(!(_la === 495 || _la === 497)) {
            this.errorHandler.recoverInline(this);
            }
            else {
                this.errorHandler.reportMatch(this);
                this.consume();
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public whenClause(): WhenClauseContext {
        let localContext = new WhenClauseContext(this.context, this.state);
        this.enterRule(localContext, 396, SparkSQLParser.RULE_whenClause);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2862;
            this.match(SparkSQLParser.KW_WHEN);
            this.state = 2863;
            localContext._condition = this.expression();
            this.state = 2864;
            this.match(SparkSQLParser.KW_THEN);
            this.state = 2865;
            localContext._result = this.expression();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public catalogPath(): CatalogPathContext {
        let localContext = new CatalogPathContext(this.context, this.state);
        this.enterRule(localContext, 398, SparkSQLParser.RULE_catalogPath);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2867;
            this.uid();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public databasePath(): DatabasePathContext {
        let localContext = new DatabasePathContext(this.context, this.state);
        this.enterRule(localContext, 400, SparkSQLParser.RULE_databasePath);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2869;
            this.uid();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public databasePathCreate(): DatabasePathCreateContext {
        let localContext = new DatabasePathCreateContext(this.context, this.state);
        this.enterRule(localContext, 402, SparkSQLParser.RULE_databasePathCreate);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2871;
            this.uid();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public tablePathCreate(): TablePathCreateContext {
        let localContext = new TablePathCreateContext(this.context, this.state);
        this.enterRule(localContext, 404, SparkSQLParser.RULE_tablePathCreate);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2873;
            this.uid();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public tablePath(): TablePathContext {
        let localContext = new TablePathContext(this.context, this.state);
        this.enterRule(localContext, 406, SparkSQLParser.RULE_tablePath);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2875;
            this.uid();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public anonymousWindowsName(): AnonymousWindowsNameContext {
        let localContext = new AnonymousWindowsNameContext(this.context, this.state);
        this.enterRule(localContext, 408, SparkSQLParser.RULE_anonymousWindowsName);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2877;
            this.identifier();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public uid(): UidContext {
        let localContext = new UidContext(this.context, this.state);
        this.enterRule(localContext, 410, SparkSQLParser.RULE_uid);
        try {
            let alternative: number;
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2879;
            this.identifier();
            this.state = 2884;
            this.errorHandler.sync(this);
            alternative = this.interpreter.adaptivePredict(this.tokenStream, 341, this.context);
            while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {
                if (alternative === 1) {
                    {
                    {
                    this.state = 2880;
                    this.match(SparkSQLParser.DOT);
                    this.state = 2881;
                    this.identifier();
                    }
                    }
                }
                this.state = 2886;
                this.errorHandler.sync(this);
                alternative = this.interpreter.adaptivePredict(this.tokenStream, 341, this.context);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public withOption(): WithOptionContext {
        let localContext = new WithOptionContext(this.context, this.state);
        this.enterRule(localContext, 412, SparkSQLParser.RULE_withOption);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2887;
            this.match(SparkSQLParser.KW_WITH);
            this.state = 2889;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 32 || _la === 419) {
                {
                this.state = 2888;
                _la = this.tokenStream.LA(1);
                if(!(_la === 32 || _la === 419)) {
                this.errorHandler.recoverInline(this);
                }
                else {
                    this.errorHandler.reportMatch(this);
                    this.consume();
                }
                }
            }

            this.state = 2891;
            this.tablePropertyList();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public ifNotExists(): IfNotExistsContext {
        let localContext = new IfNotExistsContext(this.context, this.state);
        this.enterRule(localContext, 414, SparkSQLParser.RULE_ifNotExists);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2893;
            this.match(SparkSQLParser.KW_IF);
            this.state = 2894;
            this.match(SparkSQLParser.KW_NOT);
            this.state = 2895;
            this.match(SparkSQLParser.KW_EXISTS);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public ifExists(): IfExistsContext {
        let localContext = new IfExistsContext(this.context, this.state);
        this.enterRule(localContext, 416, SparkSQLParser.RULE_ifExists);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2897;
            this.match(SparkSQLParser.KW_IF);
            this.state = 2898;
            this.match(SparkSQLParser.KW_EXISTS);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public tablePropertyList(): TablePropertyListContext {
        let localContext = new TablePropertyListContext(this.context, this.state);
        this.enterRule(localContext, 418, SparkSQLParser.RULE_tablePropertyList);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2900;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 2901;
            this.tableProperty();
            this.state = 2906;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 476) {
                {
                {
                this.state = 2902;
                this.match(SparkSQLParser.COMMA);
                this.state = 2903;
                this.tableProperty();
                }
                }
                this.state = 2908;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 2909;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public tableProperty(): TablePropertyContext {
        let localContext = new TablePropertyContext(this.context, this.state);
        this.enterRule(localContext, 420, SparkSQLParser.RULE_tableProperty);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2911;
            this.tablePropertyKey();
            this.state = 2912;
            this.match(SparkSQLParser.EQUAL_SYMBOL);
            this.state = 2914;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 256) {
                {
                this.state = 2913;
                this.match(SparkSQLParser.KW_DATE);
                }
            }

            this.state = 2916;
            this.tablePropertyValue();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public tablePropertyKey(): TablePropertyKeyContext {
        let localContext = new TablePropertyKeyContext(this.context, this.state);
        this.enterRule(localContext, 422, SparkSQLParser.RULE_tablePropertyKey);
        try {
            this.state = 2922;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 345, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 2918;
                this.identifier();
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 2919;
                this.uid();
                }
                break;
            case 3:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 2920;
                this.stringLiteral();
                }
                break;
            case 4:
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 2921;
                this.functionParam();
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public propertyName(): PropertyNameContext {
        let localContext = new PropertyNameContext(this.context, this.state);
        this.enterRule(localContext, 424, SparkSQLParser.RULE_propertyName);
        try {
            this.state = 2929;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.SINGLE_QUOTE_SYMB:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 2924;
                this.match(SparkSQLParser.SINGLE_QUOTE_SYMB);
                this.state = 2925;
                this.constant();
                this.state = 2926;
                this.match(SparkSQLParser.SINGLE_QUOTE_SYMB);
                }
                break;
            case SparkSQLParser.KW_MICROSECOND:
            case SparkSQLParser.KW_MILLISECOND:
            case SparkSQLParser.KW_QUARTER:
            case SparkSQLParser.KW_WEEK:
            case SparkSQLParser.KW_DAY:
            case SparkSQLParser.KW_FALSE:
            case SparkSQLParser.KW_HOUR:
            case SparkSQLParser.KW_INTERVAL:
            case SparkSQLParser.KW_MINUTE:
            case SparkSQLParser.KW_MONTH:
            case SparkSQLParser.KW_NOT:
            case SparkSQLParser.KW_NULL:
            case SparkSQLParser.KW_SECOND:
            case SparkSQLParser.KW_TRUE:
            case SparkSQLParser.KW_YEAR:
            case SparkSQLParser.HYPNEN_SIGN:
            case SparkSQLParser.STRING_LITERAL:
            case SparkSQLParser.DIG_LITERAL:
            case SparkSQLParser.REAL_LITERAL:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 2928;
                this.constant();
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public tablePropertyValue(): TablePropertyValueContext {
        let localContext = new TablePropertyValueContext(this.context, this.state);
        this.enterRule(localContext, 426, SparkSQLParser.RULE_tablePropertyValue);
        try {
            this.state = 2941;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 347, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 2931;
                this.match(SparkSQLParser.DIG_LITERAL);
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 2932;
                this.match(SparkSQLParser.REAL_LITERAL);
                }
                break;
            case 3:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 2933;
                this.booleanLiteral();
                }
                break;
            case 4:
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 2934;
                this.uid();
                }
                break;
            case 5:
                this.enterOuterAlt(localContext, 5);
                {
                this.state = 2935;
                this.constant();
                }
                break;
            case 6:
                this.enterOuterAlt(localContext, 6);
                {
                this.state = 2936;
                this.refVar();
                }
                break;
            case 7:
                this.enterOuterAlt(localContext, 7);
                {
                this.state = 2937;
                this.match(SparkSQLParser.SINGLE_QUOTE_SYMB);
                this.state = 2938;
                this.refVar();
                this.state = 2939;
                this.match(SparkSQLParser.SINGLE_QUOTE_SYMB);
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public comparisonOperator(): ComparisonOperatorContext {
        let localContext = new ComparisonOperatorContext(this.context, this.state);
        this.enterRule(localContext, 428, SparkSQLParser.RULE_comparisonOperator);
        try {
            this.state = 2957;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 348, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 2943;
                this.match(SparkSQLParser.EQUAL_SYMBOL);
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 2944;
                this.match(SparkSQLParser.GREATER_SYMBOL);
                }
                break;
            case 3:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 2945;
                this.match(SparkSQLParser.LESS_SYMBOL);
                }
                break;
            case 4:
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 2946;
                this.match(SparkSQLParser.LESS_SYMBOL);
                this.state = 2947;
                this.match(SparkSQLParser.EQUAL_SYMBOL);
                }
                break;
            case 5:
                this.enterOuterAlt(localContext, 5);
                {
                this.state = 2948;
                this.match(SparkSQLParser.GREATER_SYMBOL);
                this.state = 2949;
                this.match(SparkSQLParser.EQUAL_SYMBOL);
                }
                break;
            case 6:
                this.enterOuterAlt(localContext, 6);
                {
                this.state = 2950;
                this.match(SparkSQLParser.LESS_SYMBOL);
                this.state = 2951;
                this.match(SparkSQLParser.GREATER_SYMBOL);
                }
                break;
            case 7:
                this.enterOuterAlt(localContext, 7);
                {
                this.state = 2952;
                this.match(SparkSQLParser.EXCLAMATION_SYMBOL);
                this.state = 2953;
                this.match(SparkSQLParser.EQUAL_SYMBOL);
                }
                break;
            case 8:
                this.enterOuterAlt(localContext, 8);
                {
                this.state = 2954;
                this.match(SparkSQLParser.LESS_SYMBOL);
                this.state = 2955;
                this.match(SparkSQLParser.EQUAL_SYMBOL);
                this.state = 2956;
                this.match(SparkSQLParser.GREATER_SYMBOL);
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public constant(): ConstantContext {
        let localContext = new ConstantContext(this.context, this.state);
        this.enterRule(localContext, 430, SparkSQLParser.RULE_constant);
        let _la: number;
        try {
            this.state = 2972;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.KW_INTERVAL:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 2959;
                this.timeIntervalExpression();
                }
                break;
            case SparkSQLParser.KW_MICROSECOND:
            case SparkSQLParser.KW_MILLISECOND:
            case SparkSQLParser.KW_QUARTER:
            case SparkSQLParser.KW_WEEK:
            case SparkSQLParser.KW_DAY:
            case SparkSQLParser.KW_HOUR:
            case SparkSQLParser.KW_MINUTE:
            case SparkSQLParser.KW_MONTH:
            case SparkSQLParser.KW_SECOND:
            case SparkSQLParser.KW_YEAR:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 2960;
                this.timePointLiteral();
                }
                break;
            case SparkSQLParser.STRING_LITERAL:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 2961;
                this.stringLiteral();
                }
                break;
            case SparkSQLParser.HYPNEN_SIGN:
            case SparkSQLParser.DIG_LITERAL:
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 2963;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 486) {
                    {
                    this.state = 2962;
                    this.match(SparkSQLParser.HYPNEN_SIGN);
                    }
                }

                this.state = 2965;
                this.decimalLiteral();
                }
                break;
            case SparkSQLParser.KW_FALSE:
            case SparkSQLParser.KW_TRUE:
                this.enterOuterAlt(localContext, 5);
                {
                this.state = 2966;
                this.booleanLiteral();
                }
                break;
            case SparkSQLParser.REAL_LITERAL:
                this.enterOuterAlt(localContext, 6);
                {
                this.state = 2967;
                this.match(SparkSQLParser.REAL_LITERAL);
                }
                break;
            case SparkSQLParser.KW_NOT:
            case SparkSQLParser.KW_NULL:
                this.enterOuterAlt(localContext, 7);
                {
                this.state = 2969;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 351) {
                    {
                    this.state = 2968;
                    this.match(SparkSQLParser.KW_NOT);
                    }
                }

                this.state = 2971;
                this.match(SparkSQLParser.KW_NULL);
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public timePointLiteral(): TimePointLiteralContext {
        let localContext = new TimePointLiteralContext(this.context, this.state);
        this.enterRule(localContext, 432, SparkSQLParser.RULE_timePointLiteral);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2974;
            this.timePointUnit();
            this.state = 2975;
            this.stringLiteral();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public stringLiteral(): StringLiteralContext {
        let localContext = new StringLiteralContext(this.context, this.state);
        this.enterRule(localContext, 434, SparkSQLParser.RULE_stringLiteral);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2977;
            this.match(SparkSQLParser.STRING_LITERAL);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public decimalLiteral(): DecimalLiteralContext {
        let localContext = new DecimalLiteralContext(this.context, this.state);
        this.enterRule(localContext, 436, SparkSQLParser.RULE_decimalLiteral);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2979;
            this.match(SparkSQLParser.DIG_LITERAL);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public booleanLiteral(): BooleanLiteralContext {
        let localContext = new BooleanLiteralContext(this.context, this.state);
        this.enterRule(localContext, 438, SparkSQLParser.RULE_booleanLiteral);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2981;
            _la = this.tokenStream.LA(1);
            if(!(_la === 289 || _la === 431)) {
            this.errorHandler.recoverInline(this);
            }
            else {
                this.errorHandler.reportMatch(this);
                this.consume();
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public setQuantifier(): SetQuantifierContext {
        let localContext = new SetQuantifierContext(this.context, this.state);
        this.enterRule(localContext, 440, SparkSQLParser.RULE_setQuantifier);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2983;
            _la = this.tokenStream.LA(1);
            if(!(_la === 202 || _la === 268)) {
            this.errorHandler.recoverInline(this);
            }
            else {
                this.errorHandler.reportMatch(this);
                this.consume();
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public timePointUnit(): TimePointUnitContext {
        let localContext = new TimePointUnitContext(this.context, this.state);
        this.enterRule(localContext, 442, SparkSQLParser.RULE_timePointUnit);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2985;
            _la = this.tokenStream.LA(1);
            if(!(_la === 90 || _la === 92 || _la === 127 || _la === 195 || _la === 258 || _la === 304 || _la === 342 || _la === 345 || _la === 397 || _la === 452)) {
            this.errorHandler.recoverInline(this);
            }
            else {
                this.errorHandler.reportMatch(this);
                this.consume();
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public timeIntervalUnit(): TimeIntervalUnitContext {
        let localContext = new TimeIntervalUnitContext(this.context, this.state);
        this.enterRule(localContext, 444, SparkSQLParser.RULE_timeIntervalUnit);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2987;
            _la = this.tokenStream.LA(1);
            if(!(((((_la - 17)) & ~0x1F) === 0 && ((1 << (_la - 17)) & 16859137) !== 0) || ((((_la - 65)) & ~0x1F) === 0 && ((1 << (_la - 65)) & 503316481) !== 0) || ((((_la - 97)) & ~0x1F) === 0 && ((1 << (_la - 97)) & 1073741827) !== 0) || _la === 146 || ((((_la - 195)) & ~0x1F) === 0 && ((1 << (_la - 195)) & 19) !== 0) || _la === 258 || _la === 304 || _la === 342 || _la === 345 || _la === 397 || _la === 452)) {
            this.errorHandler.recoverInline(this);
            }
            else {
                this.errorHandler.reportMatch(this);
                this.consume();
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public reservedKeywordsUsedAsFuncParam(): ReservedKeywordsUsedAsFuncParamContext {
        let localContext = new ReservedKeywordsUsedAsFuncParamContext(this.context, this.state);
        this.enterRule(localContext, 446, SparkSQLParser.RULE_reservedKeywordsUsedAsFuncParam);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2989;
            _la = this.tokenStream.LA(1);
            if(!(_la === 202 || _la === 220 || _la === 268 || _la === 329 || _la === 430 || _la === 484)) {
            this.errorHandler.recoverInline(this);
            }
            else {
                this.errorHandler.reportMatch(this);
                this.consume();
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public reservedKeywordsUsedAsFuncName(): ReservedKeywordsUsedAsFuncNameContext {
        let localContext = new ReservedKeywordsUsedAsFuncNameContext(this.context, this.state);
        this.enterRule(localContext, 448, SparkSQLParser.RULE_reservedKeywordsUsedAsFuncName);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2991;
            _la = this.tokenStream.LA(1);
            if(!(_la === 66 || _la === 89 || _la === 127 || ((((_la - 195)) & ~0x1F) === 0 && ((1 << (_la - 195)) & 139329) !== 0) || ((((_la - 228)) & ~0x1F) === 0 && ((1 << (_la - 228)) & 269224451) !== 0) || ((((_la - 284)) & ~0x1F) === 0 && ((1 << (_la - 284)) & 1115153) !== 0) || ((((_la - 324)) & ~0x1F) === 0 && ((1 << (_la - 324)) & 270794841) !== 0) || ((((_la - 366)) & ~0x1F) === 0 && ((1 << (_la - 366)) & 2182748609) !== 0) || ((((_la - 412)) & ~0x1F) === 0 && ((1 << (_la - 412)) & 68220931) !== 0) || _la === 452)) {
            this.errorHandler.recoverInline(this);
            }
            else {
                this.errorHandler.reportMatch(this);
                this.consume();
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public nonReservedKeywords(): NonReservedKeywordsContext {
        let localContext = new NonReservedKeywordsContext(this.context, this.state);
        this.enterRule(localContext, 450, SparkSQLParser.RULE_nonReservedKeywords);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2993;
            _la = this.tokenStream.LA(1);
            if(!((((_la) & ~0x1F) === 0 && ((1 << _la) & 4294896624) !== 0) || ((((_la - 33)) & ~0x1F) === 0 && ((1 << (_la - 33)) & 4294803199) !== 0) || ((((_la - 65)) & ~0x1F) === 0 && ((1 << (_la - 65)) & 4281327607) !== 0) || ((((_la - 97)) & ~0x1F) === 0 && ((1 << (_la - 97)) & 2147483643) !== 0) || ((((_la - 129)) & ~0x1F) === 0 && ((1 << (_la - 129)) & 2113863675) !== 0) || ((((_la - 161)) & ~0x1F) === 0 && ((1 << (_la - 161)) & 4292341757) !== 0) || ((((_la - 193)) & ~0x1F) === 0 && ((1 << (_la - 193)) & 247) !== 0) || _la === 335)) {
            this.errorHandler.recoverInline(this);
            }
            else {
                this.errorHandler.reportMatch(this);
                this.consume();
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public selectStatementPlus(): SelectStatementPlusContext {
        let localContext = new SelectStatementPlusContext(this.context, this.state);
        this.enterRule(localContext, 452, SparkSQLParser.RULE_selectStatementPlus);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2995;
            this.match(SparkSQLParser.SEMICOLON);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }

    public override sempred(localContext: antlr.ParserRuleContext | null, ruleIndex: number, predIndex: number): boolean {
        switch (ruleIndex) {
        case 49:
            return this.queryStatement_sempred(localContext as QueryStatementContext, predIndex);
        case 68:
            return this.tableExpression_sempred(localContext as TableExpressionContext, predIndex);
        case 164:
            return this.booleanExpression_sempred(localContext as BooleanExpressionContext, predIndex);
        case 167:
            return this.valueExpression_sempred(localContext as ValueExpressionContext, predIndex);
        case 168:
            return this.primaryExpression_sempred(localContext as PrimaryExpressionContext, predIndex);
        }
        return true;
    }
    private queryStatement_sempred(localContext: QueryStatementContext | null, predIndex: number): boolean {
        switch (predIndex) {
        case 0:
            return this.precpred(this.context, 2);
        }
        return true;
    }
    private tableExpression_sempred(localContext: TableExpressionContext | null, predIndex: number): boolean {
        switch (predIndex) {
        case 1:
            return this.precpred(this.context, 4);
        case 2:
            return this.precpred(this.context, 5);
        }
        return true;
    }
    private booleanExpression_sempred(localContext: BooleanExpressionContext | null, predIndex: number): boolean {
        switch (predIndex) {
        case 3:
            return this.precpred(this.context, 3);
        case 4:
            return this.precpred(this.context, 2);
        case 5:
            return this.precpred(this.context, 1);
        }
        return true;
    }
    private valueExpression_sempred(localContext: ValueExpressionContext | null, predIndex: number): boolean {
        switch (predIndex) {
        case 6:
            return this.precpred(this.context, 6);
        case 7:
            return this.precpred(this.context, 5);
        case 8:
            return this.precpred(this.context, 4);
        case 9:
            return this.precpred(this.context, 3);
        case 10:
            return this.precpred(this.context, 2);
        case 11:
            return this.precpred(this.context, 1);
        }
        return true;
    }
    private primaryExpression_sempred(localContext: PrimaryExpressionContext | null, predIndex: number): boolean {
        switch (predIndex) {
        case 12:
            return this.precpred(this.context, 5);
        }
        return true;
    }

    public static readonly _serializedATN: number[] = [
        4,1,497,2998,2,0,7,0,2,1,7,1,2,2,7,2,2,3,7,3,2,4,7,4,2,5,7,5,2,6,
        7,6,2,7,7,7,2,8,7,8,2,9,7,9,2,10,7,10,2,11,7,11,2,12,7,12,2,13,7,
        13,2,14,7,14,2,15,7,15,2,16,7,16,2,17,7,17,2,18,7,18,2,19,7,19,2,
        20,7,20,2,21,7,21,2,22,7,22,2,23,7,23,2,24,7,24,2,25,7,25,2,26,7,
        26,2,27,7,27,2,28,7,28,2,29,7,29,2,30,7,30,2,31,7,31,2,32,7,32,2,
        33,7,33,2,34,7,34,2,35,7,35,2,36,7,36,2,37,7,37,2,38,7,38,2,39,7,
        39,2,40,7,40,2,41,7,41,2,42,7,42,2,43,7,43,2,44,7,44,2,45,7,45,2,
        46,7,46,2,47,7,47,2,48,7,48,2,49,7,49,2,50,7,50,2,51,7,51,2,52,7,
        52,2,53,7,53,2,54,7,54,2,55,7,55,2,56,7,56,2,57,7,57,2,58,7,58,2,
        59,7,59,2,60,7,60,2,61,7,61,2,62,7,62,2,63,7,63,2,64,7,64,2,65,7,
        65,2,66,7,66,2,67,7,67,2,68,7,68,2,69,7,69,2,70,7,70,2,71,7,71,2,
        72,7,72,2,73,7,73,2,74,7,74,2,75,7,75,2,76,7,76,2,77,7,77,2,78,7,
        78,2,79,7,79,2,80,7,80,2,81,7,81,2,82,7,82,2,83,7,83,2,84,7,84,2,
        85,7,85,2,86,7,86,2,87,7,87,2,88,7,88,2,89,7,89,2,90,7,90,2,91,7,
        91,2,92,7,92,2,93,7,93,2,94,7,94,2,95,7,95,2,96,7,96,2,97,7,97,2,
        98,7,98,2,99,7,99,2,100,7,100,2,101,7,101,2,102,7,102,2,103,7,103,
        2,104,7,104,2,105,7,105,2,106,7,106,2,107,7,107,2,108,7,108,2,109,
        7,109,2,110,7,110,2,111,7,111,2,112,7,112,2,113,7,113,2,114,7,114,
        2,115,7,115,2,116,7,116,2,117,7,117,2,118,7,118,2,119,7,119,2,120,
        7,120,2,121,7,121,2,122,7,122,2,123,7,123,2,124,7,124,2,125,7,125,
        2,126,7,126,2,127,7,127,2,128,7,128,2,129,7,129,2,130,7,130,2,131,
        7,131,2,132,7,132,2,133,7,133,2,134,7,134,2,135,7,135,2,136,7,136,
        2,137,7,137,2,138,7,138,2,139,7,139,2,140,7,140,2,141,7,141,2,142,
        7,142,2,143,7,143,2,144,7,144,2,145,7,145,2,146,7,146,2,147,7,147,
        2,148,7,148,2,149,7,149,2,150,7,150,2,151,7,151,2,152,7,152,2,153,
        7,153,2,154,7,154,2,155,7,155,2,156,7,156,2,157,7,157,2,158,7,158,
        2,159,7,159,2,160,7,160,2,161,7,161,2,162,7,162,2,163,7,163,2,164,
        7,164,2,165,7,165,2,166,7,166,2,167,7,167,2,168,7,168,2,169,7,169,
        2,170,7,170,2,171,7,171,2,172,7,172,2,173,7,173,2,174,7,174,2,175,
        7,175,2,176,7,176,2,177,7,177,2,178,7,178,2,179,7,179,2,180,7,180,
        2,181,7,181,2,182,7,182,2,183,7,183,2,184,7,184,2,185,7,185,2,186,
        7,186,2,187,7,187,2,188,7,188,2,189,7,189,2,190,7,190,2,191,7,191,
        2,192,7,192,2,193,7,193,2,194,7,194,2,195,7,195,2,196,7,196,2,197,
        7,197,2,198,7,198,2,199,7,199,2,200,7,200,2,201,7,201,2,202,7,202,
        2,203,7,203,2,204,7,204,2,205,7,205,2,206,7,206,2,207,7,207,2,208,
        7,208,2,209,7,209,2,210,7,210,2,211,7,211,2,212,7,212,2,213,7,213,
        2,214,7,214,2,215,7,215,2,216,7,216,2,217,7,217,2,218,7,218,2,219,
        7,219,2,220,7,220,2,221,7,221,2,222,7,222,2,223,7,223,2,224,7,224,
        2,225,7,225,2,226,7,226,1,0,1,0,1,0,1,1,1,1,5,1,460,8,1,10,1,12,
        1,463,9,1,1,2,1,2,3,2,467,8,2,1,2,1,2,1,3,1,3,1,4,1,4,1,5,1,5,3,
        5,477,8,5,1,6,1,6,1,6,1,6,1,6,1,6,3,6,485,8,6,1,7,1,7,3,7,489,8,
        7,1,7,1,7,3,7,493,8,7,1,7,1,7,5,7,497,8,7,10,7,12,7,500,9,7,1,7,
        1,7,1,7,3,7,505,8,7,1,7,5,7,508,8,7,10,7,12,7,511,9,7,1,8,1,8,1,
        8,1,8,1,8,1,8,1,8,1,8,1,8,1,8,1,8,1,8,1,8,1,8,3,8,527,8,8,1,9,1,
        9,1,9,1,10,1,10,1,10,1,10,1,10,3,10,537,8,10,1,10,1,10,1,11,1,11,
        1,11,3,11,544,8,11,1,11,1,11,1,11,1,11,3,11,550,8,11,1,12,1,12,1,
        12,1,13,1,13,5,13,557,8,13,10,13,12,13,560,9,13,1,13,3,13,563,8,
        13,1,13,1,13,1,13,5,13,568,8,13,10,13,12,13,571,9,13,1,14,1,14,1,
        14,1,14,1,14,1,14,1,14,1,14,1,14,1,14,1,14,1,14,1,14,3,14,586,8,
        14,1,15,1,15,1,15,1,15,5,15,592,8,15,10,15,12,15,595,9,15,1,16,1,
        16,1,16,1,16,1,16,1,16,1,16,3,16,604,8,16,1,17,1,17,1,17,1,17,1,
        17,5,17,611,8,17,10,17,12,17,614,9,17,1,18,1,18,1,18,1,18,1,18,1,
        18,1,18,3,18,623,8,18,1,19,1,19,1,19,1,19,1,20,1,20,1,20,1,20,1,
        20,3,20,634,8,20,1,20,1,20,1,20,3,20,639,8,20,5,20,641,8,20,10,20,
        12,20,644,9,20,1,20,1,20,1,21,1,21,1,21,1,21,1,21,1,22,1,22,1,22,
        1,22,1,22,1,23,1,23,1,23,3,23,661,8,23,1,24,1,24,1,24,1,24,3,24,
        667,8,24,1,25,1,25,3,25,671,8,25,1,26,1,26,1,26,1,26,1,27,1,27,1,
        27,3,27,680,8,27,1,27,1,27,1,27,3,27,685,8,27,5,27,687,8,27,10,27,
        12,27,690,9,27,1,27,1,27,1,27,3,27,695,8,27,3,27,697,8,27,1,27,1,
        27,1,27,3,27,702,8,27,3,27,704,8,27,1,27,1,27,1,27,3,27,709,8,27,
        3,27,711,8,27,1,27,1,27,1,28,1,28,3,28,717,8,28,1,28,1,28,3,28,721,
        8,28,1,28,1,28,5,28,725,8,28,10,28,12,28,728,9,28,1,28,1,28,1,28,
        1,28,1,28,5,28,735,8,28,10,28,12,28,738,9,28,1,28,1,28,1,28,1,28,
        1,28,5,28,745,8,28,10,28,12,28,748,9,28,1,28,1,28,1,28,5,28,753,
        8,28,10,28,12,28,756,9,28,1,28,1,28,5,28,760,8,28,10,28,12,28,763,
        9,28,1,29,1,29,1,29,1,29,1,29,1,29,3,29,771,8,29,1,30,1,30,1,30,
        1,30,3,30,777,8,30,1,30,1,30,5,30,781,8,30,10,30,12,30,784,9,30,
        1,30,1,30,5,30,788,8,30,10,30,12,30,791,9,30,1,30,1,30,1,30,1,30,
        1,30,5,30,798,8,30,10,30,12,30,801,9,30,1,30,1,30,1,30,1,30,1,30,
        5,30,808,8,30,10,30,12,30,811,9,30,1,30,1,30,1,30,5,30,816,8,30,
        10,30,12,30,819,9,30,1,30,1,30,1,30,5,30,824,8,30,10,30,12,30,827,
        9,30,1,31,1,31,1,31,1,31,1,31,1,31,3,31,835,8,31,1,32,1,32,1,32,
        3,32,840,8,32,1,32,1,32,1,32,1,32,3,32,846,8,32,1,33,1,33,1,33,1,
        33,1,33,5,33,853,8,33,10,33,12,33,856,9,33,1,33,1,33,1,33,1,33,1,
        33,1,33,1,33,5,33,865,8,33,10,33,12,33,868,9,33,1,33,1,33,1,33,3,
        33,873,8,33,1,33,1,33,5,33,877,8,33,10,33,12,33,880,9,33,1,33,1,
        33,1,33,1,33,1,33,1,33,1,33,5,33,889,8,33,10,33,12,33,892,9,33,1,
        34,1,34,1,34,1,34,1,34,1,34,1,34,3,34,901,8,34,1,35,1,35,1,35,1,
        35,1,35,1,35,5,35,909,8,35,10,35,12,35,912,9,35,1,36,1,36,1,36,3,
        36,917,8,36,1,37,1,37,1,37,3,37,922,8,37,4,37,924,8,37,11,37,12,
        37,925,3,37,928,8,37,1,38,1,38,3,38,932,8,38,1,38,1,38,1,39,1,39,
        1,39,3,39,939,8,39,1,40,1,40,3,40,943,8,40,1,40,1,40,1,40,1,41,1,
        41,1,41,1,42,1,42,1,42,1,42,1,42,1,42,1,42,3,42,958,8,42,1,43,1,
        43,1,43,1,43,1,44,1,44,1,44,1,44,1,45,1,45,1,45,1,46,3,46,972,8,
        46,1,46,1,46,1,47,1,47,1,47,3,47,979,8,47,1,47,1,47,3,47,983,8,47,
        1,47,3,47,986,8,47,1,47,1,47,1,47,1,47,1,47,1,47,1,47,1,47,3,47,
        996,8,47,1,48,1,48,1,48,1,49,1,49,1,49,1,49,1,49,1,49,1,49,1,49,
        1,49,1,49,3,49,1011,8,49,1,49,3,49,1014,8,49,1,49,3,49,1017,8,49,
        1,49,3,49,1020,8,49,1,49,3,49,1023,8,49,3,49,1025,8,49,1,49,1,49,
        1,49,3,49,1030,8,49,1,49,1,49,3,49,1034,8,49,1,49,3,49,1037,8,49,
        1,49,3,49,1040,8,49,1,49,3,49,1043,8,49,5,49,1045,8,49,10,49,12,
        49,1048,9,49,1,50,1,50,1,50,1,50,5,50,1054,8,50,10,50,12,50,1057,
        9,50,1,51,1,51,1,51,1,51,3,51,1063,8,51,1,51,5,51,1066,8,51,10,51,
        12,51,1069,9,51,1,52,1,52,1,52,1,52,5,52,1075,8,52,10,52,12,52,1078,
        9,52,1,52,1,52,1,53,1,53,1,53,1,53,1,53,5,53,1087,8,53,10,53,12,
        53,1090,9,53,1,53,1,53,3,53,1094,8,53,1,53,1,53,1,53,1,53,1,53,1,
        54,1,54,1,55,1,55,1,55,3,55,1106,8,55,1,55,3,55,1109,8,55,1,55,3,
        55,1112,8,55,1,55,3,55,1115,8,55,1,55,1,55,1,55,3,55,1120,8,55,1,
        55,3,55,1123,8,55,1,55,3,55,1126,8,55,1,55,3,55,1129,8,55,1,55,1,
        55,1,55,1,55,1,55,1,55,1,55,1,55,1,55,3,55,1140,8,55,1,56,1,56,3,
        56,1144,8,56,1,56,1,56,1,56,5,56,1149,8,56,10,56,12,56,1152,9,56,
        1,57,1,57,3,57,1156,8,57,1,57,3,57,1159,8,57,1,57,1,57,1,57,3,57,
        1164,8,57,3,57,1166,8,57,1,58,1,58,1,58,1,58,1,58,1,59,1,59,1,59,
        3,59,1176,8,59,1,59,1,59,3,59,1180,8,59,1,59,1,59,3,59,1184,8,59,
        1,59,1,59,3,59,1188,8,59,1,59,1,59,3,59,1192,8,59,1,60,1,60,1,60,
        1,60,1,60,5,60,1199,8,60,10,60,12,60,1202,9,60,1,60,1,60,3,60,1206,
        8,60,1,61,1,61,1,61,1,61,1,61,5,61,1213,8,61,10,61,12,61,1216,9,
        61,3,61,1218,8,61,1,61,1,61,1,61,3,61,1223,8,61,1,62,1,62,3,62,1227,
        8,62,1,63,1,63,1,64,1,64,1,65,1,65,1,65,1,66,1,66,1,66,1,66,1,66,
        1,66,1,66,3,66,1243,8,66,1,67,1,67,1,67,1,67,1,67,1,67,1,67,1,67,
        1,67,1,67,1,67,1,67,3,67,1257,8,67,1,68,1,68,1,68,1,68,5,68,1263,
        8,68,10,68,12,68,1266,9,68,1,68,1,68,1,68,3,68,1271,8,68,1,68,1,
        68,5,68,1275,8,68,10,68,12,68,1278,9,68,1,68,3,68,1281,8,68,1,68,
        1,68,1,68,3,68,1286,8,68,1,68,3,68,1289,8,68,1,68,1,68,1,68,1,68,
        1,68,1,68,3,68,1297,8,68,1,68,3,68,1300,8,68,1,68,3,68,1303,8,68,
        1,68,1,68,1,68,3,68,1308,8,68,1,68,1,68,5,68,1312,8,68,10,68,12,
        68,1315,9,68,5,68,1317,8,68,10,68,12,68,1320,9,68,1,69,1,69,1,70,
        1,70,1,70,1,70,1,70,5,70,1329,8,70,10,70,12,70,1332,9,70,1,70,1,
        70,1,71,1,71,1,71,3,71,1339,8,71,1,71,1,71,3,71,1343,8,71,1,71,1,
        71,1,71,1,71,5,71,1349,8,71,10,71,12,71,1352,9,71,1,72,1,72,1,72,
        1,72,1,72,1,72,1,72,1,72,3,72,1362,8,72,1,72,1,72,1,72,1,72,3,72,
        1368,8,72,1,73,1,73,3,73,1372,8,73,1,74,3,74,1375,8,74,1,74,1,74,
        3,74,1379,8,74,1,74,1,74,1,74,1,74,3,74,1385,8,74,1,74,1,74,1,74,
        1,74,1,74,1,74,3,74,1393,8,74,1,74,1,74,1,74,1,74,1,74,1,74,1,74,
        1,74,1,74,5,74,1404,8,74,10,74,12,74,1407,9,74,1,74,1,74,1,74,1,
        74,1,74,1,74,3,74,1415,8,74,1,75,1,75,1,75,1,75,3,75,1421,8,75,1,
        75,1,75,1,75,3,75,1426,8,75,5,75,1428,8,75,10,75,12,75,1431,9,75,
        1,75,1,75,1,75,1,75,1,75,1,75,3,75,1439,8,75,1,75,1,75,1,75,3,75,
        1444,8,75,5,75,1446,8,75,10,75,12,75,1449,9,75,1,75,1,75,1,75,1,
        75,1,75,1,75,1,75,1,75,5,75,1459,8,75,10,75,12,75,1462,9,75,3,75,
        1464,8,75,1,76,1,76,3,76,1468,8,76,1,76,1,76,1,76,1,76,1,76,1,77,
        1,77,1,77,1,77,1,77,1,77,1,77,3,77,1482,8,77,1,77,1,77,1,77,1,78,
        1,78,1,78,3,78,1490,8,78,1,79,1,79,1,79,1,79,5,79,1496,8,79,10,79,
        12,79,1499,9,79,1,79,1,79,1,80,1,80,1,80,1,80,1,80,1,80,1,81,1,81,
        1,82,1,82,1,82,5,82,1514,8,82,10,82,12,82,1517,9,82,1,82,3,82,1520,
        8,82,1,83,1,83,1,83,1,83,1,83,1,84,1,84,1,84,1,84,1,84,5,84,1532,
        8,84,10,84,12,84,1535,9,84,1,84,1,84,1,85,1,85,1,86,1,86,1,86,1,
        86,1,87,1,87,1,87,1,87,1,88,1,88,1,88,1,88,1,88,3,88,1554,8,88,1,
        89,1,89,1,89,1,89,3,89,1560,8,89,1,89,1,89,1,89,3,89,1565,8,89,1,
        90,1,90,1,90,3,90,1570,8,90,1,90,1,90,1,90,3,90,1575,8,90,5,90,1577,
        8,90,10,90,12,90,1580,9,90,1,90,1,90,1,91,3,91,1585,8,91,1,91,3,
        91,1588,8,91,1,91,1,91,1,91,1,91,3,91,1594,8,91,1,91,1,91,1,91,1,
        91,3,91,1600,8,91,1,92,1,92,1,92,1,92,1,92,1,92,1,92,1,92,1,92,1,
        92,1,92,1,92,1,92,1,92,1,92,3,92,1617,8,92,1,93,1,93,1,94,1,94,1,
        94,1,94,1,94,1,95,1,95,1,95,1,95,1,95,1,95,1,95,5,95,1633,8,95,10,
        95,12,95,1636,9,95,1,95,1,95,3,95,1640,8,95,1,96,1,96,1,96,1,97,
        1,97,1,97,1,97,1,97,3,97,1650,8,97,1,97,1,97,1,97,1,97,1,97,1,97,
        3,97,1658,8,97,1,97,1,97,1,97,1,97,1,97,1,97,1,97,3,97,1667,8,97,
        1,97,1,97,1,97,1,97,3,97,1673,8,97,1,97,3,97,1676,8,97,1,98,1,98,
        1,98,1,98,3,98,1682,8,98,1,99,1,99,1,99,1,99,1,99,5,99,1689,8,99,
        10,99,12,99,1692,9,99,1,100,1,100,1,100,1,100,1,100,5,100,1699,8,
        100,10,100,12,100,1702,9,100,1,101,1,101,1,101,1,101,1,101,5,101,
        1709,8,101,10,101,12,101,1712,9,101,1,102,1,102,1,102,1,102,1,102,
        5,102,1719,8,102,10,102,12,102,1722,9,102,1,102,1,102,3,102,1726,
        8,102,1,103,1,103,1,103,5,103,1731,8,103,10,103,12,103,1734,9,103,
        1,103,1,103,1,103,1,103,1,103,1,103,1,103,5,103,1743,8,103,10,103,
        12,103,1746,9,103,1,103,1,103,1,103,1,103,1,103,1,103,1,103,5,103,
        1755,8,103,10,103,12,103,1758,9,103,1,103,1,103,1,103,1,103,1,103,
        1,103,1,103,5,103,1767,8,103,10,103,12,103,1770,9,103,1,103,1,103,
        3,103,1774,8,103,1,104,1,104,1,104,1,105,1,105,1,106,1,106,1,106,
        1,106,1,106,1,106,1,106,1,107,1,107,1,108,1,108,1,109,1,109,1,109,
        1,110,1,110,1,110,1,110,5,110,1799,8,110,10,110,12,110,1802,9,110,
        1,111,1,111,1,111,1,111,1,112,3,112,1809,8,112,1,112,1,112,3,112,
        1813,8,112,1,112,3,112,1816,8,112,1,112,3,112,1819,8,112,1,112,3,
        112,1822,8,112,1,112,1,112,1,113,1,113,1,113,3,113,1829,8,113,1,
        113,3,113,1832,8,113,1,113,3,113,1835,8,113,1,113,3,113,1838,8,113,
        1,113,3,113,1841,8,113,1,113,3,113,1844,8,113,1,113,3,113,1847,8,
        113,1,113,1,113,1,113,3,113,1852,8,113,1,113,3,113,1855,8,113,1,
        114,1,114,1,114,1,114,1,114,5,114,1862,8,114,10,114,12,114,1865,
        9,114,1,115,1,115,1,115,1,115,1,115,5,115,1872,8,115,10,115,12,115,
        1875,9,115,1,116,1,116,3,116,1879,8,116,1,116,1,116,3,116,1883,8,
        116,1,117,1,117,1,117,3,117,1888,8,117,1,118,1,118,1,118,3,118,1893,
        8,118,1,119,1,119,1,119,1,119,1,119,5,119,1900,8,119,10,119,12,119,
        1903,9,119,1,120,1,120,1,120,1,120,1,120,1,120,1,120,1,120,1,120,
        1,120,1,120,1,120,1,120,1,120,1,120,1,120,3,120,1921,8,120,1,121,
        1,121,1,121,1,121,5,121,1927,8,121,10,121,12,121,1930,9,121,1,122,
        1,122,1,122,4,122,1935,8,122,11,122,12,122,1936,1,122,1,122,3,122,
        1941,8,122,1,123,1,123,3,123,1945,8,123,1,124,1,124,1,124,1,124,
        1,124,1,124,1,124,1,124,3,124,1955,8,124,1,125,1,125,1,125,1,125,
        1,125,1,125,1,125,1,125,1,125,1,125,1,125,1,125,1,125,1,125,1,125,
        1,125,1,125,1,125,1,125,1,125,1,125,1,125,1,125,1,125,3,125,1981,
        8,125,1,126,1,126,1,126,1,126,5,126,1987,8,126,10,126,12,126,1990,
        9,126,1,127,1,127,1,127,1,127,1,127,1,127,1,127,1,127,1,127,3,127,
        2001,8,127,1,128,1,128,1,128,1,128,1,128,1,129,1,129,1,129,1,130,
        1,130,1,130,1,130,1,131,1,131,1,131,1,131,1,132,1,132,1,132,3,132,
        2022,8,132,1,132,1,132,1,132,3,132,2027,8,132,5,132,2029,8,132,10,
        132,12,132,2032,9,132,1,132,1,132,1,133,1,133,1,133,1,133,1,133,
        1,133,5,133,2042,8,133,10,133,12,133,2045,9,133,1,133,1,133,3,133,
        2049,8,133,1,134,1,134,3,134,2053,8,134,1,135,1,135,1,135,1,135,
        5,135,2059,8,135,10,135,12,135,2062,9,135,1,135,3,135,2065,8,135,
        1,136,1,136,1,136,3,136,2070,8,136,1,136,1,136,1,136,1,136,3,136,
        2076,8,136,1,136,3,136,2079,8,136,1,137,1,137,1,137,1,138,1,138,
        1,138,1,138,3,138,2088,8,138,1,139,1,139,1,139,3,139,2093,8,139,
        1,140,1,140,1,140,1,140,5,140,2099,8,140,10,140,12,140,2102,9,140,
        1,140,1,140,1,141,1,141,1,141,3,141,2109,8,141,1,141,3,141,2112,
        8,141,1,142,1,142,1,143,1,143,1,143,1,143,1,143,1,143,1,143,1,143,
        1,143,1,143,3,143,2126,8,143,1,143,1,143,1,143,3,143,2131,8,143,
        1,144,1,144,3,144,2135,8,144,1,144,1,144,1,144,1,144,1,144,1,144,
        1,145,1,145,1,146,1,146,1,146,1,146,5,146,2149,8,146,10,146,12,146,
        2152,9,146,1,147,1,147,1,147,1,147,5,147,2158,8,147,10,147,12,147,
        2161,9,147,1,147,1,147,1,148,1,148,1,148,1,148,1,149,1,149,1,149,
        1,149,3,149,2173,8,149,1,149,1,149,1,150,1,150,1,150,1,150,3,150,
        2181,8,150,1,150,1,150,1,151,1,151,1,151,1,151,5,151,2189,8,151,
        10,151,12,151,2192,9,151,1,151,1,151,1,152,1,152,1,152,1,152,1,152,
        1,152,1,152,1,153,1,153,1,153,1,153,1,153,1,153,1,153,5,153,2210,
        8,153,10,153,12,153,2213,9,153,1,153,1,153,1,154,1,154,1,154,1,154,
        1,154,1,154,1,154,1,154,1,154,5,154,2226,8,154,10,154,12,154,2229,
        9,154,1,154,1,154,1,155,1,155,3,155,2235,8,155,1,155,1,155,1,155,
        1,155,3,155,2241,8,155,1,155,3,155,2244,8,155,1,155,3,155,2247,8,
        155,1,156,1,156,1,156,1,157,1,157,1,157,1,157,1,157,3,157,2257,8,
        157,1,157,3,157,2260,8,157,1,158,1,158,1,159,1,159,1,159,1,159,3,
        159,2268,8,159,1,160,1,160,3,160,2272,8,160,1,161,1,161,1,161,3,
        161,2277,8,161,1,161,1,161,1,161,3,161,2282,8,161,5,161,2284,8,161,
        10,161,12,161,2287,9,161,1,161,1,161,1,162,1,162,1,162,3,162,2294,
        8,162,1,162,1,162,3,162,2298,8,162,1,162,1,162,3,162,2302,8,162,
        1,162,1,162,3,162,2306,8,162,1,162,1,162,3,162,2310,8,162,1,162,
        1,162,3,162,2314,8,162,1,162,1,162,3,162,2318,8,162,1,162,1,162,
        3,162,2322,8,162,1,162,1,162,3,162,2326,8,162,1,162,1,162,3,162,
        2330,8,162,1,162,1,162,3,162,2334,8,162,1,162,1,162,3,162,2338,8,
        162,1,162,1,162,3,162,2342,8,162,1,162,1,162,3,162,2346,8,162,1,
        162,1,162,3,162,2350,8,162,1,162,1,162,3,162,2354,8,162,1,162,1,
        162,3,162,2358,8,162,1,162,1,162,1,162,1,162,3,162,2364,8,162,3,
        162,2366,8,162,1,163,1,163,1,164,1,164,1,164,1,164,1,164,1,164,1,
        164,1,164,1,164,1,164,3,164,2380,8,164,3,164,2382,8,164,1,164,1,
        164,1,164,1,164,1,164,1,164,1,164,1,164,1,164,3,164,2393,8,164,1,
        164,5,164,2396,8,164,10,164,12,164,2399,9,164,1,165,3,165,2402,8,
        165,1,165,1,165,3,165,2406,8,165,1,165,1,165,1,165,1,165,1,165,3,
        165,2413,8,165,1,165,1,165,1,165,1,165,1,165,5,165,2420,8,165,10,
        165,12,165,2423,9,165,1,165,1,165,1,165,3,165,2428,8,165,1,165,1,
        165,1,165,1,165,1,165,1,165,1,165,1,165,1,165,1,165,1,165,3,165,
        2441,8,165,1,165,1,165,1,165,1,165,1,165,3,165,2448,8,165,1,165,
        1,165,1,165,3,165,2453,8,165,1,165,1,165,1,165,1,165,3,165,2459,
        8,165,1,165,1,165,1,165,1,165,1,165,3,165,2466,8,165,3,165,2468,
        8,165,1,166,3,166,2471,8,166,1,166,1,166,1,166,1,166,1,166,1,166,
        1,166,1,166,5,166,2481,8,166,10,166,12,166,2484,9,166,1,166,1,166,
        3,166,2488,8,166,1,166,3,166,2491,8,166,1,166,1,166,1,166,1,166,
        3,166,2497,8,166,1,166,3,166,2500,8,166,1,166,1,166,1,166,1,166,
        3,166,2506,8,166,3,166,2508,8,166,1,167,1,167,1,167,1,167,3,167,
        2514,8,167,1,167,1,167,1,167,1,167,1,167,1,167,1,167,1,167,1,167,
        1,167,1,167,1,167,1,167,1,167,1,167,1,167,1,167,1,167,1,167,5,167,
        2535,8,167,10,167,12,167,2538,9,167,1,168,1,168,1,168,4,168,2543,
        8,168,11,168,12,168,2544,1,168,1,168,3,168,2549,8,168,1,168,1,168,
        1,168,1,168,1,168,4,168,2556,8,168,11,168,12,168,2557,1,168,1,168,
        3,168,2562,8,168,1,168,1,168,1,168,1,168,1,168,1,168,1,168,1,168,
        1,168,1,168,1,168,1,168,1,168,1,168,3,168,2578,8,168,1,168,1,168,
        1,168,1,168,1,168,1,168,1,168,3,168,2587,8,168,1,168,1,168,1,168,
        1,168,1,168,1,168,1,168,1,168,1,168,1,168,1,168,1,168,1,168,1,168,
        1,168,1,168,1,168,1,168,1,168,1,168,1,168,1,168,1,168,5,168,2612,
        8,168,10,168,12,168,2615,9,168,1,168,1,168,1,168,1,168,1,168,3,168,
        2622,8,168,1,168,1,168,1,168,5,168,2627,8,168,10,168,12,168,2630,
        9,168,3,168,2632,8,168,1,168,1,168,1,168,1,168,1,168,1,168,1,168,
        1,168,1,168,1,168,1,168,1,168,3,168,2646,8,168,1,168,1,168,1,168,
        3,168,2651,8,168,1,168,1,168,1,168,1,168,1,168,1,168,1,168,1,168,
        1,168,1,168,3,168,2663,8,168,1,168,1,168,1,168,1,168,1,168,1,168,
        1,168,3,168,2672,8,168,1,168,1,168,1,168,1,168,1,168,5,168,2679,
        8,168,10,168,12,168,2682,9,168,1,169,1,169,1,169,1,169,3,169,2688,
        8,169,1,170,1,170,1,170,1,170,1,170,5,170,2695,8,170,10,170,12,170,
        2698,9,170,1,170,1,170,1,170,1,170,1,170,1,170,5,170,2706,8,170,
        10,170,12,170,2709,9,170,1,170,1,170,1,171,1,171,1,171,1,171,1,171,
        5,171,2718,8,171,10,171,12,171,2721,9,171,1,171,1,171,1,172,1,172,
        1,172,1,172,1,172,5,172,2730,8,172,10,172,12,172,2733,9,172,1,172,
        1,172,1,173,1,173,1,173,1,173,1,173,1,173,1,173,1,174,1,174,1,174,
        1,174,3,174,2748,8,174,1,175,1,175,1,176,1,176,1,176,3,176,2755,
        8,176,1,177,1,177,1,177,1,177,1,177,1,177,3,177,2763,8,177,1,178,
        1,178,1,178,1,178,1,178,1,178,1,179,1,179,1,180,1,180,1,180,3,180,
        2776,8,180,1,181,1,181,1,181,3,181,2781,8,181,1,182,1,182,3,182,
        2785,8,182,1,183,1,183,1,183,4,183,2790,8,183,11,183,12,183,2791,
        1,184,1,184,1,184,3,184,2797,8,184,1,185,1,185,1,185,1,185,1,185,
        1,186,3,186,2805,8,186,1,186,1,186,3,186,2809,8,186,1,187,1,187,
        1,188,1,188,1,189,3,189,2816,8,189,1,189,1,189,3,189,2820,8,189,
        1,190,1,190,1,190,1,191,1,191,5,191,2827,8,191,10,191,12,191,2830,
        9,191,1,192,1,192,1,192,1,192,1,193,1,193,1,193,5,193,2839,8,193,
        10,193,12,193,2842,9,193,1,194,1,194,1,194,1,194,3,194,2848,8,194,
        1,195,1,195,1,195,1,195,3,195,2854,8,195,1,196,1,196,1,196,1,196,
        1,196,1,197,1,197,1,198,1,198,1,198,1,198,1,198,1,199,1,199,1,200,
        1,200,1,201,1,201,1,202,1,202,1,203,1,203,1,204,1,204,1,205,1,205,
        1,205,5,205,2883,8,205,10,205,12,205,2886,9,205,1,206,1,206,3,206,
        2890,8,206,1,206,1,206,1,207,1,207,1,207,1,207,1,208,1,208,1,208,
        1,209,1,209,1,209,1,209,5,209,2905,8,209,10,209,12,209,2908,9,209,
        1,209,1,209,1,210,1,210,1,210,3,210,2915,8,210,1,210,1,210,1,211,
        1,211,1,211,1,211,3,211,2923,8,211,1,212,1,212,1,212,1,212,1,212,
        3,212,2930,8,212,1,213,1,213,1,213,1,213,1,213,1,213,1,213,1,213,
        1,213,1,213,3,213,2942,8,213,1,214,1,214,1,214,1,214,1,214,1,214,
        1,214,1,214,1,214,1,214,1,214,1,214,1,214,1,214,3,214,2958,8,214,
        1,215,1,215,1,215,1,215,3,215,2964,8,215,1,215,1,215,1,215,1,215,
        3,215,2970,8,215,1,215,3,215,2973,8,215,1,216,1,216,1,216,1,217,
        1,217,1,218,1,218,1,219,1,219,1,220,1,220,1,221,1,221,1,222,1,222,
        1,223,1,223,1,224,1,224,1,225,1,225,1,226,1,226,1,226,0,5,98,136,
        328,334,336,227,0,2,4,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,
        36,38,40,42,44,46,48,50,52,54,56,58,60,62,64,66,68,70,72,74,76,78,
        80,82,84,86,88,90,92,94,96,98,100,102,104,106,108,110,112,114,116,
        118,120,122,124,126,128,130,132,134,136,138,140,142,144,146,148,
        150,152,154,156,158,160,162,164,166,168,170,172,174,176,178,180,
        182,184,186,188,190,192,194,196,198,200,202,204,206,208,210,212,
        214,216,218,220,222,224,226,228,230,232,234,236,238,240,242,244,
        246,248,250,252,254,256,258,260,262,264,266,268,270,272,274,276,
        278,280,282,284,286,288,290,292,294,296,298,300,302,304,306,308,
        310,312,314,316,318,320,322,324,326,328,330,332,334,336,338,340,
        342,344,346,348,350,352,354,356,358,360,362,364,366,368,370,372,
        374,376,378,380,382,384,386,388,390,392,394,396,398,400,402,404,
        406,408,410,412,414,416,418,420,422,424,426,428,430,432,434,436,
        438,440,442,444,446,448,450,452,0,47,2,0,8,8,35,35,4,0,258,258,304,
        304,342,342,397,397,2,0,295,295,457,457,2,0,52,52,82,82,2,0,6,6,
        9,9,2,0,106,106,316,316,4,0,280,280,314,314,341,341,433,433,2,0,
        202,202,268,268,2,0,67,67,136,136,2,0,271,271,368,368,5,0,251,251,
        288,288,324,324,327,328,353,353,4,0,267,267,352,352,372,372,386,
        386,2,0,383,383,396,396,4,0,295,295,309,309,330,330,391,391,2,0,
        45,45,68,68,3,0,27,27,64,64,178,178,5,0,28,28,156,157,164,164,170,
        170,357,357,2,0,250,250,394,394,3,0,64,64,152,152,178,178,2,0,46,
        46,307,307,3,0,24,24,109,109,202,202,3,0,46,46,107,107,307,307,3,
        0,60,60,103,103,194,194,3,0,219,219,256,256,354,354,11,0,11,11,165,
        165,172,172,215,216,230,230,257,257,312,313,406,406,423,423,428,
        428,444,445,2,0,449,449,451,451,4,0,259,260,272,272,290,290,355,
        355,2,0,208,208,346,346,4,0,289,289,354,354,431,431,435,435,2,0,
        210,210,414,414,2,0,202,202,206,206,2,0,331,331,392,392,2,0,387,
        387,392,392,2,0,461,461,486,487,4,0,37,37,484,484,488,488,491,491,
        2,0,486,487,489,489,16,0,10,10,88,88,131,131,154,154,172,173,215,
        215,219,219,256,256,260,260,272,272,290,290,312,313,355,355,406,
        406,423,424,428,428,1,0,486,487,1,0,495,496,2,0,495,495,497,497,
        2,0,32,32,419,419,2,0,289,289,431,431,10,0,90,90,92,92,127,127,195,
        195,258,258,304,304,342,342,345,345,397,397,452,452,17,0,17,17,31,
        31,33,33,41,41,65,65,90,93,97,98,127,127,146,146,195,196,199,199,
        258,258,304,304,342,342,345,345,397,397,452,452,6,0,202,202,220,
        220,268,268,329,329,430,430,484,484,35,0,66,66,89,89,127,127,195,
        195,201,201,208,208,212,212,228,229,237,237,239,239,246,247,256,
        256,284,284,288,288,294,294,300,300,304,304,324,324,327,328,330,
        330,342,342,345,345,352,352,366,366,372,374,377,378,383,383,385,
        386,391,391,397,397,412,413,423,427,432,432,438,438,452,452,24,0,
        4,9,11,11,13,15,17,31,33,40,42,47,49,49,51,67,69,77,79,84,86,86,
        89,98,100,127,129,130,132,144,146,153,155,159,161,161,163,172,174,
        179,181,181,183,195,197,200,335,335,3275,0,454,1,0,0,0,2,461,1,0,
        0,0,4,466,1,0,0,0,6,470,1,0,0,0,8,472,1,0,0,0,10,476,1,0,0,0,12,
        484,1,0,0,0,14,486,1,0,0,0,16,526,1,0,0,0,18,528,1,0,0,0,20,531,
        1,0,0,0,22,540,1,0,0,0,24,551,1,0,0,0,26,554,1,0,0,0,28,585,1,0,
        0,0,30,587,1,0,0,0,32,603,1,0,0,0,34,605,1,0,0,0,36,622,1,0,0,0,
        38,624,1,0,0,0,40,628,1,0,0,0,42,647,1,0,0,0,44,652,1,0,0,0,46,657,
        1,0,0,0,48,662,1,0,0,0,50,668,1,0,0,0,52,672,1,0,0,0,54,676,1,0,
        0,0,56,714,1,0,0,0,58,770,1,0,0,0,60,772,1,0,0,0,62,834,1,0,0,0,
        64,836,1,0,0,0,66,847,1,0,0,0,68,900,1,0,0,0,70,902,1,0,0,0,72,913,
        1,0,0,0,74,927,1,0,0,0,76,929,1,0,0,0,78,938,1,0,0,0,80,940,1,0,
        0,0,82,947,1,0,0,0,84,950,1,0,0,0,86,959,1,0,0,0,88,963,1,0,0,0,
        90,967,1,0,0,0,92,971,1,0,0,0,94,975,1,0,0,0,96,997,1,0,0,0,98,1024,
        1,0,0,0,100,1049,1,0,0,0,102,1058,1,0,0,0,104,1070,1,0,0,0,106,1081,
        1,0,0,0,108,1100,1,0,0,0,110,1139,1,0,0,0,112,1141,1,0,0,0,114,1165,
        1,0,0,0,116,1167,1,0,0,0,118,1172,1,0,0,0,120,1193,1,0,0,0,122,1222,
        1,0,0,0,124,1226,1,0,0,0,126,1228,1,0,0,0,128,1230,1,0,0,0,130,1232,
        1,0,0,0,132,1235,1,0,0,0,134,1256,1,0,0,0,136,1288,1,0,0,0,138,1321,
        1,0,0,0,140,1323,1,0,0,0,142,1335,1,0,0,0,144,1367,1,0,0,0,146,1369,
        1,0,0,0,148,1414,1,0,0,0,150,1463,1,0,0,0,152,1467,1,0,0,0,154,1474,
        1,0,0,0,156,1486,1,0,0,0,158,1491,1,0,0,0,160,1502,1,0,0,0,162,1508,
        1,0,0,0,164,1510,1,0,0,0,166,1521,1,0,0,0,168,1526,1,0,0,0,170,1538,
        1,0,0,0,172,1540,1,0,0,0,174,1544,1,0,0,0,176,1548,1,0,0,0,178,1559,
        1,0,0,0,180,1566,1,0,0,0,182,1584,1,0,0,0,184,1616,1,0,0,0,186,1618,
        1,0,0,0,188,1620,1,0,0,0,190,1639,1,0,0,0,192,1641,1,0,0,0,194,1675,
        1,0,0,0,196,1681,1,0,0,0,198,1683,1,0,0,0,200,1693,1,0,0,0,202,1703,
        1,0,0,0,204,1713,1,0,0,0,206,1773,1,0,0,0,208,1775,1,0,0,0,210,1778,
        1,0,0,0,212,1780,1,0,0,0,214,1787,1,0,0,0,216,1789,1,0,0,0,218,1791,
        1,0,0,0,220,1794,1,0,0,0,222,1803,1,0,0,0,224,1808,1,0,0,0,226,1825,
        1,0,0,0,228,1856,1,0,0,0,230,1866,1,0,0,0,232,1876,1,0,0,0,234,1884,
        1,0,0,0,236,1889,1,0,0,0,238,1894,1,0,0,0,240,1920,1,0,0,0,242,1922,
        1,0,0,0,244,1931,1,0,0,0,246,1942,1,0,0,0,248,1954,1,0,0,0,250,1980,
        1,0,0,0,252,1982,1,0,0,0,254,2000,1,0,0,0,256,2002,1,0,0,0,258,2007,
        1,0,0,0,260,2010,1,0,0,0,262,2014,1,0,0,0,264,2018,1,0,0,0,266,2048,
        1,0,0,0,268,2052,1,0,0,0,270,2054,1,0,0,0,272,2066,1,0,0,0,274,2080,
        1,0,0,0,276,2087,1,0,0,0,278,2092,1,0,0,0,280,2094,1,0,0,0,282,2105,
        1,0,0,0,284,2113,1,0,0,0,286,2130,1,0,0,0,288,2134,1,0,0,0,290,2142,
        1,0,0,0,292,2144,1,0,0,0,294,2153,1,0,0,0,296,2164,1,0,0,0,298,2168,
        1,0,0,0,300,2176,1,0,0,0,302,2184,1,0,0,0,304,2195,1,0,0,0,306,2202,
        1,0,0,0,308,2216,1,0,0,0,310,2246,1,0,0,0,312,2248,1,0,0,0,314,2251,
        1,0,0,0,316,2261,1,0,0,0,318,2263,1,0,0,0,320,2271,1,0,0,0,322,2273,
        1,0,0,0,324,2365,1,0,0,0,326,2367,1,0,0,0,328,2381,1,0,0,0,330,2467,
        1,0,0,0,332,2507,1,0,0,0,334,2513,1,0,0,0,336,2671,1,0,0,0,338,2687,
        1,0,0,0,340,2689,1,0,0,0,342,2712,1,0,0,0,344,2724,1,0,0,0,346,2736,
        1,0,0,0,348,2747,1,0,0,0,350,2749,1,0,0,0,352,2754,1,0,0,0,354,2762,
        1,0,0,0,356,2764,1,0,0,0,358,2770,1,0,0,0,360,2775,1,0,0,0,362,2777,
        1,0,0,0,364,2782,1,0,0,0,366,2789,1,0,0,0,368,2793,1,0,0,0,370,2798,
        1,0,0,0,372,2808,1,0,0,0,374,2810,1,0,0,0,376,2812,1,0,0,0,378,2815,
        1,0,0,0,380,2821,1,0,0,0,382,2828,1,0,0,0,384,2831,1,0,0,0,386,2835,
        1,0,0,0,388,2847,1,0,0,0,390,2853,1,0,0,0,392,2855,1,0,0,0,394,2860,
        1,0,0,0,396,2862,1,0,0,0,398,2867,1,0,0,0,400,2869,1,0,0,0,402,2871,
        1,0,0,0,404,2873,1,0,0,0,406,2875,1,0,0,0,408,2877,1,0,0,0,410,2879,
        1,0,0,0,412,2887,1,0,0,0,414,2893,1,0,0,0,416,2897,1,0,0,0,418,2900,
        1,0,0,0,420,2911,1,0,0,0,422,2922,1,0,0,0,424,2929,1,0,0,0,426,2941,
        1,0,0,0,428,2957,1,0,0,0,430,2972,1,0,0,0,432,2974,1,0,0,0,434,2977,
        1,0,0,0,436,2979,1,0,0,0,438,2981,1,0,0,0,440,2983,1,0,0,0,442,2985,
        1,0,0,0,444,2987,1,0,0,0,446,2989,1,0,0,0,448,2991,1,0,0,0,450,2993,
        1,0,0,0,452,2995,1,0,0,0,454,455,3,2,1,0,455,456,5,0,0,1,456,1,1,
        0,0,0,457,460,3,4,2,0,458,460,3,6,3,0,459,457,1,0,0,0,459,458,1,
        0,0,0,460,463,1,0,0,0,461,459,1,0,0,0,461,462,1,0,0,0,462,3,1,0,
        0,0,463,461,1,0,0,0,464,467,3,10,5,0,465,467,3,8,4,0,466,464,1,0,
        0,0,466,465,1,0,0,0,467,468,1,0,0,0,468,469,5,477,0,0,469,5,1,0,
        0,0,470,471,5,477,0,0,471,7,1,0,0,0,472,473,3,12,6,0,473,9,1,0,0,
        0,474,477,3,98,49,0,475,477,3,92,46,0,476,474,1,0,0,0,476,475,1,
        0,0,0,477,11,1,0,0,0,478,485,3,14,7,0,479,485,3,64,32,0,480,485,
        3,66,33,0,481,485,3,56,28,0,482,485,3,60,30,0,483,485,3,22,11,0,
        484,478,1,0,0,0,484,479,1,0,0,0,484,480,1,0,0,0,484,481,1,0,0,0,
        484,482,1,0,0,0,484,483,1,0,0,0,485,13,1,0,0,0,486,488,5,248,0,0,
        487,489,5,169,0,0,488,487,1,0,0,0,488,489,1,0,0,0,489,490,1,0,0,
        0,490,492,5,418,0,0,491,493,3,414,207,0,492,491,1,0,0,0,492,493,
        1,0,0,0,493,494,1,0,0,0,494,498,3,404,202,0,495,497,3,16,8,0,496,
        495,1,0,0,0,497,500,1,0,0,0,498,496,1,0,0,0,498,499,1,0,0,0,499,
        504,1,0,0,0,500,498,1,0,0,0,501,505,3,54,27,0,502,503,5,331,0,0,
        503,505,3,406,203,0,504,501,1,0,0,0,504,502,1,0,0,0,505,509,1,0,
        0,0,506,508,3,16,8,0,507,506,1,0,0,0,508,511,1,0,0,0,509,507,1,0,
        0,0,509,510,1,0,0,0,510,15,1,0,0,0,511,509,1,0,0,0,512,527,3,262,
        131,0,513,527,3,412,206,0,514,527,3,270,135,0,515,527,3,272,136,
        0,516,527,3,196,98,0,517,527,3,38,19,0,518,527,3,46,23,0,519,527,
        3,40,20,0,520,527,3,20,10,0,521,527,3,172,86,0,522,527,3,44,22,0,
        523,527,3,274,137,0,524,527,3,18,9,0,525,527,3,24,12,0,526,512,1,
        0,0,0,526,513,1,0,0,0,526,514,1,0,0,0,526,515,1,0,0,0,526,516,1,
        0,0,0,526,517,1,0,0,0,526,518,1,0,0,0,526,519,1,0,0,0,526,520,1,
        0,0,0,526,521,1,0,0,0,526,522,1,0,0,0,526,523,1,0,0,0,526,524,1,
        0,0,0,526,525,1,0,0,0,527,17,1,0,0,0,528,529,5,87,0,0,529,530,3,
        74,37,0,530,19,1,0,0,0,531,532,5,405,0,0,532,533,5,223,0,0,533,534,
        5,472,0,0,534,536,3,388,194,0,535,537,7,0,0,0,536,535,1,0,0,0,536,
        537,1,0,0,0,537,538,1,0,0,0,538,539,5,473,0,0,539,21,1,0,0,0,540,
        541,5,248,0,0,541,543,5,418,0,0,542,544,3,414,207,0,543,542,1,0,
        0,0,543,544,1,0,0,0,544,545,1,0,0,0,545,549,3,404,202,0,546,550,
        3,30,15,0,547,550,3,34,17,0,548,550,3,26,13,0,549,546,1,0,0,0,549,
        547,1,0,0,0,549,548,1,0,0,0,550,23,1,0,0,0,551,552,5,419,0,0,552,
        553,3,418,209,0,553,25,1,0,0,0,554,558,3,274,137,0,555,557,3,28,
        14,0,556,555,1,0,0,0,557,560,1,0,0,0,558,556,1,0,0,0,558,559,1,0,
        0,0,559,562,1,0,0,0,560,558,1,0,0,0,561,563,5,209,0,0,562,561,1,
        0,0,0,562,563,1,0,0,0,563,564,1,0,0,0,564,565,3,98,49,0,565,569,
        1,0,0,0,566,568,3,28,14,0,567,566,1,0,0,0,568,571,1,0,0,0,569,567,
        1,0,0,0,569,570,1,0,0,0,570,27,1,0,0,0,571,569,1,0,0,0,572,586,3,
        262,131,0,573,574,5,103,0,0,574,586,3,418,209,0,575,586,3,24,12,
        0,576,586,3,196,98,0,577,586,3,38,19,0,578,579,5,449,0,0,579,580,
        3,376,188,0,580,581,5,474,0,0,581,582,3,98,49,0,582,583,5,473,0,
        0,583,586,1,0,0,0,584,586,3,312,156,0,585,572,1,0,0,0,585,573,1,
        0,0,0,585,575,1,0,0,0,585,576,1,0,0,0,585,577,1,0,0,0,585,578,1,
        0,0,0,585,584,1,0,0,0,586,29,1,0,0,0,587,588,3,54,27,0,588,589,3,
        274,137,0,589,593,1,0,0,0,590,592,3,32,16,0,591,590,1,0,0,0,592,
        595,1,0,0,0,593,591,1,0,0,0,593,594,1,0,0,0,594,31,1,0,0,0,595,593,
        1,0,0,0,596,604,3,262,131,0,597,598,5,103,0,0,598,604,3,418,209,
        0,599,604,3,24,12,0,600,604,3,196,98,0,601,604,3,38,19,0,602,604,
        3,312,156,0,603,596,1,0,0,0,603,597,1,0,0,0,603,599,1,0,0,0,603,
        600,1,0,0,0,603,601,1,0,0,0,603,602,1,0,0,0,604,33,1,0,0,0,605,606,
        3,274,137,0,606,607,5,209,0,0,607,608,3,98,49,0,608,612,1,0,0,0,
        609,611,3,36,18,0,610,609,1,0,0,0,611,614,1,0,0,0,612,610,1,0,0,
        0,612,613,1,0,0,0,613,35,1,0,0,0,614,612,1,0,0,0,615,623,3,262,131,
        0,616,617,5,103,0,0,617,623,3,418,209,0,618,623,3,24,12,0,619,623,
        3,196,98,0,620,623,3,38,19,0,621,623,3,312,156,0,622,615,1,0,0,0,
        622,616,1,0,0,0,622,618,1,0,0,0,622,619,1,0,0,0,622,620,1,0,0,0,
        622,621,1,0,0,0,623,37,1,0,0,0,624,625,5,316,0,0,625,626,5,495,0,
        0,626,627,5,222,0,0,627,39,1,0,0,0,628,629,5,108,0,0,629,630,5,223,
        0,0,630,631,5,472,0,0,631,633,5,497,0,0,632,634,3,350,175,0,633,
        632,1,0,0,0,633,634,1,0,0,0,634,642,1,0,0,0,635,636,5,476,0,0,636,
        638,5,497,0,0,637,639,3,350,175,0,638,637,1,0,0,0,638,639,1,0,0,
        0,639,641,1,0,0,0,640,635,1,0,0,0,641,644,1,0,0,0,642,640,1,0,0,
        0,642,643,1,0,0,0,643,645,1,0,0,0,644,642,1,0,0,0,645,646,5,473,
        0,0,646,41,1,0,0,0,647,648,5,395,0,0,648,649,5,54,0,0,649,650,5,
        400,0,0,650,651,3,434,217,0,651,43,1,0,0,0,652,653,5,291,0,0,653,
        654,5,421,0,0,654,655,5,223,0,0,655,656,3,434,217,0,656,45,1,0,0,
        0,657,658,5,404,0,0,658,660,5,209,0,0,659,661,3,388,194,0,660,659,
        1,0,0,0,660,661,1,0,0,0,661,47,1,0,0,0,662,663,5,404,0,0,663,664,
        5,209,0,0,664,666,5,308,0,0,665,667,3,388,194,0,666,665,1,0,0,0,
        666,667,1,0,0,0,667,49,1,0,0,0,668,670,5,364,0,0,669,671,3,388,194,
        0,670,669,1,0,0,0,670,671,1,0,0,0,671,51,1,0,0,0,672,673,5,395,0,
        0,673,674,5,54,0,0,674,675,5,265,0,0,675,53,1,0,0,0,676,677,5,472,
        0,0,677,679,3,278,139,0,678,680,3,312,156,0,679,678,1,0,0,0,679,
        680,1,0,0,0,680,688,1,0,0,0,681,682,5,476,0,0,682,684,3,278,139,
        0,683,685,3,312,156,0,684,683,1,0,0,0,684,685,1,0,0,0,685,687,1,
        0,0,0,686,681,1,0,0,0,687,690,1,0,0,0,688,686,1,0,0,0,688,689,1,
        0,0,0,689,696,1,0,0,0,690,688,1,0,0,0,691,692,5,476,0,0,692,694,
        3,286,143,0,693,695,3,312,156,0,694,693,1,0,0,0,694,695,1,0,0,0,
        695,697,1,0,0,0,696,691,1,0,0,0,696,697,1,0,0,0,697,703,1,0,0,0,
        698,699,5,476,0,0,699,701,3,288,144,0,700,702,3,312,156,0,701,700,
        1,0,0,0,701,702,1,0,0,0,702,704,1,0,0,0,703,698,1,0,0,0,703,704,
        1,0,0,0,704,710,1,0,0,0,705,706,5,476,0,0,706,708,3,260,130,0,707,
        709,3,312,156,0,708,707,1,0,0,0,708,709,1,0,0,0,709,711,1,0,0,0,
        710,705,1,0,0,0,710,711,1,0,0,0,711,712,1,0,0,0,712,713,5,473,0,
        0,713,55,1,0,0,0,714,716,5,248,0,0,715,717,5,169,0,0,716,715,1,0,
        0,0,716,717,1,0,0,0,717,718,1,0,0,0,718,720,5,418,0,0,719,721,3,
        414,207,0,720,719,1,0,0,0,720,721,1,0,0,0,721,722,1,0,0,0,722,726,
        3,404,202,0,723,725,3,58,29,0,724,723,1,0,0,0,725,728,1,0,0,0,726,
        724,1,0,0,0,726,727,1,0,0,0,727,729,1,0,0,0,728,726,1,0,0,0,729,
        730,5,395,0,0,730,731,5,54,0,0,731,732,5,400,0,0,732,736,3,422,211,
        0,733,735,3,58,29,0,734,733,1,0,0,0,735,738,1,0,0,0,736,734,1,0,
        0,0,736,737,1,0,0,0,737,739,1,0,0,0,738,736,1,0,0,0,739,740,5,405,
        0,0,740,741,5,209,0,0,741,742,5,308,0,0,742,746,3,422,211,0,743,
        745,3,58,29,0,744,743,1,0,0,0,745,748,1,0,0,0,746,744,1,0,0,0,746,
        747,1,0,0,0,747,749,1,0,0,0,748,746,1,0,0,0,749,750,5,364,0,0,750,
        754,3,422,211,0,751,753,3,58,29,0,752,751,1,0,0,0,753,756,1,0,0,
        0,754,752,1,0,0,0,754,755,1,0,0,0,755,757,1,0,0,0,756,754,1,0,0,
        0,757,761,3,24,12,0,758,760,3,58,29,0,759,758,1,0,0,0,760,763,1,
        0,0,0,761,759,1,0,0,0,761,762,1,0,0,0,762,57,1,0,0,0,763,761,1,0,
        0,0,764,771,3,54,27,0,765,771,3,312,156,0,766,771,3,262,131,0,767,
        771,3,412,206,0,768,771,3,270,135,0,769,771,3,272,136,0,770,764,
        1,0,0,0,770,765,1,0,0,0,770,766,1,0,0,0,770,767,1,0,0,0,770,768,
        1,0,0,0,770,769,1,0,0,0,771,59,1,0,0,0,772,773,5,248,0,0,773,774,
        5,286,0,0,774,776,5,418,0,0,775,777,3,414,207,0,776,775,1,0,0,0,
        776,777,1,0,0,0,777,778,1,0,0,0,778,782,3,404,202,0,779,781,3,62,
        31,0,780,779,1,0,0,0,781,784,1,0,0,0,782,780,1,0,0,0,782,783,1,0,
        0,0,783,785,1,0,0,0,784,782,1,0,0,0,785,789,3,54,27,0,786,788,3,
        62,31,0,787,786,1,0,0,0,788,791,1,0,0,0,789,787,1,0,0,0,789,790,
        1,0,0,0,790,792,1,0,0,0,791,789,1,0,0,0,792,793,5,395,0,0,793,794,
        5,54,0,0,794,795,5,400,0,0,795,799,3,422,211,0,796,798,3,62,31,0,
        797,796,1,0,0,0,798,801,1,0,0,0,799,797,1,0,0,0,799,800,1,0,0,0,
        800,802,1,0,0,0,801,799,1,0,0,0,802,803,5,405,0,0,803,804,5,209,
        0,0,804,805,5,308,0,0,805,809,3,422,211,0,806,808,3,62,31,0,807,
        806,1,0,0,0,808,811,1,0,0,0,809,807,1,0,0,0,809,810,1,0,0,0,810,
        812,1,0,0,0,811,809,1,0,0,0,812,813,5,364,0,0,813,817,3,422,211,
        0,814,816,3,62,31,0,815,814,1,0,0,0,816,819,1,0,0,0,817,815,1,0,
        0,0,817,818,1,0,0,0,818,820,1,0,0,0,819,817,1,0,0,0,820,821,5,87,
        0,0,821,825,3,74,37,0,822,824,3,62,31,0,823,822,1,0,0,0,824,827,
        1,0,0,0,825,823,1,0,0,0,825,826,1,0,0,0,826,61,1,0,0,0,827,825,1,
        0,0,0,828,835,3,312,156,0,829,835,3,262,131,0,830,835,3,412,206,
        0,831,835,3,270,135,0,832,835,3,272,136,0,833,835,3,24,12,0,834,
        828,1,0,0,0,834,829,1,0,0,0,834,830,1,0,0,0,834,831,1,0,0,0,834,
        832,1,0,0,0,834,833,1,0,0,0,835,63,1,0,0,0,836,837,5,248,0,0,837,
        839,5,418,0,0,838,840,3,414,207,0,839,838,1,0,0,0,839,840,1,0,0,
        0,840,841,1,0,0,0,841,842,3,404,202,0,842,845,3,412,206,0,843,844,
        5,209,0,0,844,846,3,98,49,0,845,843,1,0,0,0,845,846,1,0,0,0,846,
        65,1,0,0,0,847,848,5,248,0,0,848,849,5,453,0,0,849,850,5,418,0,0,
        850,854,3,404,202,0,851,853,3,68,34,0,852,851,1,0,0,0,853,856,1,
        0,0,0,854,852,1,0,0,0,854,855,1,0,0,0,855,857,1,0,0,0,856,854,1,
        0,0,0,857,858,5,472,0,0,858,859,5,381,0,0,859,860,5,77,0,0,860,861,
        5,472,0,0,861,866,3,388,194,0,862,863,5,476,0,0,863,865,3,388,194,
        0,864,862,1,0,0,0,865,868,1,0,0,0,866,864,1,0,0,0,866,867,1,0,0,
        0,867,869,1,0,0,0,868,866,1,0,0,0,869,872,5,473,0,0,870,871,5,351,
        0,0,871,873,5,39,0,0,872,870,1,0,0,0,872,873,1,0,0,0,873,874,1,0,
        0,0,874,878,5,473,0,0,875,877,3,68,34,0,876,875,1,0,0,0,877,880,
        1,0,0,0,878,876,1,0,0,0,878,879,1,0,0,0,879,881,1,0,0,0,880,878,
        1,0,0,0,881,882,5,454,0,0,882,883,5,465,0,0,883,884,5,315,0,0,884,
        885,3,388,194,0,885,886,7,1,0,0,886,890,1,0,0,0,887,889,3,68,34,
        0,888,887,1,0,0,0,889,892,1,0,0,0,890,888,1,0,0,0,890,891,1,0,0,
        0,891,67,1,0,0,0,892,890,1,0,0,0,893,901,3,262,131,0,894,901,3,412,
        206,0,895,896,5,455,0,0,896,897,5,465,0,0,897,901,7,2,0,0,898,899,
        5,209,0,0,899,901,3,98,49,0,900,893,1,0,0,0,900,894,1,0,0,0,900,
        895,1,0,0,0,900,898,1,0,0,0,901,69,1,0,0,0,902,903,5,441,0,0,903,
        904,5,72,0,0,904,910,3,72,36,0,905,906,5,476,0,0,906,907,5,72,0,
        0,907,909,3,72,36,0,908,905,1,0,0,0,909,912,1,0,0,0,910,908,1,0,
        0,0,910,911,1,0,0,0,911,71,1,0,0,0,912,910,1,0,0,0,913,916,3,74,
        37,0,914,915,5,469,0,0,915,917,5,72,0,0,916,914,1,0,0,0,916,917,
        1,0,0,0,917,73,1,0,0,0,918,928,5,494,0,0,919,921,5,491,0,0,920,922,
        5,497,0,0,921,920,1,0,0,0,921,922,1,0,0,0,922,924,1,0,0,0,923,919,
        1,0,0,0,924,925,1,0,0,0,925,923,1,0,0,0,925,926,1,0,0,0,926,928,
        1,0,0,0,927,918,1,0,0,0,927,923,1,0,0,0,928,75,1,0,0,0,929,931,5,
        66,0,0,930,932,5,351,0,0,931,930,1,0,0,0,931,932,1,0,0,0,932,933,
        1,0,0,0,933,934,5,282,0,0,934,77,1,0,0,0,935,939,7,3,0,0,936,937,
        7,4,0,0,937,939,3,410,205,0,938,935,1,0,0,0,938,936,1,0,0,0,939,
        79,1,0,0,0,940,942,5,134,0,0,941,943,3,410,205,0,942,941,1,0,0,0,
        942,943,1,0,0,0,943,944,1,0,0,0,944,945,5,429,0,0,945,946,3,410,
        205,0,946,81,1,0,0,0,947,948,5,399,0,0,948,949,3,418,209,0,949,83,
        1,0,0,0,950,951,5,4,0,0,951,952,5,243,0,0,952,953,3,290,145,0,953,
        954,5,381,0,0,954,955,5,77,0,0,955,957,3,322,161,0,956,958,3,90,
        45,0,957,956,1,0,0,0,957,958,1,0,0,0,958,85,1,0,0,0,959,960,5,273,
        0,0,960,961,5,243,0,0,961,962,3,290,145,0,962,87,1,0,0,0,963,964,
        5,4,0,0,964,965,5,434,0,0,965,966,3,322,161,0,966,89,1,0,0,0,967,
        968,5,351,0,0,968,969,5,39,0,0,969,91,1,0,0,0,970,972,5,281,0,0,
        971,970,1,0,0,0,971,972,1,0,0,0,972,973,1,0,0,0,973,974,3,94,47,
        0,974,93,1,0,0,0,975,976,5,311,0,0,976,978,7,5,0,0,977,979,5,418,
        0,0,978,977,1,0,0,0,978,979,1,0,0,0,979,980,1,0,0,0,980,982,3,406,
        203,0,981,983,3,96,48,0,982,981,1,0,0,0,982,983,1,0,0,0,983,985,
        1,0,0,0,984,986,3,322,161,0,985,984,1,0,0,0,985,986,1,0,0,0,986,
        995,1,0,0,0,987,996,3,98,49,0,988,996,3,292,146,0,989,990,5,135,
        0,0,990,991,3,192,96,0,991,992,3,110,55,0,992,996,1,0,0,0,993,994,
        5,418,0,0,994,996,3,406,203,0,995,987,1,0,0,0,995,988,1,0,0,0,995,
        989,1,0,0,0,995,993,1,0,0,0,996,95,1,0,0,0,997,998,5,368,0,0,998,
        999,3,418,209,0,999,97,1,0,0,0,1000,1001,6,49,-1,0,1001,1002,3,100,
        50,0,1002,1003,3,98,49,4,1003,1025,1,0,0,0,1004,1005,5,472,0,0,1005,
        1006,3,98,49,0,1006,1007,5,473,0,0,1007,1025,1,0,0,0,1008,1011,3,
        112,56,0,1009,1011,3,110,55,0,1010,1008,1,0,0,0,1010,1009,1,0,0,
        0,1011,1013,1,0,0,0,1012,1014,3,230,115,0,1013,1012,1,0,0,0,1013,
        1014,1,0,0,0,1014,1016,1,0,0,0,1015,1017,3,228,114,0,1016,1015,1,
        0,0,0,1016,1017,1,0,0,0,1017,1019,1,0,0,0,1018,1020,3,234,117,0,
        1019,1018,1,0,0,0,1019,1020,1,0,0,0,1020,1022,1,0,0,0,1021,1023,
        3,236,118,0,1022,1021,1,0,0,0,1022,1023,1,0,0,0,1023,1025,1,0,0,
        0,1024,1000,1,0,0,0,1024,1004,1,0,0,0,1024,1010,1,0,0,0,1025,1046,
        1,0,0,0,1026,1027,10,2,0,0,1027,1029,7,6,0,0,1028,1030,7,7,0,0,1029,
        1028,1,0,0,0,1029,1030,1,0,0,0,1030,1031,1,0,0,0,1031,1033,3,98,
        49,0,1032,1034,3,230,115,0,1033,1032,1,0,0,0,1033,1034,1,0,0,0,1034,
        1036,1,0,0,0,1035,1037,3,228,114,0,1036,1035,1,0,0,0,1036,1037,1,
        0,0,0,1037,1039,1,0,0,0,1038,1040,3,234,117,0,1039,1038,1,0,0,0,
        1039,1040,1,0,0,0,1040,1042,1,0,0,0,1041,1043,3,236,118,0,1042,1041,
        1,0,0,0,1042,1043,1,0,0,0,1043,1045,1,0,0,0,1044,1026,1,0,0,0,1045,
        1048,1,0,0,0,1046,1044,1,0,0,0,1046,1047,1,0,0,0,1047,99,1,0,0,0,
        1048,1046,1,0,0,0,1049,1050,5,449,0,0,1050,1055,3,106,53,0,1051,
        1052,5,476,0,0,1052,1054,3,106,53,0,1053,1051,1,0,0,0,1054,1057,
        1,0,0,0,1055,1053,1,0,0,0,1055,1056,1,0,0,0,1056,101,1,0,0,0,1057,
        1055,1,0,0,0,1058,1059,5,443,0,0,1059,1067,3,104,52,0,1060,1063,
        5,476,0,0,1061,1063,3,376,188,0,1062,1060,1,0,0,0,1062,1061,1,0,
        0,0,1063,1064,1,0,0,0,1064,1066,3,104,52,0,1065,1062,1,0,0,0,1066,
        1069,1,0,0,0,1067,1065,1,0,0,0,1067,1068,1,0,0,0,1068,103,1,0,0,
        0,1069,1067,1,0,0,0,1070,1071,5,472,0,0,1071,1076,3,326,163,0,1072,
        1073,5,476,0,0,1073,1075,3,326,163,0,1074,1072,1,0,0,0,1075,1078,
        1,0,0,0,1076,1074,1,0,0,0,1076,1077,1,0,0,0,1077,1079,1,0,0,0,1078,
        1076,1,0,0,0,1079,1080,5,473,0,0,1080,105,1,0,0,0,1081,1093,3,108,
        54,0,1082,1083,5,472,0,0,1083,1088,3,320,160,0,1084,1085,5,476,0,
        0,1085,1087,3,320,160,0,1086,1084,1,0,0,0,1087,1090,1,0,0,0,1088,
        1086,1,0,0,0,1088,1089,1,0,0,0,1089,1091,1,0,0,0,1090,1088,1,0,0,
        0,1091,1092,5,473,0,0,1092,1094,1,0,0,0,1093,1082,1,0,0,0,1093,1094,
        1,0,0,0,1094,1095,1,0,0,0,1095,1096,5,209,0,0,1096,1097,5,472,0,
        0,1097,1098,3,98,49,0,1098,1099,5,473,0,0,1099,107,1,0,0,0,1100,
        1101,3,388,194,0,1101,109,1,0,0,0,1102,1103,3,112,56,0,1103,1105,
        3,130,65,0,1104,1106,3,192,96,0,1105,1104,1,0,0,0,1105,1106,1,0,
        0,0,1106,1108,1,0,0,0,1107,1109,3,196,98,0,1108,1107,1,0,0,0,1108,
        1109,1,0,0,0,1109,1111,1,0,0,0,1110,1112,3,218,109,0,1111,1110,1,
        0,0,0,1111,1112,1,0,0,0,1112,1114,1,0,0,0,1113,1115,3,220,110,0,
        1114,1113,1,0,0,0,1114,1115,1,0,0,0,1115,1140,1,0,0,0,1116,1117,
        3,130,65,0,1117,1119,3,112,56,0,1118,1120,3,192,96,0,1119,1118,1,
        0,0,0,1119,1120,1,0,0,0,1120,1122,1,0,0,0,1121,1123,3,196,98,0,1122,
        1121,1,0,0,0,1122,1123,1,0,0,0,1123,1125,1,0,0,0,1124,1126,3,218,
        109,0,1125,1124,1,0,0,0,1125,1126,1,0,0,0,1126,1128,1,0,0,0,1127,
        1129,3,220,110,0,1128,1127,1,0,0,0,1128,1129,1,0,0,0,1129,1140,1,
        0,0,0,1130,1131,3,112,56,0,1131,1132,3,130,65,0,1132,1133,3,226,
        113,0,1133,1140,1,0,0,0,1134,1135,3,112,56,0,1135,1136,3,130,65,
        0,1136,1137,3,194,97,0,1137,1140,1,0,0,0,1138,1140,3,452,226,0,1139,
        1102,1,0,0,0,1139,1116,1,0,0,0,1139,1130,1,0,0,0,1139,1134,1,0,0,
        0,1139,1138,1,0,0,0,1140,111,1,0,0,0,1141,1143,5,398,0,0,1142,1144,
        3,440,220,0,1143,1142,1,0,0,0,1143,1144,1,0,0,0,1144,1145,1,0,0,
        0,1145,1150,3,114,57,0,1146,1147,5,476,0,0,1147,1149,3,114,57,0,
        1148,1146,1,0,0,0,1149,1152,1,0,0,0,1150,1148,1,0,0,0,1150,1151,
        1,0,0,0,1151,113,1,0,0,0,1152,1150,1,0,0,0,1153,1158,3,118,59,0,
        1154,1156,5,209,0,0,1155,1154,1,0,0,0,1155,1156,1,0,0,0,1156,1157,
        1,0,0,0,1157,1159,3,388,194,0,1158,1155,1,0,0,0,1158,1159,1,0,0,
        0,1159,1166,1,0,0,0,1160,1163,3,326,163,0,1161,1162,5,209,0,0,1162,
        1164,3,326,163,0,1163,1161,1,0,0,0,1163,1164,1,0,0,0,1164,1166,1,
        0,0,0,1165,1153,1,0,0,0,1165,1160,1,0,0,0,1166,115,1,0,0,0,1167,
        1168,5,48,0,0,1168,1169,5,472,0,0,1169,1170,3,192,96,0,1170,1171,
        5,473,0,0,1171,117,1,0,0,0,1172,1175,3,122,61,0,1173,1174,7,8,0,
        0,1174,1176,5,100,0,0,1175,1173,1,0,0,0,1175,1176,1,0,0,0,1176,1177,
        1,0,0,0,1177,1179,5,365,0,0,1178,1180,3,408,204,0,1179,1178,1,0,
        0,0,1179,1180,1,0,0,0,1180,1191,1,0,0,0,1181,1183,5,472,0,0,1182,
        1184,3,120,60,0,1183,1182,1,0,0,0,1183,1184,1,0,0,0,1184,1185,1,
        0,0,0,1185,1187,3,228,114,0,1186,1188,3,132,66,0,1187,1186,1,0,0,
        0,1187,1188,1,0,0,0,1188,1189,1,0,0,0,1189,1190,5,473,0,0,1190,1192,
        1,0,0,0,1191,1181,1,0,0,0,1191,1192,1,0,0,0,1192,119,1,0,0,0,1193,
        1194,7,9,0,0,1194,1195,5,223,0,0,1195,1200,3,320,160,0,1196,1197,
        5,476,0,0,1197,1199,3,320,160,0,1198,1196,1,0,0,0,1199,1202,1,0,
        0,0,1200,1198,1,0,0,0,1200,1201,1,0,0,0,1201,1205,1,0,0,0,1202,1200,
        1,0,0,0,1203,1204,5,465,0,0,1204,1206,3,326,163,0,1205,1203,1,0,
        0,0,1205,1206,1,0,0,0,1206,121,1,0,0,0,1207,1208,3,124,62,0,1208,
        1217,5,472,0,0,1209,1214,3,354,177,0,1210,1211,5,476,0,0,1211,1213,
        3,354,177,0,1212,1210,1,0,0,0,1213,1216,1,0,0,0,1214,1212,1,0,0,
        0,1214,1215,1,0,0,0,1215,1218,1,0,0,0,1216,1214,1,0,0,0,1217,1209,
        1,0,0,0,1217,1218,1,0,0,0,1218,1219,1,0,0,0,1219,1220,5,473,0,0,
        1220,1223,1,0,0,0,1221,1223,3,336,168,0,1222,1207,1,0,0,0,1222,1221,
        1,0,0,0,1223,123,1,0,0,0,1224,1227,3,128,64,0,1225,1227,3,126,63,
        0,1226,1224,1,0,0,0,1226,1225,1,0,0,0,1227,125,1,0,0,0,1228,1229,
        7,10,0,0,1229,127,1,0,0,0,1230,1231,7,11,0,0,1231,129,1,0,0,0,1232,
        1233,5,293,0,0,1233,1234,3,136,68,0,1234,131,1,0,0,0,1235,1242,7,
        12,0,0,1236,1243,3,134,67,0,1237,1238,5,214,0,0,1238,1239,3,134,
        67,0,1239,1240,5,205,0,0,1240,1241,3,134,67,0,1241,1243,1,0,0,0,
        1242,1236,1,0,0,0,1242,1237,1,0,0,0,1243,133,1,0,0,0,1244,1245,5,
        182,0,0,1245,1257,5,115,0,0,1246,1247,3,326,163,0,1247,1248,5,115,
        0,0,1248,1257,1,0,0,0,1249,1250,5,252,0,0,1250,1257,5,395,0,0,1251,
        1252,3,326,163,0,1252,1253,5,53,0,0,1253,1257,1,0,0,0,1254,1255,
        5,182,0,0,1255,1257,5,53,0,0,1256,1244,1,0,0,0,1256,1246,1,0,0,0,
        1256,1249,1,0,0,0,1256,1251,1,0,0,0,1256,1254,1,0,0,0,1257,135,1,
        0,0,0,1258,1259,6,68,-1,0,1259,1264,3,146,73,0,1260,1261,5,476,0,
        0,1261,1263,3,146,73,0,1262,1260,1,0,0,0,1263,1266,1,0,0,0,1264,
        1262,1,0,0,0,1264,1265,1,0,0,0,1265,1289,1,0,0,0,1266,1264,1,0,0,
        0,1267,1268,3,146,73,0,1268,1270,3,144,72,0,1269,1271,3,376,188,
        0,1270,1269,1,0,0,0,1270,1271,1,0,0,0,1271,1289,1,0,0,0,1272,1276,
        3,146,73,0,1273,1275,3,142,71,0,1274,1273,1,0,0,0,1275,1278,1,0,
        0,0,1276,1274,1,0,0,0,1276,1277,1,0,0,0,1277,1280,1,0,0,0,1278,1276,
        1,0,0,0,1279,1281,3,376,188,0,1280,1279,1,0,0,0,1280,1281,1,0,0,
        0,1281,1289,1,0,0,0,1282,1289,3,102,51,0,1283,1285,3,138,69,0,1284,
        1286,3,376,188,0,1285,1284,1,0,0,0,1285,1286,1,0,0,0,1286,1289,1,
        0,0,0,1287,1289,3,166,83,0,1288,1258,1,0,0,0,1288,1267,1,0,0,0,1288,
        1272,1,0,0,0,1288,1282,1,0,0,0,1288,1283,1,0,0,0,1288,1287,1,0,0,
        0,1289,1318,1,0,0,0,1290,1291,10,4,0,0,1291,1292,5,249,0,0,1292,
        1293,5,322,0,0,1293,1317,3,136,68,5,1294,1296,10,5,0,0,1295,1297,
        5,347,0,0,1296,1295,1,0,0,0,1296,1297,1,0,0,0,1297,1299,1,0,0,0,
        1298,1300,7,13,0,0,1299,1298,1,0,0,0,1299,1300,1,0,0,0,1300,1302,
        1,0,0,0,1301,1303,5,363,0,0,1302,1301,1,0,0,0,1302,1303,1,0,0,0,
        1303,1304,1,0,0,0,1304,1305,5,322,0,0,1305,1307,3,136,68,0,1306,
        1308,3,190,95,0,1307,1306,1,0,0,0,1307,1308,1,0,0,0,1308,1313,1,
        0,0,0,1309,1310,5,476,0,0,1310,1312,3,146,73,0,1311,1309,1,0,0,0,
        1312,1315,1,0,0,0,1313,1311,1,0,0,0,1313,1314,1,0,0,0,1314,1317,
        1,0,0,0,1315,1313,1,0,0,0,1316,1290,1,0,0,0,1316,1294,1,0,0,0,1317,
        1320,1,0,0,0,1318,1316,1,0,0,0,1318,1319,1,0,0,0,1319,137,1,0,0,
        0,1320,1318,1,0,0,0,1321,1322,3,140,70,0,1322,139,1,0,0,0,1323,1324,
        5,383,0,0,1324,1325,5,472,0,0,1325,1330,3,326,163,0,1326,1327,5,
        476,0,0,1327,1329,3,326,163,0,1328,1326,1,0,0,0,1329,1332,1,0,0,
        0,1330,1328,1,0,0,0,1330,1331,1,0,0,0,1331,1333,1,0,0,0,1332,1330,
        1,0,0,0,1333,1334,5,473,0,0,1334,141,1,0,0,0,1335,1336,5,326,0,0,
        1336,1338,5,190,0,0,1337,1339,5,363,0,0,1338,1337,1,0,0,0,1338,1339,
        1,0,0,0,1339,1340,1,0,0,0,1340,1342,3,150,75,0,1341,1343,3,376,188,
        0,1342,1341,1,0,0,0,1342,1343,1,0,0,0,1343,1344,1,0,0,0,1344,1345,
        5,209,0,0,1345,1350,3,374,187,0,1346,1347,5,476,0,0,1347,1349,3,
        374,187,0,1348,1346,1,0,0,0,1349,1352,1,0,0,0,1350,1348,1,0,0,0,
        1350,1351,1,0,0,0,1351,143,1,0,0,0,1352,1350,1,0,0,0,1353,1354,5,
        376,0,0,1354,1355,5,472,0,0,1355,1356,3,154,77,0,1356,1357,5,473,
        0,0,1357,1368,1,0,0,0,1358,1361,5,437,0,0,1359,1360,7,14,0,0,1360,
        1362,5,100,0,0,1361,1359,1,0,0,0,1361,1362,1,0,0,0,1362,1363,1,0,
        0,0,1363,1364,5,472,0,0,1364,1365,3,152,76,0,1365,1366,5,473,0,0,
        1366,1368,1,0,0,0,1367,1353,1,0,0,0,1367,1358,1,0,0,0,1368,145,1,
        0,0,0,1369,1371,3,148,74,0,1370,1372,3,376,188,0,1371,1370,1,0,0,
        0,1371,1372,1,0,0,0,1372,147,1,0,0,0,1373,1375,5,418,0,0,1374,1373,
        1,0,0,0,1374,1375,1,0,0,0,1375,1376,1,0,0,0,1376,1378,3,406,203,
        0,1377,1379,3,160,80,0,1378,1377,1,0,0,0,1378,1379,1,0,0,0,1379,
        1415,1,0,0,0,1380,1381,5,326,0,0,1381,1384,5,418,0,0,1382,1385,3,
        150,75,0,1383,1385,3,338,169,0,1384,1382,1,0,0,0,1384,1383,1,0,0,
        0,1385,1415,1,0,0,0,1386,1387,5,326,0,0,1387,1388,5,418,0,0,1388,
        1389,5,284,0,0,1389,1392,5,472,0,0,1390,1393,3,150,75,0,1391,1393,
        3,338,169,0,1392,1390,1,0,0,0,1392,1391,1,0,0,0,1393,1394,1,0,0,
        0,1394,1395,5,473,0,0,1395,1415,1,0,0,0,1396,1397,5,326,0,0,1397,
        1398,5,472,0,0,1398,1399,3,98,49,0,1399,1400,5,473,0,0,1400,1415,
        1,0,0,0,1401,1405,5,472,0,0,1402,1404,3,98,49,0,1403,1402,1,0,0,
        0,1404,1407,1,0,0,0,1405,1403,1,0,0,0,1405,1406,1,0,0,0,1406,1408,
        1,0,0,0,1407,1405,1,0,0,0,1408,1415,5,473,0,0,1409,1410,5,436,0,
        0,1410,1411,5,472,0,0,1411,1412,3,326,163,0,1412,1413,5,473,0,0,
        1413,1415,1,0,0,0,1414,1374,1,0,0,0,1414,1380,1,0,0,0,1414,1386,
        1,0,0,0,1414,1396,1,0,0,0,1414,1401,1,0,0,0,1414,1409,1,0,0,0,1415,
        149,1,0,0,0,1416,1417,3,352,176,0,1417,1420,5,472,0,0,1418,1421,
        3,150,75,0,1419,1421,3,354,177,0,1420,1418,1,0,0,0,1420,1419,1,0,
        0,0,1421,1429,1,0,0,0,1422,1425,5,476,0,0,1423,1426,3,150,75,0,1424,
        1426,3,354,177,0,1425,1423,1,0,0,0,1425,1424,1,0,0,0,1426,1428,1,
        0,0,0,1427,1422,1,0,0,0,1428,1431,1,0,0,0,1429,1427,1,0,0,0,1429,
        1430,1,0,0,0,1430,1432,1,0,0,0,1431,1429,1,0,0,0,1432,1433,5,473,
        0,0,1433,1464,1,0,0,0,1434,1435,3,352,176,0,1435,1438,5,472,0,0,
        1436,1439,3,150,75,0,1437,1439,3,354,177,0,1438,1436,1,0,0,0,1438,
        1437,1,0,0,0,1439,1447,1,0,0,0,1440,1443,5,476,0,0,1441,1444,3,150,
        75,0,1442,1444,3,354,177,0,1443,1441,1,0,0,0,1443,1442,1,0,0,0,1444,
        1446,1,0,0,0,1445,1440,1,0,0,0,1446,1449,1,0,0,0,1447,1445,1,0,0,
        0,1447,1448,1,0,0,0,1448,1450,1,0,0,0,1449,1447,1,0,0,0,1450,1451,
        5,473,0,0,1451,1452,5,472,0,0,1452,1453,5,209,0,0,1453,1454,3,376,
        188,0,1454,1455,5,473,0,0,1455,1460,3,114,57,0,1456,1457,5,476,0,
        0,1457,1459,3,114,57,0,1458,1456,1,0,0,0,1459,1462,1,0,0,0,1460,
        1458,1,0,0,0,1460,1461,1,0,0,0,1461,1464,1,0,0,0,1462,1460,1,0,0,
        0,1463,1416,1,0,0,0,1463,1434,1,0,0,0,1464,151,1,0,0,0,1465,1468,
        3,320,160,0,1466,1468,3,322,161,0,1467,1465,1,0,0,0,1467,1466,1,
        0,0,0,1468,1469,1,0,0,0,1469,1470,5,292,0,0,1470,1471,3,320,160,
        0,1471,1472,5,306,0,0,1472,1473,3,158,79,0,1473,153,1,0,0,0,1474,
        1475,3,156,78,0,1475,1476,5,476,0,0,1476,1477,3,156,78,0,1477,1478,
        1,0,0,0,1478,1481,5,292,0,0,1479,1482,3,320,160,0,1480,1482,3,322,
        161,0,1481,1479,1,0,0,0,1481,1480,1,0,0,0,1482,1483,1,0,0,0,1483,
        1484,5,306,0,0,1484,1485,3,158,79,0,1485,155,1,0,0,0,1486,1489,3,
        326,163,0,1487,1488,5,209,0,0,1488,1490,3,374,187,0,1489,1487,1,
        0,0,0,1489,1490,1,0,0,0,1490,157,1,0,0,0,1491,1492,5,472,0,0,1492,
        1497,3,156,78,0,1493,1494,5,476,0,0,1494,1496,3,156,78,0,1495,1493,
        1,0,0,0,1496,1499,1,0,0,0,1497,1495,1,0,0,0,1497,1498,1,0,0,0,1498,
        1500,1,0,0,0,1499,1497,1,0,0,0,1500,1501,5,473,0,0,1501,159,1,0,
        0,0,1502,1503,5,292,0,0,1503,1504,5,416,0,0,1504,1505,5,209,0,0,
        1505,1506,5,356,0,0,1506,1507,3,162,81,0,1507,161,1,0,0,0,1508,1509,
        3,326,163,0,1509,163,1,0,0,0,1510,1515,3,326,163,0,1511,1512,5,476,
        0,0,1512,1514,3,326,163,0,1513,1511,1,0,0,0,1514,1517,1,0,0,0,1515,
        1513,1,0,0,0,1515,1516,1,0,0,0,1516,1519,1,0,0,0,1517,1515,1,0,0,
        0,1518,1520,3,376,188,0,1519,1518,1,0,0,0,1519,1520,1,0,0,0,1520,
        165,1,0,0,0,1521,1522,5,418,0,0,1522,1523,5,472,0,0,1523,1524,3,
        168,84,0,1524,1525,5,473,0,0,1525,167,1,0,0,0,1526,1527,3,170,85,
        0,1527,1528,5,472,0,0,1528,1533,3,184,92,0,1529,1530,5,476,0,0,1530,
        1532,3,184,92,0,1531,1529,1,0,0,0,1532,1535,1,0,0,0,1533,1531,1,
        0,0,0,1533,1534,1,0,0,0,1534,1536,1,0,0,0,1535,1533,1,0,0,0,1536,
        1537,5,473,0,0,1537,169,1,0,0,0,1538,1539,7,15,0,0,1539,171,1,0,
        0,0,1540,1541,3,182,91,0,1541,1542,3,176,88,0,1542,1543,3,182,91,
        0,1543,173,1,0,0,0,1544,1545,3,178,89,0,1545,1546,3,176,88,0,1546,
        1547,3,178,89,0,1547,175,1,0,0,0,1548,1549,5,441,0,0,1549,1550,3,
        434,217,0,1550,1553,5,209,0,0,1551,1554,3,322,161,0,1552,1554,3,
        280,140,0,1553,1551,1,0,0,0,1553,1552,1,0,0,0,1553,1554,1,0,0,0,
        1554,177,1,0,0,0,1555,1556,5,395,0,0,1556,1557,5,54,0,0,1557,1558,
        5,400,0,0,1558,1560,3,434,217,0,1559,1555,1,0,0,0,1559,1560,1,0,
        0,0,1560,1564,1,0,0,0,1561,1562,5,449,0,0,1562,1563,5,160,0,0,1563,
        1565,3,180,90,0,1564,1561,1,0,0,0,1564,1565,1,0,0,0,1565,179,1,0,
        0,0,1566,1569,5,472,0,0,1567,1570,3,420,210,0,1568,1570,3,422,211,
        0,1569,1567,1,0,0,0,1569,1568,1,0,0,0,1570,1578,1,0,0,0,1571,1574,
        5,476,0,0,1572,1575,3,420,210,0,1573,1575,3,422,211,0,1574,1572,
        1,0,0,0,1574,1573,1,0,0,0,1575,1577,1,0,0,0,1576,1571,1,0,0,0,1577,
        1580,1,0,0,0,1578,1576,1,0,0,0,1578,1579,1,0,0,0,1579,1581,1,0,0,
        0,1580,1578,1,0,0,0,1581,1582,5,473,0,0,1582,181,1,0,0,0,1583,1585,
        3,52,26,0,1584,1583,1,0,0,0,1584,1585,1,0,0,0,1585,1587,1,0,0,0,
        1586,1588,3,44,22,0,1587,1586,1,0,0,0,1587,1588,1,0,0,0,1588,1593,
        1,0,0,0,1589,1590,5,332,0,0,1590,1591,5,421,0,0,1591,1592,5,223,
        0,0,1592,1594,3,434,217,0,1593,1589,1,0,0,0,1593,1594,1,0,0,0,1594,
        1599,1,0,0,0,1595,1596,5,354,0,0,1596,1597,5,34,0,0,1597,1598,5,
        209,0,0,1598,1600,3,434,217,0,1599,1595,1,0,0,0,1599,1600,1,0,0,
        0,1600,183,1,0,0,0,1601,1602,5,418,0,0,1602,1617,3,216,108,0,1603,
        1617,3,188,94,0,1604,1617,3,362,181,0,1605,1606,5,28,0,0,1606,1607,
        5,493,0,0,1607,1608,5,418,0,0,1608,1617,3,216,108,0,1609,1610,5,
        170,0,0,1610,1611,5,493,0,0,1611,1617,3,188,94,0,1612,1613,3,186,
        93,0,1613,1614,5,493,0,0,1614,1615,3,362,181,0,1615,1617,1,0,0,0,
        1616,1601,1,0,0,0,1616,1603,1,0,0,0,1616,1604,1,0,0,0,1616,1605,
        1,0,0,0,1616,1609,1,0,0,0,1616,1612,1,0,0,0,1617,185,1,0,0,0,1618,
        1619,7,16,0,0,1619,187,1,0,0,0,1620,1621,5,36,0,0,1621,1622,5,472,
        0,0,1622,1623,3,410,205,0,1623,1624,5,473,0,0,1624,189,1,0,0,0,1625,
        1626,5,358,0,0,1626,1640,3,328,164,0,1627,1628,5,441,0,0,1628,1629,
        5,472,0,0,1629,1634,3,410,205,0,1630,1631,5,476,0,0,1631,1633,3,
        410,205,0,1632,1630,1,0,0,0,1633,1636,1,0,0,0,1634,1632,1,0,0,0,
        1634,1635,1,0,0,0,1635,1637,1,0,0,0,1636,1634,1,0,0,0,1637,1638,
        5,473,0,0,1638,1640,1,0,0,0,1639,1625,1,0,0,0,1639,1627,1,0,0,0,
        1640,191,1,0,0,0,1641,1642,5,447,0,0,1642,1643,3,328,164,0,1643,
        193,1,0,0,0,1644,1645,5,420,0,0,1645,1649,5,472,0,0,1646,1650,3,
        436,218,0,1647,1650,5,495,0,0,1648,1650,3,326,163,0,1649,1646,1,
        0,0,0,1649,1647,1,0,0,0,1649,1648,1,0,0,0,1650,1651,1,0,0,0,1651,
        1652,5,371,0,0,1652,1676,5,473,0,0,1653,1654,5,420,0,0,1654,1657,
        5,472,0,0,1655,1658,5,495,0,0,1656,1658,3,326,163,0,1657,1655,1,
        0,0,0,1657,1656,1,0,0,0,1658,1659,1,0,0,0,1659,1660,5,396,0,0,1660,
        1676,5,473,0,0,1661,1662,5,420,0,0,1662,1663,5,472,0,0,1663,1666,
        5,221,0,0,1664,1667,5,495,0,0,1665,1667,3,326,163,0,1666,1664,1,
        0,0,0,1666,1665,1,0,0,0,1667,1668,1,0,0,0,1668,1669,5,362,0,0,1669,
        1672,5,356,0,0,1670,1673,5,495,0,0,1671,1673,3,326,163,0,1672,1670,
        1,0,0,0,1672,1671,1,0,0,0,1673,1674,1,0,0,0,1674,1676,5,473,0,0,
        1675,1644,1,0,0,0,1675,1653,1,0,0,0,1675,1661,1,0,0,0,1676,195,1,
        0,0,0,1677,1682,3,200,100,0,1678,1682,3,198,99,0,1679,1682,3,202,
        101,0,1680,1682,3,204,102,0,1681,1677,1,0,0,0,1681,1678,1,0,0,0,
        1681,1679,1,0,0,0,1681,1680,1,0,0,0,1682,197,1,0,0,0,1683,1684,5,
        235,0,0,1684,1685,5,223,0,0,1685,1690,3,206,103,0,1686,1687,5,476,
        0,0,1687,1689,3,206,103,0,1688,1686,1,0,0,0,1689,1692,1,0,0,0,1690,
        1688,1,0,0,0,1690,1691,1,0,0,0,1691,199,1,0,0,0,1692,1690,1,0,0,
        0,1693,1694,5,236,0,0,1694,1695,5,223,0,0,1695,1700,3,206,103,0,
        1696,1697,5,476,0,0,1697,1699,3,206,103,0,1698,1696,1,0,0,0,1699,
        1702,1,0,0,0,1700,1698,1,0,0,0,1700,1701,1,0,0,0,1701,201,1,0,0,
        0,1702,1700,1,0,0,0,1703,1704,5,271,0,0,1704,1705,5,223,0,0,1705,
        1710,3,206,103,0,1706,1707,5,476,0,0,1707,1709,3,206,103,0,1708,
        1706,1,0,0,0,1709,1712,1,0,0,0,1710,1708,1,0,0,0,1710,1711,1,0,0,
        0,1711,203,1,0,0,0,1712,1710,1,0,0,0,1713,1714,5,299,0,0,1714,1715,
        5,223,0,0,1715,1720,3,206,103,0,1716,1717,5,476,0,0,1717,1719,3,
        206,103,0,1718,1716,1,0,0,0,1719,1722,1,0,0,0,1720,1718,1,0,0,0,
        1720,1721,1,0,0,0,1721,1725,1,0,0,0,1722,1720,1,0,0,0,1723,1724,
        5,449,0,0,1724,1726,3,210,105,0,1725,1723,1,0,0,0,1725,1726,1,0,
        0,0,1726,205,1,0,0,0,1727,1732,3,326,163,0,1728,1729,5,476,0,0,1729,
        1731,3,326,163,0,1730,1728,1,0,0,0,1731,1734,1,0,0,0,1732,1730,1,
        0,0,0,1732,1733,1,0,0,0,1733,1774,1,0,0,0,1734,1732,1,0,0,0,1735,
        1774,3,212,106,0,1736,1737,5,472,0,0,1737,1774,5,473,0,0,1738,1739,
        5,472,0,0,1739,1744,3,326,163,0,1740,1741,5,476,0,0,1741,1743,3,
        326,163,0,1742,1740,1,0,0,0,1743,1746,1,0,0,0,1744,1742,1,0,0,0,
        1744,1745,1,0,0,0,1745,1747,1,0,0,0,1746,1744,1,0,0,0,1747,1748,
        5,473,0,0,1748,1774,1,0,0,0,1749,1750,3,210,105,0,1750,1751,5,472,
        0,0,1751,1756,3,326,163,0,1752,1753,5,476,0,0,1753,1755,3,326,163,
        0,1754,1752,1,0,0,0,1755,1758,1,0,0,0,1756,1754,1,0,0,0,1756,1757,
        1,0,0,0,1757,1759,1,0,0,0,1758,1756,1,0,0,0,1759,1760,5,473,0,0,
        1760,1774,1,0,0,0,1761,1762,3,208,104,0,1762,1763,5,472,0,0,1763,
        1768,3,206,103,0,1764,1765,5,476,0,0,1765,1767,3,206,103,0,1766,
        1764,1,0,0,0,1767,1770,1,0,0,0,1768,1766,1,0,0,0,1768,1769,1,0,0,
        0,1769,1771,1,0,0,0,1770,1768,1,0,0,0,1771,1772,5,473,0,0,1772,1774,
        1,0,0,0,1773,1727,1,0,0,0,1773,1735,1,0,0,0,1773,1736,1,0,0,0,1773,
        1738,1,0,0,0,1773,1749,1,0,0,0,1773,1761,1,0,0,0,1774,207,1,0,0,
        0,1775,1776,5,300,0,0,1776,1777,5,153,0,0,1777,209,1,0,0,0,1778,
        1779,7,17,0,0,1779,211,1,0,0,0,1780,1781,3,214,107,0,1781,1782,5,
        472,0,0,1782,1783,3,216,108,0,1783,1784,5,476,0,0,1784,1785,3,362,
        181,0,1785,1786,5,473,0,0,1786,213,1,0,0,0,1787,1788,7,18,0,0,1788,
        215,1,0,0,0,1789,1790,3,410,205,0,1790,217,1,0,0,0,1791,1792,5,303,
        0,0,1792,1793,3,328,164,0,1793,219,1,0,0,0,1794,1795,5,448,0,0,1795,
        1800,3,222,111,0,1796,1797,5,476,0,0,1797,1799,3,222,111,0,1798,
        1796,1,0,0,0,1799,1802,1,0,0,0,1800,1798,1,0,0,0,1800,1801,1,0,0,
        0,1801,221,1,0,0,0,1802,1800,1,0,0,0,1803,1804,3,380,190,0,1804,
        1805,5,209,0,0,1805,1806,3,224,112,0,1806,223,1,0,0,0,1807,1809,
        3,380,190,0,1808,1807,1,0,0,0,1808,1809,1,0,0,0,1809,1810,1,0,0,
        0,1810,1812,5,472,0,0,1811,1813,3,238,119,0,1812,1811,1,0,0,0,1812,
        1813,1,0,0,0,1813,1815,1,0,0,0,1814,1816,3,230,115,0,1815,1814,1,
        0,0,0,1815,1816,1,0,0,0,1816,1818,1,0,0,0,1817,1819,3,228,114,0,
        1818,1817,1,0,0,0,1818,1819,1,0,0,0,1819,1821,1,0,0,0,1820,1822,
        3,254,127,0,1821,1820,1,0,0,0,1821,1822,1,0,0,0,1822,1823,1,0,0,
        0,1823,1824,5,473,0,0,1824,225,1,0,0,0,1825,1826,5,337,0,0,1826,
        1828,5,472,0,0,1827,1829,3,238,119,0,1828,1827,1,0,0,0,1828,1829,
        1,0,0,0,1829,1831,1,0,0,0,1830,1832,3,230,115,0,1831,1830,1,0,0,
        0,1831,1832,1,0,0,0,1832,1834,1,0,0,0,1833,1835,3,228,114,0,1834,
        1833,1,0,0,0,1834,1835,1,0,0,0,1835,1837,1,0,0,0,1836,1838,3,242,
        121,0,1837,1836,1,0,0,0,1837,1838,1,0,0,0,1838,1840,1,0,0,0,1839,
        1841,3,248,124,0,1840,1839,1,0,0,0,1840,1841,1,0,0,0,1841,1843,1,
        0,0,0,1842,1844,3,250,125,0,1843,1842,1,0,0,0,1843,1844,1,0,0,0,
        1844,1846,1,0,0,0,1845,1847,3,244,122,0,1846,1845,1,0,0,0,1846,1847,
        1,0,0,0,1847,1848,1,0,0,0,1848,1849,3,252,126,0,1849,1854,5,473,
        0,0,1850,1852,5,209,0,0,1851,1850,1,0,0,0,1851,1852,1,0,0,0,1852,
        1853,1,0,0,0,1853,1855,3,388,194,0,1854,1851,1,0,0,0,1854,1855,1,
        0,0,0,1855,227,1,0,0,0,1856,1857,5,361,0,0,1857,1858,5,223,0,0,1858,
        1863,3,232,116,0,1859,1860,5,476,0,0,1860,1862,3,232,116,0,1861,
        1859,1,0,0,0,1862,1865,1,0,0,0,1863,1861,1,0,0,0,1863,1864,1,0,0,
        0,1864,229,1,0,0,0,1865,1863,1,0,0,0,1866,1867,5,411,0,0,1867,1868,
        5,223,0,0,1868,1873,3,232,116,0,1869,1870,5,476,0,0,1870,1872,3,
        232,116,0,1871,1869,1,0,0,0,1872,1875,1,0,0,0,1873,1871,1,0,0,0,
        1873,1874,1,0,0,0,1874,231,1,0,0,0,1875,1873,1,0,0,0,1876,1878,3,
        326,163,0,1877,1879,7,0,0,0,1878,1877,1,0,0,0,1878,1879,1,0,0,0,
        1879,1882,1,0,0,0,1880,1881,5,100,0,0,1881,1883,7,3,0,0,1882,1880,
        1,0,0,0,1882,1883,1,0,0,0,1883,233,1,0,0,0,1884,1887,5,333,0,0,1885,
        1888,5,202,0,0,1886,1888,3,326,163,0,1887,1885,1,0,0,0,1887,1886,
        1,0,0,0,1888,235,1,0,0,0,1889,1892,5,357,0,0,1890,1893,5,495,0,0,
        1891,1893,3,326,163,0,1892,1890,1,0,0,0,1892,1891,1,0,0,0,1893,237,
        1,0,0,0,1894,1895,5,368,0,0,1895,1896,5,223,0,0,1896,1901,3,326,
        163,0,1897,1898,5,476,0,0,1898,1900,3,326,163,0,1899,1897,1,0,0,
        0,1900,1903,1,0,0,0,1901,1899,1,0,0,0,1901,1902,1,0,0,0,1902,239,
        1,0,0,0,1903,1901,1,0,0,0,1904,1921,5,484,0,0,1905,1921,5,487,0,
        0,1906,1921,5,492,0,0,1907,1908,5,474,0,0,1908,1909,5,495,0,0,1909,
        1910,5,476,0,0,1910,1911,5,495,0,0,1911,1921,5,475,0,0,1912,1913,
        5,474,0,0,1913,1914,5,495,0,0,1914,1915,5,476,0,0,1915,1921,5,475,
        0,0,1916,1917,5,474,0,0,1917,1918,5,476,0,0,1918,1919,5,495,0,0,
        1919,1921,5,475,0,0,1920,1904,1,0,0,0,1920,1905,1,0,0,0,1920,1906,
        1,0,0,0,1920,1907,1,0,0,0,1920,1912,1,0,0,0,1920,1916,1,0,0,0,1921,
        241,1,0,0,0,1922,1923,5,338,0,0,1923,1928,3,114,57,0,1924,1925,5,
        476,0,0,1925,1927,3,114,57,0,1926,1924,1,0,0,0,1927,1930,1,0,0,0,
        1928,1926,1,0,0,0,1928,1929,1,0,0,0,1929,243,1,0,0,0,1930,1928,1,
        0,0,0,1931,1932,5,369,0,0,1932,1934,5,472,0,0,1933,1935,3,246,123,
        0,1934,1933,1,0,0,0,1935,1936,1,0,0,0,1936,1934,1,0,0,0,1936,1937,
        1,0,0,0,1937,1938,1,0,0,0,1938,1940,5,473,0,0,1939,1941,3,258,129,
        0,1940,1939,1,0,0,0,1940,1941,1,0,0,0,1941,245,1,0,0,0,1942,1944,
        3,394,197,0,1943,1945,3,240,120,0,1944,1943,1,0,0,0,1944,1945,1,
        0,0,0,1945,247,1,0,0,0,1946,1947,5,202,0,0,1947,1948,5,396,0,0,1948,
        1949,5,370,0,0,1949,1955,5,336,0,0,1950,1951,5,359,0,0,1951,1952,
        5,395,0,0,1952,1953,5,370,0,0,1953,1955,5,336,0,0,1954,1946,1,0,
        0,0,1954,1950,1,0,0,0,1955,249,1,0,0,0,1956,1957,5,6,0,0,1957,1958,
        5,336,0,0,1958,1959,5,403,0,0,1959,1960,5,111,0,0,1960,1961,5,82,
        0,0,1961,1981,5,395,0,0,1962,1963,5,6,0,0,1963,1964,5,336,0,0,1964,
        1965,5,403,0,0,1965,1966,5,429,0,0,1966,1967,5,348,0,0,1967,1981,
        5,395,0,0,1968,1969,5,6,0,0,1969,1970,5,336,0,0,1970,1971,5,403,
        0,0,1971,1972,5,429,0,0,1972,1973,5,82,0,0,1973,1981,3,394,197,0,
        1974,1975,5,6,0,0,1975,1976,5,336,0,0,1976,1977,5,403,0,0,1977,1978,
        5,429,0,0,1978,1979,5,52,0,0,1979,1981,3,394,197,0,1980,1956,1,0,
        0,0,1980,1962,1,0,0,0,1980,1968,1,0,0,0,1980,1974,1,0,0,0,1981,251,
        1,0,0,0,1982,1983,5,263,0,0,1983,1988,3,114,57,0,1984,1985,5,476,
        0,0,1985,1987,3,114,57,0,1986,1984,1,0,0,0,1987,1990,1,0,0,0,1988,
        1986,1,0,0,0,1988,1989,1,0,0,0,1989,253,1,0,0,0,1990,1988,1,0,0,
        0,1991,1992,5,383,0,0,1992,1993,5,214,0,0,1993,1994,3,362,181,0,
        1994,1995,3,256,128,0,1995,2001,1,0,0,0,1996,1997,5,396,0,0,1997,
        1998,5,214,0,0,1998,1999,5,495,0,0,1999,2001,3,256,128,0,2000,1991,
        1,0,0,0,2000,1996,1,0,0,0,2001,255,1,0,0,0,2002,2003,5,115,0,0,2003,
        2004,5,205,0,0,2004,2005,5,252,0,0,2005,2006,5,395,0,0,2006,257,
        1,0,0,0,2007,2008,5,450,0,0,2008,2009,3,362,181,0,2009,259,1,0,0,
        0,2010,2011,5,375,0,0,2011,2012,5,292,0,0,2012,2013,5,416,0,0,2013,
        261,1,0,0,0,2014,2015,5,108,0,0,2015,2016,5,223,0,0,2016,2017,3,
        264,132,0,2017,263,1,0,0,0,2018,2019,5,472,0,0,2019,2021,3,266,133,
        0,2020,2022,3,348,174,0,2021,2020,1,0,0,0,2021,2022,1,0,0,0,2022,
        2030,1,0,0,0,2023,2024,5,476,0,0,2024,2026,3,266,133,0,2025,2027,
        3,348,174,0,2026,2025,1,0,0,0,2026,2027,1,0,0,0,2027,2029,1,0,0,
        0,2028,2023,1,0,0,0,2029,2032,1,0,0,0,2030,2028,1,0,0,0,2030,2031,
        1,0,0,0,2031,2033,1,0,0,0,2032,2030,1,0,0,0,2033,2034,5,473,0,0,
        2034,265,1,0,0,0,2035,2049,3,360,180,0,2036,2037,3,388,194,0,2037,
        2038,5,472,0,0,2038,2043,3,268,134,0,2039,2040,5,476,0,0,2040,2042,
        3,268,134,0,2041,2039,1,0,0,0,2042,2045,1,0,0,0,2043,2041,1,0,0,
        0,2043,2044,1,0,0,0,2044,2046,1,0,0,0,2045,2043,1,0,0,0,2046,2047,
        5,473,0,0,2047,2049,1,0,0,0,2048,2035,1,0,0,0,2048,2036,1,0,0,0,
        2049,267,1,0,0,0,2050,2053,3,360,180,0,2051,2053,3,430,215,0,2052,
        2050,1,0,0,0,2052,2051,1,0,0,0,2053,269,1,0,0,0,2054,2055,5,331,
        0,0,2055,2064,3,406,203,0,2056,2060,5,472,0,0,2057,2059,3,276,138,
        0,2058,2057,1,0,0,0,2059,2062,1,0,0,0,2060,2058,1,0,0,0,2060,2061,
        1,0,0,0,2061,2063,1,0,0,0,2062,2060,1,0,0,0,2063,2065,5,473,0,0,
        2064,2056,1,0,0,0,2064,2065,1,0,0,0,2065,271,1,0,0,0,2066,2075,5,
        270,0,0,2067,2069,5,223,0,0,2068,2070,5,302,0,0,2069,2068,1,0,0,
        0,2069,2070,1,0,0,0,2070,2071,1,0,0,0,2071,2072,5,472,0,0,2072,2073,
        3,388,194,0,2073,2074,5,473,0,0,2074,2076,1,0,0,0,2075,2067,1,0,
        0,0,2075,2076,1,0,0,0,2076,2078,1,0,0,0,2077,2079,3,38,19,0,2078,
        2077,1,0,0,0,2078,2079,1,0,0,0,2079,273,1,0,0,0,2080,2081,5,441,
        0,0,2081,2082,5,497,0,0,2082,275,1,0,0,0,2083,2084,7,19,0,0,2084,
        2088,7,20,0,0,2085,2086,7,21,0,0,2086,2088,7,22,0,0,2087,2083,1,
        0,0,0,2087,2085,1,0,0,0,2088,277,1,0,0,0,2089,2093,3,282,141,0,2090,
        2093,3,314,157,0,2091,2093,3,318,159,0,2092,2089,1,0,0,0,2092,2090,
        1,0,0,0,2092,2091,1,0,0,0,2093,279,1,0,0,0,2094,2095,5,472,0,0,2095,
        2100,3,282,141,0,2096,2097,5,476,0,0,2097,2099,3,282,141,0,2098,
        2096,1,0,0,0,2099,2102,1,0,0,0,2100,2098,1,0,0,0,2100,2101,1,0,0,
        0,2101,2103,1,0,0,0,2102,2100,1,0,0,0,2103,2104,5,473,0,0,2104,281,
        1,0,0,0,2105,2106,3,320,160,0,2106,2108,3,324,162,0,2107,2109,3,
        310,155,0,2108,2107,1,0,0,0,2108,2109,1,0,0,0,2109,2111,1,0,0,0,
        2110,2112,3,312,156,0,2111,2110,1,0,0,0,2111,2112,1,0,0,0,2112,283,
        1,0,0,0,2113,2114,3,326,163,0,2114,285,1,0,0,0,2115,2116,5,193,0,
        0,2116,2117,5,292,0,0,2117,2118,3,326,163,0,2118,2119,5,209,0,0,
        2119,2120,3,326,163,0,2120,2131,1,0,0,0,2121,2122,5,193,0,0,2122,
        2125,5,292,0,0,2123,2126,3,410,205,0,2124,2126,3,326,163,0,2125,
        2123,1,0,0,0,2125,2124,1,0,0,0,2126,2127,1,0,0,0,2127,2128,5,209,
        0,0,2128,2129,3,410,205,0,2129,2131,1,0,0,0,2130,2115,1,0,0,0,2130,
        2121,1,0,0,0,2131,287,1,0,0,0,2132,2133,5,243,0,0,2133,2135,3,290,
        145,0,2134,2132,1,0,0,0,2134,2135,1,0,0,0,2135,2136,1,0,0,0,2136,
        2137,5,381,0,0,2137,2138,5,77,0,0,2138,2139,3,322,161,0,2139,2140,
        5,351,0,0,2140,2141,5,39,0,0,2141,289,1,0,0,0,2142,2143,3,388,194,
        0,2143,291,1,0,0,0,2144,2145,5,443,0,0,2145,2150,3,294,147,0,2146,
        2147,5,476,0,0,2147,2149,3,294,147,0,2148,2146,1,0,0,0,2149,2152,
        1,0,0,0,2150,2148,1,0,0,0,2150,2151,1,0,0,0,2151,293,1,0,0,0,2152,
        2150,1,0,0,0,2153,2154,5,472,0,0,2154,2159,3,430,215,0,2155,2156,
        5,476,0,0,2156,2158,3,430,215,0,2157,2155,1,0,0,0,2158,2161,1,0,
        0,0,2159,2157,1,0,0,0,2159,2160,1,0,0,0,2160,2162,1,0,0,0,2161,2159,
        1,0,0,0,2162,2163,5,473,0,0,2163,295,1,0,0,0,2164,2165,5,472,0,0,
        2165,2166,3,436,218,0,2166,2167,5,473,0,0,2167,297,1,0,0,0,2168,
        2169,5,472,0,0,2169,2172,3,436,218,0,2170,2171,5,476,0,0,2171,2173,
        3,436,218,0,2172,2170,1,0,0,0,2172,2173,1,0,0,0,2173,2174,1,0,0,
        0,2174,2175,5,473,0,0,2175,299,1,0,0,0,2176,2177,5,472,0,0,2177,
        2180,3,434,217,0,2178,2179,5,476,0,0,2179,2181,3,434,217,0,2180,
        2178,1,0,0,0,2180,2181,1,0,0,0,2181,2182,1,0,0,0,2182,2183,5,473,
        0,0,2183,301,1,0,0,0,2184,2185,5,467,0,0,2185,2190,3,324,162,0,2186,
        2187,5,476,0,0,2187,2189,3,324,162,0,2188,2186,1,0,0,0,2189,2192,
        1,0,0,0,2190,2188,1,0,0,0,2190,2191,1,0,0,0,2191,2193,1,0,0,0,2192,
        2190,1,0,0,0,2193,2194,5,466,0,0,2194,303,1,0,0,0,2195,2196,5,467,
        0,0,2196,2197,3,324,162,0,2197,2198,5,476,0,0,2198,2199,3,324,162,
        0,2199,2200,1,0,0,0,2200,2201,5,466,0,0,2201,305,1,0,0,0,2202,2203,
        5,467,0,0,2203,2204,3,320,160,0,2204,2211,3,324,162,0,2205,2206,
        5,476,0,0,2206,2207,3,320,160,0,2207,2208,3,324,162,0,2208,2210,
        1,0,0,0,2209,2205,1,0,0,0,2210,2213,1,0,0,0,2211,2209,1,0,0,0,2211,
        2212,1,0,0,0,2212,2214,1,0,0,0,2213,2211,1,0,0,0,2214,2215,5,466,
        0,0,2215,307,1,0,0,0,2216,2217,5,467,0,0,2217,2218,3,320,160,0,2218,
        2219,5,483,0,0,2219,2227,3,324,162,0,2220,2221,5,476,0,0,2221,2222,
        3,320,160,0,2222,2223,5,483,0,0,2223,2224,3,324,162,0,2224,2226,
        1,0,0,0,2225,2220,1,0,0,0,2226,2229,1,0,0,0,2227,2225,1,0,0,0,2227,
        2228,1,0,0,0,2228,2230,1,0,0,0,2229,2227,1,0,0,0,2230,2231,5,466,
        0,0,2231,309,1,0,0,0,2232,2233,5,243,0,0,2233,2235,3,290,145,0,2234,
        2232,1,0,0,0,2234,2235,1,0,0,0,2235,2236,1,0,0,0,2236,2237,5,381,
        0,0,2237,2240,5,77,0,0,2238,2239,5,351,0,0,2239,2241,5,39,0,0,2240,
        2238,1,0,0,0,2240,2241,1,0,0,0,2241,2247,1,0,0,0,2242,2244,5,351,
        0,0,2243,2242,1,0,0,0,2243,2244,1,0,0,0,2244,2245,1,0,0,0,2245,2247,
        5,354,0,0,2246,2234,1,0,0,0,2246,2243,1,0,0,0,2247,311,1,0,0,0,2248,
        2249,5,21,0,0,2249,2250,3,424,212,0,2250,313,1,0,0,0,2251,2252,3,
        320,160,0,2252,2253,3,324,162,0,2253,2256,5,340,0,0,2254,2255,5,
        293,0,0,2255,2257,3,316,158,0,2256,2254,1,0,0,0,2256,2257,1,0,0,
        0,2257,2259,1,0,0,0,2258,2260,5,192,0,0,2259,2258,1,0,0,0,2259,2260,
        1,0,0,0,2260,315,1,0,0,0,2261,2262,5,494,0,0,2262,317,1,0,0,0,2263,
        2264,3,320,160,0,2264,2265,5,209,0,0,2265,2267,3,284,142,0,2266,
        2268,3,312,156,0,2267,2266,1,0,0,0,2267,2268,1,0,0,0,2268,319,1,
        0,0,0,2269,2272,3,410,205,0,2270,2272,3,326,163,0,2271,2269,1,0,
        0,0,2271,2270,1,0,0,0,2272,321,1,0,0,0,2273,2274,5,472,0,0,2274,
        2276,3,320,160,0,2275,2277,3,312,156,0,2276,2275,1,0,0,0,2276,2277,
        1,0,0,0,2277,2285,1,0,0,0,2278,2279,5,476,0,0,2279,2281,3,320,160,
        0,2280,2282,3,312,156,0,2281,2280,1,0,0,0,2281,2282,1,0,0,0,2282,
        2284,1,0,0,0,2283,2278,1,0,0,0,2284,2287,1,0,0,0,2285,2283,1,0,0,
        0,2285,2286,1,0,0,0,2286,2288,1,0,0,0,2287,2285,1,0,0,0,2288,2289,
        5,473,0,0,2289,323,1,0,0,0,2290,2366,7,23,0,0,2291,2293,7,24,0,0,
        2292,2294,3,296,148,0,2293,2292,1,0,0,0,2293,2294,1,0,0,0,2294,2366,
        1,0,0,0,2295,2297,5,424,0,0,2296,2298,3,296,148,0,2297,2296,1,0,
        0,0,2297,2298,1,0,0,0,2298,2305,1,0,0,0,2299,2301,7,25,0,0,2300,
        2302,5,334,0,0,2301,2300,1,0,0,0,2301,2302,1,0,0,0,2302,2303,1,0,
        0,0,2303,2304,5,423,0,0,2304,2306,5,200,0,0,2305,2299,1,0,0,0,2305,
        2306,1,0,0,0,2306,2366,1,0,0,0,2307,2309,5,425,0,0,2308,2310,3,296,
        148,0,2309,2308,1,0,0,0,2309,2310,1,0,0,0,2310,2317,1,0,0,0,2311,
        2313,7,25,0,0,2312,2314,5,334,0,0,2313,2312,1,0,0,0,2313,2314,1,
        0,0,0,2314,2315,1,0,0,0,2315,2316,5,423,0,0,2316,2318,5,200,0,0,
        2317,2311,1,0,0,0,2317,2318,1,0,0,0,2318,2366,1,0,0,0,2319,2321,
        5,426,0,0,2320,2322,3,296,148,0,2321,2320,1,0,0,0,2321,2322,1,0,
        0,0,2322,2329,1,0,0,0,2323,2325,7,25,0,0,2324,2326,5,334,0,0,2325,
        2324,1,0,0,0,2325,2326,1,0,0,0,2326,2327,1,0,0,0,2327,2328,5,423,
        0,0,2328,2330,5,200,0,0,2329,2323,1,0,0,0,2329,2330,1,0,0,0,2330,
        2366,1,0,0,0,2331,2333,5,427,0,0,2332,2334,3,296,148,0,2333,2332,
        1,0,0,0,2333,2334,1,0,0,0,2334,2341,1,0,0,0,2335,2337,7,25,0,0,2336,
        2338,5,334,0,0,2337,2336,1,0,0,0,2337,2338,1,0,0,0,2338,2339,1,0,
        0,0,2339,2340,5,423,0,0,2340,2342,5,200,0,0,2341,2335,1,0,0,0,2341,
        2342,1,0,0,0,2342,2366,1,0,0,0,2343,2345,7,26,0,0,2344,2346,3,298,
        149,0,2345,2344,1,0,0,0,2345,2346,1,0,0,0,2346,2366,1,0,0,0,2347,
        2349,7,27,0,0,2348,2350,3,302,151,0,2349,2348,1,0,0,0,2349,2350,
        1,0,0,0,2350,2366,1,0,0,0,2351,2353,5,89,0,0,2352,2354,3,304,152,
        0,2353,2352,1,0,0,0,2353,2354,1,0,0,0,2354,2366,1,0,0,0,2355,2357,
        5,395,0,0,2356,2358,3,306,153,0,2357,2356,1,0,0,0,2357,2358,1,0,
        0,0,2358,2366,1,0,0,0,2359,2360,5,410,0,0,2360,2366,3,308,154,0,
        2361,2363,5,129,0,0,2362,2364,3,300,150,0,2363,2362,1,0,0,0,2363,
        2364,1,0,0,0,2364,2366,1,0,0,0,2365,2290,1,0,0,0,2365,2291,1,0,0,
        0,2365,2295,1,0,0,0,2365,2307,1,0,0,0,2365,2319,1,0,0,0,2365,2331,
        1,0,0,0,2365,2343,1,0,0,0,2365,2347,1,0,0,0,2365,2351,1,0,0,0,2365,
        2355,1,0,0,0,2365,2359,1,0,0,0,2365,2361,1,0,0,0,2366,325,1,0,0,
        0,2367,2368,3,328,164,0,2368,327,1,0,0,0,2369,2370,6,164,-1,0,2370,
        2371,5,351,0,0,2371,2382,3,328,164,6,2372,2373,5,282,0,0,2373,2374,
        5,472,0,0,2374,2375,3,98,49,0,2375,2376,5,473,0,0,2376,2382,1,0,
        0,0,2377,2379,3,334,167,0,2378,2380,3,330,165,0,2379,2378,1,0,0,
        0,2379,2380,1,0,0,0,2380,2382,1,0,0,0,2381,2369,1,0,0,0,2381,2372,
        1,0,0,0,2381,2377,1,0,0,0,2382,2397,1,0,0,0,2383,2384,10,3,0,0,2384,
        2385,5,205,0,0,2385,2396,3,328,164,4,2386,2387,10,2,0,0,2387,2388,
        5,360,0,0,2388,2396,3,328,164,3,2389,2390,10,1,0,0,2390,2392,5,321,
        0,0,2391,2393,5,351,0,0,2392,2391,1,0,0,0,2392,2393,1,0,0,0,2393,
        2394,1,0,0,0,2394,2396,7,28,0,0,2395,2383,1,0,0,0,2395,2386,1,0,
        0,0,2395,2389,1,0,0,0,2396,2399,1,0,0,0,2397,2395,1,0,0,0,2397,2398,
        1,0,0,0,2398,329,1,0,0,0,2399,2397,1,0,0,0,2400,2402,5,351,0,0,2401,
        2400,1,0,0,0,2401,2402,1,0,0,0,2402,2403,1,0,0,0,2403,2405,5,214,
        0,0,2404,2406,7,29,0,0,2405,2404,1,0,0,0,2405,2406,1,0,0,0,2406,
        2407,1,0,0,0,2407,2408,3,334,167,0,2408,2409,5,205,0,0,2409,2410,
        3,334,167,0,2410,2468,1,0,0,0,2411,2413,5,351,0,0,2412,2411,1,0,
        0,0,2412,2413,1,0,0,0,2413,2414,1,0,0,0,2414,2415,5,306,0,0,2415,
        2416,5,472,0,0,2416,2421,3,326,163,0,2417,2418,5,476,0,0,2418,2420,
        3,326,163,0,2419,2417,1,0,0,0,2420,2423,1,0,0,0,2421,2419,1,0,0,
        0,2421,2422,1,0,0,0,2422,2424,1,0,0,0,2423,2421,1,0,0,0,2424,2425,
        5,473,0,0,2425,2468,1,0,0,0,2426,2428,5,351,0,0,2427,2426,1,0,0,
        0,2427,2428,1,0,0,0,2428,2429,1,0,0,0,2429,2430,5,306,0,0,2430,2431,
        5,472,0,0,2431,2432,3,98,49,0,2432,2433,5,473,0,0,2433,2468,1,0,
        0,0,2434,2435,5,282,0,0,2435,2436,5,472,0,0,2436,2437,3,98,49,0,
        2437,2438,5,473,0,0,2438,2468,1,0,0,0,2439,2441,5,351,0,0,2440,2439,
        1,0,0,0,2440,2441,1,0,0,0,2441,2442,1,0,0,0,2442,2443,5,392,0,0,
        2443,2468,3,334,167,0,2444,2468,3,332,166,0,2445,2447,5,321,0,0,
        2446,2448,5,351,0,0,2447,2446,1,0,0,0,2447,2448,1,0,0,0,2448,2449,
        1,0,0,0,2449,2468,7,28,0,0,2450,2452,5,321,0,0,2451,2453,5,351,0,
        0,2452,2451,1,0,0,0,2452,2453,1,0,0,0,2453,2454,1,0,0,0,2454,2455,
        5,268,0,0,2455,2456,5,293,0,0,2456,2468,3,334,167,0,2457,2459,5,
        351,0,0,2458,2457,1,0,0,0,2458,2459,1,0,0,0,2459,2460,1,0,0,0,2460,
        2461,5,402,0,0,2461,2462,5,429,0,0,2462,2465,3,334,167,0,2463,2464,
        5,278,0,0,2464,2466,3,434,217,0,2465,2463,1,0,0,0,2465,2466,1,0,
        0,0,2466,2468,1,0,0,0,2467,2401,1,0,0,0,2467,2412,1,0,0,0,2467,2427,
        1,0,0,0,2467,2434,1,0,0,0,2467,2440,1,0,0,0,2467,2444,1,0,0,0,2467,
        2445,1,0,0,0,2467,2450,1,0,0,0,2467,2458,1,0,0,0,2468,331,1,0,0,
        0,2469,2471,5,351,0,0,2470,2469,1,0,0,0,2470,2471,1,0,0,0,2471,2472,
        1,0,0,0,2472,2473,5,331,0,0,2473,2487,7,30,0,0,2474,2475,5,472,0,
        0,2475,2488,5,473,0,0,2476,2477,5,472,0,0,2477,2482,3,326,163,0,
        2478,2479,5,476,0,0,2479,2481,3,326,163,0,2480,2478,1,0,0,0,2481,
        2484,1,0,0,0,2482,2480,1,0,0,0,2482,2483,1,0,0,0,2483,2485,1,0,0,
        0,2484,2482,1,0,0,0,2485,2486,5,473,0,0,2486,2488,1,0,0,0,2487,2474,
        1,0,0,0,2487,2476,1,0,0,0,2488,2508,1,0,0,0,2489,2491,5,351,0,0,
        2490,2489,1,0,0,0,2490,2491,1,0,0,0,2491,2492,1,0,0,0,2492,2493,
        7,31,0,0,2493,2496,3,334,167,0,2494,2495,5,278,0,0,2495,2497,3,434,
        217,0,2496,2494,1,0,0,0,2496,2497,1,0,0,0,2497,2508,1,0,0,0,2498,
        2500,5,351,0,0,2499,2498,1,0,0,0,2499,2500,1,0,0,0,2500,2501,1,0,
        0,0,2501,2502,7,32,0,0,2502,2505,3,434,217,0,2503,2504,5,278,0,0,
        2504,2506,3,434,217,0,2505,2503,1,0,0,0,2505,2506,1,0,0,0,2506,2508,
        1,0,0,0,2507,2470,1,0,0,0,2507,2490,1,0,0,0,2507,2499,1,0,0,0,2508,
        333,1,0,0,0,2509,2510,6,167,-1,0,2510,2514,3,336,168,0,2511,2512,
        7,33,0,0,2512,2514,3,334,167,7,2513,2509,1,0,0,0,2513,2511,1,0,0,
        0,2514,2536,1,0,0,0,2515,2516,10,6,0,0,2516,2517,7,34,0,0,2517,2535,
        3,334,167,7,2518,2519,10,5,0,0,2519,2520,7,35,0,0,2520,2535,3,334,
        167,6,2521,2522,10,4,0,0,2522,2523,5,463,0,0,2523,2535,3,334,167,
        5,2524,2525,10,3,0,0,2525,2526,5,464,0,0,2526,2535,3,334,167,4,2527,
        2528,10,2,0,0,2528,2529,5,462,0,0,2529,2535,3,334,167,3,2530,2531,
        10,1,0,0,2531,2532,3,428,214,0,2532,2533,3,334,167,2,2533,2535,1,
        0,0,0,2534,2515,1,0,0,0,2534,2518,1,0,0,0,2534,2521,1,0,0,0,2534,
        2524,1,0,0,0,2534,2527,1,0,0,0,2534,2530,1,0,0,0,2535,2538,1,0,0,
        0,2536,2534,1,0,0,0,2536,2537,1,0,0,0,2537,335,1,0,0,0,2538,2536,
        1,0,0,0,2539,2540,6,168,-1,0,2540,2542,5,227,0,0,2541,2543,3,396,
        198,0,2542,2541,1,0,0,0,2543,2544,1,0,0,0,2544,2542,1,0,0,0,2544,
        2545,1,0,0,0,2545,2548,1,0,0,0,2546,2547,5,275,0,0,2547,2549,3,326,
        163,0,2548,2546,1,0,0,0,2548,2549,1,0,0,0,2549,2550,1,0,0,0,2550,
        2551,5,276,0,0,2551,2672,1,0,0,0,2552,2553,5,227,0,0,2553,2555,3,
        326,163,0,2554,2556,3,396,198,0,2555,2554,1,0,0,0,2556,2557,1,0,
        0,0,2557,2555,1,0,0,0,2557,2558,1,0,0,0,2558,2561,1,0,0,0,2559,2560,
        5,275,0,0,2560,2562,3,326,163,0,2561,2559,1,0,0,0,2561,2562,1,0,
        0,0,2562,2563,1,0,0,0,2563,2564,5,276,0,0,2564,2672,1,0,0,0,2565,
        2566,5,228,0,0,2566,2567,5,472,0,0,2567,2568,3,326,163,0,2568,2569,
        5,209,0,0,2569,2570,3,324,162,0,2570,2571,5,473,0,0,2571,2672,1,
        0,0,0,2572,2573,5,52,0,0,2573,2574,5,472,0,0,2574,2577,3,326,163,
        0,2575,2576,5,67,0,0,2576,2578,5,100,0,0,2577,2575,1,0,0,0,2577,
        2578,1,0,0,0,2578,2579,1,0,0,0,2579,2580,5,473,0,0,2580,2672,1,0,
        0,0,2581,2582,5,82,0,0,2582,2583,5,472,0,0,2583,2586,3,326,163,0,
        2584,2585,5,67,0,0,2585,2587,5,100,0,0,2586,2584,1,0,0,0,2586,2587,
        1,0,0,0,2587,2588,1,0,0,0,2588,2589,5,473,0,0,2589,2672,1,0,0,0,
        2590,2591,5,377,0,0,2591,2592,5,472,0,0,2592,2593,3,334,167,0,2593,
        2594,5,306,0,0,2594,2595,3,334,167,0,2595,2596,5,473,0,0,2596,2672,
        1,0,0,0,2597,2672,3,430,215,0,2598,2672,5,484,0,0,2599,2600,3,410,
        205,0,2600,2601,5,469,0,0,2601,2602,5,484,0,0,2602,2672,1,0,0,0,
        2603,2604,5,472,0,0,2604,2605,3,98,49,0,2605,2606,5,473,0,0,2606,
        2672,1,0,0,0,2607,2608,5,472,0,0,2608,2613,3,354,177,0,2609,2610,
        5,476,0,0,2610,2612,3,354,177,0,2611,2609,1,0,0,0,2612,2615,1,0,
        0,0,2613,2611,1,0,0,0,2613,2614,1,0,0,0,2614,2616,1,0,0,0,2615,2613,
        1,0,0,0,2616,2617,5,473,0,0,2617,2672,1,0,0,0,2618,2619,3,352,176,
        0,2619,2631,5,472,0,0,2620,2622,3,440,220,0,2621,2620,1,0,0,0,2621,
        2622,1,0,0,0,2622,2623,1,0,0,0,2623,2628,3,354,177,0,2624,2625,5,
        476,0,0,2625,2627,3,354,177,0,2626,2624,1,0,0,0,2627,2630,1,0,0,
        0,2628,2626,1,0,0,0,2628,2629,1,0,0,0,2629,2632,1,0,0,0,2630,2628,
        1,0,0,0,2631,2621,1,0,0,0,2631,2632,1,0,0,0,2632,2633,1,0,0,0,2633,
        2634,5,473,0,0,2634,2672,1,0,0,0,2635,2636,3,352,176,0,2636,2637,
        5,472,0,0,2637,2638,3,354,177,0,2638,2639,5,429,0,0,2639,2640,3,
        354,177,0,2640,2641,5,473,0,0,2641,2672,1,0,0,0,2642,2643,3,352,
        176,0,2643,2645,5,472,0,0,2644,2646,3,440,220,0,2645,2644,1,0,0,
        0,2645,2646,1,0,0,0,2646,2647,1,0,0,0,2647,2648,3,354,177,0,2648,
        2650,5,473,0,0,2649,2651,3,356,178,0,2650,2649,1,0,0,0,2650,2651,
        1,0,0,0,2651,2672,1,0,0,0,2652,2653,3,150,75,0,2653,2654,3,116,58,
        0,2654,2672,1,0,0,0,2655,2656,3,150,75,0,2656,2657,5,450,0,0,2657,
        2658,5,299,0,0,2658,2659,5,472,0,0,2659,2660,3,228,114,0,2660,2662,
        5,473,0,0,2661,2663,3,116,58,0,2662,2661,1,0,0,0,2662,2663,1,0,0,
        0,2663,2672,1,0,0,0,2664,2672,3,388,194,0,2665,2672,3,410,205,0,
        2666,2667,5,472,0,0,2667,2668,3,326,163,0,2668,2669,5,473,0,0,2669,
        2672,1,0,0,0,2670,2672,3,338,169,0,2671,2539,1,0,0,0,2671,2552,1,
        0,0,0,2671,2565,1,0,0,0,2671,2572,1,0,0,0,2671,2581,1,0,0,0,2671,
        2590,1,0,0,0,2671,2597,1,0,0,0,2671,2598,1,0,0,0,2671,2599,1,0,0,
        0,2671,2603,1,0,0,0,2671,2607,1,0,0,0,2671,2618,1,0,0,0,2671,2635,
        1,0,0,0,2671,2642,1,0,0,0,2671,2652,1,0,0,0,2671,2655,1,0,0,0,2671,
        2664,1,0,0,0,2671,2665,1,0,0,0,2671,2666,1,0,0,0,2671,2670,1,0,0,
        0,2672,2680,1,0,0,0,2673,2674,10,5,0,0,2674,2675,5,470,0,0,2675,
        2676,3,334,167,0,2676,2677,5,471,0,0,2677,2679,1,0,0,0,2678,2673,
        1,0,0,0,2679,2682,1,0,0,0,2680,2678,1,0,0,0,2680,2681,1,0,0,0,2681,
        337,1,0,0,0,2682,2680,1,0,0,0,2683,2688,3,340,170,0,2684,2688,3,
        344,172,0,2685,2688,3,346,173,0,2686,2688,3,342,171,0,2687,2683,
        1,0,0,0,2687,2684,1,0,0,0,2687,2685,1,0,0,0,2687,2686,1,0,0,0,2688,
        339,1,0,0,0,2689,2690,5,208,0,0,2690,2691,5,470,0,0,2691,2696,3,
        348,174,0,2692,2693,5,476,0,0,2693,2695,3,348,174,0,2694,2692,1,
        0,0,0,2695,2698,1,0,0,0,2696,2694,1,0,0,0,2696,2697,1,0,0,0,2697,
        2699,1,0,0,0,2698,2696,1,0,0,0,2699,2700,5,471,0,0,2700,2701,5,208,
        0,0,2701,2702,5,472,0,0,2702,2707,3,348,174,0,2703,2704,5,476,0,
        0,2704,2706,3,348,174,0,2705,2703,1,0,0,0,2706,2709,1,0,0,0,2707,
        2705,1,0,0,0,2707,2708,1,0,0,0,2708,2710,1,0,0,0,2709,2707,1,0,0,
        0,2710,2711,5,473,0,0,2711,341,1,0,0,0,2712,2713,5,410,0,0,2713,
        2714,5,472,0,0,2714,2719,3,348,174,0,2715,2716,5,476,0,0,2716,2718,
        3,348,174,0,2717,2715,1,0,0,0,2718,2721,1,0,0,0,2719,2717,1,0,0,
        0,2719,2720,1,0,0,0,2720,2722,1,0,0,0,2721,2719,1,0,0,0,2722,2723,
        5,473,0,0,2723,343,1,0,0,0,2724,2725,5,395,0,0,2725,2726,5,472,0,
        0,2726,2731,3,348,174,0,2727,2728,5,476,0,0,2728,2730,3,348,174,
        0,2729,2727,1,0,0,0,2730,2733,1,0,0,0,2731,2729,1,0,0,0,2731,2732,
        1,0,0,0,2732,2734,1,0,0,0,2733,2731,1,0,0,0,2734,2735,5,473,0,0,
        2735,345,1,0,0,0,2736,2737,5,89,0,0,2737,2738,5,470,0,0,2738,2739,
        3,348,174,0,2739,2740,5,476,0,0,2740,2741,3,348,174,0,2741,2742,
        5,471,0,0,2742,347,1,0,0,0,2743,2748,3,374,187,0,2744,2748,3,430,
        215,0,2745,2748,3,338,169,0,2746,2748,3,350,175,0,2747,2743,1,0,
        0,0,2747,2744,1,0,0,0,2747,2745,1,0,0,0,2747,2746,1,0,0,0,2748,349,
        1,0,0,0,2749,2750,7,36,0,0,2750,351,1,0,0,0,2751,2755,3,450,225,
        0,2752,2755,3,410,205,0,2753,2755,3,448,224,0,2754,2751,1,0,0,0,
        2754,2752,1,0,0,0,2754,2753,1,0,0,0,2755,353,1,0,0,0,2756,2763,3,
        446,223,0,2757,2763,3,444,222,0,2758,2763,3,442,221,0,2759,2763,
        3,326,163,0,2760,2763,3,356,178,0,2761,2763,3,430,215,0,2762,2756,
        1,0,0,0,2762,2757,1,0,0,0,2762,2758,1,0,0,0,2762,2759,1,0,0,0,2762,
        2760,1,0,0,0,2762,2761,1,0,0,0,2763,355,1,0,0,0,2764,2765,5,48,0,
        0,2765,2766,5,472,0,0,2766,2767,5,447,0,0,2767,2768,3,328,164,0,
        2768,2769,5,473,0,0,2769,357,1,0,0,0,2770,2771,3,388,194,0,2771,
        359,1,0,0,0,2772,2776,3,388,194,0,2773,2776,3,410,205,0,2774,2776,
        3,390,195,0,2775,2772,1,0,0,0,2775,2773,1,0,0,0,2775,2774,1,0,0,
        0,2776,361,1,0,0,0,2777,2780,5,315,0,0,2778,2781,3,364,182,0,2779,
        2781,3,368,184,0,2780,2778,1,0,0,0,2780,2779,1,0,0,0,2780,2781,1,
        0,0,0,2781,363,1,0,0,0,2782,2784,3,366,183,0,2783,2785,3,370,185,
        0,2784,2783,1,0,0,0,2784,2785,1,0,0,0,2785,365,1,0,0,0,2786,2787,
        3,372,186,0,2787,2788,3,444,222,0,2788,2790,1,0,0,0,2789,2786,1,
        0,0,0,2790,2791,1,0,0,0,2791,2789,1,0,0,0,2791,2792,1,0,0,0,2792,
        367,1,0,0,0,2793,2796,3,370,185,0,2794,2797,3,366,183,0,2795,2797,
        3,370,185,0,2796,2794,1,0,0,0,2796,2795,1,0,0,0,2796,2797,1,0,0,
        0,2797,369,1,0,0,0,2798,2799,3,372,186,0,2799,2800,3,444,222,0,2800,
        2801,5,429,0,0,2801,2802,3,444,222,0,2802,371,1,0,0,0,2803,2805,
        7,37,0,0,2804,2803,1,0,0,0,2804,2805,1,0,0,0,2805,2806,1,0,0,0,2806,
        2809,7,38,0,0,2807,2809,5,494,0,0,2808,2804,1,0,0,0,2808,2807,1,
        0,0,0,2809,373,1,0,0,0,2810,2811,3,378,189,0,2811,375,1,0,0,0,2812,
        2813,3,378,189,0,2813,377,1,0,0,0,2814,2816,5,209,0,0,2815,2814,
        1,0,0,0,2815,2816,1,0,0,0,2816,2817,1,0,0,0,2817,2819,3,388,194,
        0,2818,2820,3,384,192,0,2819,2818,1,0,0,0,2819,2820,1,0,0,0,2820,
        379,1,0,0,0,2821,2822,3,388,194,0,2822,2823,3,382,191,0,2823,381,
        1,0,0,0,2824,2825,5,341,0,0,2825,2827,3,388,194,0,2826,2824,1,0,
        0,0,2827,2830,1,0,0,0,2828,2826,1,0,0,0,2828,2829,1,0,0,0,2829,383,
        1,0,0,0,2830,2828,1,0,0,0,2831,2832,5,472,0,0,2832,2833,3,386,193,
        0,2833,2834,5,473,0,0,2834,385,1,0,0,0,2835,2840,3,388,194,0,2836,
        2837,5,476,0,0,2837,2839,3,388,194,0,2838,2836,1,0,0,0,2839,2842,
        1,0,0,0,2840,2838,1,0,0,0,2840,2841,1,0,0,0,2841,387,1,0,0,0,2842,
        2840,1,0,0,0,2843,2848,3,394,197,0,2844,2848,5,494,0,0,2845,2848,
        3,450,225,0,2846,2848,3,392,196,0,2847,2843,1,0,0,0,2847,2844,1,
        0,0,0,2847,2845,1,0,0,0,2847,2846,1,0,0,0,2848,389,1,0,0,0,2849,
        2854,3,394,197,0,2850,2854,3,446,223,0,2851,2854,3,450,225,0,2852,
        2854,3,448,224,0,2853,2849,1,0,0,0,2853,2850,1,0,0,0,2853,2851,1,
        0,0,0,2853,2852,1,0,0,0,2854,391,1,0,0,0,2855,2856,5,479,0,0,2856,
        2857,5,474,0,0,2857,2858,3,394,197,0,2858,2859,5,475,0,0,2859,393,
        1,0,0,0,2860,2861,7,39,0,0,2861,395,1,0,0,0,2862,2863,5,446,0,0,
        2863,2864,3,326,163,0,2864,2865,5,422,0,0,2865,2866,3,326,163,0,
        2866,397,1,0,0,0,2867,2868,3,410,205,0,2868,399,1,0,0,0,2869,2870,
        3,410,205,0,2870,401,1,0,0,0,2871,2872,3,410,205,0,2872,403,1,0,
        0,0,2873,2874,3,410,205,0,2874,405,1,0,0,0,2875,2876,3,410,205,0,
        2876,407,1,0,0,0,2877,2878,3,388,194,0,2878,409,1,0,0,0,2879,2884,
        3,388,194,0,2880,2881,5,469,0,0,2881,2883,3,388,194,0,2882,2880,
        1,0,0,0,2883,2886,1,0,0,0,2884,2882,1,0,0,0,2884,2885,1,0,0,0,2885,
        411,1,0,0,0,2886,2884,1,0,0,0,2887,2889,5,449,0,0,2888,2890,7,40,
        0,0,2889,2888,1,0,0,0,2889,2890,1,0,0,0,2890,2891,1,0,0,0,2891,2892,
        3,418,209,0,2892,413,1,0,0,0,2893,2894,5,66,0,0,2894,2895,5,351,
        0,0,2895,2896,5,282,0,0,2896,415,1,0,0,0,2897,2898,5,66,0,0,2898,
        2899,5,282,0,0,2899,417,1,0,0,0,2900,2901,5,472,0,0,2901,2906,3,
        420,210,0,2902,2903,5,476,0,0,2903,2905,3,420,210,0,2904,2902,1,
        0,0,0,2905,2908,1,0,0,0,2906,2904,1,0,0,0,2906,2907,1,0,0,0,2907,
        2909,1,0,0,0,2908,2906,1,0,0,0,2909,2910,5,473,0,0,2910,419,1,0,
        0,0,2911,2912,3,422,211,0,2912,2914,5,465,0,0,2913,2915,5,256,0,
        0,2914,2913,1,0,0,0,2914,2915,1,0,0,0,2915,2916,1,0,0,0,2916,2917,
        3,426,213,0,2917,421,1,0,0,0,2918,2923,3,388,194,0,2919,2923,3,410,
        205,0,2920,2923,3,434,217,0,2921,2923,3,354,177,0,2922,2918,1,0,
        0,0,2922,2919,1,0,0,0,2922,2920,1,0,0,0,2922,2921,1,0,0,0,2923,423,
        1,0,0,0,2924,2925,5,480,0,0,2925,2926,3,430,215,0,2926,2927,5,480,
        0,0,2927,2930,1,0,0,0,2928,2930,3,430,215,0,2929,2924,1,0,0,0,2929,
        2928,1,0,0,0,2930,425,1,0,0,0,2931,2942,5,495,0,0,2932,2942,5,496,
        0,0,2933,2942,3,438,219,0,2934,2942,3,410,205,0,2935,2942,3,430,
        215,0,2936,2942,3,392,196,0,2937,2938,5,480,0,0,2938,2939,3,392,
        196,0,2939,2940,5,480,0,0,2940,2942,1,0,0,0,2941,2931,1,0,0,0,2941,
        2932,1,0,0,0,2941,2933,1,0,0,0,2941,2934,1,0,0,0,2941,2935,1,0,0,
        0,2941,2936,1,0,0,0,2941,2937,1,0,0,0,2942,427,1,0,0,0,2943,2958,
        5,465,0,0,2944,2958,5,466,0,0,2945,2958,5,467,0,0,2946,2947,5,467,
        0,0,2947,2958,5,465,0,0,2948,2949,5,466,0,0,2949,2958,5,465,0,0,
        2950,2951,5,467,0,0,2951,2958,5,466,0,0,2952,2953,5,468,0,0,2953,
        2958,5,465,0,0,2954,2955,5,467,0,0,2955,2956,5,465,0,0,2956,2958,
        5,466,0,0,2957,2943,1,0,0,0,2957,2944,1,0,0,0,2957,2945,1,0,0,0,
        2957,2946,1,0,0,0,2957,2948,1,0,0,0,2957,2950,1,0,0,0,2957,2952,
        1,0,0,0,2957,2954,1,0,0,0,2958,429,1,0,0,0,2959,2973,3,362,181,0,
        2960,2973,3,432,216,0,2961,2973,3,434,217,0,2962,2964,5,486,0,0,
        2963,2962,1,0,0,0,2963,2964,1,0,0,0,2964,2965,1,0,0,0,2965,2973,
        3,436,218,0,2966,2973,3,438,219,0,2967,2973,5,496,0,0,2968,2970,
        5,351,0,0,2969,2968,1,0,0,0,2969,2970,1,0,0,0,2970,2971,1,0,0,0,
        2971,2973,5,354,0,0,2972,2959,1,0,0,0,2972,2960,1,0,0,0,2972,2961,
        1,0,0,0,2972,2963,1,0,0,0,2972,2966,1,0,0,0,2972,2967,1,0,0,0,2972,
        2969,1,0,0,0,2973,431,1,0,0,0,2974,2975,3,442,221,0,2975,2976,3,
        434,217,0,2976,433,1,0,0,0,2977,2978,5,494,0,0,2978,435,1,0,0,0,
        2979,2980,5,495,0,0,2980,437,1,0,0,0,2981,2982,7,41,0,0,2982,439,
        1,0,0,0,2983,2984,7,7,0,0,2984,441,1,0,0,0,2985,2986,7,42,0,0,2986,
        443,1,0,0,0,2987,2988,7,43,0,0,2988,445,1,0,0,0,2989,2990,7,44,0,
        0,2990,447,1,0,0,0,2991,2992,7,45,0,0,2992,449,1,0,0,0,2993,2994,
        7,46,0,0,2994,451,1,0,0,0,2995,2996,5,477,0,0,2996,453,1,0,0,0,352,
        459,461,466,476,484,488,492,498,504,509,526,536,543,549,558,562,
        569,585,593,603,612,622,633,638,642,660,666,670,679,684,688,694,
        696,701,703,708,710,716,720,726,736,746,754,761,770,776,782,789,
        799,809,817,825,834,839,845,854,866,872,878,890,900,910,916,921,
        925,927,931,938,942,957,971,978,982,985,995,1010,1013,1016,1019,
        1022,1024,1029,1033,1036,1039,1042,1046,1055,1062,1067,1076,1088,
        1093,1105,1108,1111,1114,1119,1122,1125,1128,1139,1143,1150,1155,
        1158,1163,1165,1175,1179,1183,1187,1191,1200,1205,1214,1217,1222,
        1226,1242,1256,1264,1270,1276,1280,1285,1288,1296,1299,1302,1307,
        1313,1316,1318,1330,1338,1342,1350,1361,1367,1371,1374,1378,1384,
        1392,1405,1414,1420,1425,1429,1438,1443,1447,1460,1463,1467,1481,
        1489,1497,1515,1519,1533,1553,1559,1564,1569,1574,1578,1584,1587,
        1593,1599,1616,1634,1639,1649,1657,1666,1672,1675,1681,1690,1700,
        1710,1720,1725,1732,1744,1756,1768,1773,1800,1808,1812,1815,1818,
        1821,1828,1831,1834,1837,1840,1843,1846,1851,1854,1863,1873,1878,
        1882,1887,1892,1901,1920,1928,1936,1940,1944,1954,1980,1988,2000,
        2021,2026,2030,2043,2048,2052,2060,2064,2069,2075,2078,2087,2092,
        2100,2108,2111,2125,2130,2134,2150,2159,2172,2180,2190,2211,2227,
        2234,2240,2243,2246,2256,2259,2267,2271,2276,2281,2285,2293,2297,
        2301,2305,2309,2313,2317,2321,2325,2329,2333,2337,2341,2345,2349,
        2353,2357,2363,2365,2379,2381,2392,2395,2397,2401,2405,2412,2421,
        2427,2440,2447,2452,2458,2465,2467,2470,2482,2487,2490,2496,2499,
        2505,2507,2513,2534,2536,2544,2548,2557,2561,2577,2586,2613,2621,
        2628,2631,2645,2650,2662,2671,2680,2687,2696,2707,2719,2731,2747,
        2754,2762,2775,2780,2784,2791,2796,2804,2808,2815,2819,2828,2840,
        2847,2853,2884,2889,2906,2914,2922,2929,2941,2957,2963,2969,2972
    ];

    private static __ATN: antlr.ATN;
    public static get _ATN(): antlr.ATN {
        if (!SparkSQLParser.__ATN) {
            SparkSQLParser.__ATN = new antlr.ATNDeserializer().deserialize(SparkSQLParser._serializedATN);
        }

        return SparkSQLParser.__ATN;
    }


    private static readonly vocabulary = new antlr.Vocabulary(SparkSQLParser.literalNames, SparkSQLParser.symbolicNames, []);

    public override get vocabulary(): antlr.Vocabulary {
        return SparkSQLParser.vocabulary;
    }

    private static readonly decisionsToDFA = SparkSQLParser._ATN.decisionToState.map( (ds: antlr.DecisionState, index: number) => new antlr.DFA(ds, index) );
}

export class StatementContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public sqlStatements(): SqlStatementsContext {
        return this.getRuleContext(0, SqlStatementsContext)!;
    }
    public EOF(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.EOF, 0)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_statement;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterStatement) {
             listener.enterStatement(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitStatement) {
             listener.exitStatement(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitStatement) {
            return visitor.visitStatement(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class SqlStatementsContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public sqlStatement(): SqlStatementContext[];
    public sqlStatement(i: number): SqlStatementContext | null;
    public sqlStatement(i?: number): SqlStatementContext[] | SqlStatementContext | null {
        if (i === undefined) {
            return this.getRuleContexts(SqlStatementContext);
        }

        return this.getRuleContext(i, SqlStatementContext);
    }
    public emptyStatement(): EmptyStatementContext[];
    public emptyStatement(i: number): EmptyStatementContext | null;
    public emptyStatement(i?: number): EmptyStatementContext[] | EmptyStatementContext | null {
        if (i === undefined) {
            return this.getRuleContexts(EmptyStatementContext);
        }

        return this.getRuleContext(i, EmptyStatementContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_sqlStatements;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterSqlStatements) {
             listener.enterSqlStatements(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitSqlStatements) {
             listener.exitSqlStatements(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitSqlStatements) {
            return visitor.visitSqlStatements(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class SqlStatementContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public SEMICOLON(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.SEMICOLON, 0)!;
    }
    public dmlStatement(): DmlStatementContext | null {
        return this.getRuleContext(0, DmlStatementContext);
    }
    public createStatement(): CreateStatementContext | null {
        return this.getRuleContext(0, CreateStatementContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_sqlStatement;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterSqlStatement) {
             listener.enterSqlStatement(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitSqlStatement) {
             listener.exitSqlStatement(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitSqlStatement) {
            return visitor.visitSqlStatement(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class EmptyStatementContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public SEMICOLON(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.SEMICOLON, 0)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_emptyStatement;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterEmptyStatement) {
             listener.enterEmptyStatement(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitEmptyStatement) {
             listener.exitEmptyStatement(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitEmptyStatement) {
            return visitor.visitEmptyStatement(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class CreateStatementContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public createTable(): CreateTableContext {
        return this.getRuleContext(0, CreateTableContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_createStatement;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterCreateStatement) {
             listener.enterCreateStatement(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitCreateStatement) {
             listener.exitCreateStatement(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitCreateStatement) {
            return visitor.visitCreateStatement(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class DmlStatementContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public queryStatement(): QueryStatementContext | null {
        return this.getRuleContext(0, QueryStatementContext);
    }
    public insertStatement(): InsertStatementContext | null {
        return this.getRuleContext(0, InsertStatementContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_dmlStatement;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterDmlStatement) {
             listener.enterDmlStatement(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitDmlStatement) {
             listener.exitDmlStatement(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitDmlStatement) {
            return visitor.visitDmlStatement(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class CreateTableContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_createTable;
    }
    public override copyFrom(ctx: CreateTableContext): void {
        super.copyFrom(ctx);
    }
}
export class Using_createContext extends CreateTableContext {
    public constructor(ctx: CreateTableContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public usingCreate(): UsingCreateContext {
        return this.getRuleContext(0, UsingCreateContext)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterUsing_create) {
             listener.enterUsing_create(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitUsing_create) {
             listener.exitUsing_create(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitUsing_create) {
            return visitor.visitUsing_create(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class MaterializedContext extends CreateTableContext {
    public constructor(ctx: CreateTableContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public createMaterializedTableAsSelect(): CreateMaterializedTableAsSelectContext {
        return this.getRuleContext(0, CreateMaterializedTableAsSelectContext)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterMaterialized) {
             listener.enterMaterialized(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitMaterialized) {
             listener.exitMaterialized(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitMaterialized) {
            return visitor.visitMaterialized(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class SimpleContext extends CreateTableContext {
    public constructor(ctx: CreateTableContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public simpleCreateTable(): SimpleCreateTableContext {
        return this.getRuleContext(0, SimpleCreateTableContext)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterSimple) {
             listener.enterSimple(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitSimple) {
             listener.exitSimple(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitSimple) {
            return visitor.visitSimple(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class AsSelectContext extends CreateTableContext {
    public constructor(ctx: CreateTableContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public createTableAsSelect(): CreateTableAsSelectContext {
        return this.getRuleContext(0, CreateTableAsSelectContext)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterAsSelect) {
             listener.enterAsSelect(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitAsSelect) {
             listener.exitAsSelect(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitAsSelect) {
            return visitor.visitAsSelect(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class CustomSerdeContext extends CreateTableContext {
    public constructor(ctx: CreateTableContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public createCustomSerde(): CreateCustomSerdeContext {
        return this.getRuleContext(0, CreateCustomSerdeContext)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterCustomSerde) {
             listener.enterCustomSerde(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitCustomSerde) {
             listener.exitCustomSerde(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitCustomSerde) {
            return visitor.visitCustomSerde(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class CustomSerdeExternalContext extends CreateTableContext {
    public constructor(ctx: CreateTableContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public createCustomSerdeExternal(): CreateCustomSerdeExternalContext {
        return this.getRuleContext(0, CreateCustomSerdeExternalContext)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterCustomSerdeExternal) {
             listener.enterCustomSerdeExternal(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitCustomSerdeExternal) {
             listener.exitCustomSerdeExternal(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitCustomSerdeExternal) {
            return visitor.visitCustomSerdeExternal(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class SimpleCreateTableContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_CREATE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_CREATE, 0)!;
    }
    public KW_TABLE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_TABLE, 0)!;
    }
    public tablePathCreate(): TablePathCreateContext {
        return this.getRuleContext(0, TablePathCreateContext)!;
    }
    public columnsBody(): ColumnsBodyContext | null {
        return this.getRuleContext(0, ColumnsBodyContext);
    }
    public KW_TEMPORARY(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TEMPORARY, 0);
    }
    public ifNotExists(): IfNotExistsContext | null {
        return this.getRuleContext(0, IfNotExistsContext);
    }
    public simpleCreateTableNoSortElement(): SimpleCreateTableNoSortElementContext[];
    public simpleCreateTableNoSortElement(i: number): SimpleCreateTableNoSortElementContext | null;
    public simpleCreateTableNoSortElement(i?: number): SimpleCreateTableNoSortElementContext[] | SimpleCreateTableNoSortElementContext | null {
        if (i === undefined) {
            return this.getRuleContexts(SimpleCreateTableNoSortElementContext);
        }

        return this.getRuleContext(i, SimpleCreateTableNoSortElementContext);
    }
    public KW_LIKE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LIKE, 0);
    }
    public tablePath(): TablePathContext | null {
        return this.getRuleContext(0, TablePathContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_simpleCreateTable;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterSimpleCreateTable) {
             listener.enterSimpleCreateTable(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitSimpleCreateTable) {
             listener.exitSimpleCreateTable(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitSimpleCreateTable) {
            return visitor.visitSimpleCreateTable(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class SimpleCreateTableNoSortElementContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public partitionDefinition(): PartitionDefinitionContext | null {
        return this.getRuleContext(0, PartitionDefinitionContext);
    }
    public withOption(): WithOptionContext | null {
        return this.getRuleContext(0, WithOptionContext);
    }
    public likeDefinition(): LikeDefinitionContext | null {
        return this.getRuleContext(0, LikeDefinitionContext);
    }
    public distribution(): DistributionContext | null {
        return this.getRuleContext(0, DistributionContext);
    }
    public someByClause(): SomeByClauseContext | null {
        return this.getRuleContext(0, SomeByClauseContext);
    }
    public intoBuckets(): IntoBucketsContext | null {
        return this.getRuleContext(0, IntoBucketsContext);
    }
    public storedAs(): StoredAsContext | null {
        return this.getRuleContext(0, StoredAsContext);
    }
    public hiveFormatpartitionDefinition(): HiveFormatpartitionDefinitionContext | null {
        return this.getRuleContext(0, HiveFormatpartitionDefinitionContext);
    }
    public sortedBy(): SortedByContext | null {
        return this.getRuleContext(0, SortedByContext);
    }
    public rowFormatDelimited(): RowFormatDelimitedContext | null {
        return this.getRuleContext(0, RowFormatDelimitedContext);
    }
    public fieldsTerminatedBy(): FieldsTerminatedByContext | null {
        return this.getRuleContext(0, FieldsTerminatedByContext);
    }
    public using(): UsingContext | null {
        return this.getRuleContext(0, UsingContext);
    }
    public location(): LocationContext | null {
        return this.getRuleContext(0, LocationContext);
    }
    public tblProperties(): TblPropertiesContext | null {
        return this.getRuleContext(0, TblPropertiesContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_simpleCreateTableNoSortElement;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterSimpleCreateTableNoSortElement) {
             listener.enterSimpleCreateTableNoSortElement(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitSimpleCreateTableNoSortElement) {
             listener.exitSimpleCreateTableNoSortElement(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitSimpleCreateTableNoSortElement) {
            return visitor.visitSimpleCreateTableNoSortElement(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class LocationContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_LOCATION(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_LOCATION, 0)!;
    }
    public filePath(): FilePathContext {
        return this.getRuleContext(0, FilePathContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_location;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterLocation) {
             listener.enterLocation(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitLocation) {
             listener.exitLocation(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitLocation) {
            return visitor.visitLocation(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class SortedByContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_SORTED(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_SORTED, 0)!;
    }
    public KW_BY(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_BY, 0)!;
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public identifier(): IdentifierContext {
        return this.getRuleContext(0, IdentifierContext)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public KW_ASC(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ASC, 0);
    }
    public KW_DESC(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DESC, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_sortedBy;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterSortedBy) {
             listener.enterSortedBy(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitSortedBy) {
             listener.exitSortedBy(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitSortedBy) {
            return visitor.visitSortedBy(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class UsingCreateContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_CREATE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_CREATE, 0)!;
    }
    public KW_TABLE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_TABLE, 0)!;
    }
    public tablePathCreate(): TablePathCreateContext {
        return this.getRuleContext(0, TablePathCreateContext)!;
    }
    public columnUsing(): ColumnUsingContext | null {
        return this.getRuleContext(0, ColumnUsingContext);
    }
    public usingByQuery(): UsingByQueryContext | null {
        return this.getRuleContext(0, UsingByQueryContext);
    }
    public defaultColumnUsing(): DefaultColumnUsingContext | null {
        return this.getRuleContext(0, DefaultColumnUsingContext);
    }
    public ifNotExists(): IfNotExistsContext | null {
        return this.getRuleContext(0, IfNotExistsContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_usingCreate;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterUsingCreate) {
             listener.enterUsingCreate(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitUsingCreate) {
             listener.exitUsingCreate(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitUsingCreate) {
            return visitor.visitUsingCreate(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class TblPropertiesContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_TBLPROPERTIES(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_TBLPROPERTIES, 0)!;
    }
    public tablePropertyList(): TablePropertyListContext {
        return this.getRuleContext(0, TablePropertyListContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_tblProperties;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterTblProperties) {
             listener.enterTblProperties(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitTblProperties) {
             listener.exitTblProperties(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitTblProperties) {
            return visitor.visitTblProperties(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class DefaultColumnUsingContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public using(): UsingContext {
        return this.getRuleContext(0, UsingContext)!;
    }
    public queryStatement(): QueryStatementContext | null {
        return this.getRuleContext(0, QueryStatementContext);
    }
    public defaultColumnUsingNoSortElement(): DefaultColumnUsingNoSortElementContext[];
    public defaultColumnUsingNoSortElement(i: number): DefaultColumnUsingNoSortElementContext | null;
    public defaultColumnUsingNoSortElement(i?: number): DefaultColumnUsingNoSortElementContext[] | DefaultColumnUsingNoSortElementContext | null {
        if (i === undefined) {
            return this.getRuleContexts(DefaultColumnUsingNoSortElementContext);
        }

        return this.getRuleContext(i, DefaultColumnUsingNoSortElementContext);
    }
    public KW_AS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_AS, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_defaultColumnUsing;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterDefaultColumnUsing) {
             listener.enterDefaultColumnUsing(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitDefaultColumnUsing) {
             listener.exitDefaultColumnUsing(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitDefaultColumnUsing) {
            return visitor.visitDefaultColumnUsing(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class DefaultColumnUsingNoSortElementContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public partitionDefinition(): PartitionDefinitionContext | null {
        return this.getRuleContext(0, PartitionDefinitionContext);
    }
    public KW_OPTIONS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_OPTIONS, 0);
    }
    public tablePropertyList(): TablePropertyListContext | null {
        return this.getRuleContext(0, TablePropertyListContext);
    }
    public tblProperties(): TblPropertiesContext | null {
        return this.getRuleContext(0, TblPropertiesContext);
    }
    public someByClause(): SomeByClauseContext | null {
        return this.getRuleContext(0, SomeByClauseContext);
    }
    public intoBuckets(): IntoBucketsContext | null {
        return this.getRuleContext(0, IntoBucketsContext);
    }
    public KW_WITH(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_WITH, 0);
    }
    public tableAlias(): TableAliasContext | null {
        return this.getRuleContext(0, TableAliasContext);
    }
    public LB_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.LB_BRACKET, 0);
    }
    public queryStatement(): QueryStatementContext | null {
        return this.getRuleContext(0, QueryStatementContext);
    }
    public RR_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0);
    }
    public commentSpec(): CommentSpecContext | null {
        return this.getRuleContext(0, CommentSpecContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_defaultColumnUsingNoSortElement;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterDefaultColumnUsingNoSortElement) {
             listener.enterDefaultColumnUsingNoSortElement(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitDefaultColumnUsingNoSortElement) {
             listener.exitDefaultColumnUsingNoSortElement(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitDefaultColumnUsingNoSortElement) {
            return visitor.visitDefaultColumnUsingNoSortElement(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ColumnUsingContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public columnsBody(): ColumnsBodyContext | null {
        return this.getRuleContext(0, ColumnsBodyContext);
    }
    public using(): UsingContext | null {
        return this.getRuleContext(0, UsingContext);
    }
    public columnUsingNoSortElement(): ColumnUsingNoSortElementContext[];
    public columnUsingNoSortElement(i: number): ColumnUsingNoSortElementContext | null;
    public columnUsingNoSortElement(i?: number): ColumnUsingNoSortElementContext[] | ColumnUsingNoSortElementContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ColumnUsingNoSortElementContext);
        }

        return this.getRuleContext(i, ColumnUsingNoSortElementContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_columnUsing;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterColumnUsing) {
             listener.enterColumnUsing(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitColumnUsing) {
             listener.exitColumnUsing(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitColumnUsing) {
            return visitor.visitColumnUsing(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ColumnUsingNoSortElementContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public partitionDefinition(): PartitionDefinitionContext | null {
        return this.getRuleContext(0, PartitionDefinitionContext);
    }
    public KW_OPTIONS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_OPTIONS, 0);
    }
    public tablePropertyList(): TablePropertyListContext | null {
        return this.getRuleContext(0, TablePropertyListContext);
    }
    public tblProperties(): TblPropertiesContext | null {
        return this.getRuleContext(0, TblPropertiesContext);
    }
    public someByClause(): SomeByClauseContext | null {
        return this.getRuleContext(0, SomeByClauseContext);
    }
    public intoBuckets(): IntoBucketsContext | null {
        return this.getRuleContext(0, IntoBucketsContext);
    }
    public commentSpec(): CommentSpecContext | null {
        return this.getRuleContext(0, CommentSpecContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_columnUsingNoSortElement;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterColumnUsingNoSortElement) {
             listener.enterColumnUsingNoSortElement(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitColumnUsingNoSortElement) {
             listener.exitColumnUsingNoSortElement(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitColumnUsingNoSortElement) {
            return visitor.visitColumnUsingNoSortElement(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class UsingByQueryContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public using(): UsingContext | null {
        return this.getRuleContext(0, UsingContext);
    }
    public KW_AS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_AS, 0);
    }
    public queryStatement(): QueryStatementContext | null {
        return this.getRuleContext(0, QueryStatementContext);
    }
    public usingByQueryNoSortElement(): UsingByQueryNoSortElementContext[];
    public usingByQueryNoSortElement(i: number): UsingByQueryNoSortElementContext | null;
    public usingByQueryNoSortElement(i?: number): UsingByQueryNoSortElementContext[] | UsingByQueryNoSortElementContext | null {
        if (i === undefined) {
            return this.getRuleContexts(UsingByQueryNoSortElementContext);
        }

        return this.getRuleContext(i, UsingByQueryNoSortElementContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_usingByQuery;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterUsingByQuery) {
             listener.enterUsingByQuery(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitUsingByQuery) {
             listener.exitUsingByQuery(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitUsingByQuery) {
            return visitor.visitUsingByQuery(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class UsingByQueryNoSortElementContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public partitionDefinition(): PartitionDefinitionContext | null {
        return this.getRuleContext(0, PartitionDefinitionContext);
    }
    public KW_OPTIONS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_OPTIONS, 0);
    }
    public tablePropertyList(): TablePropertyListContext | null {
        return this.getRuleContext(0, TablePropertyListContext);
    }
    public tblProperties(): TblPropertiesContext | null {
        return this.getRuleContext(0, TblPropertiesContext);
    }
    public someByClause(): SomeByClauseContext | null {
        return this.getRuleContext(0, SomeByClauseContext);
    }
    public intoBuckets(): IntoBucketsContext | null {
        return this.getRuleContext(0, IntoBucketsContext);
    }
    public commentSpec(): CommentSpecContext | null {
        return this.getRuleContext(0, CommentSpecContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_usingByQueryNoSortElement;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterUsingByQueryNoSortElement) {
             listener.enterUsingByQueryNoSortElement(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitUsingByQueryNoSortElement) {
             listener.exitUsingByQueryNoSortElement(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitUsingByQueryNoSortElement) {
            return visitor.visitUsingByQueryNoSortElement(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class IntoBucketsContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_INTO(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_INTO, 0)!;
    }
    public DIG_LITERAL(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.DIG_LITERAL, 0)!;
    }
    public KW_BUCKETS(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_BUCKETS, 0)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_intoBuckets;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterIntoBuckets) {
             listener.enterIntoBuckets(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitIntoBuckets) {
             listener.exitIntoBuckets(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitIntoBuckets) {
            return visitor.visitIntoBuckets(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class HiveFormatpartitionDefinitionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_PARTITIONED(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_PARTITIONED, 0)!;
    }
    public KW_BY(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_BY, 0)!;
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public ID_LITERAL(): antlr.TerminalNode[];
    public ID_LITERAL(i: number): antlr.TerminalNode | null;
    public ID_LITERAL(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.ID_LITERAL);
    	} else {
    		return this.getToken(SparkSQLParser.ID_LITERAL, i);
    	}
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public sqlSimpleType(): SqlSimpleTypeContext[];
    public sqlSimpleType(i: number): SqlSimpleTypeContext | null;
    public sqlSimpleType(i?: number): SqlSimpleTypeContext[] | SqlSimpleTypeContext | null {
        if (i === undefined) {
            return this.getRuleContexts(SqlSimpleTypeContext);
        }

        return this.getRuleContext(i, SqlSimpleTypeContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_hiveFormatpartitionDefinition;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterHiveFormatpartitionDefinition) {
             listener.enterHiveFormatpartitionDefinition(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitHiveFormatpartitionDefinition) {
             listener.exitHiveFormatpartitionDefinition(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitHiveFormatpartitionDefinition) {
            return visitor.visitHiveFormatpartitionDefinition(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class RowFormatSerdeContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_ROW(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_ROW, 0)!;
    }
    public KW_FORMAT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_FORMAT, 0)!;
    }
    public KW_SERDE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_SERDE, 0)!;
    }
    public stringLiteral(): StringLiteralContext {
        return this.getRuleContext(0, StringLiteralContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_rowFormatSerde;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterRowFormatSerde) {
             listener.enterRowFormatSerde(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitRowFormatSerde) {
             listener.exitRowFormatSerde(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitRowFormatSerde) {
            return visitor.visitRowFormatSerde(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class FieldsTerminatedByContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_FIELDS(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_FIELDS, 0)!;
    }
    public KW_TERMINATED(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_TERMINATED, 0)!;
    }
    public KW_BY(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_BY, 0)!;
    }
    public stringLiteral(): StringLiteralContext {
        return this.getRuleContext(0, StringLiteralContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_fieldsTerminatedBy;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterFieldsTerminatedBy) {
             listener.enterFieldsTerminatedBy(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitFieldsTerminatedBy) {
             listener.exitFieldsTerminatedBy(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitFieldsTerminatedBy) {
            return visitor.visitFieldsTerminatedBy(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class StoredAsContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_STORED(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_STORED, 0)!;
    }
    public KW_AS(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_AS, 0)!;
    }
    public identifier(): IdentifierContext | null {
        return this.getRuleContext(0, IdentifierContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_storedAs;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterStoredAs) {
             listener.enterStoredAs(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitStoredAs) {
             listener.exitStoredAs(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitStoredAs) {
            return visitor.visitStoredAs(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class StoredAsInputformatContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_STORED(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_STORED, 0)!;
    }
    public KW_AS(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_AS, 0)!;
    }
    public KW_INPUTFORMAT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_INPUTFORMAT, 0)!;
    }
    public identifier(): IdentifierContext | null {
        return this.getRuleContext(0, IdentifierContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_storedAsInputformat;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterStoredAsInputformat) {
             listener.enterStoredAsInputformat(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitStoredAsInputformat) {
             listener.exitStoredAsInputformat(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitStoredAsInputformat) {
            return visitor.visitStoredAsInputformat(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class OutputformatContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_OUTPUTFORMAT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_OUTPUTFORMAT, 0)!;
    }
    public identifier(): IdentifierContext | null {
        return this.getRuleContext(0, IdentifierContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_outputformat;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterOutputformat) {
             listener.enterOutputformat(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitOutputformat) {
             listener.exitOutputformat(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitOutputformat) {
            return visitor.visitOutputformat(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class RowFormatDelimtedContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_ROW(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_ROW, 0)!;
    }
    public KW_FORMAT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_FORMAT, 0)!;
    }
    public KW_DELIMITED(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_DELIMITED, 0)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_rowFormatDelimted;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterRowFormatDelimted) {
             listener.enterRowFormatDelimted(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitRowFormatDelimted) {
             listener.exitRowFormatDelimted(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitRowFormatDelimted) {
            return visitor.visitRowFormatDelimted(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ColumnsBodyContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public columnOptionDefinition(): ColumnOptionDefinitionContext[];
    public columnOptionDefinition(i: number): ColumnOptionDefinitionContext | null;
    public columnOptionDefinition(i?: number): ColumnOptionDefinitionContext[] | ColumnOptionDefinitionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ColumnOptionDefinitionContext);
        }

        return this.getRuleContext(i, ColumnOptionDefinitionContext);
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public commentSpec(): CommentSpecContext[];
    public commentSpec(i: number): CommentSpecContext | null;
    public commentSpec(i?: number): CommentSpecContext[] | CommentSpecContext | null {
        if (i === undefined) {
            return this.getRuleContexts(CommentSpecContext);
        }

        return this.getRuleContext(i, CommentSpecContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public watermarkDefinition(): WatermarkDefinitionContext | null {
        return this.getRuleContext(0, WatermarkDefinitionContext);
    }
    public tableConstraint(): TableConstraintContext | null {
        return this.getRuleContext(0, TableConstraintContext);
    }
    public selfDefinitionClause(): SelfDefinitionClauseContext | null {
        return this.getRuleContext(0, SelfDefinitionClauseContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_columnsBody;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterColumnsBody) {
             listener.enterColumnsBody(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitColumnsBody) {
             listener.exitColumnsBody(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitColumnsBody) {
            return visitor.visitColumnsBody(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class CreateCustomSerdeContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_CREATE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_CREATE, 0)!;
    }
    public KW_TABLE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_TABLE, 0)!;
    }
    public tablePathCreate(): TablePathCreateContext {
        return this.getRuleContext(0, TablePathCreateContext)!;
    }
    public KW_ROW(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_ROW, 0)!;
    }
    public KW_FORMAT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_FORMAT, 0)!;
    }
    public KW_SERDE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_SERDE, 0)!;
    }
    public tablePropertyKey(): TablePropertyKeyContext[];
    public tablePropertyKey(i: number): TablePropertyKeyContext | null;
    public tablePropertyKey(i?: number): TablePropertyKeyContext[] | TablePropertyKeyContext | null {
        if (i === undefined) {
            return this.getRuleContexts(TablePropertyKeyContext);
        }

        return this.getRuleContext(i, TablePropertyKeyContext);
    }
    public KW_SORTED(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_SORTED, 0)!;
    }
    public KW_AS(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_AS, 0)!;
    }
    public KW_INPUTFORMAT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_INPUTFORMAT, 0)!;
    }
    public KW_OUTPUTFORMAT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_OUTPUTFORMAT, 0)!;
    }
    public tblProperties(): TblPropertiesContext {
        return this.getRuleContext(0, TblPropertiesContext)!;
    }
    public KW_TEMPORARY(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TEMPORARY, 0);
    }
    public ifNotExists(): IfNotExistsContext | null {
        return this.getRuleContext(0, IfNotExistsContext);
    }
    public createCustomSerdeNoSortElement(): CreateCustomSerdeNoSortElementContext[];
    public createCustomSerdeNoSortElement(i: number): CreateCustomSerdeNoSortElementContext | null;
    public createCustomSerdeNoSortElement(i?: number): CreateCustomSerdeNoSortElementContext[] | CreateCustomSerdeNoSortElementContext | null {
        if (i === undefined) {
            return this.getRuleContexts(CreateCustomSerdeNoSortElementContext);
        }

        return this.getRuleContext(i, CreateCustomSerdeNoSortElementContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_createCustomSerde;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterCreateCustomSerde) {
             listener.enterCreateCustomSerde(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitCreateCustomSerde) {
             listener.exitCreateCustomSerde(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitCreateCustomSerde) {
            return visitor.visitCreateCustomSerde(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class CreateCustomSerdeNoSortElementContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public columnsBody(): ColumnsBodyContext | null {
        return this.getRuleContext(0, ColumnsBodyContext);
    }
    public commentSpec(): CommentSpecContext | null {
        return this.getRuleContext(0, CommentSpecContext);
    }
    public partitionDefinition(): PartitionDefinitionContext | null {
        return this.getRuleContext(0, PartitionDefinitionContext);
    }
    public withOption(): WithOptionContext | null {
        return this.getRuleContext(0, WithOptionContext);
    }
    public likeDefinition(): LikeDefinitionContext | null {
        return this.getRuleContext(0, LikeDefinitionContext);
    }
    public distribution(): DistributionContext | null {
        return this.getRuleContext(0, DistributionContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_createCustomSerdeNoSortElement;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterCreateCustomSerdeNoSortElement) {
             listener.enterCreateCustomSerdeNoSortElement(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitCreateCustomSerdeNoSortElement) {
             listener.exitCreateCustomSerdeNoSortElement(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitCreateCustomSerdeNoSortElement) {
            return visitor.visitCreateCustomSerdeNoSortElement(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class CreateCustomSerdeExternalContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_CREATE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_CREATE, 0)!;
    }
    public KW_EXTERNAL(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_EXTERNAL, 0)!;
    }
    public KW_TABLE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_TABLE, 0)!;
    }
    public tablePathCreate(): TablePathCreateContext {
        return this.getRuleContext(0, TablePathCreateContext)!;
    }
    public columnsBody(): ColumnsBodyContext {
        return this.getRuleContext(0, ColumnsBodyContext)!;
    }
    public KW_ROW(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_ROW, 0)!;
    }
    public KW_FORMAT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_FORMAT, 0)!;
    }
    public KW_SERDE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_SERDE, 0)!;
    }
    public tablePropertyKey(): TablePropertyKeyContext[];
    public tablePropertyKey(i: number): TablePropertyKeyContext | null;
    public tablePropertyKey(i?: number): TablePropertyKeyContext[] | TablePropertyKeyContext | null {
        if (i === undefined) {
            return this.getRuleContexts(TablePropertyKeyContext);
        }

        return this.getRuleContext(i, TablePropertyKeyContext);
    }
    public KW_SORTED(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_SORTED, 0)!;
    }
    public KW_AS(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_AS, 0)!;
    }
    public KW_INPUTFORMAT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_INPUTFORMAT, 0)!;
    }
    public KW_OUTPUTFORMAT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_OUTPUTFORMAT, 0)!;
    }
    public KW_LOCATION(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_LOCATION, 0)!;
    }
    public filePath(): FilePathContext {
        return this.getRuleContext(0, FilePathContext)!;
    }
    public ifNotExists(): IfNotExistsContext | null {
        return this.getRuleContext(0, IfNotExistsContext);
    }
    public createCustomSerdeExternalNoSortElement(): CreateCustomSerdeExternalNoSortElementContext[];
    public createCustomSerdeExternalNoSortElement(i: number): CreateCustomSerdeExternalNoSortElementContext | null;
    public createCustomSerdeExternalNoSortElement(i?: number): CreateCustomSerdeExternalNoSortElementContext[] | CreateCustomSerdeExternalNoSortElementContext | null {
        if (i === undefined) {
            return this.getRuleContexts(CreateCustomSerdeExternalNoSortElementContext);
        }

        return this.getRuleContext(i, CreateCustomSerdeExternalNoSortElementContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_createCustomSerdeExternal;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterCreateCustomSerdeExternal) {
             listener.enterCreateCustomSerdeExternal(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitCreateCustomSerdeExternal) {
             listener.exitCreateCustomSerdeExternal(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitCreateCustomSerdeExternal) {
            return visitor.visitCreateCustomSerdeExternal(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class CreateCustomSerdeExternalNoSortElementContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public commentSpec(): CommentSpecContext | null {
        return this.getRuleContext(0, CommentSpecContext);
    }
    public partitionDefinition(): PartitionDefinitionContext | null {
        return this.getRuleContext(0, PartitionDefinitionContext);
    }
    public withOption(): WithOptionContext | null {
        return this.getRuleContext(0, WithOptionContext);
    }
    public likeDefinition(): LikeDefinitionContext | null {
        return this.getRuleContext(0, LikeDefinitionContext);
    }
    public distribution(): DistributionContext | null {
        return this.getRuleContext(0, DistributionContext);
    }
    public tblProperties(): TblPropertiesContext | null {
        return this.getRuleContext(0, TblPropertiesContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_createCustomSerdeExternalNoSortElement;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterCreateCustomSerdeExternalNoSortElement) {
             listener.enterCreateCustomSerdeExternalNoSortElement(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitCreateCustomSerdeExternalNoSortElement) {
             listener.exitCreateCustomSerdeExternalNoSortElement(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitCreateCustomSerdeExternalNoSortElement) {
            return visitor.visitCreateCustomSerdeExternalNoSortElement(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class CreateTableAsSelectContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_CREATE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_CREATE, 0)!;
    }
    public KW_TABLE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_TABLE, 0)!;
    }
    public tablePathCreate(): TablePathCreateContext {
        return this.getRuleContext(0, TablePathCreateContext)!;
    }
    public withOption(): WithOptionContext {
        return this.getRuleContext(0, WithOptionContext)!;
    }
    public ifNotExists(): IfNotExistsContext | null {
        return this.getRuleContext(0, IfNotExistsContext);
    }
    public KW_AS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_AS, 0);
    }
    public queryStatement(): QueryStatementContext | null {
        return this.getRuleContext(0, QueryStatementContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_createTableAsSelect;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterCreateTableAsSelect) {
             listener.enterCreateTableAsSelect(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitCreateTableAsSelect) {
             listener.exitCreateTableAsSelect(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitCreateTableAsSelect) {
            return visitor.visitCreateTableAsSelect(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class CreateMaterializedTableAsSelectContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_CREATE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_CREATE, 0)!;
    }
    public KW_MATERIALIZED(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_MATERIALIZED, 0)!;
    }
    public KW_TABLE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_TABLE, 0)!;
    }
    public tablePathCreate(): TablePathCreateContext {
        return this.getRuleContext(0, TablePathCreateContext)!;
    }
    public LR_BRACKET(): antlr.TerminalNode[];
    public LR_BRACKET(i: number): antlr.TerminalNode | null;
    public LR_BRACKET(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.LR_BRACKET);
    	} else {
    		return this.getToken(SparkSQLParser.LR_BRACKET, i);
    	}
    }
    public KW_PRIMARY(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_PRIMARY, 0)!;
    }
    public KW_KEY(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_KEY, 0)!;
    }
    public identifier(): IdentifierContext[];
    public identifier(i: number): IdentifierContext | null;
    public identifier(i?: number): IdentifierContext[] | IdentifierContext | null {
        if (i === undefined) {
            return this.getRuleContexts(IdentifierContext);
        }

        return this.getRuleContext(i, IdentifierContext);
    }
    public RR_BRACKET(): antlr.TerminalNode[];
    public RR_BRACKET(i: number): antlr.TerminalNode | null;
    public RR_BRACKET(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.RR_BRACKET);
    	} else {
    		return this.getToken(SparkSQLParser.RR_BRACKET, i);
    	}
    }
    public KW_FRESHNESS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FRESHNESS, 0);
    }
    public EQUAL_SYMBOL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.EQUAL_SYMBOL, 0);
    }
    public KW_INTERVAL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_INTERVAL, 0);
    }
    public createMaterializedTableAsSelectNoSortElement(): CreateMaterializedTableAsSelectNoSortElementContext[];
    public createMaterializedTableAsSelectNoSortElement(i: number): CreateMaterializedTableAsSelectNoSortElementContext | null;
    public createMaterializedTableAsSelectNoSortElement(i?: number): CreateMaterializedTableAsSelectNoSortElementContext[] | CreateMaterializedTableAsSelectNoSortElementContext | null {
        if (i === undefined) {
            return this.getRuleContexts(CreateMaterializedTableAsSelectNoSortElementContext);
        }

        return this.getRuleContext(i, CreateMaterializedTableAsSelectNoSortElementContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public KW_NOT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NOT, 0);
    }
    public KW_ENFORCED(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ENFORCED, 0);
    }
    public KW_SECOND(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SECOND, 0);
    }
    public KW_MINUTE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MINUTE, 0);
    }
    public KW_HOUR(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_HOUR, 0);
    }
    public KW_DAY(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DAY, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_createMaterializedTableAsSelect;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterCreateMaterializedTableAsSelect) {
             listener.enterCreateMaterializedTableAsSelect(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitCreateMaterializedTableAsSelect) {
             listener.exitCreateMaterializedTableAsSelect(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitCreateMaterializedTableAsSelect) {
            return visitor.visitCreateMaterializedTableAsSelect(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class CreateMaterializedTableAsSelectNoSortElementContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public partitionDefinition(): PartitionDefinitionContext | null {
        return this.getRuleContext(0, PartitionDefinitionContext);
    }
    public withOption(): WithOptionContext | null {
        return this.getRuleContext(0, WithOptionContext);
    }
    public KW_REFRESH_MODE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_REFRESH_MODE, 0);
    }
    public EQUAL_SYMBOL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.EQUAL_SYMBOL, 0);
    }
    public KW_FULL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FULL, 0);
    }
    public KW_CONTINUOUS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_CONTINUOUS, 0);
    }
    public KW_AS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_AS, 0);
    }
    public queryStatement(): QueryStatementContext | null {
        return this.getRuleContext(0, QueryStatementContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_createMaterializedTableAsSelectNoSortElement;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterCreateMaterializedTableAsSelectNoSortElement) {
             listener.enterCreateMaterializedTableAsSelectNoSortElement(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitCreateMaterializedTableAsSelectNoSortElement) {
             listener.exitCreateMaterializedTableAsSelectNoSortElement(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitCreateMaterializedTableAsSelectNoSortElement) {
            return visitor.visitCreateMaterializedTableAsSelectNoSortElement(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class UsingClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_USING(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_USING, 0)!;
    }
    public KW_JAR(): antlr.TerminalNode[];
    public KW_JAR(i: number): antlr.TerminalNode | null;
    public KW_JAR(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.KW_JAR);
    	} else {
    		return this.getToken(SparkSQLParser.KW_JAR, i);
    	}
    }
    public jarFileName(): JarFileNameContext[];
    public jarFileName(i: number): JarFileNameContext | null;
    public jarFileName(i?: number): JarFileNameContext[] | JarFileNameContext | null {
        if (i === undefined) {
            return this.getRuleContexts(JarFileNameContext);
        }

        return this.getRuleContext(i, JarFileNameContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_usingClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterUsingClause) {
             listener.enterUsingClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitUsingClause) {
             listener.exitUsingClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitUsingClause) {
            return visitor.visitUsingClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class JarFileNameContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public filePath(): FilePathContext {
        return this.getRuleContext(0, FilePathContext)!;
    }
    public DOT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.DOT, 0);
    }
    public KW_JAR(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_JAR, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_jarFileName;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterJarFileName) {
             listener.enterJarFileName(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitJarFileName) {
             listener.exitJarFileName(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitJarFileName) {
            return visitor.visitJarFileName(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class FilePathContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public STRING_LITERAL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.STRING_LITERAL, 0);
    }
    public SLASH_SIGN(): antlr.TerminalNode[];
    public SLASH_SIGN(i: number): antlr.TerminalNode | null;
    public SLASH_SIGN(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.SLASH_SIGN);
    	} else {
    		return this.getToken(SparkSQLParser.SLASH_SIGN, i);
    	}
    }
    public ID_LITERAL(): antlr.TerminalNode[];
    public ID_LITERAL(i: number): antlr.TerminalNode | null;
    public ID_LITERAL(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.ID_LITERAL);
    	} else {
    		return this.getToken(SparkSQLParser.ID_LITERAL, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_filePath;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterFilePath) {
             listener.enterFilePath(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitFilePath) {
             listener.exitFilePath(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitFilePath) {
            return visitor.visitFilePath(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class IfExistsPartContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_IF(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_IF, 0)!;
    }
    public KW_EXISTS(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_EXISTS, 0)!;
    }
    public KW_NOT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NOT, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_ifExistsPart;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterIfExistsPart) {
             listener.enterIfExistsPart(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitIfExistsPart) {
             listener.exitIfExistsPart(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitIfExistsPart) {
            return visitor.visitIfExistsPart(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ColumnPositionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_FIRST(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FIRST, 0);
    }
    public KW_LAST(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LAST, 0);
    }
    public uid(): UidContext | null {
        return this.getRuleContext(0, UidContext);
    }
    public KW_BEFORE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_BEFORE, 0);
    }
    public KW_AFTER(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_AFTER, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_columnPosition;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterColumnPosition) {
             listener.enterColumnPosition(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitColumnPosition) {
             listener.exitColumnPosition(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitColumnPosition) {
            return visitor.visitColumnPosition(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class RenameDefinitionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_RENAME(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_RENAME, 0)!;
    }
    public KW_TO(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_TO, 0)!;
    }
    public uid(): UidContext[];
    public uid(i: number): UidContext | null;
    public uid(i?: number): UidContext[] | UidContext | null {
        if (i === undefined) {
            return this.getRuleContexts(UidContext);
        }

        return this.getRuleContext(i, UidContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_renameDefinition;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterRenameDefinition) {
             listener.enterRenameDefinition(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitRenameDefinition) {
             listener.exitRenameDefinition(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitRenameDefinition) {
            return visitor.visitRenameDefinition(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class SetKeyValueDefinitionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_SET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_SET, 0)!;
    }
    public tablePropertyList(): TablePropertyListContext {
        return this.getRuleContext(0, TablePropertyListContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_setKeyValueDefinition;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterSetKeyValueDefinition) {
             listener.enterSetKeyValueDefinition(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitSetKeyValueDefinition) {
             listener.exitSetKeyValueDefinition(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitSetKeyValueDefinition) {
            return visitor.visitSetKeyValueDefinition(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class AddConstraintContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_ADD(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_ADD, 0)!;
    }
    public KW_CONSTRAINT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_CONSTRAINT, 0)!;
    }
    public constraintName(): ConstraintNameContext {
        return this.getRuleContext(0, ConstraintNameContext)!;
    }
    public KW_PRIMARY(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_PRIMARY, 0)!;
    }
    public KW_KEY(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_KEY, 0)!;
    }
    public columnNameList(): ColumnNameListContext {
        return this.getRuleContext(0, ColumnNameListContext)!;
    }
    public notForced(): NotForcedContext | null {
        return this.getRuleContext(0, NotForcedContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_addConstraint;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterAddConstraint) {
             listener.enterAddConstraint(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitAddConstraint) {
             listener.exitAddConstraint(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitAddConstraint) {
            return visitor.visitAddConstraint(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class DropConstraintContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_DROP(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_DROP, 0)!;
    }
    public KW_CONSTRAINT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_CONSTRAINT, 0)!;
    }
    public constraintName(): ConstraintNameContext {
        return this.getRuleContext(0, ConstraintNameContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_dropConstraint;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterDropConstraint) {
             listener.enterDropConstraint(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitDropConstraint) {
             listener.exitDropConstraint(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitDropConstraint) {
            return visitor.visitDropConstraint(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class AddUniqueContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_ADD(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_ADD, 0)!;
    }
    public KW_UNIQUE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_UNIQUE, 0)!;
    }
    public columnNameList(): ColumnNameListContext {
        return this.getRuleContext(0, ColumnNameListContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_addUnique;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterAddUnique) {
             listener.enterAddUnique(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitAddUnique) {
             listener.exitAddUnique(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitAddUnique) {
            return visitor.visitAddUnique(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class NotForcedContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_NOT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_NOT, 0)!;
    }
    public KW_ENFORCED(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_ENFORCED, 0)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_notForced;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterNotForced) {
             listener.enterNotForced(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitNotForced) {
             listener.exitNotForced(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitNotForced) {
            return visitor.visitNotForced(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class InsertStatementContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public insertSimpleStatement(): InsertSimpleStatementContext {
        return this.getRuleContext(0, InsertSimpleStatementContext)!;
    }
    public KW_EXECUTE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_EXECUTE, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_insertStatement;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterInsertStatement) {
             listener.enterInsertStatement(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitInsertStatement) {
             listener.exitInsertStatement(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitInsertStatement) {
            return visitor.visitInsertStatement(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class InsertSimpleStatementContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_INSERT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_INSERT, 0)!;
    }
    public tablePath(): TablePathContext[];
    public tablePath(i: number): TablePathContext | null;
    public tablePath(i?: number): TablePathContext[] | TablePathContext | null {
        if (i === undefined) {
            return this.getRuleContexts(TablePathContext);
        }

        return this.getRuleContext(i, TablePathContext);
    }
    public KW_INTO(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_INTO, 0);
    }
    public KW_OVERWRITE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_OVERWRITE, 0);
    }
    public queryStatement(): QueryStatementContext | null {
        return this.getRuleContext(0, QueryStatementContext);
    }
    public valuesDefinition(): ValuesDefinitionContext | null {
        return this.getRuleContext(0, ValuesDefinitionContext);
    }
    public KW_TABLE(): antlr.TerminalNode[];
    public KW_TABLE(i: number): antlr.TerminalNode | null;
    public KW_TABLE(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.KW_TABLE);
    	} else {
    		return this.getToken(SparkSQLParser.KW_TABLE, i);
    	}
    }
    public insertPartitionDefinition(): InsertPartitionDefinitionContext | null {
        return this.getRuleContext(0, InsertPartitionDefinitionContext);
    }
    public columnNameList(): ColumnNameListContext | null {
        return this.getRuleContext(0, ColumnNameListContext);
    }
    public KW_REPLACE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_REPLACE, 0);
    }
    public whereClause(): WhereClauseContext | null {
        return this.getRuleContext(0, WhereClauseContext);
    }
    public selectStatement(): SelectStatementContext | null {
        return this.getRuleContext(0, SelectStatementContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_insertSimpleStatement;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterInsertSimpleStatement) {
             listener.enterInsertSimpleStatement(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitInsertSimpleStatement) {
             listener.exitInsertSimpleStatement(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitInsertSimpleStatement) {
            return visitor.visitInsertSimpleStatement(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class InsertPartitionDefinitionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_PARTITION(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_PARTITION, 0)!;
    }
    public tablePropertyList(): TablePropertyListContext {
        return this.getRuleContext(0, TablePropertyListContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_insertPartitionDefinition;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterInsertPartitionDefinition) {
             listener.enterInsertPartitionDefinition(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitInsertPartitionDefinition) {
             listener.exitInsertPartitionDefinition(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitInsertPartitionDefinition) {
            return visitor.visitInsertPartitionDefinition(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class QueryStatementContext extends antlr.ParserRuleContext {
    public _left?: QueryStatementContext;
    public _operator?: Token | null;
    public _right?: QueryStatementContext;
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public withClause(): WithClauseContext | null {
        return this.getRuleContext(0, WithClauseContext);
    }
    public queryStatement(): QueryStatementContext[];
    public queryStatement(i: number): QueryStatementContext | null;
    public queryStatement(i?: number): QueryStatementContext[] | QueryStatementContext | null {
        if (i === undefined) {
            return this.getRuleContexts(QueryStatementContext);
        }

        return this.getRuleContext(i, QueryStatementContext);
    }
    public LR_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0);
    }
    public RR_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0);
    }
    public selectClause(): SelectClauseContext | null {
        return this.getRuleContext(0, SelectClauseContext);
    }
    public selectStatement(): SelectStatementContext | null {
        return this.getRuleContext(0, SelectStatementContext);
    }
    public sortByCaluse(): SortByCaluseContext | null {
        return this.getRuleContext(0, SortByCaluseContext);
    }
    public orderByCaluse(): OrderByCaluseContext | null {
        return this.getRuleContext(0, OrderByCaluseContext);
    }
    public limitClause(): LimitClauseContext | null {
        return this.getRuleContext(0, LimitClauseContext);
    }
    public offsetClause(): OffsetClauseContext | null {
        return this.getRuleContext(0, OffsetClauseContext);
    }
    public KW_INTERSECT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_INTERSECT, 0);
    }
    public KW_UNION(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_UNION, 0);
    }
    public KW_EXCEPT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_EXCEPT, 0);
    }
    public KW_MINUS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MINUS, 0);
    }
    public KW_ALL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ALL, 0);
    }
    public KW_DISTINCT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DISTINCT, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_queryStatement;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterQueryStatement) {
             listener.enterQueryStatement(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitQueryStatement) {
             listener.exitQueryStatement(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitQueryStatement) {
            return visitor.visitQueryStatement(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class WithClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_WITH(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_WITH, 0)!;
    }
    public withItem(): WithItemContext[];
    public withItem(i: number): WithItemContext | null;
    public withItem(i?: number): WithItemContext[] | WithItemContext | null {
        if (i === undefined) {
            return this.getRuleContexts(WithItemContext);
        }

        return this.getRuleContext(i, WithItemContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_withClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterWithClause) {
             listener.enterWithClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitWithClause) {
             listener.exitWithClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitWithClause) {
            return visitor.visitWithClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ValuesCaluseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_VALUES(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_VALUES, 0);
    }
    public inlineBody(): InlineBodyContext[];
    public inlineBody(i: number): InlineBodyContext | null;
    public inlineBody(i?: number): InlineBodyContext[] | InlineBodyContext | null {
        if (i === undefined) {
            return this.getRuleContexts(InlineBodyContext);
        }

        return this.getRuleContext(i, InlineBodyContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public tableAlias(): TableAliasContext[];
    public tableAlias(i: number): TableAliasContext | null;
    public tableAlias(i?: number): TableAliasContext[] | TableAliasContext | null {
        if (i === undefined) {
            return this.getRuleContexts(TableAliasContext);
        }

        return this.getRuleContext(i, TableAliasContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_valuesCaluse;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterValuesCaluse) {
             listener.enterValuesCaluse(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitValuesCaluse) {
             listener.exitValuesCaluse(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitValuesCaluse) {
            return visitor.visitValuesCaluse(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class InlineBodyContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public expression(): ExpressionContext[];
    public expression(i: number): ExpressionContext | null;
    public expression(i?: number): ExpressionContext[] | ExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ExpressionContext);
        }

        return this.getRuleContext(i, ExpressionContext);
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_inlineBody;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterInlineBody) {
             listener.enterInlineBody(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitInlineBody) {
             listener.exitInlineBody(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitInlineBody) {
            return visitor.visitInlineBody(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class WithItemContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public withItemName(): WithItemNameContext {
        return this.getRuleContext(0, WithItemNameContext)!;
    }
    public KW_AS(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_AS, 0)!;
    }
    public LR_BRACKET(): antlr.TerminalNode[];
    public LR_BRACKET(i: number): antlr.TerminalNode | null;
    public LR_BRACKET(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.LR_BRACKET);
    	} else {
    		return this.getToken(SparkSQLParser.LR_BRACKET, i);
    	}
    }
    public queryStatement(): QueryStatementContext {
        return this.getRuleContext(0, QueryStatementContext)!;
    }
    public RR_BRACKET(): antlr.TerminalNode[];
    public RR_BRACKET(i: number): antlr.TerminalNode | null;
    public RR_BRACKET(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.RR_BRACKET);
    	} else {
    		return this.getToken(SparkSQLParser.RR_BRACKET, i);
    	}
    }
    public columnName(): ColumnNameContext[];
    public columnName(i: number): ColumnNameContext | null;
    public columnName(i?: number): ColumnNameContext[] | ColumnNameContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ColumnNameContext);
        }

        return this.getRuleContext(i, ColumnNameContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_withItem;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterWithItem) {
             listener.enterWithItem(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitWithItem) {
             listener.exitWithItem(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitWithItem) {
            return visitor.visitWithItem(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class WithItemNameContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public identifier(): IdentifierContext {
        return this.getRuleContext(0, IdentifierContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_withItemName;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterWithItemName) {
             listener.enterWithItemName(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitWithItemName) {
             listener.exitWithItemName(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitWithItemName) {
            return visitor.visitWithItemName(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class SelectStatementContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_selectStatement;
    }
    public override copyFrom(ctx: SelectStatementContext): void {
        super.copyFrom(ctx);
    }
}
export class TableSampleContext extends SelectStatementContext {
    public constructor(ctx: SelectStatementContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public selectClause(): SelectClauseContext {
        return this.getRuleContext(0, SelectClauseContext)!;
    }
    public fromClause(): FromClauseContext {
        return this.getRuleContext(0, FromClauseContext)!;
    }
    public samplingQueries(): SamplingQueriesContext {
        return this.getRuleContext(0, SamplingQueriesContext)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterTableSample) {
             listener.enterTableSample(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitTableSample) {
             listener.exitTableSample(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitTableSample) {
            return visitor.visitTableSample(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class SparkStyleSelectContext extends SelectStatementContext {
    public constructor(ctx: SelectStatementContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public fromClause(): FromClauseContext {
        return this.getRuleContext(0, FromClauseContext)!;
    }
    public selectClause(): SelectClauseContext {
        return this.getRuleContext(0, SelectClauseContext)!;
    }
    public whereClause(): WhereClauseContext | null {
        return this.getRuleContext(0, WhereClauseContext);
    }
    public someByClause(): SomeByClauseContext | null {
        return this.getRuleContext(0, SomeByClauseContext);
    }
    public havingClause(): HavingClauseContext | null {
        return this.getRuleContext(0, HavingClauseContext);
    }
    public windowClause(): WindowClauseContext | null {
        return this.getRuleContext(0, WindowClauseContext);
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterSparkStyleSelect) {
             listener.enterSparkStyleSelect(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitSparkStyleSelect) {
             listener.exitSparkStyleSelect(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitSparkStyleSelect) {
            return visitor.visitSparkStyleSelect(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class MatchRecognizeSelectContext extends SelectStatementContext {
    public constructor(ctx: SelectStatementContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public selectClause(): SelectClauseContext {
        return this.getRuleContext(0, SelectClauseContext)!;
    }
    public fromClause(): FromClauseContext {
        return this.getRuleContext(0, FromClauseContext)!;
    }
    public matchRecognizeClause(): MatchRecognizeClauseContext {
        return this.getRuleContext(0, MatchRecognizeClauseContext)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterMatchRecognizeSelect) {
             listener.enterMatchRecognizeSelect(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitMatchRecognizeSelect) {
             listener.exitMatchRecognizeSelect(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitMatchRecognizeSelect) {
            return visitor.visitMatchRecognizeSelect(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class SelectPlusContext extends SelectStatementContext {
    public constructor(ctx: SelectStatementContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public selectStatementPlus(): SelectStatementPlusContext {
        return this.getRuleContext(0, SelectStatementPlusContext)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterSelectPlus) {
             listener.enterSelectPlus(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitSelectPlus) {
             listener.exitSelectPlus(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitSelectPlus) {
            return visitor.visitSelectPlus(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class CommonSelectContext extends SelectStatementContext {
    public constructor(ctx: SelectStatementContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public selectClause(): SelectClauseContext {
        return this.getRuleContext(0, SelectClauseContext)!;
    }
    public fromClause(): FromClauseContext {
        return this.getRuleContext(0, FromClauseContext)!;
    }
    public whereClause(): WhereClauseContext | null {
        return this.getRuleContext(0, WhereClauseContext);
    }
    public someByClause(): SomeByClauseContext | null {
        return this.getRuleContext(0, SomeByClauseContext);
    }
    public havingClause(): HavingClauseContext | null {
        return this.getRuleContext(0, HavingClauseContext);
    }
    public windowClause(): WindowClauseContext | null {
        return this.getRuleContext(0, WindowClauseContext);
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterCommonSelect) {
             listener.enterCommonSelect(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitCommonSelect) {
             listener.exitCommonSelect(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitCommonSelect) {
            return visitor.visitCommonSelect(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class SelectClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_SELECT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_SELECT, 0)!;
    }
    public projectItemDefinition(): ProjectItemDefinitionContext[];
    public projectItemDefinition(i: number): ProjectItemDefinitionContext | null;
    public projectItemDefinition(i?: number): ProjectItemDefinitionContext[] | ProjectItemDefinitionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ProjectItemDefinitionContext);
        }

        return this.getRuleContext(i, ProjectItemDefinitionContext);
    }
    public setQuantifier(): SetQuantifierContext | null {
        return this.getRuleContext(0, SetQuantifierContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_selectClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterSelectClause) {
             listener.enterSelectClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitSelectClause) {
             listener.exitSelectClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitSelectClause) {
            return visitor.visitSelectClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ProjectItemDefinitionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_projectItemDefinition;
    }
    public override copyFrom(ctx: ProjectItemDefinitionContext): void {
        super.copyFrom(ctx);
    }
}
export class WindowsProrjectItemContext extends ProjectItemDefinitionContext {
    public constructor(ctx: ProjectItemDefinitionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public overWindowItem(): OverWindowItemContext {
        return this.getRuleContext(0, OverWindowItemContext)!;
    }
    public identifier(): IdentifierContext | null {
        return this.getRuleContext(0, IdentifierContext);
    }
    public KW_AS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_AS, 0);
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterWindowsProrjectItem) {
             listener.enterWindowsProrjectItem(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitWindowsProrjectItem) {
             listener.exitWindowsProrjectItem(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitWindowsProrjectItem) {
            return visitor.visitWindowsProrjectItem(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class ExpressionProjectItemContext extends ProjectItemDefinitionContext {
    public constructor(ctx: ProjectItemDefinitionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public expression(): ExpressionContext[];
    public expression(i: number): ExpressionContext | null;
    public expression(i?: number): ExpressionContext[] | ExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ExpressionContext);
        }

        return this.getRuleContext(i, ExpressionContext);
    }
    public KW_AS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_AS, 0);
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterExpressionProjectItem) {
             listener.enterExpressionProjectItem(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitExpressionProjectItem) {
             listener.exitExpressionProjectItem(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitExpressionProjectItem) {
            return visitor.visitExpressionProjectItem(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class FilterPartContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_FILTER(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_FILTER, 0)!;
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public whereClause(): WhereClauseContext {
        return this.getRuleContext(0, WhereClauseContext)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_filterPart;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterFilterPart) {
             listener.enterFilterPart(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitFilterPart) {
             listener.exitFilterPart(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitFilterPart) {
            return visitor.visitFilterPart(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class OverWindowItemContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public windowFunctioPart(): WindowFunctioPartContext {
        return this.getRuleContext(0, WindowFunctioPartContext)!;
    }
    public KW_OVER(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_OVER, 0)!;
    }
    public KW_NULLS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NULLS, 0);
    }
    public anonymousWindowsName(): AnonymousWindowsNameContext | null {
        return this.getRuleContext(0, AnonymousWindowsNameContext);
    }
    public LR_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0);
    }
    public orderByCaluse(): OrderByCaluseContext | null {
        return this.getRuleContext(0, OrderByCaluseContext);
    }
    public RR_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0);
    }
    public KW_IGNORE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_IGNORE, 0);
    }
    public KW_RESPECT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_RESPECT, 0);
    }
    public overClause(): OverClauseContext | null {
        return this.getRuleContext(0, OverClauseContext);
    }
    public windowFrameForWindowsQuery(): WindowFrameForWindowsQueryContext | null {
        return this.getRuleContext(0, WindowFrameForWindowsQueryContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_overWindowItem;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterOverWindowItem) {
             listener.enterOverWindowItem(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitOverWindowItem) {
             listener.exitOverWindowItem(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitOverWindowItem) {
            return visitor.visitOverWindowItem(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class OverClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_BY(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_BY, 0)!;
    }
    public columnName(): ColumnNameContext[];
    public columnName(i: number): ColumnNameContext | null;
    public columnName(i?: number): ColumnNameContext[] | ColumnNameContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ColumnNameContext);
        }

        return this.getRuleContext(i, ColumnNameContext);
    }
    public KW_PARTITION(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PARTITION, 0);
    }
    public KW_DISTRIBUTE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DISTRIBUTE, 0);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public EQUAL_SYMBOL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.EQUAL_SYMBOL, 0);
    }
    public expression(): ExpressionContext | null {
        return this.getRuleContext(0, ExpressionContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_overClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterOverClause) {
             listener.enterOverClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitOverClause) {
             listener.exitOverClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitOverClause) {
            return visitor.visitOverClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class WindowFunctioPartContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public windowFunctionName(): WindowFunctionNameContext | null {
        return this.getRuleContext(0, WindowFunctionNameContext);
    }
    public LR_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0);
    }
    public RR_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0);
    }
    public functionParam(): FunctionParamContext[];
    public functionParam(i: number): FunctionParamContext | null;
    public functionParam(i?: number): FunctionParamContext[] | FunctionParamContext | null {
        if (i === undefined) {
            return this.getRuleContexts(FunctionParamContext);
        }

        return this.getRuleContext(i, FunctionParamContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public primaryExpression(): PrimaryExpressionContext | null {
        return this.getRuleContext(0, PrimaryExpressionContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_windowFunctioPart;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterWindowFunctioPart) {
             listener.enterWindowFunctioPart(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitWindowFunctioPart) {
             listener.exitWindowFunctioPart(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitWindowFunctioPart) {
            return visitor.visitWindowFunctioPart(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class WindowFunctionNameContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public rangkingFunction(): RangkingFunctionContext | null {
        return this.getRuleContext(0, RangkingFunctionContext);
    }
    public analyticFunction(): AnalyticFunctionContext | null {
        return this.getRuleContext(0, AnalyticFunctionContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_windowFunctionName;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterWindowFunctionName) {
             listener.enterWindowFunctionName(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitWindowFunctionName) {
             listener.exitWindowFunctionName(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitWindowFunctionName) {
            return visitor.visitWindowFunctionName(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class AnalyticFunctionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_CUME_DIST(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_CUME_DIST, 0);
    }
    public KW_LAG(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LAG, 0);
    }
    public KW_LEAD(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LEAD, 0);
    }
    public KW_NTH_VALUE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NTH_VALUE, 0);
    }
    public KW_FIRST_VALUE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FIRST_VALUE, 0);
    }
    public KW_LAST_VALUE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LAST_VALUE, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_analyticFunction;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterAnalyticFunction) {
             listener.enterAnalyticFunction(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitAnalyticFunction) {
             listener.exitAnalyticFunction(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitAnalyticFunction) {
            return visitor.visitAnalyticFunction(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class RangkingFunctionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_RANK(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_RANK, 0);
    }
    public KW_DENSE_RANK(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DENSE_RANK, 0);
    }
    public KW_PERCENT_RANK(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PERCENT_RANK, 0);
    }
    public KW_NTILE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NTILE, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_rangkingFunction;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterRangkingFunction) {
             listener.enterRangkingFunction(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitRangkingFunction) {
             listener.exitRangkingFunction(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitRangkingFunction) {
            return visitor.visitRangkingFunction(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class FromClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_FROM(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_FROM, 0)!;
    }
    public tableExpression(): TableExpressionContext {
        return this.getRuleContext(0, TableExpressionContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_fromClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterFromClause) {
             listener.enterFromClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitFromClause) {
             listener.exitFromClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitFromClause) {
            return visitor.visitFromClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class WindowFrameForWindowsQueryContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_RANGE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_RANGE, 0);
    }
    public KW_ROWS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ROWS, 0);
    }
    public frameExpession(): FrameExpessionContext[];
    public frameExpession(i: number): FrameExpessionContext | null;
    public frameExpession(i?: number): FrameExpessionContext[] | FrameExpessionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(FrameExpessionContext);
        }

        return this.getRuleContext(i, FrameExpessionContext);
    }
    public KW_BETWEEN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_BETWEEN, 0);
    }
    public KW_AND(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_AND, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_windowFrameForWindowsQuery;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterWindowFrameForWindowsQuery) {
             listener.enterWindowFrameForWindowsQuery(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitWindowFrameForWindowsQuery) {
             listener.exitWindowFrameForWindowsQuery(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitWindowFrameForWindowsQuery) {
            return visitor.visitWindowFrameForWindowsQuery(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class FrameExpessionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_UNBOUNDED(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_UNBOUNDED, 0);
    }
    public KW_PRECEDING(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PRECEDING, 0);
    }
    public expression(): ExpressionContext | null {
        return this.getRuleContext(0, ExpressionContext);
    }
    public KW_CURRENT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_CURRENT, 0);
    }
    public KW_ROW(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ROW, 0);
    }
    public KW_FOLLOWING(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FOLLOWING, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_frameExpession;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterFrameExpession) {
             listener.enterFrameExpession(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitFrameExpession) {
             listener.exitFrameExpession(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitFrameExpession) {
            return visitor.visitFrameExpession(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class TableExpressionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public tableReference(): TableReferenceContext[];
    public tableReference(i: number): TableReferenceContext | null;
    public tableReference(i?: number): TableReferenceContext[] | TableReferenceContext | null {
        if (i === undefined) {
            return this.getRuleContexts(TableReferenceContext);
        }

        return this.getRuleContext(i, TableReferenceContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public pivotReference(): PivotReferenceContext | null {
        return this.getRuleContext(0, PivotReferenceContext);
    }
    public tableAlias(): TableAliasContext | null {
        return this.getRuleContext(0, TableAliasContext);
    }
    public viewReference(): ViewReferenceContext[];
    public viewReference(i: number): ViewReferenceContext | null;
    public viewReference(i?: number): ViewReferenceContext[] | ViewReferenceContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ViewReferenceContext);
        }

        return this.getRuleContext(i, ViewReferenceContext);
    }
    public valuesCaluse(): ValuesCaluseContext | null {
        return this.getRuleContext(0, ValuesCaluseContext);
    }
    public tvfClause(): TvfClauseContext | null {
        return this.getRuleContext(0, TvfClauseContext);
    }
    public windowTVFClause(): WindowTVFClauseContext | null {
        return this.getRuleContext(0, WindowTVFClauseContext);
    }
    public tableExpression(): TableExpressionContext[];
    public tableExpression(i: number): TableExpressionContext | null;
    public tableExpression(i?: number): TableExpressionContext[] | TableExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(TableExpressionContext);
        }

        return this.getRuleContext(i, TableExpressionContext);
    }
    public KW_CROSS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_CROSS, 0);
    }
    public KW_JOIN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_JOIN, 0);
    }
    public KW_NATURAL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NATURAL, 0);
    }
    public KW_OUTER(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_OUTER, 0);
    }
    public joinCondition(): JoinConditionContext | null {
        return this.getRuleContext(0, JoinConditionContext);
    }
    public KW_LEFT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LEFT, 0);
    }
    public KW_RIGHT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_RIGHT, 0);
    }
    public KW_FULL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FULL, 0);
    }
    public KW_INNER(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_INNER, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_tableExpression;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterTableExpression) {
             listener.enterTableExpression(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitTableExpression) {
             listener.exitTableExpression(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitTableExpression) {
            return visitor.visitTableExpression(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class TvfClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public rangeClause(): RangeClauseContext {
        return this.getRuleContext(0, RangeClauseContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_tvfClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterTvfClause) {
             listener.enterTvfClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitTvfClause) {
             listener.exitTvfClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitTvfClause) {
            return visitor.visitTvfClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class RangeClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_RANGE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_RANGE, 0)!;
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public expression(): ExpressionContext[];
    public expression(i: number): ExpressionContext | null;
    public expression(i?: number): ExpressionContext[] | ExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ExpressionContext);
        }

        return this.getRuleContext(i, ExpressionContext);
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_rangeClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterRangeClause) {
             listener.enterRangeClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitRangeClause) {
             listener.exitRangeClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitRangeClause) {
            return visitor.visitRangeClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ViewReferenceContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_LATERAL(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_LATERAL, 0)!;
    }
    public KW_VIEW(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_VIEW, 0)!;
    }
    public funtionBody(): FuntionBodyContext {
        return this.getRuleContext(0, FuntionBodyContext)!;
    }
    public KW_AS(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_AS, 0)!;
    }
    public columnAlias(): ColumnAliasContext[];
    public columnAlias(i: number): ColumnAliasContext | null;
    public columnAlias(i?: number): ColumnAliasContext[] | ColumnAliasContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ColumnAliasContext);
        }

        return this.getRuleContext(i, ColumnAliasContext);
    }
    public KW_OUTER(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_OUTER, 0);
    }
    public tableAlias(): TableAliasContext | null {
        return this.getRuleContext(0, TableAliasContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_viewReference;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterViewReference) {
             listener.enterViewReference(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitViewReference) {
             listener.exitViewReference(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitViewReference) {
            return visitor.visitViewReference(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class PivotReferenceContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_PIVOT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PIVOT, 0);
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public pivotBody(): PivotBodyContext | null {
        return this.getRuleContext(0, PivotBodyContext);
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public KW_UNPIVOT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_UNPIVOT, 0);
    }
    public unpivotBody(): UnpivotBodyContext | null {
        return this.getRuleContext(0, UnpivotBodyContext);
    }
    public KW_NULLS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NULLS, 0);
    }
    public KW_INCLUDE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_INCLUDE, 0);
    }
    public KW_EXCLUDE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_EXCLUDE, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_pivotReference;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterPivotReference) {
             listener.enterPivotReference(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitPivotReference) {
             listener.exitPivotReference(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitPivotReference) {
            return visitor.visitPivotReference(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class TableReferenceContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public tablePrimary(): TablePrimaryContext {
        return this.getRuleContext(0, TablePrimaryContext)!;
    }
    public tableAlias(): TableAliasContext | null {
        return this.getRuleContext(0, TableAliasContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_tableReference;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterTableReference) {
             listener.enterTableReference(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitTableReference) {
             listener.exitTableReference(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitTableReference) {
            return visitor.visitTableReference(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class TablePrimaryContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public tablePath(): TablePathContext | null {
        return this.getRuleContext(0, TablePathContext);
    }
    public KW_TABLE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TABLE, 0);
    }
    public systemTimePeriod(): SystemTimePeriodContext | null {
        return this.getRuleContext(0, SystemTimePeriodContext);
    }
    public KW_LATERAL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LATERAL, 0);
    }
    public funtionBody(): FuntionBodyContext | null {
        return this.getRuleContext(0, FuntionBodyContext);
    }
    public complexDataTypeExpression(): ComplexDataTypeExpressionContext | null {
        return this.getRuleContext(0, ComplexDataTypeExpressionContext);
    }
    public KW_EXPLODE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_EXPLODE, 0);
    }
    public LR_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0);
    }
    public RR_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0);
    }
    public queryStatement(): QueryStatementContext[];
    public queryStatement(i: number): QueryStatementContext | null;
    public queryStatement(i?: number): QueryStatementContext[] | QueryStatementContext | null {
        if (i === undefined) {
            return this.getRuleContexts(QueryStatementContext);
        }

        return this.getRuleContext(i, QueryStatementContext);
    }
    public KW_UNSET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_UNSET, 0);
    }
    public expression(): ExpressionContext | null {
        return this.getRuleContext(0, ExpressionContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_tablePrimary;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterTablePrimary) {
             listener.enterTablePrimary(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitTablePrimary) {
             listener.exitTablePrimary(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitTablePrimary) {
            return visitor.visitTablePrimary(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class FuntionBodyContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public functionName(): FunctionNameContext {
        return this.getRuleContext(0, FunctionNameContext)!;
    }
    public LR_BRACKET(): antlr.TerminalNode[];
    public LR_BRACKET(i: number): antlr.TerminalNode | null;
    public LR_BRACKET(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.LR_BRACKET);
    	} else {
    		return this.getToken(SparkSQLParser.LR_BRACKET, i);
    	}
    }
    public RR_BRACKET(): antlr.TerminalNode[];
    public RR_BRACKET(i: number): antlr.TerminalNode | null;
    public RR_BRACKET(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.RR_BRACKET);
    	} else {
    		return this.getToken(SparkSQLParser.RR_BRACKET, i);
    	}
    }
    public funtionBody(): FuntionBodyContext[];
    public funtionBody(i: number): FuntionBodyContext | null;
    public funtionBody(i?: number): FuntionBodyContext[] | FuntionBodyContext | null {
        if (i === undefined) {
            return this.getRuleContexts(FuntionBodyContext);
        }

        return this.getRuleContext(i, FuntionBodyContext);
    }
    public functionParam(): FunctionParamContext[];
    public functionParam(i: number): FunctionParamContext | null;
    public functionParam(i?: number): FunctionParamContext[] | FunctionParamContext | null {
        if (i === undefined) {
            return this.getRuleContexts(FunctionParamContext);
        }

        return this.getRuleContext(i, FunctionParamContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public KW_AS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_AS, 0);
    }
    public tableAlias(): TableAliasContext | null {
        return this.getRuleContext(0, TableAliasContext);
    }
    public projectItemDefinition(): ProjectItemDefinitionContext[];
    public projectItemDefinition(i: number): ProjectItemDefinitionContext | null;
    public projectItemDefinition(i?: number): ProjectItemDefinitionContext[] | ProjectItemDefinitionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ProjectItemDefinitionContext);
        }

        return this.getRuleContext(i, ProjectItemDefinitionContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_funtionBody;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterFuntionBody) {
             listener.enterFuntionBody(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitFuntionBody) {
             listener.exitFuntionBody(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitFuntionBody) {
            return visitor.visitFuntionBody(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class UnpivotBodyContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_FOR(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_FOR, 0)!;
    }
    public columnName(): ColumnNameContext[];
    public columnName(i: number): ColumnNameContext | null;
    public columnName(i?: number): ColumnNameContext[] | ColumnNameContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ColumnNameContext);
        }

        return this.getRuleContext(i, ColumnNameContext);
    }
    public KW_IN(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_IN, 0)!;
    }
    public expressionAsAliasList(): ExpressionAsAliasListContext {
        return this.getRuleContext(0, ExpressionAsAliasListContext)!;
    }
    public columnNameList(): ColumnNameListContext | null {
        return this.getRuleContext(0, ColumnNameListContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_unpivotBody;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterUnpivotBody) {
             listener.enterUnpivotBody(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitUnpivotBody) {
             listener.exitUnpivotBody(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitUnpivotBody) {
            return visitor.visitUnpivotBody(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class PivotBodyContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public expressionAsAlias(): ExpressionAsAliasContext[];
    public expressionAsAlias(i: number): ExpressionAsAliasContext | null;
    public expressionAsAlias(i?: number): ExpressionAsAliasContext[] | ExpressionAsAliasContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ExpressionAsAliasContext);
        }

        return this.getRuleContext(i, ExpressionAsAliasContext);
    }
    public KW_FOR(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_FOR, 0)!;
    }
    public KW_IN(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_IN, 0)!;
    }
    public expressionAsAliasList(): ExpressionAsAliasListContext {
        return this.getRuleContext(0, ExpressionAsAliasListContext)!;
    }
    public COMMA(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.COMMA, 0);
    }
    public columnName(): ColumnNameContext | null {
        return this.getRuleContext(0, ColumnNameContext);
    }
    public columnNameList(): ColumnNameListContext | null {
        return this.getRuleContext(0, ColumnNameListContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_pivotBody;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterPivotBody) {
             listener.enterPivotBody(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitPivotBody) {
             listener.exitPivotBody(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitPivotBody) {
            return visitor.visitPivotBody(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ExpressionAsAliasContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public expression(): ExpressionContext {
        return this.getRuleContext(0, ExpressionContext)!;
    }
    public KW_AS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_AS, 0);
    }
    public columnAlias(): ColumnAliasContext | null {
        return this.getRuleContext(0, ColumnAliasContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_expressionAsAlias;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterExpressionAsAlias) {
             listener.enterExpressionAsAlias(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitExpressionAsAlias) {
             listener.exitExpressionAsAlias(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitExpressionAsAlias) {
            return visitor.visitExpressionAsAlias(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ExpressionAsAliasListContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public expressionAsAlias(): ExpressionAsAliasContext[];
    public expressionAsAlias(i: number): ExpressionAsAliasContext | null;
    public expressionAsAlias(i?: number): ExpressionAsAliasContext[] | ExpressionAsAliasContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ExpressionAsAliasContext);
        }

        return this.getRuleContext(i, ExpressionAsAliasContext);
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_expressionAsAliasList;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterExpressionAsAliasList) {
             listener.enterExpressionAsAliasList(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitExpressionAsAliasList) {
             listener.exitExpressionAsAliasList(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitExpressionAsAliasList) {
            return visitor.visitExpressionAsAliasList(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class SystemTimePeriodContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_FOR(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_FOR, 0)!;
    }
    public KW_SYSTEM_TIME(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_SYSTEM_TIME, 0)!;
    }
    public KW_AS(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_AS, 0)!;
    }
    public KW_OF(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_OF, 0)!;
    }
    public dateTimeExpression(): DateTimeExpressionContext {
        return this.getRuleContext(0, DateTimeExpressionContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_systemTimePeriod;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterSystemTimePeriod) {
             listener.enterSystemTimePeriod(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitSystemTimePeriod) {
             listener.exitSystemTimePeriod(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitSystemTimePeriod) {
            return visitor.visitSystemTimePeriod(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class DateTimeExpressionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public expression(): ExpressionContext {
        return this.getRuleContext(0, ExpressionContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_dateTimeExpression;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterDateTimeExpression) {
             listener.enterDateTimeExpression(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitDateTimeExpression) {
             listener.exitDateTimeExpression(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitDateTimeExpression) {
            return visitor.visitDateTimeExpression(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class InlineDataValueClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public expression(): ExpressionContext[];
    public expression(i: number): ExpressionContext | null;
    public expression(i?: number): ExpressionContext[] | ExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ExpressionContext);
        }

        return this.getRuleContext(i, ExpressionContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public tableAlias(): TableAliasContext | null {
        return this.getRuleContext(0, TableAliasContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_inlineDataValueClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterInlineDataValueClause) {
             listener.enterInlineDataValueClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitInlineDataValueClause) {
             listener.exitInlineDataValueClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitInlineDataValueClause) {
            return visitor.visitInlineDataValueClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class WindowTVFClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_TABLE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_TABLE, 0)!;
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public windowTVFExpression(): WindowTVFExpressionContext {
        return this.getRuleContext(0, WindowTVFExpressionContext)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_windowTVFClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterWindowTVFClause) {
             listener.enterWindowTVFClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitWindowTVFClause) {
             listener.exitWindowTVFClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitWindowTVFClause) {
            return visitor.visitWindowTVFClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class WindowTVFExpressionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public windowTVFName(): WindowTVFNameContext {
        return this.getRuleContext(0, WindowTVFNameContext)!;
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public windowTVFParam(): WindowTVFParamContext[];
    public windowTVFParam(i: number): WindowTVFParamContext | null;
    public windowTVFParam(i?: number): WindowTVFParamContext[] | WindowTVFParamContext | null {
        if (i === undefined) {
            return this.getRuleContexts(WindowTVFParamContext);
        }

        return this.getRuleContext(i, WindowTVFParamContext);
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_windowTVFExpression;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterWindowTVFExpression) {
             listener.enterWindowTVFExpression(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitWindowTVFExpression) {
             listener.exitWindowTVFExpression(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitWindowTVFExpression) {
            return visitor.visitWindowTVFExpression(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class WindowTVFNameContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_TUMBLE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TUMBLE, 0);
    }
    public KW_HOP(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_HOP, 0);
    }
    public KW_CUMULATE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_CUMULATE, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_windowTVFName;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterWindowTVFName) {
             listener.enterWindowTVFName(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitWindowTVFName) {
             listener.exitWindowTVFName(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitWindowTVFName) {
            return visitor.visitWindowTVFName(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class RowFormatDelimitedContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public sparkRecordWriterPart(): SparkRecordWriterPartContext[];
    public sparkRecordWriterPart(i: number): SparkRecordWriterPartContext | null;
    public sparkRecordWriterPart(i?: number): SparkRecordWriterPartContext[] | SparkRecordWriterPartContext | null {
        if (i === undefined) {
            return this.getRuleContexts(SparkRecordWriterPartContext);
        }

        return this.getRuleContext(i, SparkRecordWriterPartContext);
    }
    public usingAsColumnPart(): UsingAsColumnPartContext {
        return this.getRuleContext(0, UsingAsColumnPartContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_rowFormatDelimited;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterRowFormatDelimited) {
             listener.enterRowFormatDelimited(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitRowFormatDelimited) {
             listener.exitRowFormatDelimited(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitRowFormatDelimited) {
            return visitor.visitRowFormatDelimited(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class HiveSerdeContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public hiveSerdePart(): HiveSerdePartContext[];
    public hiveSerdePart(i: number): HiveSerdePartContext | null;
    public hiveSerdePart(i?: number): HiveSerdePartContext[] | HiveSerdePartContext | null {
        if (i === undefined) {
            return this.getRuleContexts(HiveSerdePartContext);
        }

        return this.getRuleContext(i, HiveSerdePartContext);
    }
    public usingAsColumnPart(): UsingAsColumnPartContext {
        return this.getRuleContext(0, UsingAsColumnPartContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_hiveSerde;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterHiveSerde) {
             listener.enterHiveSerde(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitHiveSerde) {
             listener.exitHiveSerde(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitHiveSerde) {
            return visitor.visitHiveSerde(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class UsingAsColumnPartContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_USING(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_USING, 0)!;
    }
    public stringLiteral(): StringLiteralContext {
        return this.getRuleContext(0, StringLiteralContext)!;
    }
    public KW_AS(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_AS, 0)!;
    }
    public columnNameList(): ColumnNameListContext | null {
        return this.getRuleContext(0, ColumnNameListContext);
    }
    public physicalColumnDefinitionList(): PhysicalColumnDefinitionListContext | null {
        return this.getRuleContext(0, PhysicalColumnDefinitionListContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_usingAsColumnPart;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterUsingAsColumnPart) {
             listener.enterUsingAsColumnPart(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitUsingAsColumnPart) {
             listener.exitUsingAsColumnPart(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitUsingAsColumnPart) {
            return visitor.visitUsingAsColumnPart(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class HiveSerdePartContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_ROW(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ROW, 0);
    }
    public KW_FORMAT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FORMAT, 0);
    }
    public KW_SERDE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SERDE, 0);
    }
    public stringLiteral(): StringLiteralContext | null {
        return this.getRuleContext(0, StringLiteralContext);
    }
    public KW_WITH(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_WITH, 0);
    }
    public KW_SERDEPROPERTIES(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SERDEPROPERTIES, 0);
    }
    public tableCanHasKeyPropertyList(): TableCanHasKeyPropertyListContext | null {
        return this.getRuleContext(0, TableCanHasKeyPropertyListContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_hiveSerdePart;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterHiveSerdePart) {
             listener.enterHiveSerdePart(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitHiveSerdePart) {
             listener.exitHiveSerdePart(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitHiveSerdePart) {
            return visitor.visitHiveSerdePart(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class TableCanHasKeyPropertyListContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public tableProperty(): TablePropertyContext[];
    public tableProperty(i: number): TablePropertyContext | null;
    public tableProperty(i?: number): TablePropertyContext[] | TablePropertyContext | null {
        if (i === undefined) {
            return this.getRuleContexts(TablePropertyContext);
        }

        return this.getRuleContext(i, TablePropertyContext);
    }
    public tablePropertyKey(): TablePropertyKeyContext[];
    public tablePropertyKey(i: number): TablePropertyKeyContext | null;
    public tablePropertyKey(i?: number): TablePropertyKeyContext[] | TablePropertyKeyContext | null {
        if (i === undefined) {
            return this.getRuleContexts(TablePropertyKeyContext);
        }

        return this.getRuleContext(i, TablePropertyKeyContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_tableCanHasKeyPropertyList;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterTableCanHasKeyPropertyList) {
             listener.enterTableCanHasKeyPropertyList(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitTableCanHasKeyPropertyList) {
             listener.exitTableCanHasKeyPropertyList(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitTableCanHasKeyPropertyList) {
            return visitor.visitTableCanHasKeyPropertyList(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class SparkRecordWriterPartContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public rowFormatDelimted(): RowFormatDelimtedContext | null {
        return this.getRuleContext(0, RowFormatDelimtedContext);
    }
    public fieldsTerminatedBy(): FieldsTerminatedByContext | null {
        return this.getRuleContext(0, FieldsTerminatedByContext);
    }
    public KW_LINES(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LINES, 0);
    }
    public KW_TERMINATED(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TERMINATED, 0);
    }
    public KW_BY(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_BY, 0);
    }
    public stringLiteral(): StringLiteralContext[];
    public stringLiteral(i: number): StringLiteralContext | null;
    public stringLiteral(i?: number): StringLiteralContext[] | StringLiteralContext | null {
        if (i === undefined) {
            return this.getRuleContexts(StringLiteralContext);
        }

        return this.getRuleContext(i, StringLiteralContext);
    }
    public KW_NULL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NULL, 0);
    }
    public KW_DEFINED(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DEFINED, 0);
    }
    public KW_AS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_AS, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_sparkRecordWriterPart;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterSparkRecordWriterPart) {
             listener.enterSparkRecordWriterPart(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitSparkRecordWriterPart) {
             listener.exitSparkRecordWriterPart(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitSparkRecordWriterPart) {
            return visitor.visitSparkRecordWriterPart(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class WindowTVFParamContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_TABLE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TABLE, 0);
    }
    public timeAttrColumn(): TimeAttrColumnContext | null {
        return this.getRuleContext(0, TimeAttrColumnContext);
    }
    public columnDescriptor(): ColumnDescriptorContext | null {
        return this.getRuleContext(0, ColumnDescriptorContext);
    }
    public timeIntervalExpression(): TimeIntervalExpressionContext | null {
        return this.getRuleContext(0, TimeIntervalExpressionContext);
    }
    public KW_DATA(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DATA, 0);
    }
    public DOUBLE_RIGHT_ARROW(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.DOUBLE_RIGHT_ARROW, 0);
    }
    public KW_TIMECOL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TIMECOL, 0);
    }
    public timeIntervalParamName(): TimeIntervalParamNameContext | null {
        return this.getRuleContext(0, TimeIntervalParamNameContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_windowTVFParam;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterWindowTVFParam) {
             listener.enterWindowTVFParam(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitWindowTVFParam) {
             listener.exitWindowTVFParam(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitWindowTVFParam) {
            return visitor.visitWindowTVFParam(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class TimeIntervalParamNameContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_DATA(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DATA, 0);
    }
    public KW_TIMECOL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TIMECOL, 0);
    }
    public KW_SIZE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SIZE, 0);
    }
    public KW_OFFSET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_OFFSET, 0);
    }
    public KW_STEP(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_STEP, 0);
    }
    public KW_SLIDE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SLIDE, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_timeIntervalParamName;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterTimeIntervalParamName) {
             listener.enterTimeIntervalParamName(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitTimeIntervalParamName) {
             listener.exitTimeIntervalParamName(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitTimeIntervalParamName) {
            return visitor.visitTimeIntervalParamName(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ColumnDescriptorContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_DESCRIPTOR(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_DESCRIPTOR, 0)!;
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public uid(): UidContext {
        return this.getRuleContext(0, UidContext)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_columnDescriptor;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterColumnDescriptor) {
             listener.enterColumnDescriptor(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitColumnDescriptor) {
             listener.exitColumnDescriptor(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitColumnDescriptor) {
            return visitor.visitColumnDescriptor(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class JoinConditionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_ON(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ON, 0);
    }
    public booleanExpression(): BooleanExpressionContext | null {
        return this.getRuleContext(0, BooleanExpressionContext);
    }
    public KW_USING(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_USING, 0);
    }
    public LR_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0);
    }
    public uid(): UidContext[];
    public uid(i: number): UidContext | null;
    public uid(i?: number): UidContext[] | UidContext | null {
        if (i === undefined) {
            return this.getRuleContexts(UidContext);
        }

        return this.getRuleContext(i, UidContext);
    }
    public RR_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_joinCondition;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterJoinCondition) {
             listener.enterJoinCondition(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitJoinCondition) {
             listener.exitJoinCondition(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitJoinCondition) {
            return visitor.visitJoinCondition(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class WhereClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_WHERE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_WHERE, 0)!;
    }
    public booleanExpression(): BooleanExpressionContext {
        return this.getRuleContext(0, BooleanExpressionContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_whereClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterWhereClause) {
             listener.enterWhereClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitWhereClause) {
             listener.exitWhereClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitWhereClause) {
            return visitor.visitWhereClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class SamplingQueriesContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_TABLESAMPLE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_TABLESAMPLE, 0)!;
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public KW_PERCENT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PERCENT, 0);
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public decimalLiteral(): DecimalLiteralContext | null {
        return this.getRuleContext(0, DecimalLiteralContext);
    }
    public DIG_LITERAL(): antlr.TerminalNode[];
    public DIG_LITERAL(i: number): antlr.TerminalNode | null;
    public DIG_LITERAL(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.DIG_LITERAL);
    	} else {
    		return this.getToken(SparkSQLParser.DIG_LITERAL, i);
    	}
    }
    public expression(): ExpressionContext[];
    public expression(i: number): ExpressionContext | null;
    public expression(i?: number): ExpressionContext[] | ExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ExpressionContext);
        }

        return this.getRuleContext(i, ExpressionContext);
    }
    public KW_ROWS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ROWS, 0);
    }
    public KW_BUCKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_BUCKET, 0);
    }
    public KW_OUT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_OUT, 0);
    }
    public KW_OF(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_OF, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_samplingQueries;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterSamplingQueries) {
             listener.enterSamplingQueries(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitSamplingQueries) {
             listener.exitSamplingQueries(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitSamplingQueries) {
            return visitor.visitSamplingQueries(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class SomeByClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public clusteredByClause(): ClusteredByClauseContext | null {
        return this.getRuleContext(0, ClusteredByClauseContext);
    }
    public clusterByClause(): ClusterByClauseContext | null {
        return this.getRuleContext(0, ClusterByClauseContext);
    }
    public distributeByClause(): DistributeByClauseContext | null {
        return this.getRuleContext(0, DistributeByClauseContext);
    }
    public groupByClause(): GroupByClauseContext | null {
        return this.getRuleContext(0, GroupByClauseContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_someByClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterSomeByClause) {
             listener.enterSomeByClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitSomeByClause) {
             listener.exitSomeByClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitSomeByClause) {
            return visitor.visitSomeByClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ClusterByClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_CLUSTER(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_CLUSTER, 0)!;
    }
    public KW_BY(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_BY, 0)!;
    }
    public groupItemDefinition(): GroupItemDefinitionContext[];
    public groupItemDefinition(i: number): GroupItemDefinitionContext | null;
    public groupItemDefinition(i?: number): GroupItemDefinitionContext[] | GroupItemDefinitionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(GroupItemDefinitionContext);
        }

        return this.getRuleContext(i, GroupItemDefinitionContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_clusterByClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterClusterByClause) {
             listener.enterClusterByClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitClusterByClause) {
             listener.exitClusterByClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitClusterByClause) {
            return visitor.visitClusterByClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ClusteredByClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_CLUSTERED(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_CLUSTERED, 0)!;
    }
    public KW_BY(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_BY, 0)!;
    }
    public groupItemDefinition(): GroupItemDefinitionContext[];
    public groupItemDefinition(i: number): GroupItemDefinitionContext | null;
    public groupItemDefinition(i?: number): GroupItemDefinitionContext[] | GroupItemDefinitionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(GroupItemDefinitionContext);
        }

        return this.getRuleContext(i, GroupItemDefinitionContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_clusteredByClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterClusteredByClause) {
             listener.enterClusteredByClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitClusteredByClause) {
             listener.exitClusteredByClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitClusteredByClause) {
            return visitor.visitClusteredByClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class DistributeByClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_DISTRIBUTE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_DISTRIBUTE, 0)!;
    }
    public KW_BY(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_BY, 0)!;
    }
    public groupItemDefinition(): GroupItemDefinitionContext[];
    public groupItemDefinition(i: number): GroupItemDefinitionContext | null;
    public groupItemDefinition(i?: number): GroupItemDefinitionContext[] | GroupItemDefinitionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(GroupItemDefinitionContext);
        }

        return this.getRuleContext(i, GroupItemDefinitionContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_distributeByClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterDistributeByClause) {
             listener.enterDistributeByClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitDistributeByClause) {
             listener.exitDistributeByClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitDistributeByClause) {
            return visitor.visitDistributeByClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class GroupByClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_GROUP(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_GROUP, 0)!;
    }
    public KW_BY(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_BY, 0)!;
    }
    public groupItemDefinition(): GroupItemDefinitionContext[];
    public groupItemDefinition(i: number): GroupItemDefinitionContext | null;
    public groupItemDefinition(i?: number): GroupItemDefinitionContext[] | GroupItemDefinitionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(GroupItemDefinitionContext);
        }

        return this.getRuleContext(i, GroupItemDefinitionContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public KW_WITH(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_WITH, 0);
    }
    public groupingSetsNotionName(): GroupingSetsNotionNameContext | null {
        return this.getRuleContext(0, GroupingSetsNotionNameContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_groupByClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterGroupByClause) {
             listener.enterGroupByClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitGroupByClause) {
             listener.exitGroupByClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitGroupByClause) {
            return visitor.visitGroupByClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class GroupItemDefinitionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public expression(): ExpressionContext[];
    public expression(i: number): ExpressionContext | null;
    public expression(i?: number): ExpressionContext[] | ExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ExpressionContext);
        }

        return this.getRuleContext(i, ExpressionContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public groupWindowFunction(): GroupWindowFunctionContext | null {
        return this.getRuleContext(0, GroupWindowFunctionContext);
    }
    public LR_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0);
    }
    public RR_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0);
    }
    public groupingSetsNotionName(): GroupingSetsNotionNameContext | null {
        return this.getRuleContext(0, GroupingSetsNotionNameContext);
    }
    public groupingSets(): GroupingSetsContext | null {
        return this.getRuleContext(0, GroupingSetsContext);
    }
    public groupItemDefinition(): GroupItemDefinitionContext[];
    public groupItemDefinition(i: number): GroupItemDefinitionContext | null;
    public groupItemDefinition(i?: number): GroupItemDefinitionContext[] | GroupItemDefinitionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(GroupItemDefinitionContext);
        }

        return this.getRuleContext(i, GroupItemDefinitionContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_groupItemDefinition;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterGroupItemDefinition) {
             listener.enterGroupItemDefinition(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitGroupItemDefinition) {
             listener.exitGroupItemDefinition(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitGroupItemDefinition) {
            return visitor.visitGroupItemDefinition(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class GroupingSetsContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_GROUPING(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_GROUPING, 0)!;
    }
    public KW_SETS(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_SETS, 0)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_groupingSets;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterGroupingSets) {
             listener.enterGroupingSets(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitGroupingSets) {
             listener.exitGroupingSets(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitGroupingSets) {
            return visitor.visitGroupingSets(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class GroupingSetsNotionNameContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_CUBE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_CUBE, 0);
    }
    public KW_ROLLUP(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ROLLUP, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_groupingSetsNotionName;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterGroupingSetsNotionName) {
             listener.enterGroupingSetsNotionName(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitGroupingSetsNotionName) {
             listener.exitGroupingSetsNotionName(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitGroupingSetsNotionName) {
            return visitor.visitGroupingSetsNotionName(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class GroupWindowFunctionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public groupWindowFunctionName(): GroupWindowFunctionNameContext {
        return this.getRuleContext(0, GroupWindowFunctionNameContext)!;
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public timeAttrColumn(): TimeAttrColumnContext {
        return this.getRuleContext(0, TimeAttrColumnContext)!;
    }
    public COMMA(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.COMMA, 0)!;
    }
    public timeIntervalExpression(): TimeIntervalExpressionContext {
        return this.getRuleContext(0, TimeIntervalExpressionContext)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_groupWindowFunction;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterGroupWindowFunction) {
             listener.enterGroupWindowFunction(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitGroupWindowFunction) {
             listener.exitGroupWindowFunction(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitGroupWindowFunction) {
            return visitor.visitGroupWindowFunction(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class GroupWindowFunctionNameContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_TUMBLE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TUMBLE, 0);
    }
    public KW_HOP(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_HOP, 0);
    }
    public KW_SESSION(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SESSION, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_groupWindowFunctionName;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterGroupWindowFunctionName) {
             listener.enterGroupWindowFunctionName(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitGroupWindowFunctionName) {
             listener.exitGroupWindowFunctionName(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitGroupWindowFunctionName) {
            return visitor.visitGroupWindowFunctionName(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class TimeAttrColumnContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public uid(): UidContext {
        return this.getRuleContext(0, UidContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_timeAttrColumn;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterTimeAttrColumn) {
             listener.enterTimeAttrColumn(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitTimeAttrColumn) {
             listener.exitTimeAttrColumn(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitTimeAttrColumn) {
            return visitor.visitTimeAttrColumn(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class HavingClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_HAVING(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_HAVING, 0)!;
    }
    public booleanExpression(): BooleanExpressionContext {
        return this.getRuleContext(0, BooleanExpressionContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_havingClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterHavingClause) {
             listener.enterHavingClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitHavingClause) {
             listener.exitHavingClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitHavingClause) {
            return visitor.visitHavingClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class WindowClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_WINDOW(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_WINDOW, 0)!;
    }
    public namedWindow(): NamedWindowContext[];
    public namedWindow(i: number): NamedWindowContext | null;
    public namedWindow(i?: number): NamedWindowContext[] | NamedWindowContext | null {
        if (i === undefined) {
            return this.getRuleContexts(NamedWindowContext);
        }

        return this.getRuleContext(i, NamedWindowContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_windowClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterWindowClause) {
             listener.enterWindowClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitWindowClause) {
             listener.exitWindowClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitWindowClause) {
            return visitor.visitWindowClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class NamedWindowContext extends antlr.ParserRuleContext {
    public _name?: ErrorCapturingIdentifierContext;
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_AS(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_AS, 0)!;
    }
    public windowSpec(): WindowSpecContext {
        return this.getRuleContext(0, WindowSpecContext)!;
    }
    public errorCapturingIdentifier(): ErrorCapturingIdentifierContext {
        return this.getRuleContext(0, ErrorCapturingIdentifierContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_namedWindow;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterNamedWindow) {
             listener.enterNamedWindow(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitNamedWindow) {
             listener.exitNamedWindow(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitNamedWindow) {
            return visitor.visitNamedWindow(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class WindowSpecContext extends antlr.ParserRuleContext {
    public _name?: ErrorCapturingIdentifierContext;
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public partitionByClause(): PartitionByClauseContext | null {
        return this.getRuleContext(0, PartitionByClauseContext);
    }
    public sortByCaluse(): SortByCaluseContext | null {
        return this.getRuleContext(0, SortByCaluseContext);
    }
    public orderByCaluse(): OrderByCaluseContext | null {
        return this.getRuleContext(0, OrderByCaluseContext);
    }
    public windowFrame(): WindowFrameContext | null {
        return this.getRuleContext(0, WindowFrameContext);
    }
    public errorCapturingIdentifier(): ErrorCapturingIdentifierContext | null {
        return this.getRuleContext(0, ErrorCapturingIdentifierContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_windowSpec;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterWindowSpec) {
             listener.enterWindowSpec(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitWindowSpec) {
             listener.exitWindowSpec(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitWindowSpec) {
            return visitor.visitWindowSpec(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class MatchRecognizeClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_MATCH_RECOGNIZE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_MATCH_RECOGNIZE, 0)!;
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public patternVariablesDefinition(): PatternVariablesDefinitionContext {
        return this.getRuleContext(0, PatternVariablesDefinitionContext)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public partitionByClause(): PartitionByClauseContext | null {
        return this.getRuleContext(0, PartitionByClauseContext);
    }
    public sortByCaluse(): SortByCaluseContext | null {
        return this.getRuleContext(0, SortByCaluseContext);
    }
    public orderByCaluse(): OrderByCaluseContext | null {
        return this.getRuleContext(0, OrderByCaluseContext);
    }
    public measuresClause(): MeasuresClauseContext | null {
        return this.getRuleContext(0, MeasuresClauseContext);
    }
    public outputMode(): OutputModeContext | null {
        return this.getRuleContext(0, OutputModeContext);
    }
    public afterMatchStrategy(): AfterMatchStrategyContext | null {
        return this.getRuleContext(0, AfterMatchStrategyContext);
    }
    public patternDefinition(): PatternDefinitionContext | null {
        return this.getRuleContext(0, PatternDefinitionContext);
    }
    public identifier(): IdentifierContext | null {
        return this.getRuleContext(0, IdentifierContext);
    }
    public KW_AS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_AS, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_matchRecognizeClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterMatchRecognizeClause) {
             listener.enterMatchRecognizeClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitMatchRecognizeClause) {
             listener.exitMatchRecognizeClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitMatchRecognizeClause) {
            return visitor.visitMatchRecognizeClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class OrderByCaluseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_ORDER(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_ORDER, 0)!;
    }
    public KW_BY(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_BY, 0)!;
    }
    public orderItemDefinition(): OrderItemDefinitionContext[];
    public orderItemDefinition(i: number): OrderItemDefinitionContext | null;
    public orderItemDefinition(i?: number): OrderItemDefinitionContext[] | OrderItemDefinitionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(OrderItemDefinitionContext);
        }

        return this.getRuleContext(i, OrderItemDefinitionContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_orderByCaluse;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterOrderByCaluse) {
             listener.enterOrderByCaluse(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitOrderByCaluse) {
             listener.exitOrderByCaluse(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitOrderByCaluse) {
            return visitor.visitOrderByCaluse(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class SortByCaluseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_SORT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_SORT, 0)!;
    }
    public KW_BY(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_BY, 0)!;
    }
    public orderItemDefinition(): OrderItemDefinitionContext[];
    public orderItemDefinition(i: number): OrderItemDefinitionContext | null;
    public orderItemDefinition(i?: number): OrderItemDefinitionContext[] | OrderItemDefinitionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(OrderItemDefinitionContext);
        }

        return this.getRuleContext(i, OrderItemDefinitionContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_sortByCaluse;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterSortByCaluse) {
             listener.enterSortByCaluse(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitSortByCaluse) {
             listener.exitSortByCaluse(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitSortByCaluse) {
            return visitor.visitSortByCaluse(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class OrderItemDefinitionContext extends antlr.ParserRuleContext {
    public _ordering?: Token | null;
    public _nullOrder?: Token | null;
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public expression(): ExpressionContext {
        return this.getRuleContext(0, ExpressionContext)!;
    }
    public KW_NULLS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NULLS, 0);
    }
    public KW_ASC(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ASC, 0);
    }
    public KW_DESC(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DESC, 0);
    }
    public KW_LAST(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LAST, 0);
    }
    public KW_FIRST(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FIRST, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_orderItemDefinition;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterOrderItemDefinition) {
             listener.enterOrderItemDefinition(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitOrderItemDefinition) {
             listener.exitOrderItemDefinition(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitOrderItemDefinition) {
            return visitor.visitOrderItemDefinition(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class LimitClauseContext extends antlr.ParserRuleContext {
    public _limit?: ExpressionContext;
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_LIMIT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_LIMIT, 0)!;
    }
    public KW_ALL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ALL, 0);
    }
    public expression(): ExpressionContext | null {
        return this.getRuleContext(0, ExpressionContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_limitClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterLimitClause) {
             listener.enterLimitClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitLimitClause) {
             listener.exitLimitClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitLimitClause) {
            return visitor.visitLimitClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class OffsetClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_OFFSET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_OFFSET, 0)!;
    }
    public DIG_LITERAL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.DIG_LITERAL, 0);
    }
    public expression(): ExpressionContext | null {
        return this.getRuleContext(0, ExpressionContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_offsetClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterOffsetClause) {
             listener.enterOffsetClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitOffsetClause) {
             listener.exitOffsetClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitOffsetClause) {
            return visitor.visitOffsetClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class PartitionByClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_PARTITION(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_PARTITION, 0)!;
    }
    public KW_BY(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_BY, 0)!;
    }
    public expression(): ExpressionContext[];
    public expression(i: number): ExpressionContext | null;
    public expression(i?: number): ExpressionContext[] | ExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ExpressionContext);
        }

        return this.getRuleContext(i, ExpressionContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_partitionByClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterPartitionByClause) {
             listener.enterPartitionByClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitPartitionByClause) {
             listener.exitPartitionByClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitPartitionByClause) {
            return visitor.visitPartitionByClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class QuantifiersContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public ASTERISK_SIGN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.ASTERISK_SIGN, 0);
    }
    public ADD_SIGN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.ADD_SIGN, 0);
    }
    public QUESTION_MARK_SIGN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.QUESTION_MARK_SIGN, 0);
    }
    public LB_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.LB_BRACKET, 0);
    }
    public DIG_LITERAL(): antlr.TerminalNode[];
    public DIG_LITERAL(i: number): antlr.TerminalNode | null;
    public DIG_LITERAL(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.DIG_LITERAL);
    	} else {
    		return this.getToken(SparkSQLParser.DIG_LITERAL, i);
    	}
    }
    public COMMA(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.COMMA, 0);
    }
    public RB_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.RB_BRACKET, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_quantifiers;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterQuantifiers) {
             listener.enterQuantifiers(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitQuantifiers) {
             listener.exitQuantifiers(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitQuantifiers) {
            return visitor.visitQuantifiers(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class MeasuresClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_MEASURES(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_MEASURES, 0)!;
    }
    public projectItemDefinition(): ProjectItemDefinitionContext[];
    public projectItemDefinition(i: number): ProjectItemDefinitionContext | null;
    public projectItemDefinition(i?: number): ProjectItemDefinitionContext[] | ProjectItemDefinitionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ProjectItemDefinitionContext);
        }

        return this.getRuleContext(i, ProjectItemDefinitionContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_measuresClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterMeasuresClause) {
             listener.enterMeasuresClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitMeasuresClause) {
             listener.exitMeasuresClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitMeasuresClause) {
            return visitor.visitMeasuresClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class PatternDefinitionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_PATTERN(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_PATTERN, 0)!;
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public patternVariable(): PatternVariableContext[];
    public patternVariable(i: number): PatternVariableContext | null;
    public patternVariable(i?: number): PatternVariableContext[] | PatternVariableContext | null {
        if (i === undefined) {
            return this.getRuleContexts(PatternVariableContext);
        }

        return this.getRuleContext(i, PatternVariableContext);
    }
    public withinClause(): WithinClauseContext | null {
        return this.getRuleContext(0, WithinClauseContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_patternDefinition;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterPatternDefinition) {
             listener.enterPatternDefinition(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitPatternDefinition) {
             listener.exitPatternDefinition(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitPatternDefinition) {
            return visitor.visitPatternDefinition(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class PatternVariableContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public unquotedIdentifier(): UnquotedIdentifierContext {
        return this.getRuleContext(0, UnquotedIdentifierContext)!;
    }
    public quantifiers(): QuantifiersContext | null {
        return this.getRuleContext(0, QuantifiersContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_patternVariable;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterPatternVariable) {
             listener.enterPatternVariable(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitPatternVariable) {
             listener.exitPatternVariable(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitPatternVariable) {
            return visitor.visitPatternVariable(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class OutputModeContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_ALL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ALL, 0);
    }
    public KW_ROWS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ROWS, 0);
    }
    public KW_PER(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_PER, 0)!;
    }
    public KW_MATCH(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_MATCH, 0)!;
    }
    public KW_ONE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ONE, 0);
    }
    public KW_ROW(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ROW, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_outputMode;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterOutputMode) {
             listener.enterOutputMode(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitOutputMode) {
             listener.exitOutputMode(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitOutputMode) {
            return visitor.visitOutputMode(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class AfterMatchStrategyContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_AFTER(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_AFTER, 0)!;
    }
    public KW_MATCH(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_MATCH, 0)!;
    }
    public KW_SKIP(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_SKIP, 0)!;
    }
    public KW_PAST(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PAST, 0);
    }
    public KW_LAST(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LAST, 0);
    }
    public KW_ROW(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ROW, 0);
    }
    public KW_TO(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TO, 0);
    }
    public KW_NEXT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NEXT, 0);
    }
    public unquotedIdentifier(): UnquotedIdentifierContext | null {
        return this.getRuleContext(0, UnquotedIdentifierContext);
    }
    public KW_FIRST(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FIRST, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_afterMatchStrategy;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterAfterMatchStrategy) {
             listener.enterAfterMatchStrategy(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitAfterMatchStrategy) {
             listener.exitAfterMatchStrategy(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitAfterMatchStrategy) {
            return visitor.visitAfterMatchStrategy(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class PatternVariablesDefinitionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_DEFINE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_DEFINE, 0)!;
    }
    public projectItemDefinition(): ProjectItemDefinitionContext[];
    public projectItemDefinition(i: number): ProjectItemDefinitionContext | null;
    public projectItemDefinition(i?: number): ProjectItemDefinitionContext[] | ProjectItemDefinitionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ProjectItemDefinitionContext);
        }

        return this.getRuleContext(i, ProjectItemDefinitionContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_patternVariablesDefinition;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterPatternVariablesDefinition) {
             listener.enterPatternVariablesDefinition(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitPatternVariablesDefinition) {
             listener.exitPatternVariablesDefinition(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitPatternVariablesDefinition) {
            return visitor.visitPatternVariablesDefinition(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class WindowFrameContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_RANGE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_RANGE, 0);
    }
    public KW_BETWEEN(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_BETWEEN, 0)!;
    }
    public timeIntervalExpression(): TimeIntervalExpressionContext | null {
        return this.getRuleContext(0, TimeIntervalExpressionContext);
    }
    public frameBound(): FrameBoundContext {
        return this.getRuleContext(0, FrameBoundContext)!;
    }
    public KW_ROWS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ROWS, 0);
    }
    public DIG_LITERAL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.DIG_LITERAL, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_windowFrame;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterWindowFrame) {
             listener.enterWindowFrame(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitWindowFrame) {
             listener.exitWindowFrame(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitWindowFrame) {
            return visitor.visitWindowFrame(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class FrameBoundContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_PRECEDING(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_PRECEDING, 0)!;
    }
    public KW_AND(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_AND, 0)!;
    }
    public KW_CURRENT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_CURRENT, 0)!;
    }
    public KW_ROW(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_ROW, 0)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_frameBound;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterFrameBound) {
             listener.enterFrameBound(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitFrameBound) {
             listener.exitFrameBound(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitFrameBound) {
            return visitor.visitFrameBound(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class WithinClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_WITHIN(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_WITHIN, 0)!;
    }
    public timeIntervalExpression(): TimeIntervalExpressionContext {
        return this.getRuleContext(0, TimeIntervalExpressionContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_withinClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterWithinClause) {
             listener.enterWithinClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitWithinClause) {
             listener.exitWithinClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitWithinClause) {
            return visitor.visitWithinClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class SelfDefinitionClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_PERIOD(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_PERIOD, 0)!;
    }
    public KW_FOR(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_FOR, 0)!;
    }
    public KW_SYSTEM_TIME(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_SYSTEM_TIME, 0)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_selfDefinitionClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterSelfDefinitionClause) {
             listener.enterSelfDefinitionClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitSelfDefinitionClause) {
             listener.exitSelfDefinitionClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitSelfDefinitionClause) {
            return visitor.visitSelfDefinitionClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class PartitionDefinitionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_PARTITIONED(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_PARTITIONED, 0)!;
    }
    public KW_BY(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_BY, 0)!;
    }
    public transformList(): TransformListContext {
        return this.getRuleContext(0, TransformListContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_partitionDefinition;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterPartitionDefinition) {
             listener.enterPartitionDefinition(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitPartitionDefinition) {
             listener.exitPartitionDefinition(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitPartitionDefinition) {
            return visitor.visitPartitionDefinition(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class TransformListContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public transform(): TransformContext[];
    public transform(i: number): TransformContext | null;
    public transform(i?: number): TransformContext[] | TransformContext | null {
        if (i === undefined) {
            return this.getRuleContexts(TransformContext);
        }

        return this.getRuleContext(i, TransformContext);
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public dataTypeExpression(): DataTypeExpressionContext[];
    public dataTypeExpression(i: number): DataTypeExpressionContext | null;
    public dataTypeExpression(i?: number): DataTypeExpressionContext[] | DataTypeExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(DataTypeExpressionContext);
        }

        return this.getRuleContext(i, DataTypeExpressionContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_transformList;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterTransformList) {
             listener.enterTransformList(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitTransformList) {
             listener.exitTransformList(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitTransformList) {
            return visitor.visitTransformList(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class TransformContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_transform;
    }
    public override copyFrom(ctx: TransformContext): void {
        super.copyFrom(ctx);
    }
}
export class IdentityTransformContext extends TransformContext {
    public constructor(ctx: TransformContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public qualifiedName(): QualifiedNameContext {
        return this.getRuleContext(0, QualifiedNameContext)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterIdentityTransform) {
             listener.enterIdentityTransform(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitIdentityTransform) {
             listener.exitIdentityTransform(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitIdentityTransform) {
            return visitor.visitIdentityTransform(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class ApplyTransformContext extends TransformContext {
    public _transformName?: IdentifierContext;
    public constructor(ctx: TransformContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public transformArgument(): TransformArgumentContext[];
    public transformArgument(i: number): TransformArgumentContext | null;
    public transformArgument(i?: number): TransformArgumentContext[] | TransformArgumentContext | null {
        if (i === undefined) {
            return this.getRuleContexts(TransformArgumentContext);
        }

        return this.getRuleContext(i, TransformArgumentContext);
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public identifier(): IdentifierContext {
        return this.getRuleContext(0, IdentifierContext)!;
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterApplyTransform) {
             listener.enterApplyTransform(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitApplyTransform) {
             listener.exitApplyTransform(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitApplyTransform) {
            return visitor.visitApplyTransform(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class TransformArgumentContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public qualifiedName(): QualifiedNameContext | null {
        return this.getRuleContext(0, QualifiedNameContext);
    }
    public constant(): ConstantContext | null {
        return this.getRuleContext(0, ConstantContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_transformArgument;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterTransformArgument) {
             listener.enterTransformArgument(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitTransformArgument) {
             listener.exitTransformArgument(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitTransformArgument) {
            return visitor.visitTransformArgument(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class LikeDefinitionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_LIKE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_LIKE, 0)!;
    }
    public tablePath(): TablePathContext {
        return this.getRuleContext(0, TablePathContext)!;
    }
    public LR_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0);
    }
    public RR_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0);
    }
    public likeOption(): LikeOptionContext[];
    public likeOption(i: number): LikeOptionContext | null;
    public likeOption(i?: number): LikeOptionContext[] | LikeOptionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(LikeOptionContext);
        }

        return this.getRuleContext(i, LikeOptionContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_likeDefinition;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterLikeDefinition) {
             listener.enterLikeDefinition(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitLikeDefinition) {
             listener.exitLikeDefinition(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitLikeDefinition) {
            return visitor.visitLikeDefinition(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class DistributionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_DISTRIBUTED(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_DISTRIBUTED, 0)!;
    }
    public KW_BY(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_BY, 0);
    }
    public LR_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0);
    }
    public identifier(): IdentifierContext | null {
        return this.getRuleContext(0, IdentifierContext);
    }
    public RR_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0);
    }
    public intoBuckets(): IntoBucketsContext | null {
        return this.getRuleContext(0, IntoBucketsContext);
    }
    public KW_HASH(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_HASH, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_distribution;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterDistribution) {
             listener.enterDistribution(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitDistribution) {
             listener.exitDistribution(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitDistribution) {
            return visitor.visitDistribution(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class UsingContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_USING(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_USING, 0)!;
    }
    public ID_LITERAL(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.ID_LITERAL, 0)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_using;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterUsing) {
             listener.enterUsing(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitUsing) {
             listener.exitUsing(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitUsing) {
            return visitor.visitUsing(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class LikeOptionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_INCLUDING(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_INCLUDING, 0);
    }
    public KW_EXCLUDING(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_EXCLUDING, 0);
    }
    public KW_ALL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ALL, 0);
    }
    public KW_CONSTRAINTS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_CONSTRAINTS, 0);
    }
    public KW_PARTITIONS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PARTITIONS, 0);
    }
    public KW_OVERWRITING(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_OVERWRITING, 0);
    }
    public KW_GENERATED(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_GENERATED, 0);
    }
    public KW_OPTIONS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_OPTIONS, 0);
    }
    public KW_WATERMARKS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_WATERMARKS, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_likeOption;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterLikeOption) {
             listener.enterLikeOption(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitLikeOption) {
             listener.exitLikeOption(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitLikeOption) {
            return visitor.visitLikeOption(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ColumnOptionDefinitionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public physicalColumnDefinition(): PhysicalColumnDefinitionContext | null {
        return this.getRuleContext(0, PhysicalColumnDefinitionContext);
    }
    public metadataColumnDefinition(): MetadataColumnDefinitionContext | null {
        return this.getRuleContext(0, MetadataColumnDefinitionContext);
    }
    public computedColumnDefinition(): ComputedColumnDefinitionContext | null {
        return this.getRuleContext(0, ComputedColumnDefinitionContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_columnOptionDefinition;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterColumnOptionDefinition) {
             listener.enterColumnOptionDefinition(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitColumnOptionDefinition) {
             listener.exitColumnOptionDefinition(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitColumnOptionDefinition) {
            return visitor.visitColumnOptionDefinition(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class PhysicalColumnDefinitionListContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public physicalColumnDefinition(): PhysicalColumnDefinitionContext[];
    public physicalColumnDefinition(i: number): PhysicalColumnDefinitionContext | null;
    public physicalColumnDefinition(i?: number): PhysicalColumnDefinitionContext[] | PhysicalColumnDefinitionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(PhysicalColumnDefinitionContext);
        }

        return this.getRuleContext(i, PhysicalColumnDefinitionContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_physicalColumnDefinitionList;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterPhysicalColumnDefinitionList) {
             listener.enterPhysicalColumnDefinitionList(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitPhysicalColumnDefinitionList) {
             listener.exitPhysicalColumnDefinitionList(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitPhysicalColumnDefinitionList) {
            return visitor.visitPhysicalColumnDefinitionList(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class PhysicalColumnDefinitionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public columnName(): ColumnNameContext {
        return this.getRuleContext(0, ColumnNameContext)!;
    }
    public columnType(): ColumnTypeContext {
        return this.getRuleContext(0, ColumnTypeContext)!;
    }
    public columnConstraint(): ColumnConstraintContext | null {
        return this.getRuleContext(0, ColumnConstraintContext);
    }
    public commentSpec(): CommentSpecContext | null {
        return this.getRuleContext(0, CommentSpecContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_physicalColumnDefinition;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterPhysicalColumnDefinition) {
             listener.enterPhysicalColumnDefinition(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitPhysicalColumnDefinition) {
             listener.exitPhysicalColumnDefinition(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitPhysicalColumnDefinition) {
            return visitor.visitPhysicalColumnDefinition(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ComputedColumnExpressionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public expression(): ExpressionContext {
        return this.getRuleContext(0, ExpressionContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_computedColumnExpression;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterComputedColumnExpression) {
             listener.enterComputedColumnExpression(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitComputedColumnExpression) {
             listener.exitComputedColumnExpression(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitComputedColumnExpression) {
            return visitor.visitComputedColumnExpression(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class WatermarkDefinitionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_WATERMARK(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_WATERMARK, 0)!;
    }
    public KW_FOR(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_FOR, 0)!;
    }
    public expression(): ExpressionContext[];
    public expression(i: number): ExpressionContext | null;
    public expression(i?: number): ExpressionContext[] | ExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ExpressionContext);
        }

        return this.getRuleContext(i, ExpressionContext);
    }
    public KW_AS(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_AS, 0)!;
    }
    public uid(): UidContext[];
    public uid(i: number): UidContext | null;
    public uid(i?: number): UidContext[] | UidContext | null {
        if (i === undefined) {
            return this.getRuleContexts(UidContext);
        }

        return this.getRuleContext(i, UidContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_watermarkDefinition;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterWatermarkDefinition) {
             listener.enterWatermarkDefinition(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitWatermarkDefinition) {
             listener.exitWatermarkDefinition(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitWatermarkDefinition) {
            return visitor.visitWatermarkDefinition(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class TableConstraintContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_PRIMARY(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_PRIMARY, 0)!;
    }
    public KW_KEY(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_KEY, 0)!;
    }
    public columnNameList(): ColumnNameListContext {
        return this.getRuleContext(0, ColumnNameListContext)!;
    }
    public KW_NOT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_NOT, 0)!;
    }
    public KW_ENFORCED(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_ENFORCED, 0)!;
    }
    public KW_CONSTRAINT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_CONSTRAINT, 0);
    }
    public constraintName(): ConstraintNameContext | null {
        return this.getRuleContext(0, ConstraintNameContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_tableConstraint;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterTableConstraint) {
             listener.enterTableConstraint(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitTableConstraint) {
             listener.exitTableConstraint(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitTableConstraint) {
            return visitor.visitTableConstraint(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ConstraintNameContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public identifier(): IdentifierContext {
        return this.getRuleContext(0, IdentifierContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_constraintName;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterConstraintName) {
             listener.enterConstraintName(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitConstraintName) {
             listener.exitConstraintName(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitConstraintName) {
            return visitor.visitConstraintName(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ValuesDefinitionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_VALUES(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_VALUES, 0)!;
    }
    public valuesRowDefinition(): ValuesRowDefinitionContext[];
    public valuesRowDefinition(i: number): ValuesRowDefinitionContext | null;
    public valuesRowDefinition(i?: number): ValuesRowDefinitionContext[] | ValuesRowDefinitionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ValuesRowDefinitionContext);
        }

        return this.getRuleContext(i, ValuesRowDefinitionContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_valuesDefinition;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterValuesDefinition) {
             listener.enterValuesDefinition(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitValuesDefinition) {
             listener.exitValuesDefinition(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitValuesDefinition) {
            return visitor.visitValuesDefinition(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ValuesRowDefinitionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public constant(): ConstantContext[];
    public constant(i: number): ConstantContext | null;
    public constant(i?: number): ConstantContext[] | ConstantContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ConstantContext);
        }

        return this.getRuleContext(i, ConstantContext);
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_valuesRowDefinition;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterValuesRowDefinition) {
             listener.enterValuesRowDefinition(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitValuesRowDefinition) {
             listener.exitValuesRowDefinition(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitValuesRowDefinition) {
            return visitor.visitValuesRowDefinition(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class LengthOneDimensionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public decimalLiteral(): DecimalLiteralContext {
        return this.getRuleContext(0, DecimalLiteralContext)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_lengthOneDimension;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterLengthOneDimension) {
             listener.enterLengthOneDimension(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitLengthOneDimension) {
             listener.exitLengthOneDimension(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitLengthOneDimension) {
            return visitor.visitLengthOneDimension(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class LengthTwoOptionalDimensionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public decimalLiteral(): DecimalLiteralContext[];
    public decimalLiteral(i: number): DecimalLiteralContext | null;
    public decimalLiteral(i?: number): DecimalLiteralContext[] | DecimalLiteralContext | null {
        if (i === undefined) {
            return this.getRuleContexts(DecimalLiteralContext);
        }

        return this.getRuleContext(i, DecimalLiteralContext);
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public COMMA(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.COMMA, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_lengthTwoOptionalDimension;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterLengthTwoOptionalDimension) {
             listener.enterLengthTwoOptionalDimension(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitLengthTwoOptionalDimension) {
             listener.exitLengthTwoOptionalDimension(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitLengthTwoOptionalDimension) {
            return visitor.visitLengthTwoOptionalDimension(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class LengthTwoStringDimensionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public stringLiteral(): StringLiteralContext[];
    public stringLiteral(i: number): StringLiteralContext | null;
    public stringLiteral(i?: number): StringLiteralContext[] | StringLiteralContext | null {
        if (i === undefined) {
            return this.getRuleContexts(StringLiteralContext);
        }

        return this.getRuleContext(i, StringLiteralContext);
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public COMMA(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.COMMA, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_lengthTwoStringDimension;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterLengthTwoStringDimension) {
             listener.enterLengthTwoStringDimension(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitLengthTwoStringDimension) {
             listener.exitLengthTwoStringDimension(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitLengthTwoStringDimension) {
            return visitor.visitLengthTwoStringDimension(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class LengthOneTypeDimensionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_lengthOneTypeDimension;
    }
    public override copyFrom(ctx: LengthOneTypeDimensionContext): void {
        super.copyFrom(ctx);
    }
}
export class LengthSymbolsTypeDimensionContext extends LengthOneTypeDimensionContext {
    public constructor(ctx: LengthOneTypeDimensionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public LESS_SYMBOL(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LESS_SYMBOL, 0)!;
    }
    public columnType(): ColumnTypeContext[];
    public columnType(i: number): ColumnTypeContext | null;
    public columnType(i?: number): ColumnTypeContext[] | ColumnTypeContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ColumnTypeContext);
        }

        return this.getRuleContext(i, ColumnTypeContext);
    }
    public GREATER_SYMBOL(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.GREATER_SYMBOL, 0)!;
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterLengthSymbolsTypeDimension) {
             listener.enterLengthSymbolsTypeDimension(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitLengthSymbolsTypeDimension) {
             listener.exitLengthSymbolsTypeDimension(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitLengthSymbolsTypeDimension) {
            return visitor.visitLengthSymbolsTypeDimension(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class MapTypeDimensionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public LESS_SYMBOL(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LESS_SYMBOL, 0)!;
    }
    public columnType(): ColumnTypeContext[];
    public columnType(i: number): ColumnTypeContext | null;
    public columnType(i?: number): ColumnTypeContext[] | ColumnTypeContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ColumnTypeContext);
        }

        return this.getRuleContext(i, ColumnTypeContext);
    }
    public GREATER_SYMBOL(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.GREATER_SYMBOL, 0)!;
    }
    public COMMA(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.COMMA, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_mapTypeDimension;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterMapTypeDimension) {
             listener.enterMapTypeDimension(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitMapTypeDimension) {
             listener.exitMapTypeDimension(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitMapTypeDimension) {
            return visitor.visitMapTypeDimension(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class RowTypeDimensionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_rowTypeDimension;
    }
    public override copyFrom(ctx: RowTypeDimensionContext): void {
        super.copyFrom(ctx);
    }
}
export class RowSymbolsTypeDimensionContext extends RowTypeDimensionContext {
    public constructor(ctx: RowTypeDimensionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public LESS_SYMBOL(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LESS_SYMBOL, 0)!;
    }
    public columnName(): ColumnNameContext[];
    public columnName(i: number): ColumnNameContext | null;
    public columnName(i?: number): ColumnNameContext[] | ColumnNameContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ColumnNameContext);
        }

        return this.getRuleContext(i, ColumnNameContext);
    }
    public columnType(): ColumnTypeContext[];
    public columnType(i: number): ColumnTypeContext | null;
    public columnType(i?: number): ColumnTypeContext[] | ColumnTypeContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ColumnTypeContext);
        }

        return this.getRuleContext(i, ColumnTypeContext);
    }
    public GREATER_SYMBOL(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.GREATER_SYMBOL, 0)!;
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterRowSymbolsTypeDimension) {
             listener.enterRowSymbolsTypeDimension(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitRowSymbolsTypeDimension) {
             listener.exitRowSymbolsTypeDimension(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitRowSymbolsTypeDimension) {
            return visitor.visitRowSymbolsTypeDimension(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class StructTypeDimensionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_structTypeDimension;
    }
    public override copyFrom(ctx: StructTypeDimensionContext): void {
        super.copyFrom(ctx);
    }
}
export class StructSymbolsTypeDimensionContext extends StructTypeDimensionContext {
    public constructor(ctx: StructTypeDimensionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public LESS_SYMBOL(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LESS_SYMBOL, 0)!;
    }
    public columnName(): ColumnNameContext[];
    public columnName(i: number): ColumnNameContext | null;
    public columnName(i?: number): ColumnNameContext[] | ColumnNameContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ColumnNameContext);
        }

        return this.getRuleContext(i, ColumnNameContext);
    }
    public COLON_SYMB(): antlr.TerminalNode[];
    public COLON_SYMB(i: number): antlr.TerminalNode | null;
    public COLON_SYMB(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COLON_SYMB);
    	} else {
    		return this.getToken(SparkSQLParser.COLON_SYMB, i);
    	}
    }
    public columnType(): ColumnTypeContext[];
    public columnType(i: number): ColumnTypeContext | null;
    public columnType(i?: number): ColumnTypeContext[] | ColumnTypeContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ColumnTypeContext);
        }

        return this.getRuleContext(i, ColumnTypeContext);
    }
    public GREATER_SYMBOL(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.GREATER_SYMBOL, 0)!;
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterStructSymbolsTypeDimension) {
             listener.enterStructSymbolsTypeDimension(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitStructSymbolsTypeDimension) {
             listener.exitStructSymbolsTypeDimension(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitStructSymbolsTypeDimension) {
            return visitor.visitStructSymbolsTypeDimension(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ColumnConstraintContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_PRIMARY(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PRIMARY, 0);
    }
    public KW_KEY(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_KEY, 0);
    }
    public KW_CONSTRAINT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_CONSTRAINT, 0);
    }
    public constraintName(): ConstraintNameContext | null {
        return this.getRuleContext(0, ConstraintNameContext);
    }
    public KW_NOT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NOT, 0);
    }
    public KW_ENFORCED(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ENFORCED, 0);
    }
    public KW_NULL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NULL, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_columnConstraint;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterColumnConstraint) {
             listener.enterColumnConstraint(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitColumnConstraint) {
             listener.exitColumnConstraint(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitColumnConstraint) {
            return visitor.visitColumnConstraint(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class CommentSpecContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_COMMENT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_COMMENT, 0)!;
    }
    public propertyName(): PropertyNameContext {
        return this.getRuleContext(0, PropertyNameContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_commentSpec;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterCommentSpec) {
             listener.enterCommentSpec(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitCommentSpec) {
             listener.exitCommentSpec(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitCommentSpec) {
            return visitor.visitCommentSpec(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class MetadataColumnDefinitionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public columnName(): ColumnNameContext {
        return this.getRuleContext(0, ColumnNameContext)!;
    }
    public columnType(): ColumnTypeContext {
        return this.getRuleContext(0, ColumnTypeContext)!;
    }
    public KW_METADATA(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_METADATA, 0)!;
    }
    public KW_FROM(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FROM, 0);
    }
    public metadataKey(): MetadataKeyContext | null {
        return this.getRuleContext(0, MetadataKeyContext);
    }
    public KW_VIRTUAL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_VIRTUAL, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_metadataColumnDefinition;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterMetadataColumnDefinition) {
             listener.enterMetadataColumnDefinition(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitMetadataColumnDefinition) {
             listener.exitMetadataColumnDefinition(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitMetadataColumnDefinition) {
            return visitor.visitMetadataColumnDefinition(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class MetadataKeyContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public STRING_LITERAL(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.STRING_LITERAL, 0)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_metadataKey;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterMetadataKey) {
             listener.enterMetadataKey(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitMetadataKey) {
             listener.exitMetadataKey(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitMetadataKey) {
            return visitor.visitMetadataKey(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ComputedColumnDefinitionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public columnName(): ColumnNameContext {
        return this.getRuleContext(0, ColumnNameContext)!;
    }
    public KW_AS(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_AS, 0)!;
    }
    public computedColumnExpression(): ComputedColumnExpressionContext {
        return this.getRuleContext(0, ComputedColumnExpressionContext)!;
    }
    public commentSpec(): CommentSpecContext | null {
        return this.getRuleContext(0, CommentSpecContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_computedColumnDefinition;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterComputedColumnDefinition) {
             listener.enterComputedColumnDefinition(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitComputedColumnDefinition) {
             listener.exitComputedColumnDefinition(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitComputedColumnDefinition) {
            return visitor.visitComputedColumnDefinition(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ColumnNameContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public uid(): UidContext | null {
        return this.getRuleContext(0, UidContext);
    }
    public expression(): ExpressionContext | null {
        return this.getRuleContext(0, ExpressionContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_columnName;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterColumnName) {
             listener.enterColumnName(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitColumnName) {
             listener.exitColumnName(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitColumnName) {
            return visitor.visitColumnName(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ColumnNameListContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public columnName(): ColumnNameContext[];
    public columnName(i: number): ColumnNameContext | null;
    public columnName(i?: number): ColumnNameContext[] | ColumnNameContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ColumnNameContext);
        }

        return this.getRuleContext(i, ColumnNameContext);
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public commentSpec(): CommentSpecContext[];
    public commentSpec(i: number): CommentSpecContext | null;
    public commentSpec(i?: number): CommentSpecContext[] | CommentSpecContext | null {
        if (i === undefined) {
            return this.getRuleContexts(CommentSpecContext);
        }

        return this.getRuleContext(i, CommentSpecContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_columnNameList;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterColumnNameList) {
             listener.enterColumnNameList(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitColumnNameList) {
             listener.exitColumnNameList(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitColumnNameList) {
            return visitor.visitColumnNameList(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ColumnTypeContext extends antlr.ParserRuleContext {
    public _typeName?: Token | null;
    public _type_?: Token | null;
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_DATE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DATE, 0);
    }
    public KW_BOOLEAN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_BOOLEAN, 0);
    }
    public KW_NULL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NULL, 0);
    }
    public KW_CHAR(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_CHAR, 0);
    }
    public KW_VARCHAR(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_VARCHAR, 0);
    }
    public KW_STRING(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_STRING, 0);
    }
    public KW_BINARY(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_BINARY, 0);
    }
    public KW_VARBINARY(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_VARBINARY, 0);
    }
    public KW_BYTES(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_BYTES, 0);
    }
    public KW_TINYINT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TINYINT, 0);
    }
    public KW_SMALLINT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SMALLINT, 0);
    }
    public KW_INT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_INT, 0);
    }
    public KW_INTEGER(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_INTEGER, 0);
    }
    public KW_BIGINT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_BIGINT, 0);
    }
    public KW_TIME(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TIME, 0);
    }
    public KW_TIMESTAMP_LTZ(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TIMESTAMP_LTZ, 0);
    }
    public KW_DATETIME(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DATETIME, 0);
    }
    public lengthOneDimension(): LengthOneDimensionContext | null {
        return this.getRuleContext(0, LengthOneDimensionContext);
    }
    public KW_TIMESTAMP(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TIMESTAMP, 0);
    }
    public KW_ZONE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ZONE, 0);
    }
    public KW_WITHOUT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_WITHOUT, 0);
    }
    public KW_WITH(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_WITH, 0);
    }
    public KW_LOCAL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LOCAL, 0);
    }
    public KW_TIMESTAMP_3(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TIMESTAMP_3, 0);
    }
    public KW_TIMESTAMP_6(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TIMESTAMP_6, 0);
    }
    public KW_TIMESTAMP_9(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TIMESTAMP_9, 0);
    }
    public KW_DECIMAL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DECIMAL, 0);
    }
    public KW_DEC(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DEC, 0);
    }
    public KW_NUMERIC(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NUMERIC, 0);
    }
    public KW_FLOAT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FLOAT, 0);
    }
    public KW_DOUBLE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DOUBLE, 0);
    }
    public lengthTwoOptionalDimension(): LengthTwoOptionalDimensionContext | null {
        return this.getRuleContext(0, LengthTwoOptionalDimensionContext);
    }
    public KW_ARRAY(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ARRAY, 0);
    }
    public KW_MULTISET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MULTISET, 0);
    }
    public lengthOneTypeDimension(): LengthOneTypeDimensionContext | null {
        return this.getRuleContext(0, LengthOneTypeDimensionContext);
    }
    public KW_MAP(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MAP, 0);
    }
    public mapTypeDimension(): MapTypeDimensionContext | null {
        return this.getRuleContext(0, MapTypeDimensionContext);
    }
    public KW_ROW(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ROW, 0);
    }
    public rowTypeDimension(): RowTypeDimensionContext | null {
        return this.getRuleContext(0, RowTypeDimensionContext);
    }
    public structTypeDimension(): StructTypeDimensionContext | null {
        return this.getRuleContext(0, StructTypeDimensionContext);
    }
    public KW_STRUCT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_STRUCT, 0);
    }
    public KW_RAW(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_RAW, 0);
    }
    public lengthTwoStringDimension(): LengthTwoStringDimensionContext | null {
        return this.getRuleContext(0, LengthTwoStringDimensionContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_columnType;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterColumnType) {
             listener.enterColumnType(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitColumnType) {
             listener.exitColumnType(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitColumnType) {
            return visitor.visitColumnType(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ExpressionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public booleanExpression(): BooleanExpressionContext {
        return this.getRuleContext(0, BooleanExpressionContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_expression;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterExpression) {
             listener.enterExpression(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitExpression) {
             listener.exitExpression(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitExpression) {
            return visitor.visitExpression(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class BooleanExpressionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_booleanExpression;
    }
    public override copyFrom(ctx: BooleanExpressionContext): void {
        super.copyFrom(ctx);
    }
}
export class LogicalNotContext extends BooleanExpressionContext {
    public constructor(ctx: BooleanExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public KW_NOT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_NOT, 0)!;
    }
    public booleanExpression(): BooleanExpressionContext {
        return this.getRuleContext(0, BooleanExpressionContext)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterLogicalNot) {
             listener.enterLogicalNot(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitLogicalNot) {
             listener.exitLogicalNot(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitLogicalNot) {
            return visitor.visitLogicalNot(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class PredicatedContext extends BooleanExpressionContext {
    public constructor(ctx: BooleanExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public valueExpression(): ValueExpressionContext {
        return this.getRuleContext(0, ValueExpressionContext)!;
    }
    public predicate(): PredicateContext | null {
        return this.getRuleContext(0, PredicateContext);
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterPredicated) {
             listener.enterPredicated(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitPredicated) {
             listener.exitPredicated(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitPredicated) {
            return visitor.visitPredicated(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class ExistsContext extends BooleanExpressionContext {
    public constructor(ctx: BooleanExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public KW_EXISTS(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_EXISTS, 0)!;
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public queryStatement(): QueryStatementContext {
        return this.getRuleContext(0, QueryStatementContext)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterExists) {
             listener.enterExists(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitExists) {
             listener.exitExists(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitExists) {
            return visitor.visitExists(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class LogicalNestedContext extends BooleanExpressionContext {
    public _kind?: Token | null;
    public constructor(ctx: BooleanExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public booleanExpression(): BooleanExpressionContext {
        return this.getRuleContext(0, BooleanExpressionContext)!;
    }
    public KW_IS(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_IS, 0)!;
    }
    public KW_TRUE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TRUE, 0);
    }
    public KW_FALSE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FALSE, 0);
    }
    public KW_UNKNOWN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_UNKNOWN, 0);
    }
    public KW_NULL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NULL, 0);
    }
    public KW_NOT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NOT, 0);
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterLogicalNested) {
             listener.enterLogicalNested(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitLogicalNested) {
             listener.exitLogicalNested(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitLogicalNested) {
            return visitor.visitLogicalNested(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class LogicalBinaryContext extends BooleanExpressionContext {
    public _left?: BooleanExpressionContext;
    public _operator?: Token | null;
    public _right?: BooleanExpressionContext;
    public constructor(ctx: BooleanExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public booleanExpression(): BooleanExpressionContext[];
    public booleanExpression(i: number): BooleanExpressionContext | null;
    public booleanExpression(i?: number): BooleanExpressionContext[] | BooleanExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(BooleanExpressionContext);
        }

        return this.getRuleContext(i, BooleanExpressionContext);
    }
    public KW_AND(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_AND, 0);
    }
    public KW_OR(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_OR, 0);
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterLogicalBinary) {
             listener.enterLogicalBinary(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitLogicalBinary) {
             listener.exitLogicalBinary(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitLogicalBinary) {
            return visitor.visitLogicalBinary(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class PredicateContext extends antlr.ParserRuleContext {
    public _kind?: Token | null;
    public _lower?: ValueExpressionContext;
    public _upper?: ValueExpressionContext;
    public _pattern?: ValueExpressionContext;
    public _right?: ValueExpressionContext;
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_AND(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_AND, 0);
    }
    public KW_BETWEEN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_BETWEEN, 0);
    }
    public valueExpression(): ValueExpressionContext[];
    public valueExpression(i: number): ValueExpressionContext | null;
    public valueExpression(i?: number): ValueExpressionContext[] | ValueExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ValueExpressionContext);
        }

        return this.getRuleContext(i, ValueExpressionContext);
    }
    public KW_NOT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NOT, 0);
    }
    public KW_ASYMMETRIC(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ASYMMETRIC, 0);
    }
    public KW_SYMMETRIC(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SYMMETRIC, 0);
    }
    public LR_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0);
    }
    public expression(): ExpressionContext[];
    public expression(i: number): ExpressionContext | null;
    public expression(i?: number): ExpressionContext[] | ExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ExpressionContext);
        }

        return this.getRuleContext(i, ExpressionContext);
    }
    public RR_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0);
    }
    public KW_IN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_IN, 0);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public queryStatement(): QueryStatementContext | null {
        return this.getRuleContext(0, QueryStatementContext);
    }
    public KW_EXISTS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_EXISTS, 0);
    }
    public KW_RLIKE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_RLIKE, 0);
    }
    public likePredicate(): LikePredicateContext | null {
        return this.getRuleContext(0, LikePredicateContext);
    }
    public KW_IS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_IS, 0);
    }
    public KW_TRUE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TRUE, 0);
    }
    public KW_FALSE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FALSE, 0);
    }
    public KW_UNKNOWN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_UNKNOWN, 0);
    }
    public KW_NULL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NULL, 0);
    }
    public KW_FROM(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FROM, 0);
    }
    public KW_DISTINCT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DISTINCT, 0);
    }
    public KW_TO(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TO, 0);
    }
    public KW_SIMILAR(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SIMILAR, 0);
    }
    public KW_ESCAPE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ESCAPE, 0);
    }
    public stringLiteral(): StringLiteralContext | null {
        return this.getRuleContext(0, StringLiteralContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_predicate;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterPredicate) {
             listener.enterPredicate(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitPredicate) {
             listener.exitPredicate(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitPredicate) {
            return visitor.visitPredicate(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class LikePredicateContext extends antlr.ParserRuleContext {
    public _kind?: Token | null;
    public _quantifier?: Token | null;
    public _pattern?: ValueExpressionContext;
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_LIKE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LIKE, 0);
    }
    public KW_ANY(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ANY, 0);
    }
    public KW_ALL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ALL, 0);
    }
    public LR_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0);
    }
    public RR_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0);
    }
    public expression(): ExpressionContext[];
    public expression(i: number): ExpressionContext | null;
    public expression(i?: number): ExpressionContext[] | ExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ExpressionContext);
        }

        return this.getRuleContext(i, ExpressionContext);
    }
    public KW_NOT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NOT, 0);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public valueExpression(): ValueExpressionContext | null {
        return this.getRuleContext(0, ValueExpressionContext);
    }
    public KW_RLIKE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_RLIKE, 0);
    }
    public KW_ESCAPE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ESCAPE, 0);
    }
    public stringLiteral(): StringLiteralContext[];
    public stringLiteral(i: number): StringLiteralContext | null;
    public stringLiteral(i?: number): StringLiteralContext[] | StringLiteralContext | null {
        if (i === undefined) {
            return this.getRuleContexts(StringLiteralContext);
        }

        return this.getRuleContext(i, StringLiteralContext);
    }
    public KW_REGEXP(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_REGEXP, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_likePredicate;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterLikePredicate) {
             listener.enterLikePredicate(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitLikePredicate) {
             listener.exitLikePredicate(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitLikePredicate) {
            return visitor.visitLikePredicate(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ValueExpressionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_valueExpression;
    }
    public override copyFrom(ctx: ValueExpressionContext): void {
        super.copyFrom(ctx);
    }
}
export class ValueExpressionDefaultContext extends ValueExpressionContext {
    public constructor(ctx: ValueExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public primaryExpression(): PrimaryExpressionContext {
        return this.getRuleContext(0, PrimaryExpressionContext)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterValueExpressionDefault) {
             listener.enterValueExpressionDefault(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitValueExpressionDefault) {
             listener.exitValueExpressionDefault(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitValueExpressionDefault) {
            return visitor.visitValueExpressionDefault(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class OrContext extends ValueExpressionContext {
    public _left?: ValueExpressionContext;
    public _operator?: Token | null;
    public _right?: ValueExpressionContext;
    public constructor(ctx: ValueExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public valueExpression(): ValueExpressionContext[];
    public valueExpression(i: number): ValueExpressionContext | null;
    public valueExpression(i?: number): ValueExpressionContext[] | ValueExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ValueExpressionContext);
        }

        return this.getRuleContext(i, ValueExpressionContext);
    }
    public BIT_OR_OP(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.BIT_OR_OP, 0)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterOr) {
             listener.enterOr(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitOr) {
             listener.exitOr(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitOr) {
            return visitor.visitOr(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class ComparisonContext extends ValueExpressionContext {
    public _left?: ValueExpressionContext;
    public _operator?: ComparisonOperatorContext;
    public _right?: ValueExpressionContext;
    public constructor(ctx: ValueExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public valueExpression(): ValueExpressionContext[];
    public valueExpression(i: number): ValueExpressionContext | null;
    public valueExpression(i?: number): ValueExpressionContext[] | ValueExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ValueExpressionContext);
        }

        return this.getRuleContext(i, ValueExpressionContext);
    }
    public comparisonOperator(): ComparisonOperatorContext {
        return this.getRuleContext(0, ComparisonOperatorContext)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterComparison) {
             listener.enterComparison(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitComparison) {
             listener.exitComparison(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitComparison) {
            return visitor.visitComparison(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class ArithmeticBinaryContext extends ValueExpressionContext {
    public _left?: ValueExpressionContext;
    public _operator?: Token | null;
    public _right?: ValueExpressionContext;
    public constructor(ctx: ValueExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public valueExpression(): ValueExpressionContext[];
    public valueExpression(i: number): ValueExpressionContext | null;
    public valueExpression(i?: number): ValueExpressionContext[] | ValueExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ValueExpressionContext);
        }

        return this.getRuleContext(i, ValueExpressionContext);
    }
    public ASTERISK_SIGN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.ASTERISK_SIGN, 0);
    }
    public SLASH_SIGN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.SLASH_SIGN, 0);
    }
    public PENCENT_SIGN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.PENCENT_SIGN, 0);
    }
    public KW_DIV(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DIV, 0);
    }
    public ADD_SIGN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.ADD_SIGN, 0);
    }
    public HYPNEN_SIGN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.HYPNEN_SIGN, 0);
    }
    public DOUBLE_VERTICAL_SIGN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.DOUBLE_VERTICAL_SIGN, 0);
    }
    public BIT_AND_OP(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.BIT_AND_OP, 0);
    }
    public BIT_XOR_OP(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.BIT_XOR_OP, 0);
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterArithmeticBinary) {
             listener.enterArithmeticBinary(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitArithmeticBinary) {
             listener.exitArithmeticBinary(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitArithmeticBinary) {
            return visitor.visitArithmeticBinary(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class ArithmeticUnaryContext extends ValueExpressionContext {
    public _operator?: Token | null;
    public constructor(ctx: ValueExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public valueExpression(): ValueExpressionContext {
        return this.getRuleContext(0, ValueExpressionContext)!;
    }
    public HYPNEN_SIGN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.HYPNEN_SIGN, 0);
    }
    public ADD_SIGN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.ADD_SIGN, 0);
    }
    public BIT_NOT_OP(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.BIT_NOT_OP, 0);
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterArithmeticUnary) {
             listener.enterArithmeticUnary(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitArithmeticUnary) {
             listener.exitArithmeticUnary(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitArithmeticUnary) {
            return visitor.visitArithmeticUnary(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class PrimaryExpressionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_primaryExpression;
    }
    public override copyFrom(ctx: PrimaryExpressionContext): void {
        super.copyFrom(ctx);
    }
}
export class SimpleCaseContext extends PrimaryExpressionContext {
    public _value?: ExpressionContext;
    public _elseExpression?: ExpressionContext;
    public constructor(ctx: PrimaryExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public KW_CASE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_CASE, 0)!;
    }
    public KW_END(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_END, 0)!;
    }
    public expression(): ExpressionContext[];
    public expression(i: number): ExpressionContext | null;
    public expression(i?: number): ExpressionContext[] | ExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ExpressionContext);
        }

        return this.getRuleContext(i, ExpressionContext);
    }
    public whenClause(): WhenClauseContext[];
    public whenClause(i: number): WhenClauseContext | null;
    public whenClause(i?: number): WhenClauseContext[] | WhenClauseContext | null {
        if (i === undefined) {
            return this.getRuleContexts(WhenClauseContext);
        }

        return this.getRuleContext(i, WhenClauseContext);
    }
    public KW_ELSE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ELSE, 0);
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterSimpleCase) {
             listener.enterSimpleCase(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitSimpleCase) {
             listener.exitSimpleCase(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitSimpleCase) {
            return visitor.visitSimpleCase(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class ColumnReferenceContext extends PrimaryExpressionContext {
    public constructor(ctx: PrimaryExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public identifier(): IdentifierContext {
        return this.getRuleContext(0, IdentifierContext)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterColumnReference) {
             listener.enterColumnReference(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitColumnReference) {
             listener.exitColumnReference(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitColumnReference) {
            return visitor.visitColumnReference(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class LastContext extends PrimaryExpressionContext {
    public constructor(ctx: PrimaryExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public KW_LAST(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_LAST, 0)!;
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public expression(): ExpressionContext {
        return this.getRuleContext(0, ExpressionContext)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public KW_IGNORE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_IGNORE, 0);
    }
    public KW_NULLS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NULLS, 0);
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterLast) {
             listener.enterLast(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitLast) {
             listener.exitLast(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitLast) {
            return visitor.visitLast(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class StarContext extends PrimaryExpressionContext {
    public constructor(ctx: PrimaryExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public ASTERISK_SIGN(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.ASTERISK_SIGN, 0)!;
    }
    public uid(): UidContext | null {
        return this.getRuleContext(0, UidContext);
    }
    public DOT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.DOT, 0);
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterStar) {
             listener.enterStar(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitStar) {
             listener.exitStar(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitStar) {
            return visitor.visitStar(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class AggregateFunctionsContext extends PrimaryExpressionContext {
    public constructor(ctx: PrimaryExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public funtionBody(): FuntionBodyContext {
        return this.getRuleContext(0, FuntionBodyContext)!;
    }
    public filterPart(): FilterPartContext {
        return this.getRuleContext(0, FilterPartContext)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterAggregateFunctions) {
             listener.enterAggregateFunctions(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitAggregateFunctions) {
             listener.exitAggregateFunctions(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitAggregateFunctions) {
            return visitor.visitAggregateFunctions(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class SubscriptContext extends PrimaryExpressionContext {
    public _value?: PrimaryExpressionContext;
    public _index?: ValueExpressionContext;
    public constructor(ctx: PrimaryExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public LS_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LS_BRACKET, 0)!;
    }
    public RS_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RS_BRACKET, 0)!;
    }
    public primaryExpression(): PrimaryExpressionContext {
        return this.getRuleContext(0, PrimaryExpressionContext)!;
    }
    public valueExpression(): ValueExpressionContext {
        return this.getRuleContext(0, ValueExpressionContext)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterSubscript) {
             listener.enterSubscript(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitSubscript) {
             listener.exitSubscript(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitSubscript) {
            return visitor.visitSubscript(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class ValuesContext extends PrimaryExpressionContext {
    public constructor(ctx: PrimaryExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public functionParam(): FunctionParamContext[];
    public functionParam(i: number): FunctionParamContext | null;
    public functionParam(i?: number): FunctionParamContext[] | FunctionParamContext | null {
        if (i === undefined) {
            return this.getRuleContexts(FunctionParamContext);
        }

        return this.getRuleContext(i, FunctionParamContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterValues) {
             listener.enterValues(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitValues) {
             listener.exitValues(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitValues) {
            return visitor.visitValues(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class FunctionCallFilterContext extends PrimaryExpressionContext {
    public constructor(ctx: PrimaryExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public functionName(): FunctionNameContext {
        return this.getRuleContext(0, FunctionNameContext)!;
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public functionParam(): FunctionParamContext {
        return this.getRuleContext(0, FunctionParamContext)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public setQuantifier(): SetQuantifierContext | null {
        return this.getRuleContext(0, SetQuantifierContext);
    }
    public filterClause(): FilterClauseContext | null {
        return this.getRuleContext(0, FilterClauseContext);
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterFunctionCallFilter) {
             listener.enterFunctionCallFilter(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitFunctionCallFilter) {
             listener.exitFunctionCallFilter(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitFunctionCallFilter) {
            return visitor.visitFunctionCallFilter(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class OrderSetAggregateFunctionsContext extends PrimaryExpressionContext {
    public constructor(ctx: PrimaryExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public funtionBody(): FuntionBodyContext {
        return this.getRuleContext(0, FuntionBodyContext)!;
    }
    public KW_WITHIN(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_WITHIN, 0)!;
    }
    public KW_GROUP(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_GROUP, 0)!;
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public orderByCaluse(): OrderByCaluseContext {
        return this.getRuleContext(0, OrderByCaluseContext)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public filterPart(): FilterPartContext | null {
        return this.getRuleContext(0, FilterPartContext);
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterOrderSetAggregateFunctions) {
             listener.enterOrderSetAggregateFunctions(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitOrderSetAggregateFunctions) {
             listener.exitOrderSetAggregateFunctions(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitOrderSetAggregateFunctions) {
            return visitor.visitOrderSetAggregateFunctions(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class SubqueryExpressionContext extends PrimaryExpressionContext {
    public constructor(ctx: PrimaryExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public queryStatement(): QueryStatementContext {
        return this.getRuleContext(0, QueryStatementContext)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterSubqueryExpression) {
             listener.enterSubqueryExpression(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitSubqueryExpression) {
             listener.exitSubqueryExpression(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitSubqueryExpression) {
            return visitor.visitSubqueryExpression(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class CastContext extends PrimaryExpressionContext {
    public constructor(ctx: PrimaryExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public KW_CAST(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_CAST, 0)!;
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public expression(): ExpressionContext {
        return this.getRuleContext(0, ExpressionContext)!;
    }
    public KW_AS(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_AS, 0)!;
    }
    public columnType(): ColumnTypeContext {
        return this.getRuleContext(0, ColumnTypeContext)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterCast) {
             listener.enterCast(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitCast) {
             listener.exitCast(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitCast) {
            return visitor.visitCast(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class ConstantDefaultContext extends PrimaryExpressionContext {
    public constructor(ctx: PrimaryExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public constant(): ConstantContext {
        return this.getRuleContext(0, ConstantContext)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterConstantDefault) {
             listener.enterConstantDefault(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitConstantDefault) {
             listener.exitConstantDefault(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitConstantDefault) {
            return visitor.visitConstantDefault(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class ParenthesizedExpressionContext extends PrimaryExpressionContext {
    public constructor(ctx: PrimaryExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public expression(): ExpressionContext {
        return this.getRuleContext(0, ExpressionContext)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterParenthesizedExpression) {
             listener.enterParenthesizedExpression(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitParenthesizedExpression) {
             listener.exitParenthesizedExpression(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitParenthesizedExpression) {
            return visitor.visitParenthesizedExpression(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class ComplexDataTypeFieldExpressionContext extends PrimaryExpressionContext {
    public constructor(ctx: PrimaryExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public complexDataTypeExpression(): ComplexDataTypeExpressionContext {
        return this.getRuleContext(0, ComplexDataTypeExpressionContext)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterComplexDataTypeFieldExpression) {
             listener.enterComplexDataTypeFieldExpression(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitComplexDataTypeFieldExpression) {
             listener.exitComplexDataTypeFieldExpression(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitComplexDataTypeFieldExpression) {
            return visitor.visitComplexDataTypeFieldExpression(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class FunctionCallContext extends PrimaryExpressionContext {
    public constructor(ctx: PrimaryExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public functionName(): FunctionNameContext {
        return this.getRuleContext(0, FunctionNameContext)!;
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public functionParam(): FunctionParamContext[];
    public functionParam(i: number): FunctionParamContext | null;
    public functionParam(i?: number): FunctionParamContext[] | FunctionParamContext | null {
        if (i === undefined) {
            return this.getRuleContexts(FunctionParamContext);
        }

        return this.getRuleContext(i, FunctionParamContext);
    }
    public setQuantifier(): SetQuantifierContext | null {
        return this.getRuleContext(0, SetQuantifierContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public KW_TO(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TO, 0);
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterFunctionCall) {
             listener.enterFunctionCall(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitFunctionCall) {
             listener.exitFunctionCall(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitFunctionCall) {
            return visitor.visitFunctionCall(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class UidForColumnNameContext extends PrimaryExpressionContext {
    public constructor(ctx: PrimaryExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public uid(): UidContext {
        return this.getRuleContext(0, UidContext)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterUidForColumnName) {
             listener.enterUidForColumnName(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitUidForColumnName) {
             listener.exitUidForColumnName(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitUidForColumnName) {
            return visitor.visitUidForColumnName(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class SearchedCaseContext extends PrimaryExpressionContext {
    public _elseExpression?: ExpressionContext;
    public constructor(ctx: PrimaryExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public KW_CASE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_CASE, 0)!;
    }
    public KW_END(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_END, 0)!;
    }
    public whenClause(): WhenClauseContext[];
    public whenClause(i: number): WhenClauseContext | null;
    public whenClause(i?: number): WhenClauseContext[] | WhenClauseContext | null {
        if (i === undefined) {
            return this.getRuleContexts(WhenClauseContext);
        }

        return this.getRuleContext(i, WhenClauseContext);
    }
    public KW_ELSE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ELSE, 0);
    }
    public expression(): ExpressionContext | null {
        return this.getRuleContext(0, ExpressionContext);
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterSearchedCase) {
             listener.enterSearchedCase(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitSearchedCase) {
             listener.exitSearchedCase(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitSearchedCase) {
            return visitor.visitSearchedCase(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class PositionContext extends PrimaryExpressionContext {
    public _substr?: ValueExpressionContext;
    public _str?: ValueExpressionContext;
    public constructor(ctx: PrimaryExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public KW_POSITION(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_POSITION, 0)!;
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public KW_IN(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_IN, 0)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public valueExpression(): ValueExpressionContext[];
    public valueExpression(i: number): ValueExpressionContext | null;
    public valueExpression(i?: number): ValueExpressionContext[] | ValueExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ValueExpressionContext);
        }

        return this.getRuleContext(i, ValueExpressionContext);
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterPosition) {
             listener.enterPosition(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitPosition) {
             listener.exitPosition(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitPosition) {
            return visitor.visitPosition(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class FirstContext extends PrimaryExpressionContext {
    public constructor(ctx: PrimaryExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public KW_FIRST(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_FIRST, 0)!;
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public expression(): ExpressionContext {
        return this.getRuleContext(0, ExpressionContext)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public KW_IGNORE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_IGNORE, 0);
    }
    public KW_NULLS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NULLS, 0);
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterFirst) {
             listener.enterFirst(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitFirst) {
             listener.exitFirst(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitFirst) {
            return visitor.visitFirst(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ComplexDataTypeExpressionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public arrayExpression(): ArrayExpressionContext | null {
        return this.getRuleContext(0, ArrayExpressionContext);
    }
    public rowExpression(): RowExpressionContext | null {
        return this.getRuleContext(0, RowExpressionContext);
    }
    public mapExpression(): MapExpressionContext | null {
        return this.getRuleContext(0, MapExpressionContext);
    }
    public structExpression(): StructExpressionContext | null {
        return this.getRuleContext(0, StructExpressionContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_complexDataTypeExpression;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterComplexDataTypeExpression) {
             listener.enterComplexDataTypeExpression(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitComplexDataTypeExpression) {
             listener.exitComplexDataTypeExpression(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitComplexDataTypeExpression) {
            return visitor.visitComplexDataTypeExpression(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ArrayExpressionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_ARRAY(): antlr.TerminalNode[];
    public KW_ARRAY(i: number): antlr.TerminalNode | null;
    public KW_ARRAY(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.KW_ARRAY);
    	} else {
    		return this.getToken(SparkSQLParser.KW_ARRAY, i);
    	}
    }
    public LS_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LS_BRACKET, 0)!;
    }
    public dataTypeExpression(): DataTypeExpressionContext[];
    public dataTypeExpression(i: number): DataTypeExpressionContext | null;
    public dataTypeExpression(i?: number): DataTypeExpressionContext[] | DataTypeExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(DataTypeExpressionContext);
        }

        return this.getRuleContext(i, DataTypeExpressionContext);
    }
    public RS_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RS_BRACKET, 0)!;
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_arrayExpression;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterArrayExpression) {
             listener.enterArrayExpression(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitArrayExpression) {
             listener.exitArrayExpression(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitArrayExpression) {
            return visitor.visitArrayExpression(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class StructExpressionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_STRUCT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_STRUCT, 0)!;
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public dataTypeExpression(): DataTypeExpressionContext[];
    public dataTypeExpression(i: number): DataTypeExpressionContext | null;
    public dataTypeExpression(i?: number): DataTypeExpressionContext[] | DataTypeExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(DataTypeExpressionContext);
        }

        return this.getRuleContext(i, DataTypeExpressionContext);
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_structExpression;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterStructExpression) {
             listener.enterStructExpression(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitStructExpression) {
             listener.exitStructExpression(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitStructExpression) {
            return visitor.visitStructExpression(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class RowExpressionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_ROW(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_ROW, 0)!;
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public dataTypeExpression(): DataTypeExpressionContext[];
    public dataTypeExpression(i: number): DataTypeExpressionContext | null;
    public dataTypeExpression(i?: number): DataTypeExpressionContext[] | DataTypeExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(DataTypeExpressionContext);
        }

        return this.getRuleContext(i, DataTypeExpressionContext);
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_rowExpression;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterRowExpression) {
             listener.enterRowExpression(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitRowExpression) {
             listener.exitRowExpression(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitRowExpression) {
            return visitor.visitRowExpression(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class MapExpressionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_MAP(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_MAP, 0)!;
    }
    public LS_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LS_BRACKET, 0)!;
    }
    public dataTypeExpression(): DataTypeExpressionContext[];
    public dataTypeExpression(i: number): DataTypeExpressionContext | null;
    public dataTypeExpression(i?: number): DataTypeExpressionContext[] | DataTypeExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(DataTypeExpressionContext);
        }

        return this.getRuleContext(i, DataTypeExpressionContext);
    }
    public COMMA(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.COMMA, 0)!;
    }
    public RS_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RS_BRACKET, 0)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_mapExpression;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterMapExpression) {
             listener.enterMapExpression(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitMapExpression) {
             listener.exitMapExpression(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitMapExpression) {
            return visitor.visitMapExpression(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class DataTypeExpressionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public columnAlias(): ColumnAliasContext | null {
        return this.getRuleContext(0, ColumnAliasContext);
    }
    public constant(): ConstantContext | null {
        return this.getRuleContext(0, ConstantContext);
    }
    public complexDataTypeExpression(): ComplexDataTypeExpressionContext | null {
        return this.getRuleContext(0, ComplexDataTypeExpressionContext);
    }
    public sqlSimpleType(): SqlSimpleTypeContext | null {
        return this.getRuleContext(0, SqlSimpleTypeContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_dataTypeExpression;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterDataTypeExpression) {
             listener.enterDataTypeExpression(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitDataTypeExpression) {
             listener.exitDataTypeExpression(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitDataTypeExpression) {
            return visitor.visitDataTypeExpression(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class SqlSimpleTypeContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_BOOLEAN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_BOOLEAN, 0);
    }
    public KW_BIGINT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_BIGINT, 0);
    }
    public KW_BYTE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_BYTE, 0);
    }
    public KW_TINYINT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TINYINT, 0);
    }
    public KW_SMALLINT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SMALLINT, 0);
    }
    public KW_INT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_INT, 0);
    }
    public KW_INTEGER(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_INTEGER, 0);
    }
    public KW_FLOAT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FLOAT, 0);
    }
    public KW_DOUBLE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DOUBLE, 0);
    }
    public KW_DATE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DATE, 0);
    }
    public KW_LONG(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LONG, 0);
    }
    public KW_DECIMAL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DECIMAL, 0);
    }
    public KW_NUMERIC(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NUMERIC, 0);
    }
    public KW_TIME(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TIME, 0);
    }
    public KW_TIMESTAMP(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TIMESTAMP, 0);
    }
    public KW_TIMESTAMP_LTZ(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TIMESTAMP_LTZ, 0);
    }
    public KW_TIMESTAMP_NTZ(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TIMESTAMP_NTZ, 0);
    }
    public KW_REAL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_REAL, 0);
    }
    public KW_SHORT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SHORT, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_sqlSimpleType;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterSqlSimpleType) {
             listener.enterSqlSimpleType(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitSqlSimpleType) {
             listener.exitSqlSimpleType(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitSqlSimpleType) {
            return visitor.visitSqlSimpleType(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class FunctionNameContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public nonReservedKeywords(): NonReservedKeywordsContext | null {
        return this.getRuleContext(0, NonReservedKeywordsContext);
    }
    public uid(): UidContext | null {
        return this.getRuleContext(0, UidContext);
    }
    public reservedKeywordsUsedAsFuncName(): ReservedKeywordsUsedAsFuncNameContext | null {
        return this.getRuleContext(0, ReservedKeywordsUsedAsFuncNameContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_functionName;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterFunctionName) {
             listener.enterFunctionName(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitFunctionName) {
             listener.exitFunctionName(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitFunctionName) {
            return visitor.visitFunctionName(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class FunctionParamContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public reservedKeywordsUsedAsFuncParam(): ReservedKeywordsUsedAsFuncParamContext | null {
        return this.getRuleContext(0, ReservedKeywordsUsedAsFuncParamContext);
    }
    public timeIntervalUnit(): TimeIntervalUnitContext | null {
        return this.getRuleContext(0, TimeIntervalUnitContext);
    }
    public timePointUnit(): TimePointUnitContext | null {
        return this.getRuleContext(0, TimePointUnitContext);
    }
    public expression(): ExpressionContext | null {
        return this.getRuleContext(0, ExpressionContext);
    }
    public filterClause(): FilterClauseContext | null {
        return this.getRuleContext(0, FilterClauseContext);
    }
    public constant(): ConstantContext | null {
        return this.getRuleContext(0, ConstantContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_functionParam;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterFunctionParam) {
             listener.enterFunctionParam(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitFunctionParam) {
             listener.exitFunctionParam(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitFunctionParam) {
            return visitor.visitFunctionParam(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class FilterClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_FILTER(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_FILTER, 0)!;
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public KW_WHERE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_WHERE, 0)!;
    }
    public booleanExpression(): BooleanExpressionContext {
        return this.getRuleContext(0, BooleanExpressionContext)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_filterClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterFilterClause) {
             listener.enterFilterClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitFilterClause) {
             listener.exitFilterClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitFilterClause) {
            return visitor.visitFilterClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class CorrelationNameContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public identifier(): IdentifierContext {
        return this.getRuleContext(0, IdentifierContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_correlationName;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterCorrelationName) {
             listener.enterCorrelationName(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitCorrelationName) {
             listener.exitCorrelationName(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitCorrelationName) {
            return visitor.visitCorrelationName(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class QualifiedNameContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public identifier(): IdentifierContext | null {
        return this.getRuleContext(0, IdentifierContext);
    }
    public uid(): UidContext | null {
        return this.getRuleContext(0, UidContext);
    }
    public unquotedAnyString(): UnquotedAnyStringContext | null {
        return this.getRuleContext(0, UnquotedAnyStringContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_qualifiedName;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterQualifiedName) {
             listener.enterQualifiedName(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitQualifiedName) {
             listener.exitQualifiedName(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitQualifiedName) {
            return visitor.visitQualifiedName(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class TimeIntervalExpressionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_INTERVAL(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_INTERVAL, 0)!;
    }
    public errorCapturingMultiUnitsInterval(): ErrorCapturingMultiUnitsIntervalContext | null {
        return this.getRuleContext(0, ErrorCapturingMultiUnitsIntervalContext);
    }
    public errorCapturingUnitToUnitInterval(): ErrorCapturingUnitToUnitIntervalContext | null {
        return this.getRuleContext(0, ErrorCapturingUnitToUnitIntervalContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_timeIntervalExpression;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterTimeIntervalExpression) {
             listener.enterTimeIntervalExpression(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitTimeIntervalExpression) {
             listener.exitTimeIntervalExpression(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitTimeIntervalExpression) {
            return visitor.visitTimeIntervalExpression(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ErrorCapturingMultiUnitsIntervalContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public multiUnitsInterval(): MultiUnitsIntervalContext {
        return this.getRuleContext(0, MultiUnitsIntervalContext)!;
    }
    public unitToUnitInterval(): UnitToUnitIntervalContext | null {
        return this.getRuleContext(0, UnitToUnitIntervalContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_errorCapturingMultiUnitsInterval;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterErrorCapturingMultiUnitsInterval) {
             listener.enterErrorCapturingMultiUnitsInterval(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitErrorCapturingMultiUnitsInterval) {
             listener.exitErrorCapturingMultiUnitsInterval(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitErrorCapturingMultiUnitsInterval) {
            return visitor.visitErrorCapturingMultiUnitsInterval(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class MultiUnitsIntervalContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public intervalValue(): IntervalValueContext[];
    public intervalValue(i: number): IntervalValueContext | null;
    public intervalValue(i?: number): IntervalValueContext[] | IntervalValueContext | null {
        if (i === undefined) {
            return this.getRuleContexts(IntervalValueContext);
        }

        return this.getRuleContext(i, IntervalValueContext);
    }
    public timeIntervalUnit(): TimeIntervalUnitContext[];
    public timeIntervalUnit(i: number): TimeIntervalUnitContext | null;
    public timeIntervalUnit(i?: number): TimeIntervalUnitContext[] | TimeIntervalUnitContext | null {
        if (i === undefined) {
            return this.getRuleContexts(TimeIntervalUnitContext);
        }

        return this.getRuleContext(i, TimeIntervalUnitContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_multiUnitsInterval;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterMultiUnitsInterval) {
             listener.enterMultiUnitsInterval(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitMultiUnitsInterval) {
             listener.exitMultiUnitsInterval(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitMultiUnitsInterval) {
            return visitor.visitMultiUnitsInterval(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ErrorCapturingUnitToUnitIntervalContext extends antlr.ParserRuleContext {
    public _body?: UnitToUnitIntervalContext;
    public _error1?: MultiUnitsIntervalContext;
    public _error2?: UnitToUnitIntervalContext;
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public unitToUnitInterval(): UnitToUnitIntervalContext[];
    public unitToUnitInterval(i: number): UnitToUnitIntervalContext | null;
    public unitToUnitInterval(i?: number): UnitToUnitIntervalContext[] | UnitToUnitIntervalContext | null {
        if (i === undefined) {
            return this.getRuleContexts(UnitToUnitIntervalContext);
        }

        return this.getRuleContext(i, UnitToUnitIntervalContext);
    }
    public multiUnitsInterval(): MultiUnitsIntervalContext | null {
        return this.getRuleContext(0, MultiUnitsIntervalContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_errorCapturingUnitToUnitInterval;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterErrorCapturingUnitToUnitInterval) {
             listener.enterErrorCapturingUnitToUnitInterval(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitErrorCapturingUnitToUnitInterval) {
             listener.exitErrorCapturingUnitToUnitInterval(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitErrorCapturingUnitToUnitInterval) {
            return visitor.visitErrorCapturingUnitToUnitInterval(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class UnitToUnitIntervalContext extends antlr.ParserRuleContext {
    public _value?: IntervalValueContext;
    public _from_?: TimeIntervalUnitContext;
    public _to?: TimeIntervalUnitContext;
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_TO(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_TO, 0)!;
    }
    public intervalValue(): IntervalValueContext {
        return this.getRuleContext(0, IntervalValueContext)!;
    }
    public timeIntervalUnit(): TimeIntervalUnitContext[];
    public timeIntervalUnit(i: number): TimeIntervalUnitContext | null;
    public timeIntervalUnit(i?: number): TimeIntervalUnitContext[] | TimeIntervalUnitContext | null {
        if (i === undefined) {
            return this.getRuleContexts(TimeIntervalUnitContext);
        }

        return this.getRuleContext(i, TimeIntervalUnitContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_unitToUnitInterval;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterUnitToUnitInterval) {
             listener.enterUnitToUnitInterval(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitUnitToUnitInterval) {
             listener.exitUnitToUnitInterval(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitUnitToUnitInterval) {
            return visitor.visitUnitToUnitInterval(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class IntervalValueContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public DIG_LITERAL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.DIG_LITERAL, 0);
    }
    public REAL_LITERAL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.REAL_LITERAL, 0);
    }
    public ADD_SIGN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.ADD_SIGN, 0);
    }
    public HYPNEN_SIGN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.HYPNEN_SIGN, 0);
    }
    public STRING_LITERAL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.STRING_LITERAL, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_intervalValue;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterIntervalValue) {
             listener.enterIntervalValue(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitIntervalValue) {
             listener.exitIntervalValue(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitIntervalValue) {
            return visitor.visitIntervalValue(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ColumnAliasContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public anyAlias(): AnyAliasContext {
        return this.getRuleContext(0, AnyAliasContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_columnAlias;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterColumnAlias) {
             listener.enterColumnAlias(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitColumnAlias) {
             listener.exitColumnAlias(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitColumnAlias) {
            return visitor.visitColumnAlias(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class TableAliasContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public anyAlias(): AnyAliasContext {
        return this.getRuleContext(0, AnyAliasContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_tableAlias;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterTableAlias) {
             listener.enterTableAlias(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitTableAlias) {
             listener.exitTableAlias(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitTableAlias) {
            return visitor.visitTableAlias(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class AnyAliasContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public identifier(): IdentifierContext {
        return this.getRuleContext(0, IdentifierContext)!;
    }
    public KW_AS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_AS, 0);
    }
    public identifierList(): IdentifierListContext | null {
        return this.getRuleContext(0, IdentifierListContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_anyAlias;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterAnyAlias) {
             listener.enterAnyAlias(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitAnyAlias) {
             listener.exitAnyAlias(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitAnyAlias) {
            return visitor.visitAnyAlias(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ErrorCapturingIdentifierContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public identifier(): IdentifierContext {
        return this.getRuleContext(0, IdentifierContext)!;
    }
    public errorCapturingIdentifierExtra(): ErrorCapturingIdentifierExtraContext {
        return this.getRuleContext(0, ErrorCapturingIdentifierExtraContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_errorCapturingIdentifier;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterErrorCapturingIdentifier) {
             listener.enterErrorCapturingIdentifier(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitErrorCapturingIdentifier) {
             listener.exitErrorCapturingIdentifier(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitErrorCapturingIdentifier) {
            return visitor.visitErrorCapturingIdentifier(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ErrorCapturingIdentifierExtraContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_errorCapturingIdentifierExtra;
    }
    public override copyFrom(ctx: ErrorCapturingIdentifierExtraContext): void {
        super.copyFrom(ctx);
    }
}
export class ErrorIdentContext extends ErrorCapturingIdentifierExtraContext {
    public constructor(ctx: ErrorCapturingIdentifierExtraContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public KW_MINUS(): antlr.TerminalNode[];
    public KW_MINUS(i: number): antlr.TerminalNode | null;
    public KW_MINUS(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.KW_MINUS);
    	} else {
    		return this.getToken(SparkSQLParser.KW_MINUS, i);
    	}
    }
    public identifier(): IdentifierContext[];
    public identifier(i: number): IdentifierContext | null;
    public identifier(i?: number): IdentifierContext[] | IdentifierContext | null {
        if (i === undefined) {
            return this.getRuleContexts(IdentifierContext);
        }

        return this.getRuleContext(i, IdentifierContext);
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterErrorIdent) {
             listener.enterErrorIdent(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitErrorIdent) {
             listener.exitErrorIdent(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitErrorIdent) {
            return visitor.visitErrorIdent(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class IdentifierListContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public identifierSeq(): IdentifierSeqContext {
        return this.getRuleContext(0, IdentifierSeqContext)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_identifierList;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterIdentifierList) {
             listener.enterIdentifierList(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitIdentifierList) {
             listener.exitIdentifierList(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitIdentifierList) {
            return visitor.visitIdentifierList(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class IdentifierSeqContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public identifier(): IdentifierContext[];
    public identifier(i: number): IdentifierContext | null;
    public identifier(i?: number): IdentifierContext[] | IdentifierContext | null {
        if (i === undefined) {
            return this.getRuleContexts(IdentifierContext);
        }

        return this.getRuleContext(i, IdentifierContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_identifierSeq;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterIdentifierSeq) {
             listener.enterIdentifierSeq(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitIdentifierSeq) {
             listener.exitIdentifierSeq(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitIdentifierSeq) {
            return visitor.visitIdentifierSeq(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class IdentifierContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_identifier;
    }
    public override copyFrom(ctx: IdentifierContext): void {
        super.copyFrom(ctx);
    }
}
export class QuotedIdentifierAlternativeContext extends IdentifierContext {
    public constructor(ctx: IdentifierContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public STRING_LITERAL(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.STRING_LITERAL, 0)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterQuotedIdentifierAlternative) {
             listener.enterQuotedIdentifierAlternative(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitQuotedIdentifierAlternative) {
             listener.exitQuotedIdentifierAlternative(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitQuotedIdentifierAlternative) {
            return visitor.visitQuotedIdentifierAlternative(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class NonReservedKeywordsAlternativeContext extends IdentifierContext {
    public constructor(ctx: IdentifierContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public nonReservedKeywords(): NonReservedKeywordsContext {
        return this.getRuleContext(0, NonReservedKeywordsContext)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterNonReservedKeywordsAlternative) {
             listener.enterNonReservedKeywordsAlternative(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitNonReservedKeywordsAlternative) {
             listener.exitNonReservedKeywordsAlternative(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitNonReservedKeywordsAlternative) {
            return visitor.visitNonReservedKeywordsAlternative(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class UnquotedIdentifierAlternativeContext extends IdentifierContext {
    public constructor(ctx: IdentifierContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public unquotedIdentifier(): UnquotedIdentifierContext {
        return this.getRuleContext(0, UnquotedIdentifierContext)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterUnquotedIdentifierAlternative) {
             listener.enterUnquotedIdentifierAlternative(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitUnquotedIdentifierAlternative) {
             listener.exitUnquotedIdentifierAlternative(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitUnquotedIdentifierAlternative) {
            return visitor.visitUnquotedIdentifierAlternative(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class UrefVarAlternativeContext extends IdentifierContext {
    public constructor(ctx: IdentifierContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public refVar(): RefVarContext {
        return this.getRuleContext(0, RefVarContext)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterUrefVarAlternative) {
             listener.enterUrefVarAlternative(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitUrefVarAlternative) {
             listener.exitUrefVarAlternative(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitUrefVarAlternative) {
            return visitor.visitUrefVarAlternative(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class UnquotedAnyStringContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public unquotedIdentifier(): UnquotedIdentifierContext | null {
        return this.getRuleContext(0, UnquotedIdentifierContext);
    }
    public reservedKeywordsUsedAsFuncParam(): ReservedKeywordsUsedAsFuncParamContext | null {
        return this.getRuleContext(0, ReservedKeywordsUsedAsFuncParamContext);
    }
    public nonReservedKeywords(): NonReservedKeywordsContext | null {
        return this.getRuleContext(0, NonReservedKeywordsContext);
    }
    public reservedKeywordsUsedAsFuncName(): ReservedKeywordsUsedAsFuncNameContext | null {
        return this.getRuleContext(0, ReservedKeywordsUsedAsFuncNameContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_unquotedAnyString;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterUnquotedAnyString) {
             listener.enterUnquotedAnyString(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitUnquotedAnyString) {
             listener.exitUnquotedAnyString(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitUnquotedAnyString) {
            return visitor.visitUnquotedAnyString(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class RefVarContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public DOLLAR(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.DOLLAR, 0)!;
    }
    public LB_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LB_BRACKET, 0)!;
    }
    public unquotedIdentifier(): UnquotedIdentifierContext {
        return this.getRuleContext(0, UnquotedIdentifierContext)!;
    }
    public RB_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RB_BRACKET, 0)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_refVar;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterRefVar) {
             listener.enterRefVar(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitRefVar) {
             listener.exitRefVar(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitRefVar) {
            return visitor.visitRefVar(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class UnquotedIdentifierContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public DIG_LITERAL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.DIG_LITERAL, 0);
    }
    public ID_LITERAL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.ID_LITERAL, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_unquotedIdentifier;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterUnquotedIdentifier) {
             listener.enterUnquotedIdentifier(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitUnquotedIdentifier) {
             listener.exitUnquotedIdentifier(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitUnquotedIdentifier) {
            return visitor.visitUnquotedIdentifier(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class WhenClauseContext extends antlr.ParserRuleContext {
    public _condition?: ExpressionContext;
    public _result?: ExpressionContext;
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_WHEN(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_WHEN, 0)!;
    }
    public KW_THEN(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_THEN, 0)!;
    }
    public expression(): ExpressionContext[];
    public expression(i: number): ExpressionContext | null;
    public expression(i?: number): ExpressionContext[] | ExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ExpressionContext);
        }

        return this.getRuleContext(i, ExpressionContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_whenClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterWhenClause) {
             listener.enterWhenClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitWhenClause) {
             listener.exitWhenClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitWhenClause) {
            return visitor.visitWhenClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class CatalogPathContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public uid(): UidContext {
        return this.getRuleContext(0, UidContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_catalogPath;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterCatalogPath) {
             listener.enterCatalogPath(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitCatalogPath) {
             listener.exitCatalogPath(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitCatalogPath) {
            return visitor.visitCatalogPath(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class DatabasePathContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public uid(): UidContext {
        return this.getRuleContext(0, UidContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_databasePath;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterDatabasePath) {
             listener.enterDatabasePath(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitDatabasePath) {
             listener.exitDatabasePath(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitDatabasePath) {
            return visitor.visitDatabasePath(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class DatabasePathCreateContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public uid(): UidContext {
        return this.getRuleContext(0, UidContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_databasePathCreate;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterDatabasePathCreate) {
             listener.enterDatabasePathCreate(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitDatabasePathCreate) {
             listener.exitDatabasePathCreate(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitDatabasePathCreate) {
            return visitor.visitDatabasePathCreate(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class TablePathCreateContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public uid(): UidContext {
        return this.getRuleContext(0, UidContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_tablePathCreate;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterTablePathCreate) {
             listener.enterTablePathCreate(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitTablePathCreate) {
             listener.exitTablePathCreate(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitTablePathCreate) {
            return visitor.visitTablePathCreate(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class TablePathContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public uid(): UidContext {
        return this.getRuleContext(0, UidContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_tablePath;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterTablePath) {
             listener.enterTablePath(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitTablePath) {
             listener.exitTablePath(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitTablePath) {
            return visitor.visitTablePath(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class AnonymousWindowsNameContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public identifier(): IdentifierContext {
        return this.getRuleContext(0, IdentifierContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_anonymousWindowsName;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterAnonymousWindowsName) {
             listener.enterAnonymousWindowsName(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitAnonymousWindowsName) {
             listener.exitAnonymousWindowsName(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitAnonymousWindowsName) {
            return visitor.visitAnonymousWindowsName(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class UidContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public identifier(): IdentifierContext[];
    public identifier(i: number): IdentifierContext | null;
    public identifier(i?: number): IdentifierContext[] | IdentifierContext | null {
        if (i === undefined) {
            return this.getRuleContexts(IdentifierContext);
        }

        return this.getRuleContext(i, IdentifierContext);
    }
    public DOT(): antlr.TerminalNode[];
    public DOT(i: number): antlr.TerminalNode | null;
    public DOT(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.DOT);
    	} else {
    		return this.getToken(SparkSQLParser.DOT, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_uid;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterUid) {
             listener.enterUid(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitUid) {
             listener.exitUid(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitUid) {
            return visitor.visitUid(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class WithOptionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_WITH(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_WITH, 0)!;
    }
    public tablePropertyList(): TablePropertyListContext {
        return this.getRuleContext(0, TablePropertyListContext)!;
    }
    public KW_DBPROPERTIES(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DBPROPERTIES, 0);
    }
    public KW_TBLPROPERTIES(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TBLPROPERTIES, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_withOption;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterWithOption) {
             listener.enterWithOption(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitWithOption) {
             listener.exitWithOption(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitWithOption) {
            return visitor.visitWithOption(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class IfNotExistsContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_IF(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_IF, 0)!;
    }
    public KW_NOT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_NOT, 0)!;
    }
    public KW_EXISTS(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_EXISTS, 0)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_ifNotExists;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterIfNotExists) {
             listener.enterIfNotExists(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitIfNotExists) {
             listener.exitIfNotExists(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitIfNotExists) {
            return visitor.visitIfNotExists(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class IfExistsContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_IF(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_IF, 0)!;
    }
    public KW_EXISTS(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_EXISTS, 0)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_ifExists;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterIfExists) {
             listener.enterIfExists(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitIfExists) {
             listener.exitIfExists(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitIfExists) {
            return visitor.visitIfExists(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class TablePropertyListContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public tableProperty(): TablePropertyContext[];
    public tableProperty(i: number): TablePropertyContext | null;
    public tableProperty(i?: number): TablePropertyContext[] | TablePropertyContext | null {
        if (i === undefined) {
            return this.getRuleContexts(TablePropertyContext);
        }

        return this.getRuleContext(i, TablePropertyContext);
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_tablePropertyList;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterTablePropertyList) {
             listener.enterTablePropertyList(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitTablePropertyList) {
             listener.exitTablePropertyList(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitTablePropertyList) {
            return visitor.visitTablePropertyList(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class TablePropertyContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public tablePropertyKey(): TablePropertyKeyContext {
        return this.getRuleContext(0, TablePropertyKeyContext)!;
    }
    public EQUAL_SYMBOL(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.EQUAL_SYMBOL, 0)!;
    }
    public tablePropertyValue(): TablePropertyValueContext {
        return this.getRuleContext(0, TablePropertyValueContext)!;
    }
    public KW_DATE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DATE, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_tableProperty;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterTableProperty) {
             listener.enterTableProperty(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitTableProperty) {
             listener.exitTableProperty(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitTableProperty) {
            return visitor.visitTableProperty(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class TablePropertyKeyContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public identifier(): IdentifierContext | null {
        return this.getRuleContext(0, IdentifierContext);
    }
    public uid(): UidContext | null {
        return this.getRuleContext(0, UidContext);
    }
    public stringLiteral(): StringLiteralContext | null {
        return this.getRuleContext(0, StringLiteralContext);
    }
    public functionParam(): FunctionParamContext | null {
        return this.getRuleContext(0, FunctionParamContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_tablePropertyKey;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterTablePropertyKey) {
             listener.enterTablePropertyKey(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitTablePropertyKey) {
             listener.exitTablePropertyKey(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitTablePropertyKey) {
            return visitor.visitTablePropertyKey(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class PropertyNameContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public SINGLE_QUOTE_SYMB(): antlr.TerminalNode[];
    public SINGLE_QUOTE_SYMB(i: number): antlr.TerminalNode | null;
    public SINGLE_QUOTE_SYMB(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.SINGLE_QUOTE_SYMB);
    	} else {
    		return this.getToken(SparkSQLParser.SINGLE_QUOTE_SYMB, i);
    	}
    }
    public constant(): ConstantContext {
        return this.getRuleContext(0, ConstantContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_propertyName;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterPropertyName) {
             listener.enterPropertyName(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitPropertyName) {
             listener.exitPropertyName(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitPropertyName) {
            return visitor.visitPropertyName(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class TablePropertyValueContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public DIG_LITERAL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.DIG_LITERAL, 0);
    }
    public REAL_LITERAL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.REAL_LITERAL, 0);
    }
    public booleanLiteral(): BooleanLiteralContext | null {
        return this.getRuleContext(0, BooleanLiteralContext);
    }
    public uid(): UidContext | null {
        return this.getRuleContext(0, UidContext);
    }
    public constant(): ConstantContext | null {
        return this.getRuleContext(0, ConstantContext);
    }
    public refVar(): RefVarContext | null {
        return this.getRuleContext(0, RefVarContext);
    }
    public SINGLE_QUOTE_SYMB(): antlr.TerminalNode[];
    public SINGLE_QUOTE_SYMB(i: number): antlr.TerminalNode | null;
    public SINGLE_QUOTE_SYMB(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.SINGLE_QUOTE_SYMB);
    	} else {
    		return this.getToken(SparkSQLParser.SINGLE_QUOTE_SYMB, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_tablePropertyValue;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterTablePropertyValue) {
             listener.enterTablePropertyValue(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitTablePropertyValue) {
             listener.exitTablePropertyValue(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitTablePropertyValue) {
            return visitor.visitTablePropertyValue(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ComparisonOperatorContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public EQUAL_SYMBOL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.EQUAL_SYMBOL, 0);
    }
    public GREATER_SYMBOL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.GREATER_SYMBOL, 0);
    }
    public LESS_SYMBOL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.LESS_SYMBOL, 0);
    }
    public EXCLAMATION_SYMBOL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.EXCLAMATION_SYMBOL, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_comparisonOperator;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterComparisonOperator) {
             listener.enterComparisonOperator(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitComparisonOperator) {
             listener.exitComparisonOperator(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitComparisonOperator) {
            return visitor.visitComparisonOperator(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ConstantContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public timeIntervalExpression(): TimeIntervalExpressionContext | null {
        return this.getRuleContext(0, TimeIntervalExpressionContext);
    }
    public timePointLiteral(): TimePointLiteralContext | null {
        return this.getRuleContext(0, TimePointLiteralContext);
    }
    public stringLiteral(): StringLiteralContext | null {
        return this.getRuleContext(0, StringLiteralContext);
    }
    public decimalLiteral(): DecimalLiteralContext | null {
        return this.getRuleContext(0, DecimalLiteralContext);
    }
    public HYPNEN_SIGN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.HYPNEN_SIGN, 0);
    }
    public booleanLiteral(): BooleanLiteralContext | null {
        return this.getRuleContext(0, BooleanLiteralContext);
    }
    public REAL_LITERAL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.REAL_LITERAL, 0);
    }
    public KW_NULL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NULL, 0);
    }
    public KW_NOT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NOT, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_constant;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterConstant) {
             listener.enterConstant(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitConstant) {
             listener.exitConstant(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitConstant) {
            return visitor.visitConstant(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class TimePointLiteralContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public timePointUnit(): TimePointUnitContext {
        return this.getRuleContext(0, TimePointUnitContext)!;
    }
    public stringLiteral(): StringLiteralContext {
        return this.getRuleContext(0, StringLiteralContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_timePointLiteral;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterTimePointLiteral) {
             listener.enterTimePointLiteral(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitTimePointLiteral) {
             listener.exitTimePointLiteral(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitTimePointLiteral) {
            return visitor.visitTimePointLiteral(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class StringLiteralContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public STRING_LITERAL(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.STRING_LITERAL, 0)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_stringLiteral;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterStringLiteral) {
             listener.enterStringLiteral(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitStringLiteral) {
             listener.exitStringLiteral(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitStringLiteral) {
            return visitor.visitStringLiteral(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class DecimalLiteralContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public DIG_LITERAL(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.DIG_LITERAL, 0)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_decimalLiteral;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterDecimalLiteral) {
             listener.enterDecimalLiteral(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitDecimalLiteral) {
             listener.exitDecimalLiteral(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitDecimalLiteral) {
            return visitor.visitDecimalLiteral(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class BooleanLiteralContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_TRUE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TRUE, 0);
    }
    public KW_FALSE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FALSE, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_booleanLiteral;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterBooleanLiteral) {
             listener.enterBooleanLiteral(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitBooleanLiteral) {
             listener.exitBooleanLiteral(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitBooleanLiteral) {
            return visitor.visitBooleanLiteral(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class SetQuantifierContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_DISTINCT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DISTINCT, 0);
    }
    public KW_ALL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ALL, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_setQuantifier;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterSetQuantifier) {
             listener.enterSetQuantifier(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitSetQuantifier) {
             listener.exitSetQuantifier(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitSetQuantifier) {
            return visitor.visitSetQuantifier(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class TimePointUnitContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_YEAR(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_YEAR, 0);
    }
    public KW_QUARTER(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_QUARTER, 0);
    }
    public KW_MONTH(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MONTH, 0);
    }
    public KW_WEEK(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_WEEK, 0);
    }
    public KW_DAY(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DAY, 0);
    }
    public KW_HOUR(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_HOUR, 0);
    }
    public KW_MINUTE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MINUTE, 0);
    }
    public KW_SECOND(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SECOND, 0);
    }
    public KW_MILLISECOND(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MILLISECOND, 0);
    }
    public KW_MICROSECOND(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MICROSECOND, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_timePointUnit;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterTimePointUnit) {
             listener.enterTimePointUnit(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitTimePointUnit) {
             listener.exitTimePointUnit(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitTimePointUnit) {
            return visitor.visitTimePointUnit(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class TimeIntervalUnitContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_MILLENNIUM(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MILLENNIUM, 0);
    }
    public KW_CENTURY(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_CENTURY, 0);
    }
    public KW_DECADE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DECADE, 0);
    }
    public KW_YEAR(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_YEAR, 0);
    }
    public KW_YEARS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_YEARS, 0);
    }
    public KW_QUARTER(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_QUARTER, 0);
    }
    public KW_MONTH(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MONTH, 0);
    }
    public KW_MONTHS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MONTHS, 0);
    }
    public KW_WEEK(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_WEEK, 0);
    }
    public KW_WEEKS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_WEEKS, 0);
    }
    public KW_DAY(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DAY, 0);
    }
    public KW_DAYS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DAYS, 0);
    }
    public KW_HOUR(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_HOUR, 0);
    }
    public KW_HOURS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_HOURS, 0);
    }
    public KW_MINUTE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MINUTE, 0);
    }
    public KW_MINUTES(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MINUTES, 0);
    }
    public KW_SECOND(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SECOND, 0);
    }
    public KW_SECONDS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SECONDS, 0);
    }
    public KW_MILLISECOND(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MILLISECOND, 0);
    }
    public KW_MICROSECOND(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MICROSECOND, 0);
    }
    public KW_NANOSECOND(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NANOSECOND, 0);
    }
    public KW_EPOCH(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_EPOCH, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_timeIntervalUnit;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterTimeIntervalUnit) {
             listener.enterTimeIntervalUnit(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitTimeIntervalUnit) {
             listener.exitTimeIntervalUnit(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitTimeIntervalUnit) {
            return visitor.visitTimeIntervalUnit(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ReservedKeywordsUsedAsFuncParamContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_LEADING(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LEADING, 0);
    }
    public KW_TRAILING(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TRAILING, 0);
    }
    public KW_BOTH(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_BOTH, 0);
    }
    public KW_ALL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ALL, 0);
    }
    public KW_DISTINCT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DISTINCT, 0);
    }
    public ASTERISK_SIGN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.ASTERISK_SIGN, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_reservedKeywordsUsedAsFuncParam;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterReservedKeywordsUsedAsFuncParam) {
             listener.enterReservedKeywordsUsedAsFuncParam(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitReservedKeywordsUsedAsFuncParam) {
             listener.exitReservedKeywordsUsedAsFuncParam(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitReservedKeywordsUsedAsFuncParam) {
            return visitor.visitReservedKeywordsUsedAsFuncParam(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ReservedKeywordsUsedAsFuncNameContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_ABS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ABS, 0);
    }
    public KW_ARRAY(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ARRAY, 0);
    }
    public KW_AVG(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_AVG, 0);
    }
    public KW_CAST(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_CAST, 0);
    }
    public KW_CEIL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_CEIL, 0);
    }
    public KW_COALESCE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_COALESCE, 0);
    }
    public KW_COLLECT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_COLLECT, 0);
    }
    public KW_COUNT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_COUNT, 0);
    }
    public KW_CURRENT_TIMESTAMP(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_CURRENT_TIMESTAMP, 0);
    }
    public KW_DATE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DATE, 0);
    }
    public KW_EXPLODE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_EXPLODE, 0);
    }
    public KW_FIRST_VALUE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FIRST_VALUE, 0);
    }
    public KW_FROM_UNIXTIME(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FROM_UNIXTIME, 0);
    }
    public KW_GROUPING(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_GROUPING, 0);
    }
    public KW_HOUR(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_HOUR, 0);
    }
    public KW_IF(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_IF, 0);
    }
    public KW_LEAD(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LEAD, 0);
    }
    public KW_LAG(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LAG, 0);
    }
    public KW_LAST_VALUE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LAST_VALUE, 0);
    }
    public KW_LEFT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LEFT, 0);
    }
    public KW_NTILE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NTILE, 0);
    }
    public KW_MAP(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MAP, 0);
    }
    public KW_MINUTE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MINUTE, 0);
    }
    public KW_MONTH(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MONTH, 0);
    }
    public KW_OVERLAY(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_OVERLAY, 0);
    }
    public KW_POSITION(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_POSITION, 0);
    }
    public KW_PERCENT_RANK(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PERCENT_RANK, 0);
    }
    public KW_PERCENTILE_CONT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PERCENTILE_CONT, 0);
    }
    public KW_PERCENTILE_DISC(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PERCENTILE_DISC, 0);
    }
    public KW_POWER(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_POWER, 0);
    }
    public KW_QUARTER(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_QUARTER, 0);
    }
    public KW_RANK(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_RANK, 0);
    }
    public KW_ROW_NUMBER(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ROW_NUMBER, 0);
    }
    public KW_RANGE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_RANGE, 0);
    }
    public KW_RIGHT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_RIGHT, 0);
    }
    public KW_SECOND(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SECOND, 0);
    }
    public KW_SUBSTRING(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SUBSTRING, 0);
    }
    public KW_SUM(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SUM, 0);
    }
    public KW_TIME(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TIME, 0);
    }
    public KW_TIMESTAMP(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TIMESTAMP, 0);
    }
    public KW_TIMESTAMP_3(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TIMESTAMP_3, 0);
    }
    public KW_TIMESTAMP_6(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TIMESTAMP_6, 0);
    }
    public KW_TIMESTAMP_9(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TIMESTAMP_9, 0);
    }
    public KW_TRUNCATE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TRUNCATE, 0);
    }
    public KW_UPPER(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_UPPER, 0);
    }
    public KW_WEEK(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_WEEK, 0);
    }
    public KW_YEAR(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_YEAR, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_reservedKeywordsUsedAsFuncName;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterReservedKeywordsUsedAsFuncName) {
             listener.enterReservedKeywordsUsedAsFuncName(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitReservedKeywordsUsedAsFuncName) {
             listener.exitReservedKeywordsUsedAsFuncName(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitReservedKeywordsUsedAsFuncName) {
            return visitor.visitReservedKeywordsUsedAsFuncName(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class NonReservedKeywordsContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_ADD(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ADD, 0);
    }
    public KW_ADMIN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ADMIN, 0);
    }
    public KW_AFTER(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_AFTER, 0);
    }
    public KW_ANALYZE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ANALYZE, 0);
    }
    public KW_ASC(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ASC, 0);
    }
    public KW_BEFORE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_BEFORE, 0);
    }
    public KW_BYTES(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_BYTES, 0);
    }
    public KW_CASCADE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_CASCADE, 0);
    }
    public KW_CATALOG(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_CATALOG, 0);
    }
    public KW_CATALOGS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_CATALOGS, 0);
    }
    public KW_CENTURY(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_CENTURY, 0);
    }
    public KW_CHAIN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_CHAIN, 0);
    }
    public KW_CHANGELOG_MODE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_CHANGELOG_MODE, 0);
    }
    public KW_CHARACTERS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_CHARACTERS, 0);
    }
    public KW_COMMENT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_COMMENT, 0);
    }
    public KW_COMPACT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_COMPACT, 0);
    }
    public KW_COMPUTE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_COMPUTE, 0);
    }
    public KW_COLUMNS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_COLUMNS, 0);
    }
    public KW_CONSTRAINTS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_CONSTRAINTS, 0);
    }
    public KW_CONSTRUCTOR(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_CONSTRUCTOR, 0);
    }
    public KW_CUMULATE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_CUMULATE, 0);
    }
    public KW_DATA(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DATA, 0);
    }
    public KW_DATABASE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DATABASE, 0);
    }
    public KW_DATABASES(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DATABASES, 0);
    }
    public KW_DAYS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DAYS, 0);
    }
    public KW_DECADE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DECADE, 0);
    }
    public KW_DEFINED(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DEFINED, 0);
    }
    public KW_DESC(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DESC, 0);
    }
    public KW_DESCRIPTOR(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DESCRIPTOR, 0);
    }
    public KW_DIV(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DIV, 0);
    }
    public KW_ENCODING(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ENCODING, 0);
    }
    public KW_ENFORCED(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ENFORCED, 0);
    }
    public KW_ENGINE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ENGINE, 0);
    }
    public KW_ERROR(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ERROR, 0);
    }
    public KW_ESTIMATED_COST(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ESTIMATED_COST, 0);
    }
    public KW_EXCEPTION(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_EXCEPTION, 0);
    }
    public KW_EXCLUDE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_EXCLUDE, 0);
    }
    public KW_EXCLUDING(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_EXCLUDING, 0);
    }
    public KW_EXTENDED(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_EXTENDED, 0);
    }
    public KW_FILE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FILE, 0);
    }
    public KW_FINAL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FINAL, 0);
    }
    public KW_FIRST(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FIRST, 0);
    }
    public KW_FOLLOWING(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FOLLOWING, 0);
    }
    public KW_FORMAT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FORMAT, 0);
    }
    public KW_FORTRAN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FORTRAN, 0);
    }
    public KW_FOUND(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FOUND, 0);
    }
    public KW_FRAC_SECOND(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FRAC_SECOND, 0);
    }
    public KW_FUNCTIONS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FUNCTIONS, 0);
    }
    public KW_GENERAL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_GENERAL, 0);
    }
    public KW_GENERATED(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_GENERATED, 0);
    }
    public KW_GO(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_GO, 0);
    }
    public KW_GOTO(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_GOTO, 0);
    }
    public KW_GRANTED(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_GRANTED, 0);
    }
    public KW_HOP(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_HOP, 0);
    }
    public KW_HOURS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_HOURS, 0);
    }
    public KW_IF(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_IF, 0);
    }
    public KW_IGNORE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_IGNORE, 0);
    }
    public KW_INCREMENT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_INCREMENT, 0);
    }
    public KW_INPUT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_INPUT, 0);
    }
    public KW_INVOKER(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_INVOKER, 0);
    }
    public KW_JAR(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_JAR, 0);
    }
    public KW_JARS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_JARS, 0);
    }
    public KW_JAVA(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_JAVA, 0);
    }
    public KW_JSON(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_JSON, 0);
    }
    public KW_JSON_EXECUTION_PLAN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_JSON_EXECUTION_PLAN, 0);
    }
    public KW_KEY(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_KEY, 0);
    }
    public KW_KEY_MEMBER(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_KEY_MEMBER, 0);
    }
    public KW_KEY_TYPE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_KEY_TYPE, 0);
    }
    public KW_LABEL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LABEL, 0);
    }
    public KW_LAST(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LAST, 0);
    }
    public KW_LENGTH(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LENGTH, 0);
    }
    public KW_LEVEL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LEVEL, 0);
    }
    public KW_LOAD(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LOAD, 0);
    }
    public KW_LOCALTIMESTAMP(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LOCALTIMESTAMP, 0);
    }
    public KW_MAP(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MAP, 0);
    }
    public KW_MICROSECOND(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MICROSECOND, 0);
    }
    public KW_MILLENNIUM(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MILLENNIUM, 0);
    }
    public KW_MILLISECOND(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MILLISECOND, 0);
    }
    public KW_MINUTES(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MINUTES, 0);
    }
    public KW_MINVALUE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MINVALUE, 0);
    }
    public KW_MODIFY(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MODIFY, 0);
    }
    public KW_MODULES(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MODULES, 0);
    }
    public KW_MONTHS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MONTHS, 0);
    }
    public KW_NANOSECOND(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NANOSECOND, 0);
    }
    public KW_NULLS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NULLS, 0);
    }
    public KW_NUMBER(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NUMBER, 0);
    }
    public KW_OPTION(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_OPTION, 0);
    }
    public KW_OPTIONS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_OPTIONS, 0);
    }
    public KW_ORDERING(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ORDERING, 0);
    }
    public KW_OUTPUT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_OUTPUT, 0);
    }
    public KW_OVERWRITE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_OVERWRITE, 0);
    }
    public KW_OVERWRITING(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_OVERWRITING, 0);
    }
    public KW_PARTITIONED(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PARTITIONED, 0);
    }
    public KW_PARTITIONS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PARTITIONS, 0);
    }
    public KW_PASSING(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PASSING, 0);
    }
    public KW_PAST(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PAST, 0);
    }
    public KW_PATH(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PATH, 0);
    }
    public KW_PLACING(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PLACING, 0);
    }
    public KW_PLAN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PLAN, 0);
    }
    public KW_PRECEDING(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PRECEDING, 0);
    }
    public KW_PRESERVE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PRESERVE, 0);
    }
    public KW_PRIOR(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PRIOR, 0);
    }
    public KW_PRIVILEGES(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PRIVILEGES, 0);
    }
    public KW_PUBLIC(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PUBLIC, 0);
    }
    public KW_PYTHON(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PYTHON, 0);
    }
    public KW_PYTHON_FILES(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PYTHON_FILES, 0);
    }
    public KW_PYTHON_REQUIREMENTS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PYTHON_REQUIREMENTS, 0);
    }
    public KW_PYTHON_DEPENDENCIES(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PYTHON_DEPENDENCIES, 0);
    }
    public KW_PYTHON_JAR(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PYTHON_JAR, 0);
    }
    public KW_PYTHON_ARCHIVES(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PYTHON_ARCHIVES, 0);
    }
    public KW_PYTHON_PARAMETER(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PYTHON_PARAMETER, 0);
    }
    public KW_QUARTER(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_QUARTER, 0);
    }
    public KW_RAW(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_RAW, 0);
    }
    public KW_READ(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_READ, 0);
    }
    public KW_RELATIVE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_RELATIVE, 0);
    }
    public KW_REMOVE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_REMOVE, 0);
    }
    public KW_RENAME(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_RENAME, 0);
    }
    public KW_REPLACE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_REPLACE, 0);
    }
    public KW_RESPECT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_RESPECT, 0);
    }
    public KW_RESTART(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_RESTART, 0);
    }
    public KW_RESTRICT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_RESTRICT, 0);
    }
    public KW_ROLE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ROLE, 0);
    }
    public KW_ROW_COUNT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ROW_COUNT, 0);
    }
    public KW_SCALA(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SCALA, 0);
    }
    public KW_SCALAR(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SCALAR, 0);
    }
    public KW_SCALE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SCALE, 0);
    }
    public KW_SCHEMA(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SCHEMA, 0);
    }
    public KW_SECONDS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SECONDS, 0);
    }
    public KW_SECTION(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SECTION, 0);
    }
    public KW_SECURITY(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SECURITY, 0);
    }
    public KW_SELF(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SELF, 0);
    }
    public KW_SERVER(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SERVER, 0);
    }
    public KW_SERVER_NAME(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SERVER_NAME, 0);
    }
    public KW_SESSION(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SESSION, 0);
    }
    public KW_SETS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SETS, 0);
    }
    public KW_SIMPLE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SIMPLE, 0);
    }
    public KW_SIZE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SIZE, 0);
    }
    public KW_SLIDE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SLIDE, 0);
    }
    public KW_SOURCE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SOURCE, 0);
    }
    public KW_SPACE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SPACE, 0);
    }
    public KW_STATE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_STATE, 0);
    }
    public KW_STATEMENT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_STATEMENT, 0);
    }
    public KW_STEP(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_STEP, 0);
    }
    public KW_STRING(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_STRING, 0);
    }
    public KW_STRUCTURE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_STRUCTURE, 0);
    }
    public KW_STYLE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_STYLE, 0);
    }
    public KW_TABLES(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TABLES, 0);
    }
    public KW_TEMPORARY(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TEMPORARY, 0);
    }
    public KW_TIMECOL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TIMECOL, 0);
    }
    public KW_FLOOR(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FLOOR, 0);
    }
    public KW_TIMESTAMP_LTZ(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TIMESTAMP_LTZ, 0);
    }
    public KW_TIMESTAMPADD(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TIMESTAMPADD, 0);
    }
    public KW_TIMESTAMPDIFF(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TIMESTAMPDIFF, 0);
    }
    public KW_TOTIMESTAMP(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TOTIMESTAMP, 0);
    }
    public KW_TRANSFORM(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TRANSFORM, 0);
    }
    public KW_TUMBLE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TUMBLE, 0);
    }
    public KW_TYPE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TYPE, 0);
    }
    public KW_UNDER(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_UNDER, 0);
    }
    public KW_UNLOAD(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_UNLOAD, 0);
    }
    public KW_USAGE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_USAGE, 0);
    }
    public KW_USE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_USE, 0);
    }
    public KW_UTF16(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_UTF16, 0);
    }
    public KW_UTF32(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_UTF32, 0);
    }
    public KW_UTF8(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_UTF8, 0);
    }
    public KW_VERSION(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_VERSION, 0);
    }
    public KW_VIEW(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_VIEW, 0);
    }
    public KW_VIEWS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_VIEWS, 0);
    }
    public KW_VIRTUAL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_VIRTUAL, 0);
    }
    public KW_WATERMARK(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_WATERMARK, 0);
    }
    public KW_WATERMARKS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_WATERMARKS, 0);
    }
    public KW_WEEK(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_WEEK, 0);
    }
    public KW_WORK(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_WORK, 0);
    }
    public KW_WRAPPER(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_WRAPPER, 0);
    }
    public KW_YEARS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_YEARS, 0);
    }
    public KW_ZONE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ZONE, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_nonReservedKeywords;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterNonReservedKeywords) {
             listener.enterNonReservedKeywords(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitNonReservedKeywords) {
             listener.exitNonReservedKeywords(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitNonReservedKeywords) {
            return visitor.visitNonReservedKeywords(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class SelectStatementPlusContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public SEMICOLON(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.SEMICOLON, 0)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_selectStatementPlus;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterSelectStatementPlus) {
             listener.enterSelectStatementPlus(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitSelectStatementPlus) {
             listener.exitSelectStatementPlus(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitSelectStatementPlus) {
            return visitor.visitSelectStatementPlus(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
