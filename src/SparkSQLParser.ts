// Generated from gen/SparkSQL.g4 by ANTLR 4.13.1

import * as antlr from "antlr4ng";
import { Token } from "antlr4ng";

import { SparkSQLListener } from "./SparkSQLListener.js";
import { SparkSQLVisitor } from "./SparkSQLVisitor.js";

// for running tests with parameters, TODO: discuss strategy for typed parameters in CI
// eslint-disable-next-line no-unused-vars
type int = number;


export class SparkSQLParser extends antlr.Parser {
    public static readonly CHINESE_SIGN = 1;
    public static readonly CHINESE_STR = 2;
    public static readonly SPACE = 3;
    public static readonly COMMENT_INPUT = 4;
    public static readonly LINE_COMMENT = 5;
    public static readonly KW_ADD = 6;
    public static readonly KW_ADMIN = 7;
    public static readonly KW_AFTER = 8;
    public static readonly KW_ANALYZE = 9;
    public static readonly KW_ASC = 10;
    public static readonly KW_BEFORE = 11;
    public static readonly KW_BYTE = 12;
    public static readonly KW_BYTES = 13;
    public static readonly KW_CACHE = 14;
    public static readonly KW_CASCADE = 15;
    public static readonly KW_CATALOG = 16;
    public static readonly KW_CATALOGS = 17;
    public static readonly KW_CLEAR = 18;
    public static readonly KW_CENTURY = 19;
    public static readonly KW_CHAIN = 20;
    public static readonly KW_CHANGELOG_MODE = 21;
    public static readonly KW_CHARACTERS = 22;
    public static readonly KW_COMMENT = 23;
    public static readonly KW_COMPACT = 24;
    public static readonly KW_COLUMNS = 25;
    public static readonly KW_CONSTRAINTS = 26;
    public static readonly KW_CONSTRUCTOR = 27;
    public static readonly KW_COMPUTE = 28;
    public static readonly KW_CUMULATE = 29;
    public static readonly KW_DATA = 30;
    public static readonly KW_DATABASE = 31;
    public static readonly KW_DATABASES = 32;
    public static readonly KW_DAYS = 33;
    public static readonly KW_DBPROPERTIES = 34;
    public static readonly KW_DECADE = 35;
    public static readonly KW_DEFINED = 36;
    public static readonly KW_DESC = 37;
    public static readonly KW_DESCRIPTOR = 38;
    public static readonly KW_DIV = 39;
    public static readonly KW_ENCODING = 40;
    public static readonly KW_ENFORCED = 41;
    public static readonly KW_ENGINE = 42;
    public static readonly KW_EPOCH = 43;
    public static readonly KW_ERROR = 44;
    public static readonly KW_ESTIMATED_COST = 45;
    public static readonly KW_EXCEPTION = 46;
    public static readonly KW_EXCLUDE = 47;
    public static readonly KW_EXCLUDING = 48;
    public static readonly KW_EXTENDED = 49;
    public static readonly KW_FILTER = 50;
    public static readonly KW_FILE = 51;
    public static readonly KW_FILES = 52;
    public static readonly KW_FINAL = 53;
    public static readonly KW_FIRST = 54;
    public static readonly KW_FOLLOWING = 55;
    public static readonly KW_FORMAT = 56;
    public static readonly KW_FORTRAN = 57;
    public static readonly KW_FOUND = 58;
    public static readonly KW_FRAC_SECOND = 59;
    public static readonly KW_FUNCTIONS = 60;
    public static readonly KW_GENERAL = 61;
    public static readonly KW_GENERATED = 62;
    public static readonly KW_GO = 63;
    public static readonly KW_GOTO = 64;
    public static readonly KW_GRANTED = 65;
    public static readonly KW_HOP = 66;
    public static readonly KW_HOURS = 67;
    public static readonly KW_IF = 68;
    public static readonly KW_IGNORE = 69;
    public static readonly KW_INCLUDE = 70;
    public static readonly KW_INCREMENT = 71;
    public static readonly KW_INPUT = 72;
    public static readonly KW_INVOKER = 73;
    public static readonly KW_JAR = 74;
    public static readonly KW_JARS = 75;
    public static readonly KW_JAVA = 76;
    public static readonly KW_JSON = 77;
    public static readonly KW_JSON_EXECUTION_PLAN = 78;
    public static readonly KW_KEY = 79;
    public static readonly KW_KEYS = 80;
    public static readonly KW_KEY_MEMBER = 81;
    public static readonly KW_KEY_TYPE = 82;
    public static readonly KW_LABEL = 83;
    public static readonly KW_LAST = 84;
    public static readonly KW_LENGTH = 85;
    public static readonly KW_LEVEL = 86;
    public static readonly KW_LIST = 87;
    public static readonly KW_LOAD = 88;
    public static readonly KW_LOCATION = 89;
    public static readonly KW_LONG = 90;
    public static readonly KW_MAP = 91;
    public static readonly KW_MICROSECOND = 92;
    public static readonly KW_MILLENNIUM = 93;
    public static readonly KW_MILLISECOND = 94;
    public static readonly KW_MINUTES = 95;
    public static readonly KW_MINVALUE = 96;
    public static readonly KW_MODIFY = 97;
    public static readonly KW_MODULES = 98;
    public static readonly KW_MONTHS = 99;
    public static readonly KW_NANOSECOND = 100;
    public static readonly KW_NOSCAN = 101;
    public static readonly KW_NULLS = 102;
    public static readonly KW_NUMBER = 103;
    public static readonly KW_OPTION = 104;
    public static readonly KW_OPTIONS = 105;
    public static readonly KW_ORDERING = 106;
    public static readonly KW_OUTPUT = 107;
    public static readonly KW_OVERWRITE = 108;
    public static readonly KW_OVERWRITING = 109;
    public static readonly KW_PARTITIONED = 110;
    public static readonly KW_PARTITIONS = 111;
    public static readonly KW_PASSING = 112;
    public static readonly KW_PAST = 113;
    public static readonly KW_PATH = 114;
    public static readonly KW_PLACING = 115;
    public static readonly KW_PLAN = 116;
    public static readonly KW_PRECEDING = 117;
    public static readonly KW_PRESERVE = 118;
    public static readonly KW_PRIOR = 119;
    public static readonly KW_PRIVILEGES = 120;
    public static readonly KW_PUBLIC = 121;
    public static readonly KW_PYTHON = 122;
    public static readonly KW_PYTHON_FILES = 123;
    public static readonly KW_PYTHON_REQUIREMENTS = 124;
    public static readonly KW_PYTHON_DEPENDENCIES = 125;
    public static readonly KW_PYTHON_JAR = 126;
    public static readonly KW_PYTHON_ARCHIVES = 127;
    public static readonly KW_PYTHON_PARAMETER = 128;
    public static readonly KW_QUARTER = 129;
    public static readonly KW_QUERY = 130;
    public static readonly KW_RAW = 131;
    public static readonly KW_READ = 132;
    public static readonly KW_REAL = 133;
    public static readonly KW_RECORDREADER = 134;
    public static readonly KW_RELATIVE = 135;
    public static readonly KW_REMOVE = 136;
    public static readonly KW_RENAME = 137;
    public static readonly KW_REPLACE = 138;
    public static readonly KW_RESPECT = 139;
    public static readonly KW_RESTART = 140;
    public static readonly KW_RESTRICT = 141;
    public static readonly KW_ROLE = 142;
    public static readonly KW_ROW_COUNT = 143;
    public static readonly KW_SCALA = 144;
    public static readonly KW_SCALAR = 145;
    public static readonly KW_SCALE = 146;
    public static readonly KW_SCHEMA = 147;
    public static readonly KW_SCHEMAS = 148;
    public static readonly KW_SECONDS = 149;
    public static readonly KW_SECTION = 150;
    public static readonly KW_SECURITY = 151;
    public static readonly KW_SELF = 152;
    public static readonly KW_SERVER = 153;
    public static readonly KW_SERVER_NAME = 154;
    public static readonly KW_SESSION = 155;
    public static readonly KW_SETS = 156;
    public static readonly KW_SHORT = 157;
    public static readonly KW_SIMPLE = 158;
    public static readonly KW_SIZE = 159;
    public static readonly KW_SLIDE = 160;
    public static readonly KW_SOURCE = 161;
    public static readonly KW_SPACE = 162;
    public static readonly KW_SERDEPROPERTIES = 163;
    public static readonly KW_STATE = 164;
    public static readonly KW_STATISTICS = 165;
    public static readonly KW_STATEMENT = 166;
    public static readonly KW_STEP = 167;
    public static readonly KW_STRING = 168;
    public static readonly KW_STRUCTURE = 169;
    public static readonly KW_STYLE = 170;
    public static readonly KW_TABLES = 171;
    public static readonly KW_TEMPORARY = 172;
    public static readonly KW_TIMECOL = 173;
    public static readonly KW_FLOOR = 174;
    public static readonly KW_TIMESTAMP_LTZ = 175;
    public static readonly KW_TIMESTAMP_NTZ = 176;
    public static readonly KW_TIMESTAMPADD = 177;
    public static readonly KW_TIMESTAMPDIFF = 178;
    public static readonly KW_TOTIMESTAMP = 179;
    public static readonly KW_TRANSFORM = 180;
    public static readonly KW_TUMBLE = 181;
    public static readonly KW_TYPE = 182;
    public static readonly KW_UNCACHE = 183;
    public static readonly KW_UNDER = 184;
    public static readonly KW_UNBOUNDED = 185;
    public static readonly KW_UNLOAD = 186;
    public static readonly KW_USAGE = 187;
    public static readonly KW_USE = 188;
    public static readonly KW_UTF16 = 189;
    public static readonly KW_UTF32 = 190;
    public static readonly KW_UTF8 = 191;
    public static readonly KW_VERSION = 192;
    public static readonly KW_VIEW = 193;
    public static readonly KW_VIEWS = 194;
    public static readonly KW_VIRTUAL = 195;
    public static readonly KW_WATERMARK = 196;
    public static readonly KW_WATERMARKS = 197;
    public static readonly KW_WEEK = 198;
    public static readonly KW_WEEKS = 199;
    public static readonly KW_WORK = 200;
    public static readonly KW_WRAPPER = 201;
    public static readonly KW_YEARS = 202;
    public static readonly KW_ZONE = 203;
    public static readonly KW_ABS = 204;
    public static readonly KW_ALL = 205;
    public static readonly KW_ALLOW = 206;
    public static readonly KW_ALTER = 207;
    public static readonly KW_AND = 208;
    public static readonly KW_ANY = 209;
    public static readonly KW_ARE = 210;
    public static readonly KW_ARRAY = 211;
    public static readonly KW_AS = 212;
    public static readonly KW_ASYMMETRIC = 213;
    public static readonly KW_AT = 214;
    public static readonly KW_AVG = 215;
    public static readonly KW_BEGIN = 216;
    public static readonly KW_BETWEEN = 217;
    public static readonly KW_BIGINT = 218;
    public static readonly KW_BINARY = 219;
    public static readonly KW_BIT = 220;
    public static readonly KW_BLOB = 221;
    public static readonly KW_BOOLEAN = 222;
    public static readonly KW_BOTH = 223;
    public static readonly KW_BUCKET = 224;
    public static readonly KW_BUCKETS = 225;
    public static readonly KW_BY = 226;
    public static readonly KW_CALL = 227;
    public static readonly KW_CALLED = 228;
    public static readonly KW_CASCADED = 229;
    public static readonly KW_CASE = 230;
    public static readonly KW_CAST = 231;
    public static readonly KW_CEIL = 232;
    public static readonly KW_CHAR = 233;
    public static readonly KW_CHARACTER = 234;
    public static readonly KW_CHECK = 235;
    public static readonly KW_CLOB = 236;
    public static readonly KW_CLOSE = 237;
    public static readonly KW_CLUSTER = 238;
    public static readonly KW_CLUSTERED = 239;
    public static readonly KW_COALESCE = 240;
    public static readonly KW_COLLATE = 241;
    public static readonly KW_COLLECT = 242;
    public static readonly KW_COLUMN = 243;
    public static readonly KW_COMMIT = 244;
    public static readonly KW_CONNECT = 245;
    public static readonly KW_CONSTRAINT = 246;
    public static readonly KW_CONTAINS = 247;
    public static readonly KW_CONVERT = 248;
    public static readonly KW_COUNT = 249;
    public static readonly KW_CURRENT_TIMESTAMP = 250;
    public static readonly KW_CREATE = 251;
    public static readonly KW_CROSS = 252;
    public static readonly KW_CUBE = 253;
    public static readonly KW_CUME_DIST = 254;
    public static readonly KW_CURRENT = 255;
    public static readonly KW_CURSOR = 256;
    public static readonly KW_CYCLE = 257;
    public static readonly KW_COLLECTION = 258;
    public static readonly KW_DATE = 259;
    public static readonly KW_DATETIME = 260;
    public static readonly KW_DAY = 261;
    public static readonly KW_DEC = 262;
    public static readonly KW_DECIMAL = 263;
    public static readonly KW_DECLARE = 264;
    public static readonly KW_DEFAULT = 265;
    public static readonly KW_DEFINE = 266;
    public static readonly KW_DELETE = 267;
    public static readonly KW_DELIMITED = 268;
    public static readonly KW_DESCRIBE = 269;
    public static readonly KW_DENSE_RANK = 270;
    public static readonly KW_DISTINCT = 271;
    public static readonly KW_DIRECTORY = 272;
    public static readonly KW_DISTRIBUTED = 273;
    public static readonly KW_DISTRIBUTE = 274;
    public static readonly KW_DOUBLE = 275;
    public static readonly KW_DROP = 276;
    public static readonly KW_EACH = 277;
    public static readonly KW_ELSE = 278;
    public static readonly KW_END = 279;
    public static readonly KW_EQUALS = 280;
    public static readonly KW_ESCAPE = 281;
    public static readonly KW_ESCAPED = 282;
    public static readonly KW_EXCEPT = 283;
    public static readonly KW_EXECUTE = 284;
    public static readonly KW_EXISTS = 285;
    public static readonly KW_EXPLAIN = 286;
    public static readonly KW_EXPLODE = 287;
    public static readonly KW_EXPLODE_OUTER = 288;
    public static readonly KW_EXTERNAL = 289;
    public static readonly KW_EXTRACT = 290;
    public static readonly KW_FIRST_VALUE = 291;
    public static readonly KW_FALSE = 292;
    public static readonly KW_FLOAT = 293;
    public static readonly KW_FIELDS = 294;
    public static readonly KW_FOR = 295;
    public static readonly KW_FROM = 296;
    public static readonly KW_FROM_UNIXTIME = 297;
    public static readonly KW_FULL = 298;
    public static readonly KW_FUNCTION = 299;
    public static readonly KW_GLOBAL = 300;
    public static readonly KW_GRANT = 301;
    public static readonly KW_GROUP = 302;
    public static readonly KW_GROUPING = 303;
    public static readonly KW_GROUPS = 304;
    public static readonly KW_HASH = 305;
    public static readonly KW_HAVING = 306;
    public static readonly KW_HOUR = 307;
    public static readonly KW_IMPORT = 308;
    public static readonly KW_IN = 309;
    public static readonly KW_INCLUDING = 310;
    public static readonly KW_INPUTFORMAT = 311;
    public static readonly KW_INNER = 312;
    public static readonly KW_INOUT = 313;
    public static readonly KW_INSERT = 314;
    public static readonly KW_INT = 315;
    public static readonly KW_INTEGER = 316;
    public static readonly KW_INTERSECT = 317;
    public static readonly KW_INTERVAL = 318;
    public static readonly KW_INTO = 319;
    public static readonly KW_INPATH = 320;
    public static readonly KW_INLINE = 321;
    public static readonly KW_INLINE_OUTER = 322;
    public static readonly KW_ITEMS = 323;
    public static readonly KW_IS = 324;
    public static readonly KW_JOIN = 325;
    public static readonly KW_JSON_TUPLE = 326;
    public static readonly KW_LAG = 327;
    public static readonly KW_LANGUAGE = 328;
    public static readonly KW_LATERAL = 329;
    public static readonly KW_LAST_VALUE = 330;
    public static readonly KW_LEAD = 331;
    public static readonly KW_LEADING = 332;
    public static readonly KW_LEFT = 333;
    public static readonly KW_LIKE = 334;
    public static readonly KW_LINES = 335;
    public static readonly KW_LIMIT = 336;
    public static readonly KW_LOCAL = 337;
    public static readonly KW_LOCALTIMESTAMP = 338;
    public static readonly KW_MATCH = 339;
    public static readonly KW_MATCH_RECOGNIZE = 340;
    public static readonly KW_MEASURES = 341;
    public static readonly KW_MERGE = 342;
    public static readonly KW_METADATA = 343;
    public static readonly KW_MINUS = 344;
    public static readonly KW_MINUTE = 345;
    public static readonly KW_MODIFIES = 346;
    public static readonly KW_MODULE = 347;
    public static readonly KW_MONTH = 348;
    public static readonly KW_MULTISET = 349;
    public static readonly KW_NATURAL = 350;
    public static readonly KW_NEXT = 351;
    public static readonly KW_NO = 352;
    public static readonly KW_NONE = 353;
    public static readonly KW_NOT = 354;
    public static readonly KW_NTILE = 355;
    public static readonly KW_NTH_VALUE = 356;
    public static readonly KW_NULL = 357;
    public static readonly KW_NUMERIC = 358;
    public static readonly KW_OF = 359;
    public static readonly KW_OFFSET = 360;
    public static readonly KW_ON = 361;
    public static readonly KW_ONE = 362;
    public static readonly KW_OR = 363;
    public static readonly KW_ORDER = 364;
    public static readonly KW_OUT = 365;
    public static readonly KW_OUTER = 366;
    public static readonly KW_OUTPUTFORMAT = 367;
    public static readonly KW_OVER = 368;
    public static readonly KW_OVERLAY = 369;
    public static readonly KW_PARSE_URL = 370;
    public static readonly KW_PARTITION = 371;
    public static readonly KW_PATTERN = 372;
    public static readonly KW_PER = 373;
    public static readonly KW_PERCENT = 374;
    public static readonly KW_PERCENT_RANK = 375;
    public static readonly KW_PERCENTILE_CONT = 376;
    public static readonly KW_PERCENTILE_DISC = 377;
    public static readonly KW_PERIOD = 378;
    public static readonly KW_PIVOT = 379;
    public static readonly KW_POSITION = 380;
    public static readonly KW_POWER = 381;
    public static readonly KW_POSEXPLODE = 382;
    public static readonly KW_POSEXPLODE_OUTER = 383;
    public static readonly KW_PRIMARY = 384;
    public static readonly KW_PURGE = 385;
    public static readonly KW_RANGE = 386;
    public static readonly KW_RECORDWRITER = 387;
    public static readonly KW_ROW_NUMBER = 388;
    public static readonly KW_RANK = 389;
    public static readonly KW_REGEXP = 390;
    public static readonly KW_RESET = 391;
    public static readonly KW_REVOKE = 392;
    public static readonly KW_REPAIR = 393;
    public static readonly KW_RIGHT = 394;
    public static readonly KW_RLIKE = 395;
    public static readonly KW_ROLLBACK = 396;
    public static readonly KW_ROLLUP = 397;
    public static readonly KW_ROW = 398;
    public static readonly KW_ROWS = 399;
    public static readonly KW_SECOND = 400;
    public static readonly KW_SELECT = 401;
    public static readonly KW_SEMI = 402;
    public static readonly KW_SET = 403;
    public static readonly KW_SERDE = 404;
    public static readonly KW_SHOW = 405;
    public static readonly KW_SIMILAR = 406;
    public static readonly KW_SKIP = 407;
    public static readonly KW_STORED = 408;
    public static readonly KW_SORTED = 409;
    public static readonly KW_SMALLINT = 410;
    public static readonly KW_STACK = 411;
    public static readonly KW_START = 412;
    public static readonly KW_STATIC = 413;
    public static readonly KW_STRUCT = 414;
    public static readonly KW_SORT = 415;
    public static readonly KW_SUBSTRING = 416;
    public static readonly KW_SUM = 417;
    public static readonly KW_SYMMETRIC = 418;
    public static readonly KW_SYSTEM = 419;
    public static readonly KW_SYSTEM_TIME = 420;
    public static readonly KW_SYSTEM_USER = 421;
    public static readonly KW_TABLE = 422;
    public static readonly KW_TBLPROPERTIES = 423;
    public static readonly KW_TABLESAMPLE = 424;
    public static readonly KW_TERMINATED = 425;
    public static readonly KW_THEN = 426;
    public static readonly KW_TIME = 427;
    public static readonly KW_TIMESTAMP = 428;
    public static readonly KW_TIMESTAMP_3 = 429;
    public static readonly KW_TIMESTAMP_6 = 430;
    public static readonly KW_TIMESTAMP_9 = 431;
    public static readonly KW_TINYINT = 432;
    public static readonly KW_TO = 433;
    public static readonly KW_TRAILING = 434;
    public static readonly KW_TRUE = 435;
    public static readonly KW_TRUNCATE = 436;
    public static readonly KW_UNION = 437;
    public static readonly KW_UNIQUE = 438;
    public static readonly KW_UNKNOWN = 439;
    public static readonly KW_UNSET = 440;
    public static readonly KW_UNPIVOT = 441;
    public static readonly KW_UPPER = 442;
    public static readonly KW_UPSERT = 443;
    public static readonly KW_USER = 444;
    public static readonly KW_USING = 445;
    public static readonly KW_VALUE = 446;
    public static readonly KW_VALUES = 447;
    public static readonly KW_VARBINARY = 448;
    public static readonly KW_VARCHAR = 449;
    public static readonly KW_WHEN = 450;
    public static readonly KW_WHERE = 451;
    public static readonly KW_WINDOW = 452;
    public static readonly KW_WITH = 453;
    public static readonly KW_WITHIN = 454;
    public static readonly KW_WITHOUT = 455;
    public static readonly KW_YEAR = 456;
    public static readonly KW_MATERIALIZED = 457;
    public static readonly KW_FRESHNESS = 458;
    public static readonly KW_REFRESH_MODE = 459;
    public static readonly KW_RECOVER = 460;
    public static readonly KW_CONTINUOUS = 461;
    public static readonly KW_SUSPEND = 462;
    public static readonly KW_RESUME = 463;
    public static readonly KW_REFRESH = 464;
    public static readonly BIT_NOT_OP = 465;
    public static readonly BIT_OR_OP = 466;
    public static readonly BIT_AND_OP = 467;
    public static readonly BIT_XOR_OP = 468;
    public static readonly EQUAL_SYMBOL = 469;
    public static readonly GREATER_SYMBOL = 470;
    public static readonly LESS_SYMBOL = 471;
    public static readonly EXCLAMATION_SYMBOL = 472;
    public static readonly DOT = 473;
    public static readonly LS_BRACKET = 474;
    public static readonly RS_BRACKET = 475;
    public static readonly LR_BRACKET = 476;
    public static readonly RR_BRACKET = 477;
    public static readonly LB_BRACKET = 478;
    public static readonly RB_BRACKET = 479;
    public static readonly COMMA = 480;
    public static readonly SEMICOLON = 481;
    public static readonly AT_SIGN = 482;
    public static readonly DOLLAR = 483;
    public static readonly SINGLE_QUOTE_SYMB = 484;
    public static readonly DOUBLE_QUOTE_SYMB = 485;
    public static readonly REVERSE_QUOTE_SYMB = 486;
    public static readonly COLON_SYMB = 487;
    public static readonly ASTERISK_SIGN = 488;
    public static readonly UNDERLINE_SIGN = 489;
    public static readonly HYPNEN_SIGN = 490;
    public static readonly ADD_SIGN = 491;
    public static readonly PENCENT_SIGN = 492;
    public static readonly DOUBLE_VERTICAL_SIGN = 493;
    public static readonly DOUBLE_HYPNEN_SIGN = 494;
    public static readonly SLASH_SIGN = 495;
    public static readonly QUESTION_MARK_SIGN = 496;
    public static readonly DOUBLE_RIGHT_ARROW = 497;
    public static readonly STRING_LITERAL = 498;
    public static readonly DIG_LITERAL = 499;
    public static readonly REAL_LITERAL = 500;
    public static readonly ID_LITERAL = 501;
    public static readonly RULE_statement = 0;
    public static readonly RULE_sqlStatements = 1;
    public static readonly RULE_emptyStatement = 2;
    public static readonly RULE_createStatement = 3;
    public static readonly RULE_dmlStatement = 4;
    public static readonly RULE_createTable = 5;
    public static readonly RULE_simpleCreateTable = 6;
    public static readonly RULE_simpleCreateTableNoSortElement = 7;
    public static readonly RULE_location = 8;
    public static readonly RULE_sortedBy = 9;
    public static readonly RULE_usingCreate = 10;
    public static readonly RULE_tblProperties = 11;
    public static readonly RULE_defaultColumnUsing = 12;
    public static readonly RULE_defaultColumnUsingNoSortElement = 13;
    public static readonly RULE_columnUsing = 14;
    public static readonly RULE_columnUsingNoSortElement = 15;
    public static readonly RULE_usingByQuery = 16;
    public static readonly RULE_usingByQueryNoSortElement = 17;
    public static readonly RULE_intoBuckets = 18;
    public static readonly RULE_hiveFormatpartitionDefinition = 19;
    public static readonly RULE_rowFormatSerde = 20;
    public static readonly RULE_fieldsTerminatedBy = 21;
    public static readonly RULE_storedAs = 22;
    public static readonly RULE_storedAsInputformat = 23;
    public static readonly RULE_outputformat = 24;
    public static readonly RULE_rowFormatDelimted = 25;
    public static readonly RULE_columnsBody = 26;
    public static readonly RULE_createCustomSerde = 27;
    public static readonly RULE_createCustomSerdeNoSortElement = 28;
    public static readonly RULE_createCustomSerdeExternal = 29;
    public static readonly RULE_createCustomSerdeExternalNoSortElement = 30;
    public static readonly RULE_createTableAsSelect = 31;
    public static readonly RULE_createMaterializedTableAsSelect = 32;
    public static readonly RULE_createMaterializedTableAsSelectNoSortElement = 33;
    public static readonly RULE_usingClause = 34;
    public static readonly RULE_jarFileName = 35;
    public static readonly RULE_filePath = 36;
    public static readonly RULE_ifExistsPart = 37;
    public static readonly RULE_columnPosition = 38;
    public static readonly RULE_renameDefinition = 39;
    public static readonly RULE_setKeyValueDefinition = 40;
    public static readonly RULE_addConstraint = 41;
    public static readonly RULE_dropConstraint = 42;
    public static readonly RULE_addUnique = 43;
    public static readonly RULE_notForced = 44;
    public static readonly RULE_insertStatement = 45;
    public static readonly RULE_insertSimpleStatement = 46;
    public static readonly RULE_insertPartitionDefinition = 47;
    public static readonly RULE_queryStatement = 48;
    public static readonly RULE_withClause = 49;
    public static readonly RULE_valuesCaluse = 50;
    public static readonly RULE_inlineBody = 51;
    public static readonly RULE_withItem = 52;
    public static readonly RULE_withItemName = 53;
    public static readonly RULE_selectClause = 54;
    public static readonly RULE_filterPart = 55;
    public static readonly RULE_overWindowItem = 56;
    public static readonly RULE_overClause = 57;
    public static readonly RULE_windowFunctioPart = 58;
    public static readonly RULE_windowFunctionName = 59;
    public static readonly RULE_analyticFunction = 60;
    public static readonly RULE_rangkingFunction = 61;
    public static readonly RULE_fromClause = 62;
    public static readonly RULE_windowFrameForWindowsQuery = 63;
    public static readonly RULE_frameExpession = 64;
    public static readonly RULE_tableExpression = 65;
    public static readonly RULE_tvfClause = 66;
    public static readonly RULE_rangeClause = 67;
    public static readonly RULE_viewReference = 68;
    public static readonly RULE_pivotReference = 69;
    public static readonly RULE_tableReference = 70;
    public static readonly RULE_tablePrimary = 71;
    public static readonly RULE_funtionBody = 72;
    public static readonly RULE_unpivotBody = 73;
    public static readonly RULE_pivotBody = 74;
    public static readonly RULE_expressionAsAlias = 75;
    public static readonly RULE_expressionAsAliasList = 76;
    public static readonly RULE_systemTimePeriod = 77;
    public static readonly RULE_dateTimeExpression = 78;
    public static readonly RULE_inlineDataValueClause = 79;
    public static readonly RULE_windowTVFClause = 80;
    public static readonly RULE_windowTVFExpression = 81;
    public static readonly RULE_windowTVFName = 82;
    public static readonly RULE_rowFormatDelimited = 83;
    public static readonly RULE_hiveSerde = 84;
    public static readonly RULE_usingAsColumnPart = 85;
    public static readonly RULE_hiveSerdePart = 86;
    public static readonly RULE_tableCanHasKeyPropertyList = 87;
    public static readonly RULE_sparkRecordWriterPart = 88;
    public static readonly RULE_windowTVFParam = 89;
    public static readonly RULE_timeIntervalParamName = 90;
    public static readonly RULE_columnDescriptor = 91;
    public static readonly RULE_joinCondition = 92;
    public static readonly RULE_whereClause = 93;
    public static readonly RULE_samplingQueries = 94;
    public static readonly RULE_someByClause = 95;
    public static readonly RULE_clusterByClause = 96;
    public static readonly RULE_clusteredByClause = 97;
    public static readonly RULE_distributeByClause = 98;
    public static readonly RULE_groupByClause = 99;
    public static readonly RULE_groupItemDefinition = 100;
    public static readonly RULE_groupingSet = 101;
    public static readonly RULE_groupingSets = 102;
    public static readonly RULE_groupingSetsNotionName = 103;
    public static readonly RULE_groupWindowFunction = 104;
    public static readonly RULE_groupWindowFunctionName = 105;
    public static readonly RULE_timeAttrColumn = 106;
    public static readonly RULE_havingClause = 107;
    public static readonly RULE_windowClause = 108;
    public static readonly RULE_namedWindow = 109;
    public static readonly RULE_windowSpec = 110;
    public static readonly RULE_matchRecognizeClause = 111;
    public static readonly RULE_orderByCaluse = 112;
    public static readonly RULE_sortByCaluse = 113;
    public static readonly RULE_orderItemDefinition = 114;
    public static readonly RULE_limitClause = 115;
    public static readonly RULE_offsetClause = 116;
    public static readonly RULE_partitionByClause = 117;
    public static readonly RULE_quantifiers = 118;
    public static readonly RULE_measuresClause = 119;
    public static readonly RULE_patternDefinition = 120;
    public static readonly RULE_patternVariable = 121;
    public static readonly RULE_outputMode = 122;
    public static readonly RULE_afterMatchStrategy = 123;
    public static readonly RULE_patternVariablesDefinition = 124;
    public static readonly RULE_windowFrame = 125;
    public static readonly RULE_frameBound = 126;
    public static readonly RULE_withinClause = 127;
    public static readonly RULE_selfDefinitionClause = 128;
    public static readonly RULE_partitionDefinition = 129;
    public static readonly RULE_transformList = 130;
    public static readonly RULE_transform = 131;
    public static readonly RULE_transformArgument = 132;
    public static readonly RULE_likeDefinition = 133;
    public static readonly RULE_distribution = 134;
    public static readonly RULE_using = 135;
    public static readonly RULE_likeOption = 136;
    public static readonly RULE_columnOptionDefinition = 137;
    public static readonly RULE_physicalColumnDefinitionList = 138;
    public static readonly RULE_physicalColumnDefinition = 139;
    public static readonly RULE_computedColumnExpression = 140;
    public static readonly RULE_watermarkDefinition = 141;
    public static readonly RULE_tableConstraint = 142;
    public static readonly RULE_constraintName = 143;
    public static readonly RULE_valuesDefinition = 144;
    public static readonly RULE_valuesRowDefinition = 145;
    public static readonly RULE_lengthOneDimension = 146;
    public static readonly RULE_lengthTwoOptionalDimension = 147;
    public static readonly RULE_lengthTwoStringDimension = 148;
    public static readonly RULE_lengthOneTypeDimension = 149;
    public static readonly RULE_mapTypeDimension = 150;
    public static readonly RULE_rowTypeDimension = 151;
    public static readonly RULE_structTypeDimension = 152;
    public static readonly RULE_columnConstraint = 153;
    public static readonly RULE_commentSpec = 154;
    public static readonly RULE_metadataColumnDefinition = 155;
    public static readonly RULE_metadataKey = 156;
    public static readonly RULE_computedColumnDefinition = 157;
    public static readonly RULE_columnName = 158;
    public static readonly RULE_columnNameList = 159;
    public static readonly RULE_columnType = 160;
    public static readonly RULE_expression = 161;
    public static readonly RULE_booleanExpression = 162;
    public static readonly RULE_predicate = 163;
    public static readonly RULE_likePredicate = 164;
    public static readonly RULE_valueExpression = 165;
    public static readonly RULE_primaryExpression = 166;
    public static readonly RULE_complexDataTypeExpression = 167;
    public static readonly RULE_arrayExpression = 168;
    public static readonly RULE_structExpression = 169;
    public static readonly RULE_rowExpression = 170;
    public static readonly RULE_mapExpression = 171;
    public static readonly RULE_dataTypeExpression = 172;
    public static readonly RULE_sqlSimpleType = 173;
    public static readonly RULE_functionName = 174;
    public static readonly RULE_functionParam = 175;
    public static readonly RULE_filterClause = 176;
    public static readonly RULE_correlationName = 177;
    public static readonly RULE_qualifiedName = 178;
    public static readonly RULE_timeIntervalExpression = 179;
    public static readonly RULE_errorCapturingMultiUnitsInterval = 180;
    public static readonly RULE_multiUnitsInterval = 181;
    public static readonly RULE_errorCapturingUnitToUnitInterval = 182;
    public static readonly RULE_unitToUnitInterval = 183;
    public static readonly RULE_intervalValue = 184;
    public static readonly RULE_columnAlias = 185;
    public static readonly RULE_tableAlias = 186;
    public static readonly RULE_anyAlias = 187;
    public static readonly RULE_errorCapturingIdentifier = 188;
    public static readonly RULE_errorCapturingIdentifierExtra = 189;
    public static readonly RULE_identifierList = 190;
    public static readonly RULE_identifierSeq = 191;
    public static readonly RULE_identifier = 192;
    public static readonly RULE_unquotedAnyString = 193;
    public static readonly RULE_refVar = 194;
    public static readonly RULE_unquotedIdentifier = 195;
    public static readonly RULE_whenClause = 196;
    public static readonly RULE_catalogPath = 197;
    public static readonly RULE_databasePath = 198;
    public static readonly RULE_databasePathCreate = 199;
    public static readonly RULE_tablePathCreate = 200;
    public static readonly RULE_tablePath = 201;
    public static readonly RULE_anonymousWindowsName = 202;
    public static readonly RULE_uid = 203;
    public static readonly RULE_withOption = 204;
    public static readonly RULE_ifNotExists = 205;
    public static readonly RULE_ifExists = 206;
    public static readonly RULE_tablePropertyList = 207;
    public static readonly RULE_tableProperty = 208;
    public static readonly RULE_tablePropertyKey = 209;
    public static readonly RULE_propertyName = 210;
    public static readonly RULE_tablePropertyValue = 211;
    public static readonly RULE_comparisonOperator = 212;
    public static readonly RULE_constant = 213;
    public static readonly RULE_timePointLiteral = 214;
    public static readonly RULE_stringLiteral = 215;
    public static readonly RULE_decimalLiteral = 216;
    public static readonly RULE_booleanLiteral = 217;
    public static readonly RULE_setQuantifier = 218;
    public static readonly RULE_timePointUnit = 219;
    public static readonly RULE_timeIntervalUnit = 220;
    public static readonly RULE_reservedKeywordsUsedAsFuncParam = 221;
    public static readonly RULE_reservedKeywordsUsedAsFuncName = 222;
    public static readonly RULE_nonReservedKeywords = 223;
    public static readonly RULE_sqlStatement = 224;
    public static readonly RULE_selectStatement = 225;
    public static readonly RULE_projectItemDefinition = 226;

    public static readonly literalNames = [
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, "'~'", "'|'", "'&'", "'^'", "'='", "'>'", "'<'", 
        "'!'", "'.'", "'['", "']'", "'('", "')'", "'{'", "'}'", "','", "';'", 
        "'@'", "'$'", "'''", "'\"'", "'`'", "':'", "'*'", "'_'", "'-'", 
        "'+'", "'%'", null, null, "'/'", "'?'"
    ];

    public static readonly symbolicNames = [
        null, "CHINESE_SIGN", "CHINESE_STR", "SPACE", "COMMENT_INPUT", "LINE_COMMENT", 
        "KW_ADD", "KW_ADMIN", "KW_AFTER", "KW_ANALYZE", "KW_ASC", "KW_BEFORE", 
        "KW_BYTE", "KW_BYTES", "KW_CACHE", "KW_CASCADE", "KW_CATALOG", "KW_CATALOGS", 
        "KW_CLEAR", "KW_CENTURY", "KW_CHAIN", "KW_CHANGELOG_MODE", "KW_CHARACTERS", 
        "KW_COMMENT", "KW_COMPACT", "KW_COLUMNS", "KW_CONSTRAINTS", "KW_CONSTRUCTOR", 
        "KW_COMPUTE", "KW_CUMULATE", "KW_DATA", "KW_DATABASE", "KW_DATABASES", 
        "KW_DAYS", "KW_DBPROPERTIES", "KW_DECADE", "KW_DEFINED", "KW_DESC", 
        "KW_DESCRIPTOR", "KW_DIV", "KW_ENCODING", "KW_ENFORCED", "KW_ENGINE", 
        "KW_EPOCH", "KW_ERROR", "KW_ESTIMATED_COST", "KW_EXCEPTION", "KW_EXCLUDE", 
        "KW_EXCLUDING", "KW_EXTENDED", "KW_FILTER", "KW_FILE", "KW_FILES", 
        "KW_FINAL", "KW_FIRST", "KW_FOLLOWING", "KW_FORMAT", "KW_FORTRAN", 
        "KW_FOUND", "KW_FRAC_SECOND", "KW_FUNCTIONS", "KW_GENERAL", "KW_GENERATED", 
        "KW_GO", "KW_GOTO", "KW_GRANTED", "KW_HOP", "KW_HOURS", "KW_IF", 
        "KW_IGNORE", "KW_INCLUDE", "KW_INCREMENT", "KW_INPUT", "KW_INVOKER", 
        "KW_JAR", "KW_JARS", "KW_JAVA", "KW_JSON", "KW_JSON_EXECUTION_PLAN", 
        "KW_KEY", "KW_KEYS", "KW_KEY_MEMBER", "KW_KEY_TYPE", "KW_LABEL", 
        "KW_LAST", "KW_LENGTH", "KW_LEVEL", "KW_LIST", "KW_LOAD", "KW_LOCATION", 
        "KW_LONG", "KW_MAP", "KW_MICROSECOND", "KW_MILLENNIUM", "KW_MILLISECOND", 
        "KW_MINUTES", "KW_MINVALUE", "KW_MODIFY", "KW_MODULES", "KW_MONTHS", 
        "KW_NANOSECOND", "KW_NOSCAN", "KW_NULLS", "KW_NUMBER", "KW_OPTION", 
        "KW_OPTIONS", "KW_ORDERING", "KW_OUTPUT", "KW_OVERWRITE", "KW_OVERWRITING", 
        "KW_PARTITIONED", "KW_PARTITIONS", "KW_PASSING", "KW_PAST", "KW_PATH", 
        "KW_PLACING", "KW_PLAN", "KW_PRECEDING", "KW_PRESERVE", "KW_PRIOR", 
        "KW_PRIVILEGES", "KW_PUBLIC", "KW_PYTHON", "KW_PYTHON_FILES", "KW_PYTHON_REQUIREMENTS", 
        "KW_PYTHON_DEPENDENCIES", "KW_PYTHON_JAR", "KW_PYTHON_ARCHIVES", 
        "KW_PYTHON_PARAMETER", "KW_QUARTER", "KW_QUERY", "KW_RAW", "KW_READ", 
        "KW_REAL", "KW_RECORDREADER", "KW_RELATIVE", "KW_REMOVE", "KW_RENAME", 
        "KW_REPLACE", "KW_RESPECT", "KW_RESTART", "KW_RESTRICT", "KW_ROLE", 
        "KW_ROW_COUNT", "KW_SCALA", "KW_SCALAR", "KW_SCALE", "KW_SCHEMA", 
        "KW_SCHEMAS", "KW_SECONDS", "KW_SECTION", "KW_SECURITY", "KW_SELF", 
        "KW_SERVER", "KW_SERVER_NAME", "KW_SESSION", "KW_SETS", "KW_SHORT", 
        "KW_SIMPLE", "KW_SIZE", "KW_SLIDE", "KW_SOURCE", "KW_SPACE", "KW_SERDEPROPERTIES", 
        "KW_STATE", "KW_STATISTICS", "KW_STATEMENT", "KW_STEP", "KW_STRING", 
        "KW_STRUCTURE", "KW_STYLE", "KW_TABLES", "KW_TEMPORARY", "KW_TIMECOL", 
        "KW_FLOOR", "KW_TIMESTAMP_LTZ", "KW_TIMESTAMP_NTZ", "KW_TIMESTAMPADD", 
        "KW_TIMESTAMPDIFF", "KW_TOTIMESTAMP", "KW_TRANSFORM", "KW_TUMBLE", 
        "KW_TYPE", "KW_UNCACHE", "KW_UNDER", "KW_UNBOUNDED", "KW_UNLOAD", 
        "KW_USAGE", "KW_USE", "KW_UTF16", "KW_UTF32", "KW_UTF8", "KW_VERSION", 
        "KW_VIEW", "KW_VIEWS", "KW_VIRTUAL", "KW_WATERMARK", "KW_WATERMARKS", 
        "KW_WEEK", "KW_WEEKS", "KW_WORK", "KW_WRAPPER", "KW_YEARS", "KW_ZONE", 
        "KW_ABS", "KW_ALL", "KW_ALLOW", "KW_ALTER", "KW_AND", "KW_ANY", 
        "KW_ARE", "KW_ARRAY", "KW_AS", "KW_ASYMMETRIC", "KW_AT", "KW_AVG", 
        "KW_BEGIN", "KW_BETWEEN", "KW_BIGINT", "KW_BINARY", "KW_BIT", "KW_BLOB", 
        "KW_BOOLEAN", "KW_BOTH", "KW_BUCKET", "KW_BUCKETS", "KW_BY", "KW_CALL", 
        "KW_CALLED", "KW_CASCADED", "KW_CASE", "KW_CAST", "KW_CEIL", "KW_CHAR", 
        "KW_CHARACTER", "KW_CHECK", "KW_CLOB", "KW_CLOSE", "KW_CLUSTER", 
        "KW_CLUSTERED", "KW_COALESCE", "KW_COLLATE", "KW_COLLECT", "KW_COLUMN", 
        "KW_COMMIT", "KW_CONNECT", "KW_CONSTRAINT", "KW_CONTAINS", "KW_CONVERT", 
        "KW_COUNT", "KW_CURRENT_TIMESTAMP", "KW_CREATE", "KW_CROSS", "KW_CUBE", 
        "KW_CUME_DIST", "KW_CURRENT", "KW_CURSOR", "KW_CYCLE", "KW_COLLECTION", 
        "KW_DATE", "KW_DATETIME", "KW_DAY", "KW_DEC", "KW_DECIMAL", "KW_DECLARE", 
        "KW_DEFAULT", "KW_DEFINE", "KW_DELETE", "KW_DELIMITED", "KW_DESCRIBE", 
        "KW_DENSE_RANK", "KW_DISTINCT", "KW_DIRECTORY", "KW_DISTRIBUTED", 
        "KW_DISTRIBUTE", "KW_DOUBLE", "KW_DROP", "KW_EACH", "KW_ELSE", "KW_END", 
        "KW_EQUALS", "KW_ESCAPE", "KW_ESCAPED", "KW_EXCEPT", "KW_EXECUTE", 
        "KW_EXISTS", "KW_EXPLAIN", "KW_EXPLODE", "KW_EXPLODE_OUTER", "KW_EXTERNAL", 
        "KW_EXTRACT", "KW_FIRST_VALUE", "KW_FALSE", "KW_FLOAT", "KW_FIELDS", 
        "KW_FOR", "KW_FROM", "KW_FROM_UNIXTIME", "KW_FULL", "KW_FUNCTION", 
        "KW_GLOBAL", "KW_GRANT", "KW_GROUP", "KW_GROUPING", "KW_GROUPS", 
        "KW_HASH", "KW_HAVING", "KW_HOUR", "KW_IMPORT", "KW_IN", "KW_INCLUDING", 
        "KW_INPUTFORMAT", "KW_INNER", "KW_INOUT", "KW_INSERT", "KW_INT", 
        "KW_INTEGER", "KW_INTERSECT", "KW_INTERVAL", "KW_INTO", "KW_INPATH", 
        "KW_INLINE", "KW_INLINE_OUTER", "KW_ITEMS", "KW_IS", "KW_JOIN", 
        "KW_JSON_TUPLE", "KW_LAG", "KW_LANGUAGE", "KW_LATERAL", "KW_LAST_VALUE", 
        "KW_LEAD", "KW_LEADING", "KW_LEFT", "KW_LIKE", "KW_LINES", "KW_LIMIT", 
        "KW_LOCAL", "KW_LOCALTIMESTAMP", "KW_MATCH", "KW_MATCH_RECOGNIZE", 
        "KW_MEASURES", "KW_MERGE", "KW_METADATA", "KW_MINUS", "KW_MINUTE", 
        "KW_MODIFIES", "KW_MODULE", "KW_MONTH", "KW_MULTISET", "KW_NATURAL", 
        "KW_NEXT", "KW_NO", "KW_NONE", "KW_NOT", "KW_NTILE", "KW_NTH_VALUE", 
        "KW_NULL", "KW_NUMERIC", "KW_OF", "KW_OFFSET", "KW_ON", "KW_ONE", 
        "KW_OR", "KW_ORDER", "KW_OUT", "KW_OUTER", "KW_OUTPUTFORMAT", "KW_OVER", 
        "KW_OVERLAY", "KW_PARSE_URL", "KW_PARTITION", "KW_PATTERN", "KW_PER", 
        "KW_PERCENT", "KW_PERCENT_RANK", "KW_PERCENTILE_CONT", "KW_PERCENTILE_DISC", 
        "KW_PERIOD", "KW_PIVOT", "KW_POSITION", "KW_POWER", "KW_POSEXPLODE", 
        "KW_POSEXPLODE_OUTER", "KW_PRIMARY", "KW_PURGE", "KW_RANGE", "KW_RECORDWRITER", 
        "KW_ROW_NUMBER", "KW_RANK", "KW_REGEXP", "KW_RESET", "KW_REVOKE", 
        "KW_REPAIR", "KW_RIGHT", "KW_RLIKE", "KW_ROLLBACK", "KW_ROLLUP", 
        "KW_ROW", "KW_ROWS", "KW_SECOND", "KW_SELECT", "KW_SEMI", "KW_SET", 
        "KW_SERDE", "KW_SHOW", "KW_SIMILAR", "KW_SKIP", "KW_STORED", "KW_SORTED", 
        "KW_SMALLINT", "KW_STACK", "KW_START", "KW_STATIC", "KW_STRUCT", 
        "KW_SORT", "KW_SUBSTRING", "KW_SUM", "KW_SYMMETRIC", "KW_SYSTEM", 
        "KW_SYSTEM_TIME", "KW_SYSTEM_USER", "KW_TABLE", "KW_TBLPROPERTIES", 
        "KW_TABLESAMPLE", "KW_TERMINATED", "KW_THEN", "KW_TIME", "KW_TIMESTAMP", 
        "KW_TIMESTAMP_3", "KW_TIMESTAMP_6", "KW_TIMESTAMP_9", "KW_TINYINT", 
        "KW_TO", "KW_TRAILING", "KW_TRUE", "KW_TRUNCATE", "KW_UNION", "KW_UNIQUE", 
        "KW_UNKNOWN", "KW_UNSET", "KW_UNPIVOT", "KW_UPPER", "KW_UPSERT", 
        "KW_USER", "KW_USING", "KW_VALUE", "KW_VALUES", "KW_VARBINARY", 
        "KW_VARCHAR", "KW_WHEN", "KW_WHERE", "KW_WINDOW", "KW_WITH", "KW_WITHIN", 
        "KW_WITHOUT", "KW_YEAR", "KW_MATERIALIZED", "KW_FRESHNESS", "KW_REFRESH_MODE", 
        "KW_RECOVER", "KW_CONTINUOUS", "KW_SUSPEND", "KW_RESUME", "KW_REFRESH", 
        "BIT_NOT_OP", "BIT_OR_OP", "BIT_AND_OP", "BIT_XOR_OP", "EQUAL_SYMBOL", 
        "GREATER_SYMBOL", "LESS_SYMBOL", "EXCLAMATION_SYMBOL", "DOT", "LS_BRACKET", 
        "RS_BRACKET", "LR_BRACKET", "RR_BRACKET", "LB_BRACKET", "RB_BRACKET", 
        "COMMA", "SEMICOLON", "AT_SIGN", "DOLLAR", "SINGLE_QUOTE_SYMB", 
        "DOUBLE_QUOTE_SYMB", "REVERSE_QUOTE_SYMB", "COLON_SYMB", "ASTERISK_SIGN", 
        "UNDERLINE_SIGN", "HYPNEN_SIGN", "ADD_SIGN", "PENCENT_SIGN", "DOUBLE_VERTICAL_SIGN", 
        "DOUBLE_HYPNEN_SIGN", "SLASH_SIGN", "QUESTION_MARK_SIGN", "DOUBLE_RIGHT_ARROW", 
        "STRING_LITERAL", "DIG_LITERAL", "REAL_LITERAL", "ID_LITERAL"
    ];
    public static readonly ruleNames = [
        "statement", "sqlStatements", "emptyStatement", "createStatement", 
        "dmlStatement", "createTable", "simpleCreateTable", "simpleCreateTableNoSortElement", 
        "location", "sortedBy", "usingCreate", "tblProperties", "defaultColumnUsing", 
        "defaultColumnUsingNoSortElement", "columnUsing", "columnUsingNoSortElement", 
        "usingByQuery", "usingByQueryNoSortElement", "intoBuckets", "hiveFormatpartitionDefinition", 
        "rowFormatSerde", "fieldsTerminatedBy", "storedAs", "storedAsInputformat", 
        "outputformat", "rowFormatDelimted", "columnsBody", "createCustomSerde", 
        "createCustomSerdeNoSortElement", "createCustomSerdeExternal", "createCustomSerdeExternalNoSortElement", 
        "createTableAsSelect", "createMaterializedTableAsSelect", "createMaterializedTableAsSelectNoSortElement", 
        "usingClause", "jarFileName", "filePath", "ifExistsPart", "columnPosition", 
        "renameDefinition", "setKeyValueDefinition", "addConstraint", "dropConstraint", 
        "addUnique", "notForced", "insertStatement", "insertSimpleStatement", 
        "insertPartitionDefinition", "queryStatement", "withClause", "valuesCaluse", 
        "inlineBody", "withItem", "withItemName", "selectClause", "filterPart", 
        "overWindowItem", "overClause", "windowFunctioPart", "windowFunctionName", 
        "analyticFunction", "rangkingFunction", "fromClause", "windowFrameForWindowsQuery", 
        "frameExpession", "tableExpression", "tvfClause", "rangeClause", 
        "viewReference", "pivotReference", "tableReference", "tablePrimary", 
        "funtionBody", "unpivotBody", "pivotBody", "expressionAsAlias", 
        "expressionAsAliasList", "systemTimePeriod", "dateTimeExpression", 
        "inlineDataValueClause", "windowTVFClause", "windowTVFExpression", 
        "windowTVFName", "rowFormatDelimited", "hiveSerde", "usingAsColumnPart", 
        "hiveSerdePart", "tableCanHasKeyPropertyList", "sparkRecordWriterPart", 
        "windowTVFParam", "timeIntervalParamName", "columnDescriptor", "joinCondition", 
        "whereClause", "samplingQueries", "someByClause", "clusterByClause", 
        "clusteredByClause", "distributeByClause", "groupByClause", "groupItemDefinition", 
        "groupingSet", "groupingSets", "groupingSetsNotionName", "groupWindowFunction", 
        "groupWindowFunctionName", "timeAttrColumn", "havingClause", "windowClause", 
        "namedWindow", "windowSpec", "matchRecognizeClause", "orderByCaluse", 
        "sortByCaluse", "orderItemDefinition", "limitClause", "offsetClause", 
        "partitionByClause", "quantifiers", "measuresClause", "patternDefinition", 
        "patternVariable", "outputMode", "afterMatchStrategy", "patternVariablesDefinition", 
        "windowFrame", "frameBound", "withinClause", "selfDefinitionClause", 
        "partitionDefinition", "transformList", "transform", "transformArgument", 
        "likeDefinition", "distribution", "using", "likeOption", "columnOptionDefinition", 
        "physicalColumnDefinitionList", "physicalColumnDefinition", "computedColumnExpression", 
        "watermarkDefinition", "tableConstraint", "constraintName", "valuesDefinition", 
        "valuesRowDefinition", "lengthOneDimension", "lengthTwoOptionalDimension", 
        "lengthTwoStringDimension", "lengthOneTypeDimension", "mapTypeDimension", 
        "rowTypeDimension", "structTypeDimension", "columnConstraint", "commentSpec", 
        "metadataColumnDefinition", "metadataKey", "computedColumnDefinition", 
        "columnName", "columnNameList", "columnType", "expression", "booleanExpression", 
        "predicate", "likePredicate", "valueExpression", "primaryExpression", 
        "complexDataTypeExpression", "arrayExpression", "structExpression", 
        "rowExpression", "mapExpression", "dataTypeExpression", "sqlSimpleType", 
        "functionName", "functionParam", "filterClause", "correlationName", 
        "qualifiedName", "timeIntervalExpression", "errorCapturingMultiUnitsInterval", 
        "multiUnitsInterval", "errorCapturingUnitToUnitInterval", "unitToUnitInterval", 
        "intervalValue", "columnAlias", "tableAlias", "anyAlias", "errorCapturingIdentifier", 
        "errorCapturingIdentifierExtra", "identifierList", "identifierSeq", 
        "identifier", "unquotedAnyString", "refVar", "unquotedIdentifier", 
        "whenClause", "catalogPath", "databasePath", "databasePathCreate", 
        "tablePathCreate", "tablePath", "anonymousWindowsName", "uid", "withOption", 
        "ifNotExists", "ifExists", "tablePropertyList", "tableProperty", 
        "tablePropertyKey", "propertyName", "tablePropertyValue", "comparisonOperator", 
        "constant", "timePointLiteral", "stringLiteral", "decimalLiteral", 
        "booleanLiteral", "setQuantifier", "timePointUnit", "timeIntervalUnit", 
        "reservedKeywordsUsedAsFuncParam", "reservedKeywordsUsedAsFuncName", 
        "nonReservedKeywords", "sqlStatement", "selectStatement", "projectItemDefinition",
    ];

    public get grammarFileName(): string { return "SparkSQL.g4"; }
    public get literalNames(): (string | null)[] { return SparkSQLParser.literalNames; }
    public get symbolicNames(): (string | null)[] { return SparkSQLParser.symbolicNames; }
    public get ruleNames(): string[] { return SparkSQLParser.ruleNames; }
    public get serializedATN(): number[] { return SparkSQLParser._serializedATN; }

    protected createFailedPredicateException(predicate?: string, message?: string): antlr.FailedPredicateException {
        return new antlr.FailedPredicateException(this, predicate, message);
    }

    public constructor(input: antlr.TokenStream) {
        super(input);
        this.interpreter = new antlr.ParserATNSimulator(this, SparkSQLParser._ATN, SparkSQLParser.decisionsToDFA, new antlr.PredictionContextCache());
    }
    public statement(): StatementContext {
        let localContext = new StatementContext(this.context, this.state);
        this.enterRule(localContext, 0, SparkSQLParser.RULE_statement);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 454;
            this.sqlStatements();
            this.state = 455;
            this.match(SparkSQLParser.EOF);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public sqlStatements(): SqlStatementsContext {
        let localContext = new SqlStatementsContext(this.context, this.state);
        this.enterRule(localContext, 2, SparkSQLParser.RULE_sqlStatements);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 461;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 251 || ((((_la - 284)) & ~0x1F) === 0 && ((1 << (_la - 284)) & 1073745921) !== 0) || _la === 401 || ((((_la - 453)) & ~0x1F) === 0 && ((1 << (_la - 453)) & 276824065) !== 0)) {
                {
                this.state = 459;
                this.errorHandler.sync(this);
                switch (this.tokenStream.LA(1)) {
                case SparkSQLParser.KW_CREATE:
                case SparkSQLParser.KW_EXECUTE:
                case SparkSQLParser.KW_FROM:
                case SparkSQLParser.KW_INSERT:
                case SparkSQLParser.KW_SELECT:
                case SparkSQLParser.KW_WITH:
                case SparkSQLParser.LR_BRACKET:
                    {
                    this.state = 457;
                    this.sqlStatement();
                    }
                    break;
                case SparkSQLParser.SEMICOLON:
                    {
                    this.state = 458;
                    this.emptyStatement();
                    }
                    break;
                default:
                    throw new antlr.NoViableAltException(this);
                }
                }
                this.state = 463;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public emptyStatement(): EmptyStatementContext {
        let localContext = new EmptyStatementContext(this.context, this.state);
        this.enterRule(localContext, 4, SparkSQLParser.RULE_emptyStatement);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 464;
            this.match(SparkSQLParser.SEMICOLON);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public createStatement(): CreateStatementContext {
        let localContext = new CreateStatementContext(this.context, this.state);
        this.enterRule(localContext, 6, SparkSQLParser.RULE_createStatement);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 466;
            this.createTable();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public dmlStatement(): DmlStatementContext {
        let localContext = new DmlStatementContext(this.context, this.state);
        this.enterRule(localContext, 8, SparkSQLParser.RULE_dmlStatement);
        try {
            this.state = 470;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.KW_FROM:
            case SparkSQLParser.KW_SELECT:
            case SparkSQLParser.KW_WITH:
            case SparkSQLParser.LR_BRACKET:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 468;
                this.queryStatement(0);
                }
                break;
            case SparkSQLParser.KW_EXECUTE:
            case SparkSQLParser.KW_INSERT:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 469;
                this.insertStatement();
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public createTable(): CreateTableContext {
        let localContext = new CreateTableContext(this.context, this.state);
        this.enterRule(localContext, 10, SparkSQLParser.RULE_createTable);
        try {
            this.state = 478;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 3, this.context) ) {
            case 1:
                localContext = new SimpleContext(localContext);
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 472;
                this.simpleCreateTable();
                }
                break;
            case 2:
                localContext = new AsSelectContext(localContext);
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 473;
                this.createTableAsSelect();
                }
                break;
            case 3:
                localContext = new MaterializedContext(localContext);
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 474;
                this.createMaterializedTableAsSelect();
                }
                break;
            case 4:
                localContext = new CustomSerdeContext(localContext);
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 475;
                this.createCustomSerde();
                }
                break;
            case 5:
                localContext = new CustomSerdeExternalContext(localContext);
                this.enterOuterAlt(localContext, 5);
                {
                this.state = 476;
                this.createCustomSerdeExternal();
                }
                break;
            case 6:
                localContext = new Using_createContext(localContext);
                this.enterOuterAlt(localContext, 6);
                {
                this.state = 477;
                this.usingCreate();
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public simpleCreateTable(): SimpleCreateTableContext {
        let localContext = new SimpleCreateTableContext(this.context, this.state);
        this.enterRule(localContext, 12, SparkSQLParser.RULE_simpleCreateTable);
        let _la: number;
        try {
            let alternative: number;
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 480;
            this.match(SparkSQLParser.KW_CREATE);
            this.state = 482;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 172) {
                {
                this.state = 481;
                this.match(SparkSQLParser.KW_TEMPORARY);
                }
            }

            this.state = 484;
            this.match(SparkSQLParser.KW_TABLE);
            this.state = 486;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 5, this.context) ) {
            case 1:
                {
                this.state = 485;
                this.ifNotExists();
                }
                break;
            }
            this.state = 488;
            this.tablePathCreate();
            this.state = 492;
            this.errorHandler.sync(this);
            alternative = this.interpreter.adaptivePredict(this.tokenStream, 6, this.context);
            while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {
                if (alternative === 1) {
                    {
                    {
                    this.state = 489;
                    this.simpleCreateTableNoSortElement();
                    }
                    }
                }
                this.state = 494;
                this.errorHandler.sync(this);
                alternative = this.interpreter.adaptivePredict(this.tokenStream, 6, this.context);
            }
            this.state = 498;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.LR_BRACKET:
                {
                this.state = 495;
                this.columnsBody();
                }
                break;
            case SparkSQLParser.KW_LIKE:
                {
                {
                this.state = 496;
                this.match(SparkSQLParser.KW_LIKE);
                this.state = 497;
                this.tablePath();
                }
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
            this.state = 503;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 89 || _la === 110 || _la === 238 || _la === 239 || ((((_la - 273)) & ~0x1F) === 0 && ((1 << (_la - 273)) & 538968067) !== 0) || ((((_la - 319)) & ~0x1F) === 0 && ((1 << (_la - 319)) & 98305) !== 0) || _la === 357 || ((((_la - 398)) & ~0x1F) === 0 && ((1 << (_la - 398)) & 33557505) !== 0) || _la === 445 || _la === 453) {
                {
                {
                this.state = 500;
                this.simpleCreateTableNoSortElement();
                }
                }
                this.state = 505;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public simpleCreateTableNoSortElement(): SimpleCreateTableNoSortElementContext {
        let localContext = new SimpleCreateTableNoSortElementContext(this.context, this.state);
        this.enterRule(localContext, 14, SparkSQLParser.RULE_simpleCreateTableNoSortElement);
        try {
            this.state = 520;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 9, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 506;
                this.partitionDefinition();
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 507;
                this.withOption();
                }
                break;
            case 3:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 508;
                this.likeDefinition();
                }
                break;
            case 4:
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 509;
                this.distribution();
                }
                break;
            case 5:
                this.enterOuterAlt(localContext, 5);
                {
                this.state = 510;
                this.someByClause();
                }
                break;
            case 6:
                this.enterOuterAlt(localContext, 6);
                {
                this.state = 511;
                this.intoBuckets();
                }
                break;
            case 7:
                this.enterOuterAlt(localContext, 7);
                {
                this.state = 512;
                this.storedAs();
                }
                break;
            case 8:
                this.enterOuterAlt(localContext, 8);
                {
                this.state = 513;
                this.hiveFormatpartitionDefinition();
                }
                break;
            case 9:
                this.enterOuterAlt(localContext, 9);
                {
                this.state = 514;
                this.sortedBy();
                }
                break;
            case 10:
                this.enterOuterAlt(localContext, 10);
                {
                this.state = 515;
                this.rowFormatDelimited();
                }
                break;
            case 11:
                this.enterOuterAlt(localContext, 11);
                {
                this.state = 516;
                this.fieldsTerminatedBy();
                }
                break;
            case 12:
                this.enterOuterAlt(localContext, 12);
                {
                this.state = 517;
                this.using();
                }
                break;
            case 13:
                this.enterOuterAlt(localContext, 13);
                {
                this.state = 518;
                this.location();
                }
                break;
            case 14:
                this.enterOuterAlt(localContext, 14);
                {
                this.state = 519;
                this.tblProperties();
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public location(): LocationContext {
        let localContext = new LocationContext(this.context, this.state);
        this.enterRule(localContext, 16, SparkSQLParser.RULE_location);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 522;
            this.match(SparkSQLParser.KW_LOCATION);
            this.state = 523;
            this.filePath();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public sortedBy(): SortedByContext {
        let localContext = new SortedByContext(this.context, this.state);
        this.enterRule(localContext, 18, SparkSQLParser.RULE_sortedBy);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 525;
            this.match(SparkSQLParser.KW_SORTED);
            this.state = 526;
            this.match(SparkSQLParser.KW_BY);
            this.state = 527;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 528;
            this.identifier();
            this.state = 530;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 10 || _la === 37) {
                {
                this.state = 529;
                _la = this.tokenStream.LA(1);
                if(!(_la === 10 || _la === 37)) {
                this.errorHandler.recoverInline(this);
                }
                else {
                    this.errorHandler.reportMatch(this);
                    this.consume();
                }
                }
            }

            this.state = 532;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public usingCreate(): UsingCreateContext {
        let localContext = new UsingCreateContext(this.context, this.state);
        this.enterRule(localContext, 20, SparkSQLParser.RULE_usingCreate);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 534;
            this.match(SparkSQLParser.KW_CREATE);
            this.state = 535;
            this.match(SparkSQLParser.KW_TABLE);
            this.state = 537;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 11, this.context) ) {
            case 1:
                {
                this.state = 536;
                this.ifNotExists();
                }
                break;
            }
            this.state = 539;
            this.tablePathCreate();
            this.state = 543;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 12, this.context) ) {
            case 1:
                {
                this.state = 540;
                this.columnUsing();
                }
                break;
            case 2:
                {
                this.state = 541;
                this.usingByQuery();
                }
                break;
            case 3:
                {
                this.state = 542;
                this.defaultColumnUsing();
                }
                break;
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public tblProperties(): TblPropertiesContext {
        let localContext = new TblPropertiesContext(this.context, this.state);
        this.enterRule(localContext, 22, SparkSQLParser.RULE_tblProperties);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 545;
            this.match(SparkSQLParser.KW_TBLPROPERTIES);
            this.state = 546;
            this.tablePropertyList();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public defaultColumnUsing(): DefaultColumnUsingContext {
        let localContext = new DefaultColumnUsingContext(this.context, this.state);
        this.enterRule(localContext, 24, SparkSQLParser.RULE_defaultColumnUsing);
        let _la: number;
        try {
            let alternative: number;
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 548;
            this.using();
            this.state = 552;
            this.errorHandler.sync(this);
            alternative = this.interpreter.adaptivePredict(this.tokenStream, 13, this.context);
            while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {
                if (alternative === 1) {
                    {
                    {
                    this.state = 549;
                    this.defaultColumnUsingNoSortElement();
                    }
                    }
                }
                this.state = 554;
                this.errorHandler.sync(this);
                alternative = this.interpreter.adaptivePredict(this.tokenStream, 13, this.context);
            }
            {
            this.state = 556;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 212) {
                {
                this.state = 555;
                this.match(SparkSQLParser.KW_AS);
                }
            }

            this.state = 558;
            this.queryStatement(0);
            }
            this.state = 563;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 23 || _la === 105 || _la === 110 || _la === 238 || _la === 239 || _la === 274 || _la === 302 || _la === 319 || _la === 423 || _la === 453) {
                {
                {
                this.state = 560;
                this.defaultColumnUsingNoSortElement();
                }
                }
                this.state = 565;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public defaultColumnUsingNoSortElement(): DefaultColumnUsingNoSortElementContext {
        let localContext = new DefaultColumnUsingNoSortElementContext(this.context, this.state);
        this.enterRule(localContext, 26, SparkSQLParser.RULE_defaultColumnUsingNoSortElement);
        try {
            this.state = 579;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.KW_PARTITIONED:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 566;
                this.partitionDefinition();
                }
                break;
            case SparkSQLParser.KW_OPTIONS:
                this.enterOuterAlt(localContext, 2);
                {
                {
                this.state = 567;
                this.match(SparkSQLParser.KW_OPTIONS);
                this.state = 568;
                this.tablePropertyList();
                }
                }
                break;
            case SparkSQLParser.KW_TBLPROPERTIES:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 569;
                this.tblProperties();
                }
                break;
            case SparkSQLParser.KW_CLUSTER:
            case SparkSQLParser.KW_CLUSTERED:
            case SparkSQLParser.KW_DISTRIBUTE:
            case SparkSQLParser.KW_GROUP:
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 570;
                this.someByClause();
                }
                break;
            case SparkSQLParser.KW_INTO:
                this.enterOuterAlt(localContext, 5);
                {
                this.state = 571;
                this.intoBuckets();
                }
                break;
            case SparkSQLParser.KW_WITH:
                this.enterOuterAlt(localContext, 6);
                {
                {
                this.state = 572;
                this.match(SparkSQLParser.KW_WITH);
                this.state = 573;
                this.tableAlias();
                this.state = 574;
                this.match(SparkSQLParser.LB_BRACKET);
                this.state = 575;
                this.queryStatement(0);
                this.state = 576;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                }
                break;
            case SparkSQLParser.KW_COMMENT:
                this.enterOuterAlt(localContext, 7);
                {
                this.state = 578;
                this.commentSpec();
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public columnUsing(): ColumnUsingContext {
        let localContext = new ColumnUsingContext(this.context, this.state);
        this.enterRule(localContext, 28, SparkSQLParser.RULE_columnUsing);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            {
            this.state = 581;
            this.columnsBody();
            this.state = 582;
            this.using();
            }
            this.state = 587;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 23 || _la === 105 || _la === 110 || _la === 238 || _la === 239 || _la === 274 || _la === 302 || _la === 319 || _la === 423) {
                {
                {
                this.state = 584;
                this.columnUsingNoSortElement();
                }
                }
                this.state = 589;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public columnUsingNoSortElement(): ColumnUsingNoSortElementContext {
        let localContext = new ColumnUsingNoSortElementContext(this.context, this.state);
        this.enterRule(localContext, 30, SparkSQLParser.RULE_columnUsingNoSortElement);
        try {
            this.state = 597;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.KW_PARTITIONED:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 590;
                this.partitionDefinition();
                }
                break;
            case SparkSQLParser.KW_OPTIONS:
                this.enterOuterAlt(localContext, 2);
                {
                {
                this.state = 591;
                this.match(SparkSQLParser.KW_OPTIONS);
                this.state = 592;
                this.tablePropertyList();
                }
                }
                break;
            case SparkSQLParser.KW_TBLPROPERTIES:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 593;
                this.tblProperties();
                }
                break;
            case SparkSQLParser.KW_CLUSTER:
            case SparkSQLParser.KW_CLUSTERED:
            case SparkSQLParser.KW_DISTRIBUTE:
            case SparkSQLParser.KW_GROUP:
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 594;
                this.someByClause();
                }
                break;
            case SparkSQLParser.KW_INTO:
                this.enterOuterAlt(localContext, 5);
                {
                this.state = 595;
                this.intoBuckets();
                }
                break;
            case SparkSQLParser.KW_COMMENT:
                this.enterOuterAlt(localContext, 6);
                {
                this.state = 596;
                this.commentSpec();
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public usingByQuery(): UsingByQueryContext {
        let localContext = new UsingByQueryContext(this.context, this.state);
        this.enterRule(localContext, 32, SparkSQLParser.RULE_usingByQuery);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            {
            this.state = 599;
            this.using();
            this.state = 600;
            this.match(SparkSQLParser.KW_AS);
            this.state = 601;
            this.queryStatement(0);
            }
            this.state = 606;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 23 || _la === 105 || _la === 110 || _la === 238 || _la === 239 || _la === 274 || _la === 302 || _la === 319 || _la === 423) {
                {
                {
                this.state = 603;
                this.usingByQueryNoSortElement();
                }
                }
                this.state = 608;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public usingByQueryNoSortElement(): UsingByQueryNoSortElementContext {
        let localContext = new UsingByQueryNoSortElementContext(this.context, this.state);
        this.enterRule(localContext, 34, SparkSQLParser.RULE_usingByQueryNoSortElement);
        try {
            this.state = 616;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.KW_PARTITIONED:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 609;
                this.partitionDefinition();
                }
                break;
            case SparkSQLParser.KW_OPTIONS:
                this.enterOuterAlt(localContext, 2);
                {
                {
                this.state = 610;
                this.match(SparkSQLParser.KW_OPTIONS);
                this.state = 611;
                this.tablePropertyList();
                }
                }
                break;
            case SparkSQLParser.KW_TBLPROPERTIES:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 612;
                this.tblProperties();
                }
                break;
            case SparkSQLParser.KW_CLUSTER:
            case SparkSQLParser.KW_CLUSTERED:
            case SparkSQLParser.KW_DISTRIBUTE:
            case SparkSQLParser.KW_GROUP:
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 613;
                this.someByClause();
                }
                break;
            case SparkSQLParser.KW_INTO:
                this.enterOuterAlt(localContext, 5);
                {
                this.state = 614;
                this.intoBuckets();
                }
                break;
            case SparkSQLParser.KW_COMMENT:
                this.enterOuterAlt(localContext, 6);
                {
                this.state = 615;
                this.commentSpec();
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public intoBuckets(): IntoBucketsContext {
        let localContext = new IntoBucketsContext(this.context, this.state);
        this.enterRule(localContext, 36, SparkSQLParser.RULE_intoBuckets);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 618;
            this.match(SparkSQLParser.KW_INTO);
            this.state = 619;
            this.match(SparkSQLParser.DIG_LITERAL);
            this.state = 620;
            this.match(SparkSQLParser.KW_BUCKETS);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public hiveFormatpartitionDefinition(): HiveFormatpartitionDefinitionContext {
        let localContext = new HiveFormatpartitionDefinitionContext(this.context, this.state);
        this.enterRule(localContext, 38, SparkSQLParser.RULE_hiveFormatpartitionDefinition);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 622;
            this.match(SparkSQLParser.KW_PARTITIONED);
            this.state = 623;
            this.match(SparkSQLParser.KW_BY);
            this.state = 624;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 625;
            this.match(SparkSQLParser.ID_LITERAL);
            this.state = 627;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 12 || _la === 90 || _la === 133 || _la === 157 || _la === 175 || _la === 176 || _la === 218 || _la === 222 || ((((_la - 259)) & ~0x1F) === 0 && ((1 << (_la - 259)) & 65553) !== 0) || ((((_la - 293)) & ~0x1F) === 0 && ((1 << (_la - 293)) & 12582913) !== 0) || _la === 358 || ((((_la - 410)) & ~0x1F) === 0 && ((1 << (_la - 410)) & 4587521) !== 0)) {
                {
                this.state = 626;
                this.sqlSimpleType();
                }
            }

            this.state = 636;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 480) {
                {
                {
                this.state = 629;
                this.match(SparkSQLParser.COMMA);
                this.state = 630;
                this.match(SparkSQLParser.ID_LITERAL);
                this.state = 632;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 12 || _la === 90 || _la === 133 || _la === 157 || _la === 175 || _la === 176 || _la === 218 || _la === 222 || ((((_la - 259)) & ~0x1F) === 0 && ((1 << (_la - 259)) & 65553) !== 0) || ((((_la - 293)) & ~0x1F) === 0 && ((1 << (_la - 293)) & 12582913) !== 0) || _la === 358 || ((((_la - 410)) & ~0x1F) === 0 && ((1 << (_la - 410)) & 4587521) !== 0)) {
                    {
                    this.state = 631;
                    this.sqlSimpleType();
                    }
                }

                }
                }
                this.state = 638;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 639;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public rowFormatSerde(): RowFormatSerdeContext {
        let localContext = new RowFormatSerdeContext(this.context, this.state);
        this.enterRule(localContext, 40, SparkSQLParser.RULE_rowFormatSerde);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 641;
            this.match(SparkSQLParser.KW_ROW);
            this.state = 642;
            this.match(SparkSQLParser.KW_FORMAT);
            this.state = 643;
            this.match(SparkSQLParser.KW_SERDE);
            this.state = 644;
            this.stringLiteral();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public fieldsTerminatedBy(): FieldsTerminatedByContext {
        let localContext = new FieldsTerminatedByContext(this.context, this.state);
        this.enterRule(localContext, 42, SparkSQLParser.RULE_fieldsTerminatedBy);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 646;
            this.match(SparkSQLParser.KW_FIELDS);
            this.state = 647;
            this.match(SparkSQLParser.KW_TERMINATED);
            this.state = 648;
            this.match(SparkSQLParser.KW_BY);
            this.state = 649;
            this.stringLiteral();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public storedAs(): StoredAsContext {
        let localContext = new StoredAsContext(this.context, this.state);
        this.enterRule(localContext, 44, SparkSQLParser.RULE_storedAs);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 651;
            this.match(SparkSQLParser.KW_STORED);
            this.state = 652;
            this.match(SparkSQLParser.KW_AS);
            this.state = 654;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 24, this.context) ) {
            case 1:
                {
                this.state = 653;
                this.identifier();
                }
                break;
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public storedAsInputformat(): StoredAsInputformatContext {
        let localContext = new StoredAsInputformatContext(this.context, this.state);
        this.enterRule(localContext, 46, SparkSQLParser.RULE_storedAsInputformat);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 656;
            this.match(SparkSQLParser.KW_STORED);
            this.state = 657;
            this.match(SparkSQLParser.KW_AS);
            this.state = 658;
            this.match(SparkSQLParser.KW_INPUTFORMAT);
            this.state = 660;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if ((((_la) & ~0x1F) === 0 && ((1 << _la) & 4294684608) !== 0) || ((((_la - 32)) & ~0x1F) === 0 && ((1 << (_la - 32)) & 4293654523) !== 0) || ((((_la - 64)) & ~0x1F) === 0 && ((1 << (_la - 64)) & 4185849791) !== 0) || ((((_la - 96)) & ~0x1F) === 0 && ((1 << (_la - 96)) & 4294967263) !== 0) || ((((_la - 128)) & ~0x1F) === 0 && ((1 << (_la - 128)) & 3757047707) !== 0) || ((((_la - 160)) & ~0x1F) === 0 && ((1 << (_la - 160)) & 4252958679) !== 0) || ((((_la - 192)) & ~0x1F) === 0 && ((1 << (_la - 192)) & 3967) !== 0) || _la === 338 || ((((_la - 483)) & ~0x1F) === 0 && ((1 << (_la - 483)) & 360449) !== 0)) {
                {
                this.state = 659;
                this.identifier();
                }
            }

            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public outputformat(): OutputformatContext {
        let localContext = new OutputformatContext(this.context, this.state);
        this.enterRule(localContext, 48, SparkSQLParser.RULE_outputformat);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 662;
            this.match(SparkSQLParser.KW_OUTPUTFORMAT);
            this.state = 664;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if ((((_la) & ~0x1F) === 0 && ((1 << _la) & 4294684608) !== 0) || ((((_la - 32)) & ~0x1F) === 0 && ((1 << (_la - 32)) & 4293654523) !== 0) || ((((_la - 64)) & ~0x1F) === 0 && ((1 << (_la - 64)) & 4185849791) !== 0) || ((((_la - 96)) & ~0x1F) === 0 && ((1 << (_la - 96)) & 4294967263) !== 0) || ((((_la - 128)) & ~0x1F) === 0 && ((1 << (_la - 128)) & 3757047707) !== 0) || ((((_la - 160)) & ~0x1F) === 0 && ((1 << (_la - 160)) & 4252958679) !== 0) || ((((_la - 192)) & ~0x1F) === 0 && ((1 << (_la - 192)) & 3967) !== 0) || _la === 338 || ((((_la - 483)) & ~0x1F) === 0 && ((1 << (_la - 483)) & 360449) !== 0)) {
                {
                this.state = 663;
                this.identifier();
                }
            }

            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public rowFormatDelimted(): RowFormatDelimtedContext {
        let localContext = new RowFormatDelimtedContext(this.context, this.state);
        this.enterRule(localContext, 50, SparkSQLParser.RULE_rowFormatDelimted);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 666;
            this.match(SparkSQLParser.KW_ROW);
            this.state = 667;
            this.match(SparkSQLParser.KW_FORMAT);
            this.state = 668;
            this.match(SparkSQLParser.KW_DELIMITED);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public columnsBody(): ColumnsBodyContext {
        let localContext = new ColumnsBodyContext(this.context, this.state);
        this.enterRule(localContext, 52, SparkSQLParser.RULE_columnsBody);
        let _la: number;
        try {
            let alternative: number;
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 670;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 671;
            this.columnOptionDefinition();
            this.state = 673;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 23) {
                {
                this.state = 672;
                this.commentSpec();
                }
            }

            this.state = 682;
            this.errorHandler.sync(this);
            alternative = this.interpreter.adaptivePredict(this.tokenStream, 29, this.context);
            while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {
                if (alternative === 1) {
                    {
                    {
                    this.state = 675;
                    this.match(SparkSQLParser.COMMA);
                    this.state = 676;
                    this.columnOptionDefinition();
                    this.state = 678;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                    if (_la === 23) {
                        {
                        this.state = 677;
                        this.commentSpec();
                        }
                    }

                    }
                    }
                }
                this.state = 684;
                this.errorHandler.sync(this);
                alternative = this.interpreter.adaptivePredict(this.tokenStream, 29, this.context);
            }
            this.state = 690;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 31, this.context) ) {
            case 1:
                {
                this.state = 685;
                this.match(SparkSQLParser.COMMA);
                this.state = 686;
                this.watermarkDefinition();
                this.state = 688;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 23) {
                    {
                    this.state = 687;
                    this.commentSpec();
                    }
                }

                }
                break;
            }
            this.state = 697;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 33, this.context) ) {
            case 1:
                {
                this.state = 692;
                this.match(SparkSQLParser.COMMA);
                this.state = 693;
                this.tableConstraint();
                this.state = 695;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 23) {
                    {
                    this.state = 694;
                    this.commentSpec();
                    }
                }

                }
                break;
            }
            this.state = 704;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 480) {
                {
                this.state = 699;
                this.match(SparkSQLParser.COMMA);
                this.state = 700;
                this.selfDefinitionClause();
                this.state = 702;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 23) {
                    {
                    this.state = 701;
                    this.commentSpec();
                    }
                }

                }
            }

            this.state = 706;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public createCustomSerde(): CreateCustomSerdeContext {
        let localContext = new CreateCustomSerdeContext(this.context, this.state);
        this.enterRule(localContext, 54, SparkSQLParser.RULE_createCustomSerde);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 708;
            this.match(SparkSQLParser.KW_CREATE);
            this.state = 710;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 172) {
                {
                this.state = 709;
                this.match(SparkSQLParser.KW_TEMPORARY);
                }
            }

            this.state = 712;
            this.match(SparkSQLParser.KW_TABLE);
            this.state = 714;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 37, this.context) ) {
            case 1:
                {
                this.state = 713;
                this.ifNotExists();
                }
                break;
            }
            this.state = 716;
            this.tablePathCreate();
            this.state = 720;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 23 || _la === 110 || _la === 273 || _la === 334 || _la === 453 || _la === 476) {
                {
                {
                this.state = 717;
                this.createCustomSerdeNoSortElement();
                }
                }
                this.state = 722;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 723;
            this.match(SparkSQLParser.KW_ROW);
            this.state = 724;
            this.match(SparkSQLParser.KW_FORMAT);
            this.state = 725;
            this.match(SparkSQLParser.KW_SERDE);
            this.state = 726;
            this.tablePropertyKey();
            this.state = 730;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 23 || _la === 110 || _la === 273 || _la === 334 || _la === 453 || _la === 476) {
                {
                {
                this.state = 727;
                this.createCustomSerdeNoSortElement();
                }
                }
                this.state = 732;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 733;
            this.match(SparkSQLParser.KW_SORTED);
            this.state = 734;
            this.match(SparkSQLParser.KW_AS);
            this.state = 735;
            this.match(SparkSQLParser.KW_INPUTFORMAT);
            this.state = 736;
            this.tablePropertyKey();
            this.state = 740;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 23 || _la === 110 || _la === 273 || _la === 334 || _la === 453 || _la === 476) {
                {
                {
                this.state = 737;
                this.createCustomSerdeNoSortElement();
                }
                }
                this.state = 742;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 743;
            this.match(SparkSQLParser.KW_OUTPUTFORMAT);
            this.state = 744;
            this.tablePropertyKey();
            this.state = 748;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 23 || _la === 110 || _la === 273 || _la === 334 || _la === 453 || _la === 476) {
                {
                {
                this.state = 745;
                this.createCustomSerdeNoSortElement();
                }
                }
                this.state = 750;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 751;
            this.tblProperties();
            this.state = 755;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 23 || _la === 110 || _la === 273 || _la === 334 || _la === 453 || _la === 476) {
                {
                {
                this.state = 752;
                this.createCustomSerdeNoSortElement();
                }
                }
                this.state = 757;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public createCustomSerdeNoSortElement(): CreateCustomSerdeNoSortElementContext {
        let localContext = new CreateCustomSerdeNoSortElementContext(this.context, this.state);
        this.enterRule(localContext, 56, SparkSQLParser.RULE_createCustomSerdeNoSortElement);
        try {
            this.state = 764;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.LR_BRACKET:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 758;
                this.columnsBody();
                }
                break;
            case SparkSQLParser.KW_COMMENT:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 759;
                this.commentSpec();
                }
                break;
            case SparkSQLParser.KW_PARTITIONED:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 760;
                this.partitionDefinition();
                }
                break;
            case SparkSQLParser.KW_WITH:
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 761;
                this.withOption();
                }
                break;
            case SparkSQLParser.KW_LIKE:
                this.enterOuterAlt(localContext, 5);
                {
                this.state = 762;
                this.likeDefinition();
                }
                break;
            case SparkSQLParser.KW_DISTRIBUTED:
                this.enterOuterAlt(localContext, 6);
                {
                this.state = 763;
                this.distribution();
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public createCustomSerdeExternal(): CreateCustomSerdeExternalContext {
        let localContext = new CreateCustomSerdeExternalContext(this.context, this.state);
        this.enterRule(localContext, 58, SparkSQLParser.RULE_createCustomSerdeExternal);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 766;
            this.match(SparkSQLParser.KW_CREATE);
            this.state = 767;
            this.match(SparkSQLParser.KW_EXTERNAL);
            this.state = 768;
            this.match(SparkSQLParser.KW_TABLE);
            this.state = 770;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 44, this.context) ) {
            case 1:
                {
                this.state = 769;
                this.ifNotExists();
                }
                break;
            }
            this.state = 772;
            this.tablePathCreate();
            this.state = 776;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 23 || _la === 110 || _la === 273 || _la === 334 || _la === 423 || _la === 453) {
                {
                {
                this.state = 773;
                this.createCustomSerdeExternalNoSortElement();
                }
                }
                this.state = 778;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 779;
            this.columnsBody();
            this.state = 783;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 23 || _la === 110 || _la === 273 || _la === 334 || _la === 423 || _la === 453) {
                {
                {
                this.state = 780;
                this.createCustomSerdeExternalNoSortElement();
                }
                }
                this.state = 785;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 786;
            this.match(SparkSQLParser.KW_ROW);
            this.state = 787;
            this.match(SparkSQLParser.KW_FORMAT);
            this.state = 788;
            this.match(SparkSQLParser.KW_SERDE);
            this.state = 789;
            this.tablePropertyKey();
            this.state = 793;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 23 || _la === 110 || _la === 273 || _la === 334 || _la === 423 || _la === 453) {
                {
                {
                this.state = 790;
                this.createCustomSerdeExternalNoSortElement();
                }
                }
                this.state = 795;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 796;
            this.match(SparkSQLParser.KW_SORTED);
            this.state = 797;
            this.match(SparkSQLParser.KW_AS);
            this.state = 798;
            this.match(SparkSQLParser.KW_INPUTFORMAT);
            this.state = 799;
            this.tablePropertyKey();
            this.state = 803;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 23 || _la === 110 || _la === 273 || _la === 334 || _la === 423 || _la === 453) {
                {
                {
                this.state = 800;
                this.createCustomSerdeExternalNoSortElement();
                }
                }
                this.state = 805;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 806;
            this.match(SparkSQLParser.KW_OUTPUTFORMAT);
            this.state = 807;
            this.tablePropertyKey();
            this.state = 811;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 23 || _la === 110 || _la === 273 || _la === 334 || _la === 423 || _la === 453) {
                {
                {
                this.state = 808;
                this.createCustomSerdeExternalNoSortElement();
                }
                }
                this.state = 813;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 814;
            this.match(SparkSQLParser.KW_LOCATION);
            this.state = 815;
            this.filePath();
            this.state = 819;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 23 || _la === 110 || _la === 273 || _la === 334 || _la === 423 || _la === 453) {
                {
                {
                this.state = 816;
                this.createCustomSerdeExternalNoSortElement();
                }
                }
                this.state = 821;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public createCustomSerdeExternalNoSortElement(): CreateCustomSerdeExternalNoSortElementContext {
        let localContext = new CreateCustomSerdeExternalNoSortElementContext(this.context, this.state);
        this.enterRule(localContext, 60, SparkSQLParser.RULE_createCustomSerdeExternalNoSortElement);
        try {
            this.state = 828;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.KW_COMMENT:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 822;
                this.commentSpec();
                }
                break;
            case SparkSQLParser.KW_PARTITIONED:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 823;
                this.partitionDefinition();
                }
                break;
            case SparkSQLParser.KW_WITH:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 824;
                this.withOption();
                }
                break;
            case SparkSQLParser.KW_LIKE:
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 825;
                this.likeDefinition();
                }
                break;
            case SparkSQLParser.KW_DISTRIBUTED:
                this.enterOuterAlt(localContext, 5);
                {
                this.state = 826;
                this.distribution();
                }
                break;
            case SparkSQLParser.KW_TBLPROPERTIES:
                this.enterOuterAlt(localContext, 6);
                {
                this.state = 827;
                this.tblProperties();
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public createTableAsSelect(): CreateTableAsSelectContext {
        let localContext = new CreateTableAsSelectContext(this.context, this.state);
        this.enterRule(localContext, 62, SparkSQLParser.RULE_createTableAsSelect);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 830;
            this.match(SparkSQLParser.KW_CREATE);
            this.state = 831;
            this.match(SparkSQLParser.KW_TABLE);
            this.state = 833;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 52, this.context) ) {
            case 1:
                {
                this.state = 832;
                this.ifNotExists();
                }
                break;
            }
            this.state = 835;
            this.tablePathCreate();
            this.state = 836;
            this.withOption();
            this.state = 839;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 212) {
                {
                this.state = 837;
                this.match(SparkSQLParser.KW_AS);
                this.state = 838;
                this.queryStatement(0);
                }
            }

            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public createMaterializedTableAsSelect(): CreateMaterializedTableAsSelectContext {
        let localContext = new CreateMaterializedTableAsSelectContext(this.context, this.state);
        this.enterRule(localContext, 64, SparkSQLParser.RULE_createMaterializedTableAsSelect);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 841;
            this.match(SparkSQLParser.KW_CREATE);
            this.state = 842;
            this.match(SparkSQLParser.KW_MATERIALIZED);
            this.state = 843;
            this.match(SparkSQLParser.KW_TABLE);
            this.state = 844;
            this.tablePathCreate();
            this.state = 848;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 110 || _la === 212 || _la === 453 || _la === 459) {
                {
                {
                this.state = 845;
                this.createMaterializedTableAsSelectNoSortElement();
                }
                }
                this.state = 850;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 851;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 852;
            this.match(SparkSQLParser.KW_PRIMARY);
            this.state = 853;
            this.match(SparkSQLParser.KW_KEY);
            this.state = 854;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 855;
            this.identifier();
            this.state = 860;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 480) {
                {
                {
                this.state = 856;
                this.match(SparkSQLParser.COMMA);
                this.state = 857;
                this.identifier();
                }
                }
                this.state = 862;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 863;
            this.match(SparkSQLParser.RR_BRACKET);
            this.state = 866;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 354) {
                {
                this.state = 864;
                this.match(SparkSQLParser.KW_NOT);
                this.state = 865;
                this.match(SparkSQLParser.KW_ENFORCED);
                }
            }

            this.state = 868;
            this.match(SparkSQLParser.RR_BRACKET);
            this.state = 872;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 110 || _la === 212 || _la === 453 || _la === 459) {
                {
                {
                this.state = 869;
                this.createMaterializedTableAsSelectNoSortElement();
                }
                }
                this.state = 874;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            {
            this.state = 875;
            this.match(SparkSQLParser.KW_FRESHNESS);
            this.state = 876;
            this.match(SparkSQLParser.EQUAL_SYMBOL);
            this.state = 877;
            this.match(SparkSQLParser.KW_INTERVAL);
            this.state = 878;
            this.identifier();
            this.state = 879;
            _la = this.tokenStream.LA(1);
            if(!(_la === 261 || _la === 307 || _la === 345 || _la === 400)) {
            this.errorHandler.recoverInline(this);
            }
            else {
                this.errorHandler.reportMatch(this);
                this.consume();
            }
            }
            this.state = 884;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 110 || _la === 212 || _la === 453 || _la === 459) {
                {
                {
                this.state = 881;
                this.createMaterializedTableAsSelectNoSortElement();
                }
                }
                this.state = 886;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public createMaterializedTableAsSelectNoSortElement(): CreateMaterializedTableAsSelectNoSortElementContext {
        let localContext = new CreateMaterializedTableAsSelectNoSortElementContext(this.context, this.state);
        this.enterRule(localContext, 66, SparkSQLParser.RULE_createMaterializedTableAsSelectNoSortElement);
        let _la: number;
        try {
            this.state = 894;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.KW_PARTITIONED:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 887;
                this.partitionDefinition();
                }
                break;
            case SparkSQLParser.KW_WITH:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 888;
                this.withOption();
                }
                break;
            case SparkSQLParser.KW_REFRESH_MODE:
                this.enterOuterAlt(localContext, 3);
                {
                {
                this.state = 889;
                this.match(SparkSQLParser.KW_REFRESH_MODE);
                this.state = 890;
                this.match(SparkSQLParser.EQUAL_SYMBOL);
                this.state = 891;
                _la = this.tokenStream.LA(1);
                if(!(_la === 298 || _la === 461)) {
                this.errorHandler.recoverInline(this);
                }
                else {
                    this.errorHandler.reportMatch(this);
                    this.consume();
                }
                }
                }
                break;
            case SparkSQLParser.KW_AS:
                this.enterOuterAlt(localContext, 4);
                {
                {
                this.state = 892;
                this.match(SparkSQLParser.KW_AS);
                this.state = 893;
                this.queryStatement(0);
                }
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public usingClause(): UsingClauseContext {
        let localContext = new UsingClauseContext(this.context, this.state);
        this.enterRule(localContext, 68, SparkSQLParser.RULE_usingClause);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 896;
            this.match(SparkSQLParser.KW_USING);
            this.state = 897;
            this.match(SparkSQLParser.KW_JAR);
            this.state = 898;
            this.jarFileName();
            this.state = 904;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 480) {
                {
                {
                this.state = 899;
                this.match(SparkSQLParser.COMMA);
                this.state = 900;
                this.match(SparkSQLParser.KW_JAR);
                this.state = 901;
                this.jarFileName();
                }
                }
                this.state = 906;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public jarFileName(): JarFileNameContext {
        let localContext = new JarFileNameContext(this.context, this.state);
        this.enterRule(localContext, 70, SparkSQLParser.RULE_jarFileName);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 907;
            this.filePath();
            this.state = 910;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 473) {
                {
                this.state = 908;
                this.match(SparkSQLParser.DOT);
                this.state = 909;
                this.match(SparkSQLParser.KW_JAR);
                }
            }

            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public filePath(): FilePathContext {
        let localContext = new FilePathContext(this.context, this.state);
        this.enterRule(localContext, 72, SparkSQLParser.RULE_filePath);
        let _la: number;
        try {
            this.state = 921;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.STRING_LITERAL:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 912;
                this.match(SparkSQLParser.STRING_LITERAL);
                }
                break;
            case SparkSQLParser.SLASH_SIGN:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 917;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                do {
                    {
                    {
                    this.state = 913;
                    this.match(SparkSQLParser.SLASH_SIGN);
                    this.state = 915;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                    if (_la === 501) {
                        {
                        this.state = 914;
                        this.match(SparkSQLParser.ID_LITERAL);
                        }
                    }

                    }
                    }
                    this.state = 919;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                } while (_la === 495);
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public ifExistsPart(): IfExistsPartContext {
        let localContext = new IfExistsPartContext(this.context, this.state);
        this.enterRule(localContext, 74, SparkSQLParser.RULE_ifExistsPart);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 923;
            this.match(SparkSQLParser.KW_IF);
            this.state = 925;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 354) {
                {
                this.state = 924;
                this.match(SparkSQLParser.KW_NOT);
                }
            }

            this.state = 927;
            this.match(SparkSQLParser.KW_EXISTS);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public columnPosition(): ColumnPositionContext {
        let localContext = new ColumnPositionContext(this.context, this.state);
        this.enterRule(localContext, 76, SparkSQLParser.RULE_columnPosition);
        let _la: number;
        try {
            this.state = 932;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.KW_FIRST:
            case SparkSQLParser.KW_LAST:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 929;
                _la = this.tokenStream.LA(1);
                if(!(_la === 54 || _la === 84)) {
                this.errorHandler.recoverInline(this);
                }
                else {
                    this.errorHandler.reportMatch(this);
                    this.consume();
                }
                }
                break;
            case SparkSQLParser.KW_AFTER:
            case SparkSQLParser.KW_BEFORE:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 930;
                _la = this.tokenStream.LA(1);
                if(!(_la === 8 || _la === 11)) {
                this.errorHandler.recoverInline(this);
                }
                else {
                    this.errorHandler.reportMatch(this);
                    this.consume();
                }
                this.state = 931;
                this.uid();
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public renameDefinition(): RenameDefinitionContext {
        let localContext = new RenameDefinitionContext(this.context, this.state);
        this.enterRule(localContext, 78, SparkSQLParser.RULE_renameDefinition);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 934;
            this.match(SparkSQLParser.KW_RENAME);
            this.state = 936;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if ((((_la) & ~0x1F) === 0 && ((1 << _la) & 4294684608) !== 0) || ((((_la - 32)) & ~0x1F) === 0 && ((1 << (_la - 32)) & 4293654523) !== 0) || ((((_la - 64)) & ~0x1F) === 0 && ((1 << (_la - 64)) & 4185849791) !== 0) || ((((_la - 96)) & ~0x1F) === 0 && ((1 << (_la - 96)) & 4294967263) !== 0) || ((((_la - 128)) & ~0x1F) === 0 && ((1 << (_la - 128)) & 3757047707) !== 0) || ((((_la - 160)) & ~0x1F) === 0 && ((1 << (_la - 160)) & 4252958679) !== 0) || ((((_la - 192)) & ~0x1F) === 0 && ((1 << (_la - 192)) & 3967) !== 0) || _la === 338 || ((((_la - 483)) & ~0x1F) === 0 && ((1 << (_la - 483)) & 360449) !== 0)) {
                {
                this.state = 935;
                this.uid();
                }
            }

            this.state = 938;
            this.match(SparkSQLParser.KW_TO);
            this.state = 939;
            this.uid();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public setKeyValueDefinition(): SetKeyValueDefinitionContext {
        let localContext = new SetKeyValueDefinitionContext(this.context, this.state);
        this.enterRule(localContext, 80, SparkSQLParser.RULE_setKeyValueDefinition);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 941;
            this.match(SparkSQLParser.KW_SET);
            this.state = 942;
            this.tablePropertyList();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public addConstraint(): AddConstraintContext {
        let localContext = new AddConstraintContext(this.context, this.state);
        this.enterRule(localContext, 82, SparkSQLParser.RULE_addConstraint);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 944;
            this.match(SparkSQLParser.KW_ADD);
            this.state = 945;
            this.match(SparkSQLParser.KW_CONSTRAINT);
            this.state = 946;
            this.constraintName();
            this.state = 947;
            this.match(SparkSQLParser.KW_PRIMARY);
            this.state = 948;
            this.match(SparkSQLParser.KW_KEY);
            this.state = 949;
            this.columnNameList();
            this.state = 951;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 354) {
                {
                this.state = 950;
                this.notForced();
                }
            }

            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public dropConstraint(): DropConstraintContext {
        let localContext = new DropConstraintContext(this.context, this.state);
        this.enterRule(localContext, 84, SparkSQLParser.RULE_dropConstraint);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 953;
            this.match(SparkSQLParser.KW_DROP);
            this.state = 954;
            this.match(SparkSQLParser.KW_CONSTRAINT);
            this.state = 955;
            this.constraintName();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public addUnique(): AddUniqueContext {
        let localContext = new AddUniqueContext(this.context, this.state);
        this.enterRule(localContext, 86, SparkSQLParser.RULE_addUnique);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 957;
            this.match(SparkSQLParser.KW_ADD);
            this.state = 958;
            this.match(SparkSQLParser.KW_UNIQUE);
            this.state = 959;
            this.columnNameList();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public notForced(): NotForcedContext {
        let localContext = new NotForcedContext(this.context, this.state);
        this.enterRule(localContext, 88, SparkSQLParser.RULE_notForced);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 961;
            this.match(SparkSQLParser.KW_NOT);
            this.state = 962;
            this.match(SparkSQLParser.KW_ENFORCED);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public insertStatement(): InsertStatementContext {
        let localContext = new InsertStatementContext(this.context, this.state);
        this.enterRule(localContext, 90, SparkSQLParser.RULE_insertStatement);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 965;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 284) {
                {
                this.state = 964;
                this.match(SparkSQLParser.KW_EXECUTE);
                }
            }

            this.state = 967;
            this.insertSimpleStatement();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public insertSimpleStatement(): InsertSimpleStatementContext {
        let localContext = new InsertSimpleStatementContext(this.context, this.state);
        this.enterRule(localContext, 92, SparkSQLParser.RULE_insertSimpleStatement);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 969;
            this.match(SparkSQLParser.KW_INSERT);
            this.state = 970;
            _la = this.tokenStream.LA(1);
            if(!(_la === 108 || _la === 319)) {
            this.errorHandler.recoverInline(this);
            }
            else {
                this.errorHandler.reportMatch(this);
                this.consume();
            }
            this.state = 972;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 422) {
                {
                this.state = 971;
                this.match(SparkSQLParser.KW_TABLE);
                }
            }

            this.state = 974;
            this.tablePath();
            this.state = 976;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 371) {
                {
                this.state = 975;
                this.insertPartitionDefinition();
                }
            }

            this.state = 979;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 72, this.context) ) {
            case 1:
                {
                this.state = 978;
                this.columnNameList();
                }
                break;
            }
            this.state = 989;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.KW_FROM:
            case SparkSQLParser.KW_SELECT:
            case SparkSQLParser.KW_WITH:
            case SparkSQLParser.LR_BRACKET:
                {
                this.state = 981;
                this.queryStatement(0);
                }
                break;
            case SparkSQLParser.KW_VALUES:
                {
                this.state = 982;
                this.valuesDefinition();
                }
                break;
            case SparkSQLParser.KW_REPLACE:
                {
                {
                this.state = 983;
                this.match(SparkSQLParser.KW_REPLACE);
                this.state = 984;
                this.whereClause();
                this.state = 985;
                this.selectStatement();
                }
                }
                break;
            case SparkSQLParser.KW_TABLE:
                {
                {
                this.state = 987;
                this.match(SparkSQLParser.KW_TABLE);
                this.state = 988;
                this.tablePath();
                }
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public insertPartitionDefinition(): InsertPartitionDefinitionContext {
        let localContext = new InsertPartitionDefinitionContext(this.context, this.state);
        this.enterRule(localContext, 94, SparkSQLParser.RULE_insertPartitionDefinition);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 991;
            this.match(SparkSQLParser.KW_PARTITION);
            this.state = 992;
            this.tablePropertyList();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }

    public queryStatement(): QueryStatementContext;
    public queryStatement(_p: number): QueryStatementContext;
    public queryStatement(_p?: number): QueryStatementContext {
        if (_p === undefined) {
            _p = 0;
        }

        let parentContext = this.context;
        let parentState = this.state;
        let localContext = new QueryStatementContext(this.context, parentState);
        let previousContext = localContext;
        let _startState = 96;
        this.enterRecursionRule(localContext, 96, SparkSQLParser.RULE_queryStatement, _p);
        let _la: number;
        try {
            let alternative: number;
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1018;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.KW_WITH:
                {
                this.state = 995;
                this.withClause();
                this.state = 996;
                this.queryStatement(4);
                }
                break;
            case SparkSQLParser.LR_BRACKET:
                {
                this.state = 998;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 999;
                this.queryStatement(0);
                this.state = 1000;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case SparkSQLParser.KW_FROM:
            case SparkSQLParser.KW_SELECT:
                {
                this.state = 1004;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 74, this.context) ) {
                case 1:
                    {
                    this.state = 1002;
                    this.selectClause();
                    }
                    break;
                case 2:
                    {
                    this.state = 1003;
                    this.selectStatement();
                    }
                    break;
                }
                this.state = 1007;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 75, this.context) ) {
                case 1:
                    {
                    this.state = 1006;
                    this.sortByCaluse();
                    }
                    break;
                }
                this.state = 1010;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 76, this.context) ) {
                case 1:
                    {
                    this.state = 1009;
                    this.orderByCaluse();
                    }
                    break;
                }
                this.state = 1013;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 77, this.context) ) {
                case 1:
                    {
                    this.state = 1012;
                    this.limitClause();
                    }
                    break;
                }
                this.state = 1016;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 78, this.context) ) {
                case 1:
                    {
                    this.state = 1015;
                    this.offsetClause();
                    }
                    break;
                }
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
            this.context!.stop = this.tokenStream.LT(-1);
            this.state = 1040;
            this.errorHandler.sync(this);
            alternative = this.interpreter.adaptivePredict(this.tokenStream, 85, this.context);
            while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {
                if (alternative === 1) {
                    if (this.parseListeners != null) {
                        this.triggerExitRuleEvent();
                    }
                    previousContext = localContext;
                    {
                    {
                    localContext = new QueryStatementContext(parentContext, parentState);
                    localContext._left = previousContext;
                    this.pushNewRecursionContext(localContext, _startState, SparkSQLParser.RULE_queryStatement);
                    this.state = 1020;
                    if (!(this.precpred(this.context, 2))) {
                        throw this.createFailedPredicateException("this.precpred(this.context, 2)");
                    }
                    this.state = 1021;
                    localContext._operator = this.tokenStream.LT(1);
                    _la = this.tokenStream.LA(1);
                    if(!(_la === 283 || _la === 317 || _la === 344 || _la === 437)) {
                        localContext._operator = this.errorHandler.recoverInline(this);
                    }
                    else {
                        this.errorHandler.reportMatch(this);
                        this.consume();
                    }
                    this.state = 1023;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                    if (_la === 205 || _la === 271) {
                        {
                        this.state = 1022;
                        _la = this.tokenStream.LA(1);
                        if(!(_la === 205 || _la === 271)) {
                        this.errorHandler.recoverInline(this);
                        }
                        else {
                            this.errorHandler.reportMatch(this);
                            this.consume();
                        }
                        }
                    }

                    this.state = 1025;
                    localContext._right = this.queryStatement(0);
                    this.state = 1027;
                    this.errorHandler.sync(this);
                    switch (this.interpreter.adaptivePredict(this.tokenStream, 81, this.context) ) {
                    case 1:
                        {
                        this.state = 1026;
                        this.sortByCaluse();
                        }
                        break;
                    }
                    this.state = 1030;
                    this.errorHandler.sync(this);
                    switch (this.interpreter.adaptivePredict(this.tokenStream, 82, this.context) ) {
                    case 1:
                        {
                        this.state = 1029;
                        this.orderByCaluse();
                        }
                        break;
                    }
                    this.state = 1033;
                    this.errorHandler.sync(this);
                    switch (this.interpreter.adaptivePredict(this.tokenStream, 83, this.context) ) {
                    case 1:
                        {
                        this.state = 1032;
                        this.limitClause();
                        }
                        break;
                    }
                    this.state = 1036;
                    this.errorHandler.sync(this);
                    switch (this.interpreter.adaptivePredict(this.tokenStream, 84, this.context) ) {
                    case 1:
                        {
                        this.state = 1035;
                        this.offsetClause();
                        }
                        break;
                    }
                    }
                    }
                }
                this.state = 1042;
                this.errorHandler.sync(this);
                alternative = this.interpreter.adaptivePredict(this.tokenStream, 85, this.context);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.unrollRecursionContexts(parentContext);
        }
        return localContext;
    }
    public withClause(): WithClauseContext {
        let localContext = new WithClauseContext(this.context, this.state);
        this.enterRule(localContext, 98, SparkSQLParser.RULE_withClause);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1043;
            this.match(SparkSQLParser.KW_WITH);
            this.state = 1044;
            this.withItem();
            this.state = 1049;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 480) {
                {
                {
                this.state = 1045;
                this.match(SparkSQLParser.COMMA);
                this.state = 1046;
                this.withItem();
                }
                }
                this.state = 1051;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public valuesCaluse(): ValuesCaluseContext {
        let localContext = new ValuesCaluseContext(this.context, this.state);
        this.enterRule(localContext, 100, SparkSQLParser.RULE_valuesCaluse);
        try {
            let alternative: number;
            this.enterOuterAlt(localContext, 1);
            {
            {
            this.state = 1052;
            this.match(SparkSQLParser.KW_VALUES);
            this.state = 1053;
            this.inlineBody();
            this.state = 1061;
            this.errorHandler.sync(this);
            alternative = this.interpreter.adaptivePredict(this.tokenStream, 88, this.context);
            while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {
                if (alternative === 1) {
                    {
                    {
                    this.state = 1056;
                    this.errorHandler.sync(this);
                    switch (this.tokenStream.LA(1)) {
                    case SparkSQLParser.COMMA:
                        {
                        this.state = 1054;
                        this.match(SparkSQLParser.COMMA);
                        }
                        break;
                    case SparkSQLParser.KW_ADD:
                    case SparkSQLParser.KW_ADMIN:
                    case SparkSQLParser.KW_AFTER:
                    case SparkSQLParser.KW_ANALYZE:
                    case SparkSQLParser.KW_ASC:
                    case SparkSQLParser.KW_BEFORE:
                    case SparkSQLParser.KW_BYTES:
                    case SparkSQLParser.KW_CASCADE:
                    case SparkSQLParser.KW_CATALOG:
                    case SparkSQLParser.KW_CATALOGS:
                    case SparkSQLParser.KW_CENTURY:
                    case SparkSQLParser.KW_CHAIN:
                    case SparkSQLParser.KW_CHANGELOG_MODE:
                    case SparkSQLParser.KW_CHARACTERS:
                    case SparkSQLParser.KW_COMMENT:
                    case SparkSQLParser.KW_COMPACT:
                    case SparkSQLParser.KW_COLUMNS:
                    case SparkSQLParser.KW_CONSTRAINTS:
                    case SparkSQLParser.KW_CONSTRUCTOR:
                    case SparkSQLParser.KW_COMPUTE:
                    case SparkSQLParser.KW_CUMULATE:
                    case SparkSQLParser.KW_DATA:
                    case SparkSQLParser.KW_DATABASE:
                    case SparkSQLParser.KW_DATABASES:
                    case SparkSQLParser.KW_DAYS:
                    case SparkSQLParser.KW_DECADE:
                    case SparkSQLParser.KW_DEFINED:
                    case SparkSQLParser.KW_DESC:
                    case SparkSQLParser.KW_DESCRIPTOR:
                    case SparkSQLParser.KW_DIV:
                    case SparkSQLParser.KW_ENCODING:
                    case SparkSQLParser.KW_ENFORCED:
                    case SparkSQLParser.KW_ENGINE:
                    case SparkSQLParser.KW_ERROR:
                    case SparkSQLParser.KW_ESTIMATED_COST:
                    case SparkSQLParser.KW_EXCEPTION:
                    case SparkSQLParser.KW_EXCLUDE:
                    case SparkSQLParser.KW_EXCLUDING:
                    case SparkSQLParser.KW_EXTENDED:
                    case SparkSQLParser.KW_FILE:
                    case SparkSQLParser.KW_FINAL:
                    case SparkSQLParser.KW_FIRST:
                    case SparkSQLParser.KW_FOLLOWING:
                    case SparkSQLParser.KW_FORMAT:
                    case SparkSQLParser.KW_FORTRAN:
                    case SparkSQLParser.KW_FOUND:
                    case SparkSQLParser.KW_FRAC_SECOND:
                    case SparkSQLParser.KW_FUNCTIONS:
                    case SparkSQLParser.KW_GENERAL:
                    case SparkSQLParser.KW_GENERATED:
                    case SparkSQLParser.KW_GO:
                    case SparkSQLParser.KW_GOTO:
                    case SparkSQLParser.KW_GRANTED:
                    case SparkSQLParser.KW_HOP:
                    case SparkSQLParser.KW_HOURS:
                    case SparkSQLParser.KW_IF:
                    case SparkSQLParser.KW_IGNORE:
                    case SparkSQLParser.KW_INCREMENT:
                    case SparkSQLParser.KW_INPUT:
                    case SparkSQLParser.KW_INVOKER:
                    case SparkSQLParser.KW_JAR:
                    case SparkSQLParser.KW_JARS:
                    case SparkSQLParser.KW_JAVA:
                    case SparkSQLParser.KW_JSON:
                    case SparkSQLParser.KW_JSON_EXECUTION_PLAN:
                    case SparkSQLParser.KW_KEY:
                    case SparkSQLParser.KW_KEY_MEMBER:
                    case SparkSQLParser.KW_KEY_TYPE:
                    case SparkSQLParser.KW_LABEL:
                    case SparkSQLParser.KW_LAST:
                    case SparkSQLParser.KW_LENGTH:
                    case SparkSQLParser.KW_LEVEL:
                    case SparkSQLParser.KW_LOAD:
                    case SparkSQLParser.KW_MAP:
                    case SparkSQLParser.KW_MICROSECOND:
                    case SparkSQLParser.KW_MILLENNIUM:
                    case SparkSQLParser.KW_MILLISECOND:
                    case SparkSQLParser.KW_MINUTES:
                    case SparkSQLParser.KW_MINVALUE:
                    case SparkSQLParser.KW_MODIFY:
                    case SparkSQLParser.KW_MODULES:
                    case SparkSQLParser.KW_MONTHS:
                    case SparkSQLParser.KW_NANOSECOND:
                    case SparkSQLParser.KW_NULLS:
                    case SparkSQLParser.KW_NUMBER:
                    case SparkSQLParser.KW_OPTION:
                    case SparkSQLParser.KW_OPTIONS:
                    case SparkSQLParser.KW_ORDERING:
                    case SparkSQLParser.KW_OUTPUT:
                    case SparkSQLParser.KW_OVERWRITE:
                    case SparkSQLParser.KW_OVERWRITING:
                    case SparkSQLParser.KW_PARTITIONED:
                    case SparkSQLParser.KW_PARTITIONS:
                    case SparkSQLParser.KW_PASSING:
                    case SparkSQLParser.KW_PAST:
                    case SparkSQLParser.KW_PATH:
                    case SparkSQLParser.KW_PLACING:
                    case SparkSQLParser.KW_PLAN:
                    case SparkSQLParser.KW_PRECEDING:
                    case SparkSQLParser.KW_PRESERVE:
                    case SparkSQLParser.KW_PRIOR:
                    case SparkSQLParser.KW_PRIVILEGES:
                    case SparkSQLParser.KW_PUBLIC:
                    case SparkSQLParser.KW_PYTHON:
                    case SparkSQLParser.KW_PYTHON_FILES:
                    case SparkSQLParser.KW_PYTHON_REQUIREMENTS:
                    case SparkSQLParser.KW_PYTHON_DEPENDENCIES:
                    case SparkSQLParser.KW_PYTHON_JAR:
                    case SparkSQLParser.KW_PYTHON_ARCHIVES:
                    case SparkSQLParser.KW_PYTHON_PARAMETER:
                    case SparkSQLParser.KW_QUARTER:
                    case SparkSQLParser.KW_RAW:
                    case SparkSQLParser.KW_READ:
                    case SparkSQLParser.KW_RELATIVE:
                    case SparkSQLParser.KW_REMOVE:
                    case SparkSQLParser.KW_RENAME:
                    case SparkSQLParser.KW_REPLACE:
                    case SparkSQLParser.KW_RESPECT:
                    case SparkSQLParser.KW_RESTART:
                    case SparkSQLParser.KW_RESTRICT:
                    case SparkSQLParser.KW_ROLE:
                    case SparkSQLParser.KW_ROW_COUNT:
                    case SparkSQLParser.KW_SCALA:
                    case SparkSQLParser.KW_SCALAR:
                    case SparkSQLParser.KW_SCALE:
                    case SparkSQLParser.KW_SCHEMA:
                    case SparkSQLParser.KW_SECONDS:
                    case SparkSQLParser.KW_SECTION:
                    case SparkSQLParser.KW_SECURITY:
                    case SparkSQLParser.KW_SELF:
                    case SparkSQLParser.KW_SERVER:
                    case SparkSQLParser.KW_SERVER_NAME:
                    case SparkSQLParser.KW_SESSION:
                    case SparkSQLParser.KW_SETS:
                    case SparkSQLParser.KW_SIMPLE:
                    case SparkSQLParser.KW_SIZE:
                    case SparkSQLParser.KW_SLIDE:
                    case SparkSQLParser.KW_SOURCE:
                    case SparkSQLParser.KW_SPACE:
                    case SparkSQLParser.KW_STATE:
                    case SparkSQLParser.KW_STATEMENT:
                    case SparkSQLParser.KW_STEP:
                    case SparkSQLParser.KW_STRING:
                    case SparkSQLParser.KW_STRUCTURE:
                    case SparkSQLParser.KW_STYLE:
                    case SparkSQLParser.KW_TABLES:
                    case SparkSQLParser.KW_TEMPORARY:
                    case SparkSQLParser.KW_TIMECOL:
                    case SparkSQLParser.KW_FLOOR:
                    case SparkSQLParser.KW_TIMESTAMP_LTZ:
                    case SparkSQLParser.KW_TIMESTAMPADD:
                    case SparkSQLParser.KW_TIMESTAMPDIFF:
                    case SparkSQLParser.KW_TOTIMESTAMP:
                    case SparkSQLParser.KW_TRANSFORM:
                    case SparkSQLParser.KW_TUMBLE:
                    case SparkSQLParser.KW_TYPE:
                    case SparkSQLParser.KW_UNDER:
                    case SparkSQLParser.KW_UNLOAD:
                    case SparkSQLParser.KW_USAGE:
                    case SparkSQLParser.KW_USE:
                    case SparkSQLParser.KW_UTF16:
                    case SparkSQLParser.KW_UTF32:
                    case SparkSQLParser.KW_UTF8:
                    case SparkSQLParser.KW_VERSION:
                    case SparkSQLParser.KW_VIEW:
                    case SparkSQLParser.KW_VIEWS:
                    case SparkSQLParser.KW_VIRTUAL:
                    case SparkSQLParser.KW_WATERMARK:
                    case SparkSQLParser.KW_WATERMARKS:
                    case SparkSQLParser.KW_WEEK:
                    case SparkSQLParser.KW_WORK:
                    case SparkSQLParser.KW_WRAPPER:
                    case SparkSQLParser.KW_YEARS:
                    case SparkSQLParser.KW_ZONE:
                    case SparkSQLParser.KW_AS:
                    case SparkSQLParser.KW_LOCALTIMESTAMP:
                    case SparkSQLParser.DOLLAR:
                    case SparkSQLParser.STRING_LITERAL:
                    case SparkSQLParser.DIG_LITERAL:
                    case SparkSQLParser.ID_LITERAL:
                        {
                        this.state = 1055;
                        this.tableAlias();
                        }
                        break;
                    default:
                        throw new antlr.NoViableAltException(this);
                    }
                    this.state = 1058;
                    this.inlineBody();
                    }
                    }
                }
                this.state = 1063;
                this.errorHandler.sync(this);
                alternative = this.interpreter.adaptivePredict(this.tokenStream, 88, this.context);
            }
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public inlineBody(): InlineBodyContext {
        let localContext = new InlineBodyContext(this.context, this.state);
        this.enterRule(localContext, 102, SparkSQLParser.RULE_inlineBody);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1064;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 1065;
            this.expression();
            this.state = 1070;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 480) {
                {
                {
                this.state = 1066;
                this.match(SparkSQLParser.COMMA);
                this.state = 1067;
                this.expression();
                }
                }
                this.state = 1072;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 1073;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public withItem(): WithItemContext {
        let localContext = new WithItemContext(this.context, this.state);
        this.enterRule(localContext, 104, SparkSQLParser.RULE_withItem);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1075;
            this.withItemName();
            this.state = 1087;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 476) {
                {
                this.state = 1076;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 1077;
                this.columnName();
                this.state = 1082;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                while (_la === 480) {
                    {
                    {
                    this.state = 1078;
                    this.match(SparkSQLParser.COMMA);
                    this.state = 1079;
                    this.columnName();
                    }
                    }
                    this.state = 1084;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                }
                this.state = 1085;
                this.match(SparkSQLParser.RR_BRACKET);
                }
            }

            this.state = 1089;
            this.match(SparkSQLParser.KW_AS);
            this.state = 1090;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 1091;
            this.queryStatement(0);
            this.state = 1092;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public withItemName(): WithItemNameContext {
        let localContext = new WithItemNameContext(this.context, this.state);
        this.enterRule(localContext, 106, SparkSQLParser.RULE_withItemName);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1094;
            this.identifier();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public selectClause(): SelectClauseContext {
        let localContext = new SelectClauseContext(this.context, this.state);
        this.enterRule(localContext, 108, SparkSQLParser.RULE_selectClause);
        let _la: number;
        try {
            let alternative: number;
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1096;
            this.match(SparkSQLParser.KW_SELECT);
            this.state = 1098;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 205 || _la === 271) {
                {
                this.state = 1097;
                this.setQuantifier();
                }
            }

            this.state = 1100;
            this.projectItemDefinition();
            this.state = 1105;
            this.errorHandler.sync(this);
            alternative = this.interpreter.adaptivePredict(this.tokenStream, 93, this.context);
            while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {
                if (alternative === 1) {
                    {
                    {
                    this.state = 1101;
                    this.match(SparkSQLParser.COMMA);
                    this.state = 1102;
                    this.projectItemDefinition();
                    }
                    }
                }
                this.state = 1107;
                this.errorHandler.sync(this);
                alternative = this.interpreter.adaptivePredict(this.tokenStream, 93, this.context);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public filterPart(): FilterPartContext {
        let localContext = new FilterPartContext(this.context, this.state);
        this.enterRule(localContext, 110, SparkSQLParser.RULE_filterPart);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1108;
            this.match(SparkSQLParser.KW_FILTER);
            this.state = 1109;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 1110;
            this.whereClause();
            this.state = 1111;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public overWindowItem(): OverWindowItemContext {
        let localContext = new OverWindowItemContext(this.context, this.state);
        this.enterRule(localContext, 112, SparkSQLParser.RULE_overWindowItem);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1113;
            this.windowFunctioPart();
            this.state = 1116;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 69 || _la === 139) {
                {
                this.state = 1114;
                _la = this.tokenStream.LA(1);
                if(!(_la === 69 || _la === 139)) {
                this.errorHandler.recoverInline(this);
                }
                else {
                    this.errorHandler.reportMatch(this);
                    this.consume();
                }
                this.state = 1115;
                this.match(SparkSQLParser.KW_NULLS);
                }
            }

            this.state = 1118;
            this.match(SparkSQLParser.KW_OVER);
            this.state = 1120;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 95, this.context) ) {
            case 1:
                {
                this.state = 1119;
                this.anonymousWindowsName();
                }
                break;
            }
            this.state = 1132;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 98, this.context) ) {
            case 1:
                {
                this.state = 1122;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 1124;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 274 || _la === 371) {
                    {
                    this.state = 1123;
                    this.overClause();
                    }
                }

                this.state = 1126;
                this.orderByCaluse();
                this.state = 1128;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 386 || _la === 399) {
                    {
                    this.state = 1127;
                    this.windowFrameForWindowsQuery();
                    }
                }

                this.state = 1130;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public overClause(): OverClauseContext {
        let localContext = new OverClauseContext(this.context, this.state);
        this.enterRule(localContext, 114, SparkSQLParser.RULE_overClause);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1134;
            _la = this.tokenStream.LA(1);
            if(!(_la === 274 || _la === 371)) {
            this.errorHandler.recoverInline(this);
            }
            else {
                this.errorHandler.reportMatch(this);
                this.consume();
            }
            this.state = 1135;
            this.match(SparkSQLParser.KW_BY);
            this.state = 1136;
            this.columnName();
            this.state = 1141;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 480) {
                {
                {
                this.state = 1137;
                this.match(SparkSQLParser.COMMA);
                this.state = 1138;
                this.columnName();
                }
                }
                this.state = 1143;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 1146;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 469) {
                {
                this.state = 1144;
                this.match(SparkSQLParser.EQUAL_SYMBOL);
                this.state = 1145;
                this.expression();
                }
            }

            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public windowFunctioPart(): WindowFunctioPartContext {
        let localContext = new WindowFunctioPartContext(this.context, this.state);
        this.enterRule(localContext, 116, SparkSQLParser.RULE_windowFunctioPart);
        let _la: number;
        try {
            this.state = 1163;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 103, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 1148;
                this.windowFunctionName();
                this.state = 1149;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 1158;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if ((((_la) & ~0x1F) === 0 && ((1 << _la) & 4294684608) !== 0) || ((((_la - 32)) & ~0x1F) === 0 && ((1 << (_la - 32)) & 4293918715) !== 0) || ((((_la - 64)) & ~0x1F) === 0 && ((1 << (_la - 64)) & 4185849791) !== 0) || ((((_la - 96)) & ~0x1F) === 0 && ((1 << (_la - 96)) & 4294967263) !== 0) || ((((_la - 128)) & ~0x1F) === 0 && ((1 << (_la - 128)) & 3757047707) !== 0) || ((((_la - 160)) & ~0x1F) === 0 && ((1 << (_la - 160)) & 4252958679) !== 0) || ((((_la - 192)) & ~0x1F) === 0 && ((1 << (_la - 192)) & 2156412927) !== 0) || ((((_la - 230)) & ~0x1F) === 0 && ((1 << (_la - 230)) & 2685932551) !== 0) || ((((_la - 271)) & ~0x1F) === 0 && ((1 << (_la - 271)) & 70336513) !== 0) || ((((_la - 303)) & ~0x1F) === 0 && ((1 << (_la - 303)) & 2030075921) !== 0) || ((((_la - 338)) & ~0x1F) === 0 && ((1 << (_la - 338)) & 2148205697) !== 0) || ((((_la - 375)) & ~0x1F) === 0 && ((1 << (_la - 375)) & 42494055) !== 0) || ((((_la - 414)) & ~0x1F) === 0 && ((1 << (_la - 414)) & 276029453) !== 0) || ((((_la - 456)) & ~0x1F) === 0 && ((1 << (_la - 456)) & 135266817) !== 0) || ((((_la - 488)) & ~0x1F) === 0 && ((1 << (_la - 488)) & 15373) !== 0)) {
                    {
                    this.state = 1150;
                    this.functionParam();
                    this.state = 1155;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                    while (_la === 480) {
                        {
                        {
                        this.state = 1151;
                        this.match(SparkSQLParser.COMMA);
                        this.state = 1152;
                        this.functionParam();
                        }
                        }
                        this.state = 1157;
                        this.errorHandler.sync(this);
                        _la = this.tokenStream.LA(1);
                    }
                    }
                }

                this.state = 1160;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 1162;
                this.primaryExpression(0);
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public windowFunctionName(): WindowFunctionNameContext {
        let localContext = new WindowFunctionNameContext(this.context, this.state);
        this.enterRule(localContext, 118, SparkSQLParser.RULE_windowFunctionName);
        try {
            this.state = 1167;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.KW_DENSE_RANK:
            case SparkSQLParser.KW_NTILE:
            case SparkSQLParser.KW_PERCENT_RANK:
            case SparkSQLParser.KW_RANK:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 1165;
                this.rangkingFunction();
                }
                break;
            case SparkSQLParser.KW_CUME_DIST:
            case SparkSQLParser.KW_FIRST_VALUE:
            case SparkSQLParser.KW_LAG:
            case SparkSQLParser.KW_LAST_VALUE:
            case SparkSQLParser.KW_LEAD:
            case SparkSQLParser.KW_NTH_VALUE:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 1166;
                this.analyticFunction();
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public analyticFunction(): AnalyticFunctionContext {
        let localContext = new AnalyticFunctionContext(this.context, this.state);
        this.enterRule(localContext, 120, SparkSQLParser.RULE_analyticFunction);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1169;
            _la = this.tokenStream.LA(1);
            if(!(_la === 254 || _la === 291 || ((((_la - 327)) & ~0x1F) === 0 && ((1 << (_la - 327)) & 536870937) !== 0))) {
            this.errorHandler.recoverInline(this);
            }
            else {
                this.errorHandler.reportMatch(this);
                this.consume();
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public rangkingFunction(): RangkingFunctionContext {
        let localContext = new RangkingFunctionContext(this.context, this.state);
        this.enterRule(localContext, 122, SparkSQLParser.RULE_rangkingFunction);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1171;
            _la = this.tokenStream.LA(1);
            if(!(_la === 270 || _la === 355 || _la === 375 || _la === 389)) {
            this.errorHandler.recoverInline(this);
            }
            else {
                this.errorHandler.reportMatch(this);
                this.consume();
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public fromClause(): FromClauseContext {
        let localContext = new FromClauseContext(this.context, this.state);
        this.enterRule(localContext, 124, SparkSQLParser.RULE_fromClause);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1173;
            this.match(SparkSQLParser.KW_FROM);
            this.state = 1174;
            this.tableExpression(0);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public windowFrameForWindowsQuery(): WindowFrameForWindowsQueryContext {
        let localContext = new WindowFrameForWindowsQueryContext(this.context, this.state);
        this.enterRule(localContext, 126, SparkSQLParser.RULE_windowFrameForWindowsQuery);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1176;
            _la = this.tokenStream.LA(1);
            if(!(_la === 386 || _la === 399)) {
            this.errorHandler.recoverInline(this);
            }
            else {
                this.errorHandler.reportMatch(this);
                this.consume();
            }
            this.state = 1183;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.KW_ADD:
            case SparkSQLParser.KW_ADMIN:
            case SparkSQLParser.KW_AFTER:
            case SparkSQLParser.KW_ANALYZE:
            case SparkSQLParser.KW_ASC:
            case SparkSQLParser.KW_BEFORE:
            case SparkSQLParser.KW_BYTES:
            case SparkSQLParser.KW_CASCADE:
            case SparkSQLParser.KW_CATALOG:
            case SparkSQLParser.KW_CATALOGS:
            case SparkSQLParser.KW_CENTURY:
            case SparkSQLParser.KW_CHAIN:
            case SparkSQLParser.KW_CHANGELOG_MODE:
            case SparkSQLParser.KW_CHARACTERS:
            case SparkSQLParser.KW_COMMENT:
            case SparkSQLParser.KW_COMPACT:
            case SparkSQLParser.KW_COLUMNS:
            case SparkSQLParser.KW_CONSTRAINTS:
            case SparkSQLParser.KW_CONSTRUCTOR:
            case SparkSQLParser.KW_COMPUTE:
            case SparkSQLParser.KW_CUMULATE:
            case SparkSQLParser.KW_DATA:
            case SparkSQLParser.KW_DATABASE:
            case SparkSQLParser.KW_DATABASES:
            case SparkSQLParser.KW_DAYS:
            case SparkSQLParser.KW_DECADE:
            case SparkSQLParser.KW_DEFINED:
            case SparkSQLParser.KW_DESC:
            case SparkSQLParser.KW_DESCRIPTOR:
            case SparkSQLParser.KW_DIV:
            case SparkSQLParser.KW_ENCODING:
            case SparkSQLParser.KW_ENFORCED:
            case SparkSQLParser.KW_ENGINE:
            case SparkSQLParser.KW_ERROR:
            case SparkSQLParser.KW_ESTIMATED_COST:
            case SparkSQLParser.KW_EXCEPTION:
            case SparkSQLParser.KW_EXCLUDE:
            case SparkSQLParser.KW_EXCLUDING:
            case SparkSQLParser.KW_EXTENDED:
            case SparkSQLParser.KW_FILE:
            case SparkSQLParser.KW_FINAL:
            case SparkSQLParser.KW_FIRST:
            case SparkSQLParser.KW_FOLLOWING:
            case SparkSQLParser.KW_FORMAT:
            case SparkSQLParser.KW_FORTRAN:
            case SparkSQLParser.KW_FOUND:
            case SparkSQLParser.KW_FRAC_SECOND:
            case SparkSQLParser.KW_FUNCTIONS:
            case SparkSQLParser.KW_GENERAL:
            case SparkSQLParser.KW_GENERATED:
            case SparkSQLParser.KW_GO:
            case SparkSQLParser.KW_GOTO:
            case SparkSQLParser.KW_GRANTED:
            case SparkSQLParser.KW_HOP:
            case SparkSQLParser.KW_HOURS:
            case SparkSQLParser.KW_IF:
            case SparkSQLParser.KW_IGNORE:
            case SparkSQLParser.KW_INCREMENT:
            case SparkSQLParser.KW_INPUT:
            case SparkSQLParser.KW_INVOKER:
            case SparkSQLParser.KW_JAR:
            case SparkSQLParser.KW_JARS:
            case SparkSQLParser.KW_JAVA:
            case SparkSQLParser.KW_JSON:
            case SparkSQLParser.KW_JSON_EXECUTION_PLAN:
            case SparkSQLParser.KW_KEY:
            case SparkSQLParser.KW_KEY_MEMBER:
            case SparkSQLParser.KW_KEY_TYPE:
            case SparkSQLParser.KW_LABEL:
            case SparkSQLParser.KW_LAST:
            case SparkSQLParser.KW_LENGTH:
            case SparkSQLParser.KW_LEVEL:
            case SparkSQLParser.KW_LOAD:
            case SparkSQLParser.KW_MAP:
            case SparkSQLParser.KW_MICROSECOND:
            case SparkSQLParser.KW_MILLENNIUM:
            case SparkSQLParser.KW_MILLISECOND:
            case SparkSQLParser.KW_MINUTES:
            case SparkSQLParser.KW_MINVALUE:
            case SparkSQLParser.KW_MODIFY:
            case SparkSQLParser.KW_MODULES:
            case SparkSQLParser.KW_MONTHS:
            case SparkSQLParser.KW_NANOSECOND:
            case SparkSQLParser.KW_NULLS:
            case SparkSQLParser.KW_NUMBER:
            case SparkSQLParser.KW_OPTION:
            case SparkSQLParser.KW_OPTIONS:
            case SparkSQLParser.KW_ORDERING:
            case SparkSQLParser.KW_OUTPUT:
            case SparkSQLParser.KW_OVERWRITE:
            case SparkSQLParser.KW_OVERWRITING:
            case SparkSQLParser.KW_PARTITIONED:
            case SparkSQLParser.KW_PARTITIONS:
            case SparkSQLParser.KW_PASSING:
            case SparkSQLParser.KW_PAST:
            case SparkSQLParser.KW_PATH:
            case SparkSQLParser.KW_PLACING:
            case SparkSQLParser.KW_PLAN:
            case SparkSQLParser.KW_PRECEDING:
            case SparkSQLParser.KW_PRESERVE:
            case SparkSQLParser.KW_PRIOR:
            case SparkSQLParser.KW_PRIVILEGES:
            case SparkSQLParser.KW_PUBLIC:
            case SparkSQLParser.KW_PYTHON:
            case SparkSQLParser.KW_PYTHON_FILES:
            case SparkSQLParser.KW_PYTHON_REQUIREMENTS:
            case SparkSQLParser.KW_PYTHON_DEPENDENCIES:
            case SparkSQLParser.KW_PYTHON_JAR:
            case SparkSQLParser.KW_PYTHON_ARCHIVES:
            case SparkSQLParser.KW_PYTHON_PARAMETER:
            case SparkSQLParser.KW_QUARTER:
            case SparkSQLParser.KW_RAW:
            case SparkSQLParser.KW_READ:
            case SparkSQLParser.KW_RELATIVE:
            case SparkSQLParser.KW_REMOVE:
            case SparkSQLParser.KW_RENAME:
            case SparkSQLParser.KW_REPLACE:
            case SparkSQLParser.KW_RESPECT:
            case SparkSQLParser.KW_RESTART:
            case SparkSQLParser.KW_RESTRICT:
            case SparkSQLParser.KW_ROLE:
            case SparkSQLParser.KW_ROW_COUNT:
            case SparkSQLParser.KW_SCALA:
            case SparkSQLParser.KW_SCALAR:
            case SparkSQLParser.KW_SCALE:
            case SparkSQLParser.KW_SCHEMA:
            case SparkSQLParser.KW_SECONDS:
            case SparkSQLParser.KW_SECTION:
            case SparkSQLParser.KW_SECURITY:
            case SparkSQLParser.KW_SELF:
            case SparkSQLParser.KW_SERVER:
            case SparkSQLParser.KW_SERVER_NAME:
            case SparkSQLParser.KW_SESSION:
            case SparkSQLParser.KW_SETS:
            case SparkSQLParser.KW_SIMPLE:
            case SparkSQLParser.KW_SIZE:
            case SparkSQLParser.KW_SLIDE:
            case SparkSQLParser.KW_SOURCE:
            case SparkSQLParser.KW_SPACE:
            case SparkSQLParser.KW_STATE:
            case SparkSQLParser.KW_STATEMENT:
            case SparkSQLParser.KW_STEP:
            case SparkSQLParser.KW_STRING:
            case SparkSQLParser.KW_STRUCTURE:
            case SparkSQLParser.KW_STYLE:
            case SparkSQLParser.KW_TABLES:
            case SparkSQLParser.KW_TEMPORARY:
            case SparkSQLParser.KW_TIMECOL:
            case SparkSQLParser.KW_FLOOR:
            case SparkSQLParser.KW_TIMESTAMP_LTZ:
            case SparkSQLParser.KW_TIMESTAMPADD:
            case SparkSQLParser.KW_TIMESTAMPDIFF:
            case SparkSQLParser.KW_TOTIMESTAMP:
            case SparkSQLParser.KW_TRANSFORM:
            case SparkSQLParser.KW_TUMBLE:
            case SparkSQLParser.KW_TYPE:
            case SparkSQLParser.KW_UNDER:
            case SparkSQLParser.KW_UNBOUNDED:
            case SparkSQLParser.KW_UNLOAD:
            case SparkSQLParser.KW_USAGE:
            case SparkSQLParser.KW_USE:
            case SparkSQLParser.KW_UTF16:
            case SparkSQLParser.KW_UTF32:
            case SparkSQLParser.KW_UTF8:
            case SparkSQLParser.KW_VERSION:
            case SparkSQLParser.KW_VIEW:
            case SparkSQLParser.KW_VIEWS:
            case SparkSQLParser.KW_VIRTUAL:
            case SparkSQLParser.KW_WATERMARK:
            case SparkSQLParser.KW_WATERMARKS:
            case SparkSQLParser.KW_WEEK:
            case SparkSQLParser.KW_WORK:
            case SparkSQLParser.KW_WRAPPER:
            case SparkSQLParser.KW_YEARS:
            case SparkSQLParser.KW_ZONE:
            case SparkSQLParser.KW_ABS:
            case SparkSQLParser.KW_ARRAY:
            case SparkSQLParser.KW_AVG:
            case SparkSQLParser.KW_CASE:
            case SparkSQLParser.KW_CAST:
            case SparkSQLParser.KW_CEIL:
            case SparkSQLParser.KW_COALESCE:
            case SparkSQLParser.KW_COLLECT:
            case SparkSQLParser.KW_COUNT:
            case SparkSQLParser.KW_CURRENT_TIMESTAMP:
            case SparkSQLParser.KW_CURRENT:
            case SparkSQLParser.KW_DATE:
            case SparkSQLParser.KW_DAY:
            case SparkSQLParser.KW_EXISTS:
            case SparkSQLParser.KW_EXPLODE:
            case SparkSQLParser.KW_FIRST_VALUE:
            case SparkSQLParser.KW_FALSE:
            case SparkSQLParser.KW_FROM_UNIXTIME:
            case SparkSQLParser.KW_GROUPING:
            case SparkSQLParser.KW_HOUR:
            case SparkSQLParser.KW_INTERVAL:
            case SparkSQLParser.KW_LAG:
            case SparkSQLParser.KW_LAST_VALUE:
            case SparkSQLParser.KW_LEAD:
            case SparkSQLParser.KW_LEFT:
            case SparkSQLParser.KW_LOCALTIMESTAMP:
            case SparkSQLParser.KW_MINUTE:
            case SparkSQLParser.KW_MONTH:
            case SparkSQLParser.KW_NOT:
            case SparkSQLParser.KW_NTILE:
            case SparkSQLParser.KW_NULL:
            case SparkSQLParser.KW_OVERLAY:
            case SparkSQLParser.KW_PERCENT_RANK:
            case SparkSQLParser.KW_PERCENTILE_CONT:
            case SparkSQLParser.KW_PERCENTILE_DISC:
            case SparkSQLParser.KW_POSITION:
            case SparkSQLParser.KW_POWER:
            case SparkSQLParser.KW_RANGE:
            case SparkSQLParser.KW_ROW_NUMBER:
            case SparkSQLParser.KW_RANK:
            case SparkSQLParser.KW_RIGHT:
            case SparkSQLParser.KW_ROW:
            case SparkSQLParser.KW_SECOND:
            case SparkSQLParser.KW_STRUCT:
            case SparkSQLParser.KW_SUBSTRING:
            case SparkSQLParser.KW_SUM:
            case SparkSQLParser.KW_TIME:
            case SparkSQLParser.KW_TIMESTAMP:
            case SparkSQLParser.KW_TIMESTAMP_3:
            case SparkSQLParser.KW_TIMESTAMP_6:
            case SparkSQLParser.KW_TIMESTAMP_9:
            case SparkSQLParser.KW_TRUE:
            case SparkSQLParser.KW_TRUNCATE:
            case SparkSQLParser.KW_UPPER:
            case SparkSQLParser.KW_YEAR:
            case SparkSQLParser.BIT_NOT_OP:
            case SparkSQLParser.LR_BRACKET:
            case SparkSQLParser.DOLLAR:
            case SparkSQLParser.ASTERISK_SIGN:
            case SparkSQLParser.HYPNEN_SIGN:
            case SparkSQLParser.ADD_SIGN:
            case SparkSQLParser.STRING_LITERAL:
            case SparkSQLParser.DIG_LITERAL:
            case SparkSQLParser.REAL_LITERAL:
            case SparkSQLParser.ID_LITERAL:
                {
                this.state = 1177;
                this.frameExpession();
                }
                break;
            case SparkSQLParser.KW_BETWEEN:
                {
                {
                this.state = 1178;
                this.match(SparkSQLParser.KW_BETWEEN);
                this.state = 1179;
                this.frameExpession();
                this.state = 1180;
                this.match(SparkSQLParser.KW_AND);
                this.state = 1181;
                this.frameExpession();
                }
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public frameExpession(): FrameExpessionContext {
        let localContext = new FrameExpessionContext(this.context, this.state);
        this.enterRule(localContext, 128, SparkSQLParser.RULE_frameExpession);
        try {
            this.state = 1197;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 106, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                {
                this.state = 1185;
                this.match(SparkSQLParser.KW_UNBOUNDED);
                this.state = 1186;
                this.match(SparkSQLParser.KW_PRECEDING);
                }
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                {
                this.state = 1187;
                this.expression();
                this.state = 1188;
                this.match(SparkSQLParser.KW_PRECEDING);
                }
                }
                break;
            case 3:
                this.enterOuterAlt(localContext, 3);
                {
                {
                this.state = 1190;
                this.match(SparkSQLParser.KW_CURRENT);
                this.state = 1191;
                this.match(SparkSQLParser.KW_ROW);
                }
                }
                break;
            case 4:
                this.enterOuterAlt(localContext, 4);
                {
                {
                this.state = 1192;
                this.expression();
                this.state = 1193;
                this.match(SparkSQLParser.KW_FOLLOWING);
                }
                }
                break;
            case 5:
                this.enterOuterAlt(localContext, 5);
                {
                {
                this.state = 1195;
                this.match(SparkSQLParser.KW_UNBOUNDED);
                this.state = 1196;
                this.match(SparkSQLParser.KW_FOLLOWING);
                }
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }

    public tableExpression(): TableExpressionContext;
    public tableExpression(_p: number): TableExpressionContext;
    public tableExpression(_p?: number): TableExpressionContext {
        if (_p === undefined) {
            _p = 0;
        }

        let parentContext = this.context;
        let parentState = this.state;
        let localContext = new TableExpressionContext(this.context, parentState);
        let previousContext = localContext;
        let _startState = 130;
        this.enterRecursionRule(localContext, 130, SparkSQLParser.RULE_tableExpression, _p);
        let _la: number;
        try {
            let alternative: number;
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1229;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 112, this.context) ) {
            case 1:
                {
                this.state = 1200;
                this.tableReference();
                this.state = 1205;
                this.errorHandler.sync(this);
                alternative = this.interpreter.adaptivePredict(this.tokenStream, 107, this.context);
                while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {
                    if (alternative === 1) {
                        {
                        {
                        this.state = 1201;
                        this.match(SparkSQLParser.COMMA);
                        this.state = 1202;
                        this.tableReference();
                        }
                        }
                    }
                    this.state = 1207;
                    this.errorHandler.sync(this);
                    alternative = this.interpreter.adaptivePredict(this.tokenStream, 107, this.context);
                }
                }
                break;
            case 2:
                {
                this.state = 1208;
                this.tableReference();
                this.state = 1209;
                this.pivotReference();
                this.state = 1211;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 108, this.context) ) {
                case 1:
                    {
                    this.state = 1210;
                    this.tableAlias();
                    }
                    break;
                }
                }
                break;
            case 3:
                {
                this.state = 1213;
                this.tableReference();
                this.state = 1217;
                this.errorHandler.sync(this);
                alternative = this.interpreter.adaptivePredict(this.tokenStream, 109, this.context);
                while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {
                    if (alternative === 1) {
                        {
                        {
                        this.state = 1214;
                        this.viewReference();
                        }
                        }
                    }
                    this.state = 1219;
                    this.errorHandler.sync(this);
                    alternative = this.interpreter.adaptivePredict(this.tokenStream, 109, this.context);
                }
                this.state = 1221;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 110, this.context) ) {
                case 1:
                    {
                    this.state = 1220;
                    this.tableAlias();
                    }
                    break;
                }
                }
                break;
            case 4:
                {
                this.state = 1223;
                this.valuesCaluse();
                }
                break;
            case 5:
                {
                this.state = 1224;
                this.tvfClause();
                this.state = 1226;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 111, this.context) ) {
                case 1:
                    {
                    this.state = 1225;
                    this.tableAlias();
                    }
                    break;
                }
                }
                break;
            case 6:
                {
                this.state = 1228;
                this.windowTVFClause();
                }
                break;
            }
            this.context!.stop = this.tokenStream.LT(-1);
            this.state = 1258;
            this.errorHandler.sync(this);
            alternative = this.interpreter.adaptivePredict(this.tokenStream, 119, this.context);
            while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {
                if (alternative === 1) {
                    if (this.parseListeners != null) {
                        this.triggerExitRuleEvent();
                    }
                    previousContext = localContext;
                    {
                    {
                    localContext = new TableExpressionContext(parentContext, parentState);
                    this.pushNewRecursionContext(localContext, _startState, SparkSQLParser.RULE_tableExpression);
                    this.state = 1231;
                    if (!(this.precpred(this.context, 4))) {
                        throw this.createFailedPredicateException("this.precpred(this.context, 4)");
                    }
                    this.state = 1233;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                    if (_la === 350) {
                        {
                        this.state = 1232;
                        this.match(SparkSQLParser.KW_NATURAL);
                        }
                    }

                    this.state = 1236;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                    if (_la === 252 || _la === 298 || _la === 312 || _la === 333 || _la === 394) {
                        {
                        this.state = 1235;
                        _la = this.tokenStream.LA(1);
                        if(!(_la === 252 || _la === 298 || _la === 312 || _la === 333 || _la === 394)) {
                        this.errorHandler.recoverInline(this);
                        }
                        else {
                            this.errorHandler.reportMatch(this);
                            this.consume();
                        }
                        }
                    }

                    this.state = 1239;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                    if (_la === 366) {
                        {
                        this.state = 1238;
                        this.match(SparkSQLParser.KW_OUTER);
                        }
                    }

                    this.state = 1242;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                    if (_la === 402) {
                        {
                        this.state = 1241;
                        this.match(SparkSQLParser.KW_SEMI);
                        }
                    }

                    this.state = 1244;
                    this.match(SparkSQLParser.KW_JOIN);
                    this.state = 1245;
                    this.tableExpression(0);
                    this.state = 1247;
                    this.errorHandler.sync(this);
                    switch (this.interpreter.adaptivePredict(this.tokenStream, 117, this.context) ) {
                    case 1:
                        {
                        this.state = 1246;
                        this.joinCondition();
                        }
                        break;
                    }
                    this.state = 1253;
                    this.errorHandler.sync(this);
                    alternative = this.interpreter.adaptivePredict(this.tokenStream, 118, this.context);
                    while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {
                        if (alternative === 1) {
                            {
                            {
                            this.state = 1249;
                            this.match(SparkSQLParser.COMMA);
                            this.state = 1250;
                            this.tableReference();
                            }
                            }
                        }
                        this.state = 1255;
                        this.errorHandler.sync(this);
                        alternative = this.interpreter.adaptivePredict(this.tokenStream, 118, this.context);
                    }
                    }
                    }
                }
                this.state = 1260;
                this.errorHandler.sync(this);
                alternative = this.interpreter.adaptivePredict(this.tokenStream, 119, this.context);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.unrollRecursionContexts(parentContext);
        }
        return localContext;
    }
    public tvfClause(): TvfClauseContext {
        let localContext = new TvfClauseContext(this.context, this.state);
        this.enterRule(localContext, 132, SparkSQLParser.RULE_tvfClause);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1261;
            this.rangeClause();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public rangeClause(): RangeClauseContext {
        let localContext = new RangeClauseContext(this.context, this.state);
        this.enterRule(localContext, 134, SparkSQLParser.RULE_rangeClause);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1263;
            this.match(SparkSQLParser.KW_RANGE);
            this.state = 1264;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 1265;
            this.expression();
            this.state = 1270;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 480) {
                {
                {
                this.state = 1266;
                this.match(SparkSQLParser.COMMA);
                this.state = 1267;
                this.expression();
                }
                }
                this.state = 1272;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 1273;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public viewReference(): ViewReferenceContext {
        let localContext = new ViewReferenceContext(this.context, this.state);
        this.enterRule(localContext, 136, SparkSQLParser.RULE_viewReference);
        let _la: number;
        try {
            let alternative: number;
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1275;
            this.match(SparkSQLParser.KW_LATERAL);
            this.state = 1276;
            this.match(SparkSQLParser.KW_VIEW);
            this.state = 1278;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 366) {
                {
                this.state = 1277;
                this.match(SparkSQLParser.KW_OUTER);
                }
            }

            this.state = 1280;
            this.funtionBody();
            this.state = 1282;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 122, this.context) ) {
            case 1:
                {
                this.state = 1281;
                this.tableAlias();
                }
                break;
            }
            this.state = 1284;
            this.match(SparkSQLParser.KW_AS);
            this.state = 1285;
            this.columnAlias();
            this.state = 1290;
            this.errorHandler.sync(this);
            alternative = this.interpreter.adaptivePredict(this.tokenStream, 123, this.context);
            while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {
                if (alternative === 1) {
                    {
                    {
                    this.state = 1286;
                    this.match(SparkSQLParser.COMMA);
                    this.state = 1287;
                    this.columnAlias();
                    }
                    }
                }
                this.state = 1292;
                this.errorHandler.sync(this);
                alternative = this.interpreter.adaptivePredict(this.tokenStream, 123, this.context);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public pivotReference(): PivotReferenceContext {
        let localContext = new PivotReferenceContext(this.context, this.state);
        this.enterRule(localContext, 138, SparkSQLParser.RULE_pivotReference);
        let _la: number;
        try {
            this.state = 1307;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.KW_PIVOT:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 1293;
                this.match(SparkSQLParser.KW_PIVOT);
                this.state = 1294;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 1295;
                this.pivotBody();
                this.state = 1296;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case SparkSQLParser.KW_UNPIVOT:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 1298;
                this.match(SparkSQLParser.KW_UNPIVOT);
                this.state = 1301;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 47 || _la === 70) {
                    {
                    this.state = 1299;
                    _la = this.tokenStream.LA(1);
                    if(!(_la === 47 || _la === 70)) {
                    this.errorHandler.recoverInline(this);
                    }
                    else {
                        this.errorHandler.reportMatch(this);
                        this.consume();
                    }
                    this.state = 1300;
                    this.match(SparkSQLParser.KW_NULLS);
                    }
                }

                this.state = 1303;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 1304;
                this.unpivotBody();
                this.state = 1305;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public tableReference(): TableReferenceContext {
        let localContext = new TableReferenceContext(this.context, this.state);
        this.enterRule(localContext, 140, SparkSQLParser.RULE_tableReference);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1309;
            this.tablePrimary();
            this.state = 1311;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 126, this.context) ) {
            case 1:
                {
                this.state = 1310;
                this.tableAlias();
                }
                break;
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public tablePrimary(): TablePrimaryContext {
        let localContext = new TablePrimaryContext(this.context, this.state);
        this.enterRule(localContext, 142, SparkSQLParser.RULE_tablePrimary);
        let _la: number;
        try {
            this.state = 1354;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 132, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 1314;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 422) {
                    {
                    this.state = 1313;
                    this.match(SparkSQLParser.KW_TABLE);
                    }
                }

                this.state = 1316;
                this.tablePath();
                this.state = 1318;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 128, this.context) ) {
                case 1:
                    {
                    this.state = 1317;
                    this.systemTimePeriod();
                    }
                    break;
                }
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 1320;
                this.match(SparkSQLParser.KW_LATERAL);
                this.state = 1321;
                this.match(SparkSQLParser.KW_TABLE);
                this.state = 1324;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 129, this.context) ) {
                case 1:
                    {
                    this.state = 1322;
                    this.funtionBody();
                    }
                    break;
                case 2:
                    {
                    this.state = 1323;
                    this.complexDataTypeExpression();
                    }
                    break;
                }
                }
                break;
            case 3:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 1326;
                this.match(SparkSQLParser.KW_LATERAL);
                this.state = 1327;
                this.match(SparkSQLParser.KW_TABLE);
                this.state = 1328;
                this.match(SparkSQLParser.KW_EXPLODE);
                this.state = 1329;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 1332;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 130, this.context) ) {
                case 1:
                    {
                    this.state = 1330;
                    this.funtionBody();
                    }
                    break;
                case 2:
                    {
                    this.state = 1331;
                    this.complexDataTypeExpression();
                    }
                    break;
                }
                this.state = 1334;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case 4:
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 1336;
                this.match(SparkSQLParser.KW_LATERAL);
                this.state = 1337;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 1338;
                this.queryStatement(0);
                this.state = 1339;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case 5:
                this.enterOuterAlt(localContext, 5);
                {
                this.state = 1341;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 1345;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                while (_la === 296 || _la === 401 || _la === 453 || _la === 476) {
                    {
                    {
                    this.state = 1342;
                    this.queryStatement(0);
                    }
                    }
                    this.state = 1347;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                }
                this.state = 1348;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case 6:
                this.enterOuterAlt(localContext, 6);
                {
                this.state = 1349;
                this.match(SparkSQLParser.KW_UNSET);
                this.state = 1350;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 1351;
                this.expression();
                this.state = 1352;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public funtionBody(): FuntionBodyContext {
        let localContext = new FuntionBodyContext(this.context, this.state);
        this.enterRule(localContext, 144, SparkSQLParser.RULE_funtionBody);
        let _la: number;
        try {
            let alternative: number;
            this.state = 1403;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 140, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 1356;
                this.functionName();
                this.state = 1357;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 1360;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 133, this.context) ) {
                case 1:
                    {
                    this.state = 1358;
                    this.funtionBody();
                    }
                    break;
                case 2:
                    {
                    this.state = 1359;
                    this.functionParam();
                    }
                    break;
                }
                this.state = 1369;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                while (_la === 480) {
                    {
                    {
                    this.state = 1362;
                    this.match(SparkSQLParser.COMMA);
                    this.state = 1365;
                    this.errorHandler.sync(this);
                    switch (this.interpreter.adaptivePredict(this.tokenStream, 134, this.context) ) {
                    case 1:
                        {
                        this.state = 1363;
                        this.funtionBody();
                        }
                        break;
                    case 2:
                        {
                        this.state = 1364;
                        this.functionParam();
                        }
                        break;
                    }
                    }
                    }
                    this.state = 1371;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                }
                this.state = 1372;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 1374;
                this.functionName();
                this.state = 1375;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 1378;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 136, this.context) ) {
                case 1:
                    {
                    this.state = 1376;
                    this.funtionBody();
                    }
                    break;
                case 2:
                    {
                    this.state = 1377;
                    this.functionParam();
                    }
                    break;
                }
                this.state = 1387;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                while (_la === 480) {
                    {
                    {
                    this.state = 1380;
                    this.match(SparkSQLParser.COMMA);
                    this.state = 1383;
                    this.errorHandler.sync(this);
                    switch (this.interpreter.adaptivePredict(this.tokenStream, 137, this.context) ) {
                    case 1:
                        {
                        this.state = 1381;
                        this.funtionBody();
                        }
                        break;
                    case 2:
                        {
                        this.state = 1382;
                        this.functionParam();
                        }
                        break;
                    }
                    }
                    }
                    this.state = 1389;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                }
                this.state = 1390;
                this.match(SparkSQLParser.RR_BRACKET);
                this.state = 1391;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 1392;
                this.match(SparkSQLParser.KW_AS);
                this.state = 1393;
                this.tableAlias();
                this.state = 1394;
                this.match(SparkSQLParser.RR_BRACKET);
                this.state = 1395;
                this.projectItemDefinition();
                this.state = 1400;
                this.errorHandler.sync(this);
                alternative = this.interpreter.adaptivePredict(this.tokenStream, 139, this.context);
                while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {
                    if (alternative === 1) {
                        {
                        {
                        this.state = 1396;
                        this.match(SparkSQLParser.COMMA);
                        this.state = 1397;
                        this.projectItemDefinition();
                        }
                        }
                    }
                    this.state = 1402;
                    this.errorHandler.sync(this);
                    alternative = this.interpreter.adaptivePredict(this.tokenStream, 139, this.context);
                }
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public unpivotBody(): UnpivotBodyContext {
        let localContext = new UnpivotBodyContext(this.context, this.state);
        this.enterRule(localContext, 146, SparkSQLParser.RULE_unpivotBody);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1407;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 141, this.context) ) {
            case 1:
                {
                this.state = 1405;
                this.columnName();
                }
                break;
            case 2:
                {
                this.state = 1406;
                this.columnNameList();
                }
                break;
            }
            this.state = 1409;
            this.match(SparkSQLParser.KW_FOR);
            this.state = 1410;
            this.columnName();
            this.state = 1411;
            this.match(SparkSQLParser.KW_IN);
            this.state = 1412;
            this.expressionAsAliasList();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public pivotBody(): PivotBodyContext {
        let localContext = new PivotBodyContext(this.context, this.state);
        this.enterRule(localContext, 148, SparkSQLParser.RULE_pivotBody);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1414;
            this.expressionAsAlias();
            {
            this.state = 1415;
            this.match(SparkSQLParser.COMMA);
            this.state = 1416;
            this.expressionAsAlias();
            }
            this.state = 1418;
            this.match(SparkSQLParser.KW_FOR);
            this.state = 1421;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 142, this.context) ) {
            case 1:
                {
                this.state = 1419;
                this.columnName();
                }
                break;
            case 2:
                {
                this.state = 1420;
                this.columnNameList();
                }
                break;
            }
            this.state = 1423;
            this.match(SparkSQLParser.KW_IN);
            this.state = 1424;
            this.expressionAsAliasList();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public expressionAsAlias(): ExpressionAsAliasContext {
        let localContext = new ExpressionAsAliasContext(this.context, this.state);
        this.enterRule(localContext, 150, SparkSQLParser.RULE_expressionAsAlias);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1426;
            this.expression();
            this.state = 1429;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 212) {
                {
                this.state = 1427;
                this.match(SparkSQLParser.KW_AS);
                this.state = 1428;
                this.columnAlias();
                }
            }

            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public expressionAsAliasList(): ExpressionAsAliasListContext {
        let localContext = new ExpressionAsAliasListContext(this.context, this.state);
        this.enterRule(localContext, 152, SparkSQLParser.RULE_expressionAsAliasList);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1431;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 1432;
            this.expressionAsAlias();
            this.state = 1437;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 480) {
                {
                {
                this.state = 1433;
                this.match(SparkSQLParser.COMMA);
                this.state = 1434;
                this.expressionAsAlias();
                }
                }
                this.state = 1439;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 1440;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public systemTimePeriod(): SystemTimePeriodContext {
        let localContext = new SystemTimePeriodContext(this.context, this.state);
        this.enterRule(localContext, 154, SparkSQLParser.RULE_systemTimePeriod);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1442;
            this.match(SparkSQLParser.KW_FOR);
            this.state = 1443;
            this.match(SparkSQLParser.KW_SYSTEM_TIME);
            this.state = 1444;
            this.match(SparkSQLParser.KW_AS);
            this.state = 1445;
            this.match(SparkSQLParser.KW_OF);
            this.state = 1446;
            this.dateTimeExpression();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public dateTimeExpression(): DateTimeExpressionContext {
        let localContext = new DateTimeExpressionContext(this.context, this.state);
        this.enterRule(localContext, 156, SparkSQLParser.RULE_dateTimeExpression);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1448;
            this.expression();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public inlineDataValueClause(): InlineDataValueClauseContext {
        let localContext = new InlineDataValueClauseContext(this.context, this.state);
        this.enterRule(localContext, 158, SparkSQLParser.RULE_inlineDataValueClause);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1450;
            this.expression();
            this.state = 1455;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 480) {
                {
                {
                this.state = 1451;
                this.match(SparkSQLParser.COMMA);
                this.state = 1452;
                this.expression();
                }
                }
                this.state = 1457;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 1459;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if ((((_la) & ~0x1F) === 0 && ((1 << _la) & 4294684608) !== 0) || ((((_la - 32)) & ~0x1F) === 0 && ((1 << (_la - 32)) & 4293654523) !== 0) || ((((_la - 64)) & ~0x1F) === 0 && ((1 << (_la - 64)) & 4185849791) !== 0) || ((((_la - 96)) & ~0x1F) === 0 && ((1 << (_la - 96)) & 4294967263) !== 0) || ((((_la - 128)) & ~0x1F) === 0 && ((1 << (_la - 128)) & 3757047707) !== 0) || ((((_la - 160)) & ~0x1F) === 0 && ((1 << (_la - 160)) & 4252958679) !== 0) || ((((_la - 192)) & ~0x1F) === 0 && ((1 << (_la - 192)) & 1052543) !== 0) || _la === 338 || ((((_la - 483)) & ~0x1F) === 0 && ((1 << (_la - 483)) & 360449) !== 0)) {
                {
                this.state = 1458;
                this.tableAlias();
                }
            }

            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public windowTVFClause(): WindowTVFClauseContext {
        let localContext = new WindowTVFClauseContext(this.context, this.state);
        this.enterRule(localContext, 160, SparkSQLParser.RULE_windowTVFClause);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1461;
            this.match(SparkSQLParser.KW_TABLE);
            this.state = 1462;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 1463;
            this.windowTVFExpression();
            this.state = 1464;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public windowTVFExpression(): WindowTVFExpressionContext {
        let localContext = new WindowTVFExpressionContext(this.context, this.state);
        this.enterRule(localContext, 162, SparkSQLParser.RULE_windowTVFExpression);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1466;
            this.windowTVFName();
            this.state = 1467;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 1468;
            this.windowTVFParam();
            this.state = 1473;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 480) {
                {
                {
                this.state = 1469;
                this.match(SparkSQLParser.COMMA);
                this.state = 1470;
                this.windowTVFParam();
                }
                }
                this.state = 1475;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 1476;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public windowTVFName(): WindowTVFNameContext {
        let localContext = new WindowTVFNameContext(this.context, this.state);
        this.enterRule(localContext, 164, SparkSQLParser.RULE_windowTVFName);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1478;
            _la = this.tokenStream.LA(1);
            if(!(_la === 29 || _la === 66 || _la === 181)) {
            this.errorHandler.recoverInline(this);
            }
            else {
                this.errorHandler.reportMatch(this);
                this.consume();
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public rowFormatDelimited(): RowFormatDelimitedContext {
        let localContext = new RowFormatDelimitedContext(this.context, this.state);
        this.enterRule(localContext, 166, SparkSQLParser.RULE_rowFormatDelimited);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1480;
            this.sparkRecordWriterPart();
            this.state = 1481;
            this.usingAsColumnPart();
            this.state = 1482;
            this.sparkRecordWriterPart();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public hiveSerde(): HiveSerdeContext {
        let localContext = new HiveSerdeContext(this.context, this.state);
        this.enterRule(localContext, 168, SparkSQLParser.RULE_hiveSerde);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1484;
            this.hiveSerdePart();
            this.state = 1485;
            this.usingAsColumnPart();
            this.state = 1486;
            this.hiveSerdePart();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public usingAsColumnPart(): UsingAsColumnPartContext {
        let localContext = new UsingAsColumnPartContext(this.context, this.state);
        this.enterRule(localContext, 170, SparkSQLParser.RULE_usingAsColumnPart);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1488;
            this.match(SparkSQLParser.KW_USING);
            this.state = 1489;
            this.stringLiteral();
            this.state = 1490;
            this.match(SparkSQLParser.KW_AS);
            {
            this.state = 1493;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 148, this.context) ) {
            case 1:
                {
                this.state = 1491;
                this.columnNameList();
                }
                break;
            case 2:
                {
                this.state = 1492;
                this.physicalColumnDefinitionList();
                }
                break;
            }
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public hiveSerdePart(): HiveSerdePartContext {
        let localContext = new HiveSerdePartContext(this.context, this.state);
        this.enterRule(localContext, 172, SparkSQLParser.RULE_hiveSerdePart);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1499;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 398) {
                {
                this.state = 1495;
                this.match(SparkSQLParser.KW_ROW);
                this.state = 1496;
                this.match(SparkSQLParser.KW_FORMAT);
                this.state = 1497;
                this.match(SparkSQLParser.KW_SERDE);
                this.state = 1498;
                this.stringLiteral();
                }
            }

            this.state = 1504;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 453) {
                {
                this.state = 1501;
                this.match(SparkSQLParser.KW_WITH);
                this.state = 1502;
                this.match(SparkSQLParser.KW_SERDEPROPERTIES);
                this.state = 1503;
                this.tableCanHasKeyPropertyList();
                }
            }

            this.state = 1508;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 387) {
                {
                this.state = 1506;
                this.match(SparkSQLParser.KW_RECORDWRITER);
                this.state = 1507;
                this.stringLiteral();
                }
            }

            this.state = 1511;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 294) {
                {
                this.state = 1510;
                this.fieldsTerminatedBy();
                }
            }

            this.state = 1515;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 134) {
                {
                this.state = 1513;
                this.match(SparkSQLParser.KW_RECORDREADER);
                this.state = 1514;
                this.stringLiteral();
                }
            }

            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public tableCanHasKeyPropertyList(): TableCanHasKeyPropertyListContext {
        let localContext = new TableCanHasKeyPropertyListContext(this.context, this.state);
        this.enterRule(localContext, 174, SparkSQLParser.RULE_tableCanHasKeyPropertyList);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1517;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 1520;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 154, this.context) ) {
            case 1:
                {
                this.state = 1518;
                this.tableProperty();
                }
                break;
            case 2:
                {
                this.state = 1519;
                this.tablePropertyKey();
                }
                break;
            }
            this.state = 1529;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 480) {
                {
                {
                this.state = 1522;
                this.match(SparkSQLParser.COMMA);
                this.state = 1525;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 155, this.context) ) {
                case 1:
                    {
                    this.state = 1523;
                    this.tableProperty();
                    }
                    break;
                case 2:
                    {
                    this.state = 1524;
                    this.tablePropertyKey();
                    }
                    break;
                }
                }
                }
                this.state = 1531;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 1532;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public sparkRecordWriterPart(): SparkRecordWriterPartContext {
        let localContext = new SparkRecordWriterPartContext(this.context, this.state);
        this.enterRule(localContext, 176, SparkSQLParser.RULE_sparkRecordWriterPart);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1535;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 157, this.context) ) {
            case 1:
                {
                this.state = 1534;
                this.rowFormatDelimted();
                }
                break;
            }
            this.state = 1538;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 158, this.context) ) {
            case 1:
                {
                this.state = 1537;
                this.fieldsTerminatedBy();
                }
                break;
            }
            this.state = 1544;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 159, this.context) ) {
            case 1:
                {
                this.state = 1540;
                this.match(SparkSQLParser.KW_LINES);
                this.state = 1541;
                this.match(SparkSQLParser.KW_TERMINATED);
                this.state = 1542;
                this.match(SparkSQLParser.KW_BY);
                this.state = 1543;
                this.stringLiteral();
                }
                break;
            }
            this.state = 1550;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 160, this.context) ) {
            case 1:
                {
                this.state = 1546;
                this.match(SparkSQLParser.KW_NULL);
                this.state = 1547;
                this.match(SparkSQLParser.KW_DEFINED);
                this.state = 1548;
                this.match(SparkSQLParser.KW_AS);
                this.state = 1549;
                this.stringLiteral();
                }
                break;
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public windowTVFParam(): WindowTVFParamContext {
        let localContext = new WindowTVFParamContext(this.context, this.state);
        this.enterRule(localContext, 178, SparkSQLParser.RULE_windowTVFParam);
        try {
            this.state = 1567;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 161, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 1552;
                this.match(SparkSQLParser.KW_TABLE);
                this.state = 1553;
                this.timeAttrColumn();
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 1554;
                this.columnDescriptor();
                }
                break;
            case 3:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 1555;
                this.timeIntervalExpression();
                }
                break;
            case 4:
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 1556;
                this.match(SparkSQLParser.KW_DATA);
                this.state = 1557;
                this.match(SparkSQLParser.DOUBLE_RIGHT_ARROW);
                this.state = 1558;
                this.match(SparkSQLParser.KW_TABLE);
                this.state = 1559;
                this.timeAttrColumn();
                }
                break;
            case 5:
                this.enterOuterAlt(localContext, 5);
                {
                this.state = 1560;
                this.match(SparkSQLParser.KW_TIMECOL);
                this.state = 1561;
                this.match(SparkSQLParser.DOUBLE_RIGHT_ARROW);
                this.state = 1562;
                this.columnDescriptor();
                }
                break;
            case 6:
                this.enterOuterAlt(localContext, 6);
                {
                this.state = 1563;
                this.timeIntervalParamName();
                this.state = 1564;
                this.match(SparkSQLParser.DOUBLE_RIGHT_ARROW);
                this.state = 1565;
                this.timeIntervalExpression();
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public timeIntervalParamName(): TimeIntervalParamNameContext {
        let localContext = new TimeIntervalParamNameContext(this.context, this.state);
        this.enterRule(localContext, 180, SparkSQLParser.RULE_timeIntervalParamName);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1569;
            _la = this.tokenStream.LA(1);
            if(!(_la === 30 || ((((_la - 159)) & ~0x1F) === 0 && ((1 << (_la - 159)) & 16643) !== 0) || _la === 360)) {
            this.errorHandler.recoverInline(this);
            }
            else {
                this.errorHandler.reportMatch(this);
                this.consume();
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public columnDescriptor(): ColumnDescriptorContext {
        let localContext = new ColumnDescriptorContext(this.context, this.state);
        this.enterRule(localContext, 182, SparkSQLParser.RULE_columnDescriptor);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1571;
            this.match(SparkSQLParser.KW_DESCRIPTOR);
            this.state = 1572;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 1573;
            this.uid();
            this.state = 1574;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public joinCondition(): JoinConditionContext {
        let localContext = new JoinConditionContext(this.context, this.state);
        this.enterRule(localContext, 184, SparkSQLParser.RULE_joinCondition);
        let _la: number;
        try {
            this.state = 1590;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.KW_ON:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 1576;
                this.match(SparkSQLParser.KW_ON);
                this.state = 1577;
                this.booleanExpression(0);
                }
                break;
            case SparkSQLParser.KW_USING:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 1578;
                this.match(SparkSQLParser.KW_USING);
                this.state = 1579;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 1580;
                this.uid();
                this.state = 1585;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                while (_la === 480) {
                    {
                    {
                    this.state = 1581;
                    this.match(SparkSQLParser.COMMA);
                    this.state = 1582;
                    this.uid();
                    }
                    }
                    this.state = 1587;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                }
                this.state = 1588;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public whereClause(): WhereClauseContext {
        let localContext = new WhereClauseContext(this.context, this.state);
        this.enterRule(localContext, 186, SparkSQLParser.RULE_whereClause);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1592;
            this.match(SparkSQLParser.KW_WHERE);
            this.state = 1593;
            this.booleanExpression(0);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public samplingQueries(): SamplingQueriesContext {
        let localContext = new SamplingQueriesContext(this.context, this.state);
        this.enterRule(localContext, 188, SparkSQLParser.RULE_samplingQueries);
        try {
            this.state = 1626;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 168, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 1595;
                this.match(SparkSQLParser.KW_TABLESAMPLE);
                this.state = 1596;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 1600;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 164, this.context) ) {
                case 1:
                    {
                    this.state = 1597;
                    this.decimalLiteral();
                    }
                    break;
                case 2:
                    {
                    this.state = 1598;
                    this.match(SparkSQLParser.DIG_LITERAL);
                    }
                    break;
                case 3:
                    {
                    this.state = 1599;
                    this.expression();
                    }
                    break;
                }
                this.state = 1602;
                this.match(SparkSQLParser.KW_PERCENT);
                this.state = 1603;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 1604;
                this.match(SparkSQLParser.KW_TABLESAMPLE);
                this.state = 1605;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 1608;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 165, this.context) ) {
                case 1:
                    {
                    this.state = 1606;
                    this.match(SparkSQLParser.DIG_LITERAL);
                    }
                    break;
                case 2:
                    {
                    this.state = 1607;
                    this.expression();
                    }
                    break;
                }
                this.state = 1610;
                this.match(SparkSQLParser.KW_ROWS);
                this.state = 1611;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case 3:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 1612;
                this.match(SparkSQLParser.KW_TABLESAMPLE);
                this.state = 1613;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 1614;
                this.match(SparkSQLParser.KW_BUCKET);
                this.state = 1617;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 166, this.context) ) {
                case 1:
                    {
                    this.state = 1615;
                    this.match(SparkSQLParser.DIG_LITERAL);
                    }
                    break;
                case 2:
                    {
                    this.state = 1616;
                    this.expression();
                    }
                    break;
                }
                this.state = 1619;
                this.match(SparkSQLParser.KW_OUT);
                this.state = 1620;
                this.match(SparkSQLParser.KW_OF);
                this.state = 1623;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 167, this.context) ) {
                case 1:
                    {
                    this.state = 1621;
                    this.match(SparkSQLParser.DIG_LITERAL);
                    }
                    break;
                case 2:
                    {
                    this.state = 1622;
                    this.expression();
                    }
                    break;
                }
                this.state = 1625;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public someByClause(): SomeByClauseContext {
        let localContext = new SomeByClauseContext(this.context, this.state);
        this.enterRule(localContext, 190, SparkSQLParser.RULE_someByClause);
        try {
            this.state = 1632;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.KW_CLUSTERED:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 1628;
                this.clusteredByClause();
                }
                break;
            case SparkSQLParser.KW_CLUSTER:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 1629;
                this.clusterByClause();
                }
                break;
            case SparkSQLParser.KW_DISTRIBUTE:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 1630;
                this.distributeByClause();
                }
                break;
            case SparkSQLParser.KW_GROUP:
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 1631;
                this.groupByClause();
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public clusterByClause(): ClusterByClauseContext {
        let localContext = new ClusterByClauseContext(this.context, this.state);
        this.enterRule(localContext, 192, SparkSQLParser.RULE_clusterByClause);
        try {
            let alternative: number;
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1634;
            this.match(SparkSQLParser.KW_CLUSTER);
            this.state = 1635;
            this.match(SparkSQLParser.KW_BY);
            this.state = 1636;
            this.groupItemDefinition();
            this.state = 1641;
            this.errorHandler.sync(this);
            alternative = this.interpreter.adaptivePredict(this.tokenStream, 170, this.context);
            while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {
                if (alternative === 1) {
                    {
                    {
                    this.state = 1637;
                    this.match(SparkSQLParser.COMMA);
                    this.state = 1638;
                    this.groupItemDefinition();
                    }
                    }
                }
                this.state = 1643;
                this.errorHandler.sync(this);
                alternative = this.interpreter.adaptivePredict(this.tokenStream, 170, this.context);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public clusteredByClause(): ClusteredByClauseContext {
        let localContext = new ClusteredByClauseContext(this.context, this.state);
        this.enterRule(localContext, 194, SparkSQLParser.RULE_clusteredByClause);
        try {
            let alternative: number;
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1644;
            this.match(SparkSQLParser.KW_CLUSTERED);
            this.state = 1645;
            this.match(SparkSQLParser.KW_BY);
            this.state = 1646;
            this.groupItemDefinition();
            this.state = 1651;
            this.errorHandler.sync(this);
            alternative = this.interpreter.adaptivePredict(this.tokenStream, 171, this.context);
            while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {
                if (alternative === 1) {
                    {
                    {
                    this.state = 1647;
                    this.match(SparkSQLParser.COMMA);
                    this.state = 1648;
                    this.groupItemDefinition();
                    }
                    }
                }
                this.state = 1653;
                this.errorHandler.sync(this);
                alternative = this.interpreter.adaptivePredict(this.tokenStream, 171, this.context);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public distributeByClause(): DistributeByClauseContext {
        let localContext = new DistributeByClauseContext(this.context, this.state);
        this.enterRule(localContext, 196, SparkSQLParser.RULE_distributeByClause);
        try {
            let alternative: number;
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1654;
            this.match(SparkSQLParser.KW_DISTRIBUTE);
            this.state = 1655;
            this.match(SparkSQLParser.KW_BY);
            this.state = 1656;
            this.groupItemDefinition();
            this.state = 1661;
            this.errorHandler.sync(this);
            alternative = this.interpreter.adaptivePredict(this.tokenStream, 172, this.context);
            while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {
                if (alternative === 1) {
                    {
                    {
                    this.state = 1657;
                    this.match(SparkSQLParser.COMMA);
                    this.state = 1658;
                    this.groupItemDefinition();
                    }
                    }
                }
                this.state = 1663;
                this.errorHandler.sync(this);
                alternative = this.interpreter.adaptivePredict(this.tokenStream, 172, this.context);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public groupByClause(): GroupByClauseContext {
        let localContext = new GroupByClauseContext(this.context, this.state);
        this.enterRule(localContext, 198, SparkSQLParser.RULE_groupByClause);
        try {
            let alternative: number;
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1664;
            this.match(SparkSQLParser.KW_GROUP);
            this.state = 1665;
            this.match(SparkSQLParser.KW_BY);
            {
            this.state = 1667;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 173, this.context) ) {
            case 1:
                {
                this.state = 1666;
                this.groupItemDefinition();
                }
                break;
            }
            this.state = 1673;
            this.errorHandler.sync(this);
            alternative = this.interpreter.adaptivePredict(this.tokenStream, 174, this.context);
            while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {
                if (alternative === 1) {
                    {
                    {
                    this.state = 1669;
                    this.match(SparkSQLParser.COMMA);
                    this.state = 1670;
                    this.groupItemDefinition();
                    }
                    }
                }
                this.state = 1675;
                this.errorHandler.sync(this);
                alternative = this.interpreter.adaptivePredict(this.tokenStream, 174, this.context);
            }
            }
            this.state = 1677;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 175, this.context) ) {
            case 1:
                {
                this.state = 1676;
                this.groupingSet();
                }
                break;
            }
            this.state = 1681;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 176, this.context) ) {
            case 1:
                {
                this.state = 1679;
                this.match(SparkSQLParser.KW_WITH);
                this.state = 1680;
                this.groupingSetsNotionName();
                }
                break;
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public groupItemDefinition(): GroupItemDefinitionContext {
        let localContext = new GroupItemDefinitionContext(this.context, this.state);
        this.enterRule(localContext, 200, SparkSQLParser.RULE_groupItemDefinition);
        let _la: number;
        try {
            let alternative: number;
            this.state = 1717;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 180, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 1683;
                this.expression();
                this.state = 1688;
                this.errorHandler.sync(this);
                alternative = this.interpreter.adaptivePredict(this.tokenStream, 177, this.context);
                while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {
                    if (alternative === 1) {
                        {
                        {
                        this.state = 1684;
                        this.match(SparkSQLParser.COMMA);
                        this.state = 1685;
                        this.expression();
                        }
                        }
                    }
                    this.state = 1690;
                    this.errorHandler.sync(this);
                    alternative = this.interpreter.adaptivePredict(this.tokenStream, 177, this.context);
                }
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 1691;
                this.groupWindowFunction();
                }
                break;
            case 3:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 1692;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 1693;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case 4:
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 1694;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 1695;
                this.expression();
                this.state = 1700;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                while (_la === 480) {
                    {
                    {
                    this.state = 1696;
                    this.match(SparkSQLParser.COMMA);
                    this.state = 1697;
                    this.expression();
                    }
                    }
                    this.state = 1702;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                }
                this.state = 1703;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case 5:
                this.enterOuterAlt(localContext, 5);
                {
                this.state = 1705;
                this.groupingSetsNotionName();
                this.state = 1706;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 1707;
                this.expression();
                this.state = 1712;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                while (_la === 480) {
                    {
                    {
                    this.state = 1708;
                    this.match(SparkSQLParser.COMMA);
                    this.state = 1709;
                    this.expression();
                    }
                    }
                    this.state = 1714;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                }
                this.state = 1715;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public groupingSet(): GroupingSetContext {
        let localContext = new GroupingSetContext(this.context, this.state);
        this.enterRule(localContext, 202, SparkSQLParser.RULE_groupingSet);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1719;
            this.groupingSets();
            this.state = 1720;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 1721;
            this.groupItemDefinition();
            this.state = 1726;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 480) {
                {
                {
                this.state = 1722;
                this.match(SparkSQLParser.COMMA);
                this.state = 1723;
                this.groupItemDefinition();
                }
                }
                this.state = 1728;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 1729;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public groupingSets(): GroupingSetsContext {
        let localContext = new GroupingSetsContext(this.context, this.state);
        this.enterRule(localContext, 204, SparkSQLParser.RULE_groupingSets);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1731;
            this.match(SparkSQLParser.KW_GROUPING);
            this.state = 1732;
            this.match(SparkSQLParser.KW_SETS);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public groupingSetsNotionName(): GroupingSetsNotionNameContext {
        let localContext = new GroupingSetsNotionNameContext(this.context, this.state);
        this.enterRule(localContext, 206, SparkSQLParser.RULE_groupingSetsNotionName);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1734;
            _la = this.tokenStream.LA(1);
            if(!(_la === 253 || _la === 397)) {
            this.errorHandler.recoverInline(this);
            }
            else {
                this.errorHandler.reportMatch(this);
                this.consume();
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public groupWindowFunction(): GroupWindowFunctionContext {
        let localContext = new GroupWindowFunctionContext(this.context, this.state);
        this.enterRule(localContext, 208, SparkSQLParser.RULE_groupWindowFunction);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1736;
            this.groupWindowFunctionName();
            this.state = 1737;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 1738;
            this.timeAttrColumn();
            this.state = 1739;
            this.match(SparkSQLParser.COMMA);
            this.state = 1740;
            this.timeIntervalExpression();
            this.state = 1741;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public groupWindowFunctionName(): GroupWindowFunctionNameContext {
        let localContext = new GroupWindowFunctionNameContext(this.context, this.state);
        this.enterRule(localContext, 210, SparkSQLParser.RULE_groupWindowFunctionName);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1743;
            _la = this.tokenStream.LA(1);
            if(!(_la === 66 || _la === 155 || _la === 181)) {
            this.errorHandler.recoverInline(this);
            }
            else {
                this.errorHandler.reportMatch(this);
                this.consume();
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public timeAttrColumn(): TimeAttrColumnContext {
        let localContext = new TimeAttrColumnContext(this.context, this.state);
        this.enterRule(localContext, 212, SparkSQLParser.RULE_timeAttrColumn);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1745;
            this.uid();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public havingClause(): HavingClauseContext {
        let localContext = new HavingClauseContext(this.context, this.state);
        this.enterRule(localContext, 214, SparkSQLParser.RULE_havingClause);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1747;
            this.match(SparkSQLParser.KW_HAVING);
            this.state = 1748;
            this.booleanExpression(0);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public windowClause(): WindowClauseContext {
        let localContext = new WindowClauseContext(this.context, this.state);
        this.enterRule(localContext, 216, SparkSQLParser.RULE_windowClause);
        try {
            let alternative: number;
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1750;
            this.match(SparkSQLParser.KW_WINDOW);
            this.state = 1751;
            this.namedWindow();
            this.state = 1756;
            this.errorHandler.sync(this);
            alternative = this.interpreter.adaptivePredict(this.tokenStream, 182, this.context);
            while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {
                if (alternative === 1) {
                    {
                    {
                    this.state = 1752;
                    this.match(SparkSQLParser.COMMA);
                    this.state = 1753;
                    this.namedWindow();
                    }
                    }
                }
                this.state = 1758;
                this.errorHandler.sync(this);
                alternative = this.interpreter.adaptivePredict(this.tokenStream, 182, this.context);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public namedWindow(): NamedWindowContext {
        let localContext = new NamedWindowContext(this.context, this.state);
        this.enterRule(localContext, 218, SparkSQLParser.RULE_namedWindow);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1759;
            localContext._name = this.errorCapturingIdentifier();
            this.state = 1760;
            this.match(SparkSQLParser.KW_AS);
            this.state = 1761;
            this.windowSpec();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public windowSpec(): WindowSpecContext {
        let localContext = new WindowSpecContext(this.context, this.state);
        this.enterRule(localContext, 220, SparkSQLParser.RULE_windowSpec);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1764;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if ((((_la) & ~0x1F) === 0 && ((1 << _la) & 4294684608) !== 0) || ((((_la - 32)) & ~0x1F) === 0 && ((1 << (_la - 32)) & 4293654523) !== 0) || ((((_la - 64)) & ~0x1F) === 0 && ((1 << (_la - 64)) & 4185849791) !== 0) || ((((_la - 96)) & ~0x1F) === 0 && ((1 << (_la - 96)) & 4294967263) !== 0) || ((((_la - 128)) & ~0x1F) === 0 && ((1 << (_la - 128)) & 3757047707) !== 0) || ((((_la - 160)) & ~0x1F) === 0 && ((1 << (_la - 160)) & 4252958679) !== 0) || ((((_la - 192)) & ~0x1F) === 0 && ((1 << (_la - 192)) & 3967) !== 0) || _la === 338 || ((((_la - 483)) & ~0x1F) === 0 && ((1 << (_la - 483)) & 360449) !== 0)) {
                {
                this.state = 1763;
                localContext._name = this.errorCapturingIdentifier();
                }
            }

            this.state = 1766;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 1768;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 371) {
                {
                this.state = 1767;
                this.partitionByClause();
                }
            }

            this.state = 1771;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 415) {
                {
                this.state = 1770;
                this.sortByCaluse();
                }
            }

            this.state = 1774;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 364) {
                {
                this.state = 1773;
                this.orderByCaluse();
                }
            }

            this.state = 1777;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 386 || _la === 399) {
                {
                this.state = 1776;
                this.windowFrame();
                }
            }

            this.state = 1779;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public matchRecognizeClause(): MatchRecognizeClauseContext {
        let localContext = new MatchRecognizeClauseContext(this.context, this.state);
        this.enterRule(localContext, 222, SparkSQLParser.RULE_matchRecognizeClause);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1781;
            this.match(SparkSQLParser.KW_MATCH_RECOGNIZE);
            this.state = 1782;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 1784;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 371) {
                {
                this.state = 1783;
                this.partitionByClause();
                }
            }

            this.state = 1787;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 415) {
                {
                this.state = 1786;
                this.sortByCaluse();
                }
            }

            this.state = 1790;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 364) {
                {
                this.state = 1789;
                this.orderByCaluse();
                }
            }

            this.state = 1793;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 341) {
                {
                this.state = 1792;
                this.measuresClause();
                }
            }

            this.state = 1796;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 205 || _la === 362) {
                {
                this.state = 1795;
                this.outputMode();
                }
            }

            this.state = 1799;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 8) {
                {
                this.state = 1798;
                this.afterMatchStrategy();
                }
            }

            this.state = 1802;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 372) {
                {
                this.state = 1801;
                this.patternDefinition();
                }
            }

            this.state = 1804;
            this.patternVariablesDefinition();
            this.state = 1805;
            this.match(SparkSQLParser.RR_BRACKET);
            this.state = 1810;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 196, this.context) ) {
            case 1:
                {
                this.state = 1807;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 212) {
                    {
                    this.state = 1806;
                    this.match(SparkSQLParser.KW_AS);
                    }
                }

                this.state = 1809;
                this.identifier();
                }
                break;
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public orderByCaluse(): OrderByCaluseContext {
        let localContext = new OrderByCaluseContext(this.context, this.state);
        this.enterRule(localContext, 224, SparkSQLParser.RULE_orderByCaluse);
        try {
            let alternative: number;
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1812;
            this.match(SparkSQLParser.KW_ORDER);
            this.state = 1813;
            this.match(SparkSQLParser.KW_BY);
            this.state = 1814;
            this.orderItemDefinition();
            this.state = 1819;
            this.errorHandler.sync(this);
            alternative = this.interpreter.adaptivePredict(this.tokenStream, 197, this.context);
            while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {
                if (alternative === 1) {
                    {
                    {
                    this.state = 1815;
                    this.match(SparkSQLParser.COMMA);
                    this.state = 1816;
                    this.orderItemDefinition();
                    }
                    }
                }
                this.state = 1821;
                this.errorHandler.sync(this);
                alternative = this.interpreter.adaptivePredict(this.tokenStream, 197, this.context);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public sortByCaluse(): SortByCaluseContext {
        let localContext = new SortByCaluseContext(this.context, this.state);
        this.enterRule(localContext, 226, SparkSQLParser.RULE_sortByCaluse);
        try {
            let alternative: number;
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1822;
            this.match(SparkSQLParser.KW_SORT);
            this.state = 1823;
            this.match(SparkSQLParser.KW_BY);
            this.state = 1824;
            this.orderItemDefinition();
            this.state = 1829;
            this.errorHandler.sync(this);
            alternative = this.interpreter.adaptivePredict(this.tokenStream, 198, this.context);
            while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {
                if (alternative === 1) {
                    {
                    {
                    this.state = 1825;
                    this.match(SparkSQLParser.COMMA);
                    this.state = 1826;
                    this.orderItemDefinition();
                    }
                    }
                }
                this.state = 1831;
                this.errorHandler.sync(this);
                alternative = this.interpreter.adaptivePredict(this.tokenStream, 198, this.context);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public orderItemDefinition(): OrderItemDefinitionContext {
        let localContext = new OrderItemDefinitionContext(this.context, this.state);
        this.enterRule(localContext, 228, SparkSQLParser.RULE_orderItemDefinition);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1832;
            this.expression();
            this.state = 1834;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 199, this.context) ) {
            case 1:
                {
                this.state = 1833;
                localContext._ordering = this.tokenStream.LT(1);
                _la = this.tokenStream.LA(1);
                if(!(_la === 10 || _la === 37)) {
                    localContext._ordering = this.errorHandler.recoverInline(this);
                }
                else {
                    this.errorHandler.reportMatch(this);
                    this.consume();
                }
                }
                break;
            }
            this.state = 1838;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 200, this.context) ) {
            case 1:
                {
                this.state = 1836;
                this.match(SparkSQLParser.KW_NULLS);
                this.state = 1837;
                localContext._nullOrder = this.tokenStream.LT(1);
                _la = this.tokenStream.LA(1);
                if(!(_la === 54 || _la === 84)) {
                    localContext._nullOrder = this.errorHandler.recoverInline(this);
                }
                else {
                    this.errorHandler.reportMatch(this);
                    this.consume();
                }
                }
                break;
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public limitClause(): LimitClauseContext {
        let localContext = new LimitClauseContext(this.context, this.state);
        this.enterRule(localContext, 230, SparkSQLParser.RULE_limitClause);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1840;
            this.match(SparkSQLParser.KW_LIMIT);
            this.state = 1843;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.KW_ALL:
                {
                this.state = 1841;
                this.match(SparkSQLParser.KW_ALL);
                }
                break;
            case SparkSQLParser.KW_ADD:
            case SparkSQLParser.KW_ADMIN:
            case SparkSQLParser.KW_AFTER:
            case SparkSQLParser.KW_ANALYZE:
            case SparkSQLParser.KW_ASC:
            case SparkSQLParser.KW_BEFORE:
            case SparkSQLParser.KW_BYTES:
            case SparkSQLParser.KW_CASCADE:
            case SparkSQLParser.KW_CATALOG:
            case SparkSQLParser.KW_CATALOGS:
            case SparkSQLParser.KW_CENTURY:
            case SparkSQLParser.KW_CHAIN:
            case SparkSQLParser.KW_CHANGELOG_MODE:
            case SparkSQLParser.KW_CHARACTERS:
            case SparkSQLParser.KW_COMMENT:
            case SparkSQLParser.KW_COMPACT:
            case SparkSQLParser.KW_COLUMNS:
            case SparkSQLParser.KW_CONSTRAINTS:
            case SparkSQLParser.KW_CONSTRUCTOR:
            case SparkSQLParser.KW_COMPUTE:
            case SparkSQLParser.KW_CUMULATE:
            case SparkSQLParser.KW_DATA:
            case SparkSQLParser.KW_DATABASE:
            case SparkSQLParser.KW_DATABASES:
            case SparkSQLParser.KW_DAYS:
            case SparkSQLParser.KW_DECADE:
            case SparkSQLParser.KW_DEFINED:
            case SparkSQLParser.KW_DESC:
            case SparkSQLParser.KW_DESCRIPTOR:
            case SparkSQLParser.KW_DIV:
            case SparkSQLParser.KW_ENCODING:
            case SparkSQLParser.KW_ENFORCED:
            case SparkSQLParser.KW_ENGINE:
            case SparkSQLParser.KW_ERROR:
            case SparkSQLParser.KW_ESTIMATED_COST:
            case SparkSQLParser.KW_EXCEPTION:
            case SparkSQLParser.KW_EXCLUDE:
            case SparkSQLParser.KW_EXCLUDING:
            case SparkSQLParser.KW_EXTENDED:
            case SparkSQLParser.KW_FILE:
            case SparkSQLParser.KW_FINAL:
            case SparkSQLParser.KW_FIRST:
            case SparkSQLParser.KW_FOLLOWING:
            case SparkSQLParser.KW_FORMAT:
            case SparkSQLParser.KW_FORTRAN:
            case SparkSQLParser.KW_FOUND:
            case SparkSQLParser.KW_FRAC_SECOND:
            case SparkSQLParser.KW_FUNCTIONS:
            case SparkSQLParser.KW_GENERAL:
            case SparkSQLParser.KW_GENERATED:
            case SparkSQLParser.KW_GO:
            case SparkSQLParser.KW_GOTO:
            case SparkSQLParser.KW_GRANTED:
            case SparkSQLParser.KW_HOP:
            case SparkSQLParser.KW_HOURS:
            case SparkSQLParser.KW_IF:
            case SparkSQLParser.KW_IGNORE:
            case SparkSQLParser.KW_INCREMENT:
            case SparkSQLParser.KW_INPUT:
            case SparkSQLParser.KW_INVOKER:
            case SparkSQLParser.KW_JAR:
            case SparkSQLParser.KW_JARS:
            case SparkSQLParser.KW_JAVA:
            case SparkSQLParser.KW_JSON:
            case SparkSQLParser.KW_JSON_EXECUTION_PLAN:
            case SparkSQLParser.KW_KEY:
            case SparkSQLParser.KW_KEY_MEMBER:
            case SparkSQLParser.KW_KEY_TYPE:
            case SparkSQLParser.KW_LABEL:
            case SparkSQLParser.KW_LAST:
            case SparkSQLParser.KW_LENGTH:
            case SparkSQLParser.KW_LEVEL:
            case SparkSQLParser.KW_LOAD:
            case SparkSQLParser.KW_MAP:
            case SparkSQLParser.KW_MICROSECOND:
            case SparkSQLParser.KW_MILLENNIUM:
            case SparkSQLParser.KW_MILLISECOND:
            case SparkSQLParser.KW_MINUTES:
            case SparkSQLParser.KW_MINVALUE:
            case SparkSQLParser.KW_MODIFY:
            case SparkSQLParser.KW_MODULES:
            case SparkSQLParser.KW_MONTHS:
            case SparkSQLParser.KW_NANOSECOND:
            case SparkSQLParser.KW_NULLS:
            case SparkSQLParser.KW_NUMBER:
            case SparkSQLParser.KW_OPTION:
            case SparkSQLParser.KW_OPTIONS:
            case SparkSQLParser.KW_ORDERING:
            case SparkSQLParser.KW_OUTPUT:
            case SparkSQLParser.KW_OVERWRITE:
            case SparkSQLParser.KW_OVERWRITING:
            case SparkSQLParser.KW_PARTITIONED:
            case SparkSQLParser.KW_PARTITIONS:
            case SparkSQLParser.KW_PASSING:
            case SparkSQLParser.KW_PAST:
            case SparkSQLParser.KW_PATH:
            case SparkSQLParser.KW_PLACING:
            case SparkSQLParser.KW_PLAN:
            case SparkSQLParser.KW_PRECEDING:
            case SparkSQLParser.KW_PRESERVE:
            case SparkSQLParser.KW_PRIOR:
            case SparkSQLParser.KW_PRIVILEGES:
            case SparkSQLParser.KW_PUBLIC:
            case SparkSQLParser.KW_PYTHON:
            case SparkSQLParser.KW_PYTHON_FILES:
            case SparkSQLParser.KW_PYTHON_REQUIREMENTS:
            case SparkSQLParser.KW_PYTHON_DEPENDENCIES:
            case SparkSQLParser.KW_PYTHON_JAR:
            case SparkSQLParser.KW_PYTHON_ARCHIVES:
            case SparkSQLParser.KW_PYTHON_PARAMETER:
            case SparkSQLParser.KW_QUARTER:
            case SparkSQLParser.KW_RAW:
            case SparkSQLParser.KW_READ:
            case SparkSQLParser.KW_RELATIVE:
            case SparkSQLParser.KW_REMOVE:
            case SparkSQLParser.KW_RENAME:
            case SparkSQLParser.KW_REPLACE:
            case SparkSQLParser.KW_RESPECT:
            case SparkSQLParser.KW_RESTART:
            case SparkSQLParser.KW_RESTRICT:
            case SparkSQLParser.KW_ROLE:
            case SparkSQLParser.KW_ROW_COUNT:
            case SparkSQLParser.KW_SCALA:
            case SparkSQLParser.KW_SCALAR:
            case SparkSQLParser.KW_SCALE:
            case SparkSQLParser.KW_SCHEMA:
            case SparkSQLParser.KW_SECONDS:
            case SparkSQLParser.KW_SECTION:
            case SparkSQLParser.KW_SECURITY:
            case SparkSQLParser.KW_SELF:
            case SparkSQLParser.KW_SERVER:
            case SparkSQLParser.KW_SERVER_NAME:
            case SparkSQLParser.KW_SESSION:
            case SparkSQLParser.KW_SETS:
            case SparkSQLParser.KW_SIMPLE:
            case SparkSQLParser.KW_SIZE:
            case SparkSQLParser.KW_SLIDE:
            case SparkSQLParser.KW_SOURCE:
            case SparkSQLParser.KW_SPACE:
            case SparkSQLParser.KW_STATE:
            case SparkSQLParser.KW_STATEMENT:
            case SparkSQLParser.KW_STEP:
            case SparkSQLParser.KW_STRING:
            case SparkSQLParser.KW_STRUCTURE:
            case SparkSQLParser.KW_STYLE:
            case SparkSQLParser.KW_TABLES:
            case SparkSQLParser.KW_TEMPORARY:
            case SparkSQLParser.KW_TIMECOL:
            case SparkSQLParser.KW_FLOOR:
            case SparkSQLParser.KW_TIMESTAMP_LTZ:
            case SparkSQLParser.KW_TIMESTAMPADD:
            case SparkSQLParser.KW_TIMESTAMPDIFF:
            case SparkSQLParser.KW_TOTIMESTAMP:
            case SparkSQLParser.KW_TRANSFORM:
            case SparkSQLParser.KW_TUMBLE:
            case SparkSQLParser.KW_TYPE:
            case SparkSQLParser.KW_UNDER:
            case SparkSQLParser.KW_UNLOAD:
            case SparkSQLParser.KW_USAGE:
            case SparkSQLParser.KW_USE:
            case SparkSQLParser.KW_UTF16:
            case SparkSQLParser.KW_UTF32:
            case SparkSQLParser.KW_UTF8:
            case SparkSQLParser.KW_VERSION:
            case SparkSQLParser.KW_VIEW:
            case SparkSQLParser.KW_VIEWS:
            case SparkSQLParser.KW_VIRTUAL:
            case SparkSQLParser.KW_WATERMARK:
            case SparkSQLParser.KW_WATERMARKS:
            case SparkSQLParser.KW_WEEK:
            case SparkSQLParser.KW_WORK:
            case SparkSQLParser.KW_WRAPPER:
            case SparkSQLParser.KW_YEARS:
            case SparkSQLParser.KW_ZONE:
            case SparkSQLParser.KW_ABS:
            case SparkSQLParser.KW_ARRAY:
            case SparkSQLParser.KW_AVG:
            case SparkSQLParser.KW_CASE:
            case SparkSQLParser.KW_CAST:
            case SparkSQLParser.KW_CEIL:
            case SparkSQLParser.KW_COALESCE:
            case SparkSQLParser.KW_COLLECT:
            case SparkSQLParser.KW_COUNT:
            case SparkSQLParser.KW_CURRENT_TIMESTAMP:
            case SparkSQLParser.KW_DATE:
            case SparkSQLParser.KW_DAY:
            case SparkSQLParser.KW_EXISTS:
            case SparkSQLParser.KW_EXPLODE:
            case SparkSQLParser.KW_FIRST_VALUE:
            case SparkSQLParser.KW_FALSE:
            case SparkSQLParser.KW_FROM_UNIXTIME:
            case SparkSQLParser.KW_GROUPING:
            case SparkSQLParser.KW_HOUR:
            case SparkSQLParser.KW_INTERVAL:
            case SparkSQLParser.KW_LAG:
            case SparkSQLParser.KW_LAST_VALUE:
            case SparkSQLParser.KW_LEAD:
            case SparkSQLParser.KW_LEFT:
            case SparkSQLParser.KW_LOCALTIMESTAMP:
            case SparkSQLParser.KW_MINUTE:
            case SparkSQLParser.KW_MONTH:
            case SparkSQLParser.KW_NOT:
            case SparkSQLParser.KW_NTILE:
            case SparkSQLParser.KW_NULL:
            case SparkSQLParser.KW_OVERLAY:
            case SparkSQLParser.KW_PERCENT_RANK:
            case SparkSQLParser.KW_PERCENTILE_CONT:
            case SparkSQLParser.KW_PERCENTILE_DISC:
            case SparkSQLParser.KW_POSITION:
            case SparkSQLParser.KW_POWER:
            case SparkSQLParser.KW_RANGE:
            case SparkSQLParser.KW_ROW_NUMBER:
            case SparkSQLParser.KW_RANK:
            case SparkSQLParser.KW_RIGHT:
            case SparkSQLParser.KW_ROW:
            case SparkSQLParser.KW_SECOND:
            case SparkSQLParser.KW_STRUCT:
            case SparkSQLParser.KW_SUBSTRING:
            case SparkSQLParser.KW_SUM:
            case SparkSQLParser.KW_TIME:
            case SparkSQLParser.KW_TIMESTAMP:
            case SparkSQLParser.KW_TIMESTAMP_3:
            case SparkSQLParser.KW_TIMESTAMP_6:
            case SparkSQLParser.KW_TIMESTAMP_9:
            case SparkSQLParser.KW_TRUE:
            case SparkSQLParser.KW_TRUNCATE:
            case SparkSQLParser.KW_UPPER:
            case SparkSQLParser.KW_YEAR:
            case SparkSQLParser.BIT_NOT_OP:
            case SparkSQLParser.LR_BRACKET:
            case SparkSQLParser.DOLLAR:
            case SparkSQLParser.ASTERISK_SIGN:
            case SparkSQLParser.HYPNEN_SIGN:
            case SparkSQLParser.ADD_SIGN:
            case SparkSQLParser.STRING_LITERAL:
            case SparkSQLParser.DIG_LITERAL:
            case SparkSQLParser.REAL_LITERAL:
            case SparkSQLParser.ID_LITERAL:
                {
                this.state = 1842;
                localContext._limit = this.expression();
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public offsetClause(): OffsetClauseContext {
        let localContext = new OffsetClauseContext(this.context, this.state);
        this.enterRule(localContext, 232, SparkSQLParser.RULE_offsetClause);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1845;
            this.match(SparkSQLParser.KW_OFFSET);
            this.state = 1848;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 202, this.context) ) {
            case 1:
                {
                this.state = 1846;
                this.match(SparkSQLParser.DIG_LITERAL);
                }
                break;
            case 2:
                {
                this.state = 1847;
                this.expression();
                }
                break;
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public partitionByClause(): PartitionByClauseContext {
        let localContext = new PartitionByClauseContext(this.context, this.state);
        this.enterRule(localContext, 234, SparkSQLParser.RULE_partitionByClause);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1850;
            this.match(SparkSQLParser.KW_PARTITION);
            this.state = 1851;
            this.match(SparkSQLParser.KW_BY);
            this.state = 1852;
            this.expression();
            this.state = 1857;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 480) {
                {
                {
                this.state = 1853;
                this.match(SparkSQLParser.COMMA);
                this.state = 1854;
                this.expression();
                }
                }
                this.state = 1859;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public quantifiers(): QuantifiersContext {
        let localContext = new QuantifiersContext(this.context, this.state);
        this.enterRule(localContext, 236, SparkSQLParser.RULE_quantifiers);
        try {
            this.state = 1876;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 204, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                {
                this.state = 1860;
                this.match(SparkSQLParser.ASTERISK_SIGN);
                }
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                {
                this.state = 1861;
                this.match(SparkSQLParser.ADD_SIGN);
                }
                }
                break;
            case 3:
                this.enterOuterAlt(localContext, 3);
                {
                {
                this.state = 1862;
                this.match(SparkSQLParser.QUESTION_MARK_SIGN);
                }
                }
                break;
            case 4:
                this.enterOuterAlt(localContext, 4);
                {
                {
                this.state = 1863;
                this.match(SparkSQLParser.LB_BRACKET);
                this.state = 1864;
                this.match(SparkSQLParser.DIG_LITERAL);
                this.state = 1865;
                this.match(SparkSQLParser.COMMA);
                this.state = 1866;
                this.match(SparkSQLParser.DIG_LITERAL);
                this.state = 1867;
                this.match(SparkSQLParser.RB_BRACKET);
                }
                }
                break;
            case 5:
                this.enterOuterAlt(localContext, 5);
                {
                {
                this.state = 1868;
                this.match(SparkSQLParser.LB_BRACKET);
                this.state = 1869;
                this.match(SparkSQLParser.DIG_LITERAL);
                this.state = 1870;
                this.match(SparkSQLParser.COMMA);
                this.state = 1871;
                this.match(SparkSQLParser.RB_BRACKET);
                }
                }
                break;
            case 6:
                this.enterOuterAlt(localContext, 6);
                {
                {
                this.state = 1872;
                this.match(SparkSQLParser.LB_BRACKET);
                this.state = 1873;
                this.match(SparkSQLParser.COMMA);
                this.state = 1874;
                this.match(SparkSQLParser.DIG_LITERAL);
                this.state = 1875;
                this.match(SparkSQLParser.RB_BRACKET);
                }
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public measuresClause(): MeasuresClauseContext {
        let localContext = new MeasuresClauseContext(this.context, this.state);
        this.enterRule(localContext, 238, SparkSQLParser.RULE_measuresClause);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1878;
            this.match(SparkSQLParser.KW_MEASURES);
            this.state = 1879;
            this.projectItemDefinition();
            this.state = 1884;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 480) {
                {
                {
                this.state = 1880;
                this.match(SparkSQLParser.COMMA);
                this.state = 1881;
                this.projectItemDefinition();
                }
                }
                this.state = 1886;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public patternDefinition(): PatternDefinitionContext {
        let localContext = new PatternDefinitionContext(this.context, this.state);
        this.enterRule(localContext, 240, SparkSQLParser.RULE_patternDefinition);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1887;
            this.match(SparkSQLParser.KW_PATTERN);
            this.state = 1888;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 1890;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            do {
                {
                {
                this.state = 1889;
                this.patternVariable();
                }
                }
                this.state = 1892;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            } while (_la === 499 || _la === 501);
            this.state = 1894;
            this.match(SparkSQLParser.RR_BRACKET);
            this.state = 1896;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 454) {
                {
                this.state = 1895;
                this.withinClause();
                }
            }

            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public patternVariable(): PatternVariableContext {
        let localContext = new PatternVariableContext(this.context, this.state);
        this.enterRule(localContext, 242, SparkSQLParser.RULE_patternVariable);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1898;
            this.unquotedIdentifier();
            this.state = 1900;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (((((_la - 478)) & ~0x1F) === 0 && ((1 << (_la - 478)) & 271361) !== 0)) {
                {
                this.state = 1899;
                this.quantifiers();
                }
            }

            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public outputMode(): OutputModeContext {
        let localContext = new OutputModeContext(this.context, this.state);
        this.enterRule(localContext, 244, SparkSQLParser.RULE_outputMode);
        try {
            this.state = 1910;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.KW_ALL:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 1902;
                this.match(SparkSQLParser.KW_ALL);
                this.state = 1903;
                this.match(SparkSQLParser.KW_ROWS);
                this.state = 1904;
                this.match(SparkSQLParser.KW_PER);
                this.state = 1905;
                this.match(SparkSQLParser.KW_MATCH);
                }
                break;
            case SparkSQLParser.KW_ONE:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 1906;
                this.match(SparkSQLParser.KW_ONE);
                this.state = 1907;
                this.match(SparkSQLParser.KW_ROW);
                this.state = 1908;
                this.match(SparkSQLParser.KW_PER);
                this.state = 1909;
                this.match(SparkSQLParser.KW_MATCH);
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public afterMatchStrategy(): AfterMatchStrategyContext {
        let localContext = new AfterMatchStrategyContext(this.context, this.state);
        this.enterRule(localContext, 246, SparkSQLParser.RULE_afterMatchStrategy);
        try {
            this.state = 1936;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 210, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 1912;
                this.match(SparkSQLParser.KW_AFTER);
                this.state = 1913;
                this.match(SparkSQLParser.KW_MATCH);
                this.state = 1914;
                this.match(SparkSQLParser.KW_SKIP);
                this.state = 1915;
                this.match(SparkSQLParser.KW_PAST);
                this.state = 1916;
                this.match(SparkSQLParser.KW_LAST);
                this.state = 1917;
                this.match(SparkSQLParser.KW_ROW);
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 1918;
                this.match(SparkSQLParser.KW_AFTER);
                this.state = 1919;
                this.match(SparkSQLParser.KW_MATCH);
                this.state = 1920;
                this.match(SparkSQLParser.KW_SKIP);
                this.state = 1921;
                this.match(SparkSQLParser.KW_TO);
                this.state = 1922;
                this.match(SparkSQLParser.KW_NEXT);
                this.state = 1923;
                this.match(SparkSQLParser.KW_ROW);
                }
                break;
            case 3:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 1924;
                this.match(SparkSQLParser.KW_AFTER);
                this.state = 1925;
                this.match(SparkSQLParser.KW_MATCH);
                this.state = 1926;
                this.match(SparkSQLParser.KW_SKIP);
                this.state = 1927;
                this.match(SparkSQLParser.KW_TO);
                this.state = 1928;
                this.match(SparkSQLParser.KW_LAST);
                this.state = 1929;
                this.unquotedIdentifier();
                }
                break;
            case 4:
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 1930;
                this.match(SparkSQLParser.KW_AFTER);
                this.state = 1931;
                this.match(SparkSQLParser.KW_MATCH);
                this.state = 1932;
                this.match(SparkSQLParser.KW_SKIP);
                this.state = 1933;
                this.match(SparkSQLParser.KW_TO);
                this.state = 1934;
                this.match(SparkSQLParser.KW_FIRST);
                this.state = 1935;
                this.unquotedIdentifier();
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public patternVariablesDefinition(): PatternVariablesDefinitionContext {
        let localContext = new PatternVariablesDefinitionContext(this.context, this.state);
        this.enterRule(localContext, 248, SparkSQLParser.RULE_patternVariablesDefinition);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1938;
            this.match(SparkSQLParser.KW_DEFINE);
            this.state = 1939;
            this.projectItemDefinition();
            this.state = 1944;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 480) {
                {
                {
                this.state = 1940;
                this.match(SparkSQLParser.COMMA);
                this.state = 1941;
                this.projectItemDefinition();
                }
                }
                this.state = 1946;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public windowFrame(): WindowFrameContext {
        let localContext = new WindowFrameContext(this.context, this.state);
        this.enterRule(localContext, 250, SparkSQLParser.RULE_windowFrame);
        try {
            this.state = 1956;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.KW_RANGE:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 1947;
                this.match(SparkSQLParser.KW_RANGE);
                this.state = 1948;
                this.match(SparkSQLParser.KW_BETWEEN);
                this.state = 1949;
                this.timeIntervalExpression();
                this.state = 1950;
                this.frameBound();
                }
                break;
            case SparkSQLParser.KW_ROWS:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 1952;
                this.match(SparkSQLParser.KW_ROWS);
                this.state = 1953;
                this.match(SparkSQLParser.KW_BETWEEN);
                this.state = 1954;
                this.match(SparkSQLParser.DIG_LITERAL);
                this.state = 1955;
                this.frameBound();
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public frameBound(): FrameBoundContext {
        let localContext = new FrameBoundContext(this.context, this.state);
        this.enterRule(localContext, 252, SparkSQLParser.RULE_frameBound);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1958;
            this.match(SparkSQLParser.KW_PRECEDING);
            this.state = 1959;
            this.match(SparkSQLParser.KW_AND);
            this.state = 1960;
            this.match(SparkSQLParser.KW_CURRENT);
            this.state = 1961;
            this.match(SparkSQLParser.KW_ROW);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public withinClause(): WithinClauseContext {
        let localContext = new WithinClauseContext(this.context, this.state);
        this.enterRule(localContext, 254, SparkSQLParser.RULE_withinClause);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1963;
            this.match(SparkSQLParser.KW_WITHIN);
            this.state = 1964;
            this.timeIntervalExpression();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public selfDefinitionClause(): SelfDefinitionClauseContext {
        let localContext = new SelfDefinitionClauseContext(this.context, this.state);
        this.enterRule(localContext, 256, SparkSQLParser.RULE_selfDefinitionClause);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1966;
            this.match(SparkSQLParser.KW_PERIOD);
            this.state = 1967;
            this.match(SparkSQLParser.KW_FOR);
            this.state = 1968;
            this.match(SparkSQLParser.KW_SYSTEM_TIME);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public partitionDefinition(): PartitionDefinitionContext {
        let localContext = new PartitionDefinitionContext(this.context, this.state);
        this.enterRule(localContext, 258, SparkSQLParser.RULE_partitionDefinition);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1970;
            this.match(SparkSQLParser.KW_PARTITIONED);
            this.state = 1971;
            this.match(SparkSQLParser.KW_BY);
            this.state = 1972;
            this.transformList();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public transformList(): TransformListContext {
        let localContext = new TransformListContext(this.context, this.state);
        this.enterRule(localContext, 260, SparkSQLParser.RULE_transformList);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1974;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 1975;
            this.transform();
            this.state = 1977;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if ((((_la) & ~0x1F) === 0 && ((1 << _la) & 4294688704) !== 0) || ((((_la - 32)) & ~0x1F) === 0 && ((1 << (_la - 32)) & 4293654523) !== 0) || ((((_la - 64)) & ~0x1F) === 0 && ((1 << (_la - 64)) & 4252958655) !== 0) || ((((_la - 96)) & ~0x1F) === 0 && ((1 << (_la - 96)) & 4294967263) !== 0) || ((((_la - 128)) & ~0x1F) === 0 && ((1 << (_la - 128)) & 4293918651) !== 0) || ((((_la - 160)) & ~0x1F) === 0 && ((1 << (_la - 160)) & 4253024215) !== 0) || ((((_la - 192)) & ~0x1F) === 0 && ((1 << (_la - 192)) & 1142427519) !== 0) || ((((_la - 259)) & ~0x1F) === 0 && ((1 << (_la - 259)) & 65557) !== 0) || ((((_la - 292)) & ~0x1F) === 0 && ((1 << (_la - 292)) & 92307459) !== 0) || ((((_la - 338)) & ~0x1F) === 0 && ((1 << (_la - 338)) & 1639553) !== 0) || ((((_la - 398)) & ~0x1F) === 0 && ((1 << (_la - 398)) & 1610682373) !== 0) || ((((_la - 432)) & ~0x1F) === 0 && ((1 << (_la - 432)) & 16777225) !== 0) || ((((_la - 483)) & ~0x1F) === 0 && ((1 << (_la - 483)) & 491649) !== 0)) {
                {
                this.state = 1976;
                this.dataTypeExpression();
                }
            }

            this.state = 1986;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 480) {
                {
                {
                this.state = 1979;
                this.match(SparkSQLParser.COMMA);
                this.state = 1980;
                this.transform();
                this.state = 1982;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if ((((_la) & ~0x1F) === 0 && ((1 << _la) & 4294688704) !== 0) || ((((_la - 32)) & ~0x1F) === 0 && ((1 << (_la - 32)) & 4293654523) !== 0) || ((((_la - 64)) & ~0x1F) === 0 && ((1 << (_la - 64)) & 4252958655) !== 0) || ((((_la - 96)) & ~0x1F) === 0 && ((1 << (_la - 96)) & 4294967263) !== 0) || ((((_la - 128)) & ~0x1F) === 0 && ((1 << (_la - 128)) & 4293918651) !== 0) || ((((_la - 160)) & ~0x1F) === 0 && ((1 << (_la - 160)) & 4253024215) !== 0) || ((((_la - 192)) & ~0x1F) === 0 && ((1 << (_la - 192)) & 1142427519) !== 0) || ((((_la - 259)) & ~0x1F) === 0 && ((1 << (_la - 259)) & 65557) !== 0) || ((((_la - 292)) & ~0x1F) === 0 && ((1 << (_la - 292)) & 92307459) !== 0) || ((((_la - 338)) & ~0x1F) === 0 && ((1 << (_la - 338)) & 1639553) !== 0) || ((((_la - 398)) & ~0x1F) === 0 && ((1 << (_la - 398)) & 1610682373) !== 0) || ((((_la - 432)) & ~0x1F) === 0 && ((1 << (_la - 432)) & 16777225) !== 0) || ((((_la - 483)) & ~0x1F) === 0 && ((1 << (_la - 483)) & 491649) !== 0)) {
                    {
                    this.state = 1981;
                    this.dataTypeExpression();
                    }
                }

                }
                }
                this.state = 1988;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 1989;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public transform(): TransformContext {
        let localContext = new TransformContext(this.context, this.state);
        this.enterRule(localContext, 262, SparkSQLParser.RULE_transform);
        let _la: number;
        try {
            this.state = 2004;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 217, this.context) ) {
            case 1:
                localContext = new IdentityTransformContext(localContext);
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 1991;
                this.qualifiedName();
                }
                break;
            case 2:
                localContext = new ApplyTransformContext(localContext);
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 1992;
                (localContext as ApplyTransformContext)._transformName = this.identifier();
                this.state = 1993;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 1994;
                this.transformArgument();
                this.state = 1999;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                while (_la === 480) {
                    {
                    {
                    this.state = 1995;
                    this.match(SparkSQLParser.COMMA);
                    this.state = 1996;
                    this.transformArgument();
                    }
                    }
                    this.state = 2001;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                }
                this.state = 2002;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public transformArgument(): TransformArgumentContext {
        let localContext = new TransformArgumentContext(this.context, this.state);
        this.enterRule(localContext, 264, SparkSQLParser.RULE_transformArgument);
        try {
            this.state = 2008;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 218, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 2006;
                this.qualifiedName();
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 2007;
                this.constant();
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public likeDefinition(): LikeDefinitionContext {
        let localContext = new LikeDefinitionContext(this.context, this.state);
        this.enterRule(localContext, 266, SparkSQLParser.RULE_likeDefinition);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2010;
            this.match(SparkSQLParser.KW_LIKE);
            this.state = 2011;
            this.tablePath();
            this.state = 2020;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 220, this.context) ) {
            case 1:
                {
                this.state = 2012;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 2016;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                while (_la === 48 || _la === 109 || _la === 310) {
                    {
                    {
                    this.state = 2013;
                    this.likeOption();
                    }
                    }
                    this.state = 2018;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                }
                this.state = 2019;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public distribution(): DistributionContext {
        let localContext = new DistributionContext(this.context, this.state);
        this.enterRule(localContext, 268, SparkSQLParser.RULE_distribution);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2022;
            this.match(SparkSQLParser.KW_DISTRIBUTED);
            this.state = 2031;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 226) {
                {
                this.state = 2023;
                this.match(SparkSQLParser.KW_BY);
                this.state = 2025;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 305) {
                    {
                    this.state = 2024;
                    this.match(SparkSQLParser.KW_HASH);
                    }
                }

                this.state = 2027;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 2028;
                this.identifier();
                this.state = 2029;
                this.match(SparkSQLParser.RR_BRACKET);
                }
            }

            this.state = 2034;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 223, this.context) ) {
            case 1:
                {
                this.state = 2033;
                this.intoBuckets();
                }
                break;
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public using(): UsingContext {
        let localContext = new UsingContext(this.context, this.state);
        this.enterRule(localContext, 270, SparkSQLParser.RULE_using);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2036;
            this.match(SparkSQLParser.KW_USING);
            this.state = 2037;
            this.match(SparkSQLParser.ID_LITERAL);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public likeOption(): LikeOptionContext {
        let localContext = new LikeOptionContext(this.context, this.state);
        this.enterRule(localContext, 272, SparkSQLParser.RULE_likeOption);
        let _la: number;
        try {
            this.state = 2043;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 224, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                {
                this.state = 2039;
                _la = this.tokenStream.LA(1);
                if(!(_la === 48 || _la === 310)) {
                this.errorHandler.recoverInline(this);
                }
                else {
                    this.errorHandler.reportMatch(this);
                    this.consume();
                }
                this.state = 2040;
                _la = this.tokenStream.LA(1);
                if(!(_la === 26 || _la === 111 || _la === 205)) {
                this.errorHandler.recoverInline(this);
                }
                else {
                    this.errorHandler.reportMatch(this);
                    this.consume();
                }
                }
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                {
                this.state = 2041;
                _la = this.tokenStream.LA(1);
                if(!(_la === 48 || _la === 109 || _la === 310)) {
                this.errorHandler.recoverInline(this);
                }
                else {
                    this.errorHandler.reportMatch(this);
                    this.consume();
                }
                this.state = 2042;
                _la = this.tokenStream.LA(1);
                if(!(_la === 62 || _la === 105 || _la === 197)) {
                this.errorHandler.recoverInline(this);
                }
                else {
                    this.errorHandler.reportMatch(this);
                    this.consume();
                }
                }
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public columnOptionDefinition(): ColumnOptionDefinitionContext {
        let localContext = new ColumnOptionDefinitionContext(this.context, this.state);
        this.enterRule(localContext, 274, SparkSQLParser.RULE_columnOptionDefinition);
        try {
            this.state = 2048;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 225, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 2045;
                this.physicalColumnDefinition();
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 2046;
                this.metadataColumnDefinition();
                }
                break;
            case 3:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 2047;
                this.computedColumnDefinition();
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public physicalColumnDefinitionList(): PhysicalColumnDefinitionListContext {
        let localContext = new PhysicalColumnDefinitionListContext(this.context, this.state);
        this.enterRule(localContext, 276, SparkSQLParser.RULE_physicalColumnDefinitionList);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2050;
            this.match(SparkSQLParser.LR_BRACKET);
            {
            this.state = 2051;
            this.physicalColumnDefinition();
            }
            this.state = 2056;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 480) {
                {
                {
                this.state = 2052;
                this.match(SparkSQLParser.COMMA);
                this.state = 2053;
                this.physicalColumnDefinition();
                }
                }
                this.state = 2058;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 2059;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public physicalColumnDefinition(): PhysicalColumnDefinitionContext {
        let localContext = new PhysicalColumnDefinitionContext(this.context, this.state);
        this.enterRule(localContext, 278, SparkSQLParser.RULE_physicalColumnDefinition);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2061;
            this.columnName();
            this.state = 2062;
            this.columnType();
            this.state = 2064;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 246 || ((((_la - 354)) & ~0x1F) === 0 && ((1 << (_la - 354)) & 1073741833) !== 0)) {
                {
                this.state = 2063;
                this.columnConstraint();
                }
            }

            this.state = 2067;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 228, this.context) ) {
            case 1:
                {
                this.state = 2066;
                this.commentSpec();
                }
                break;
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public computedColumnExpression(): ComputedColumnExpressionContext {
        let localContext = new ComputedColumnExpressionContext(this.context, this.state);
        this.enterRule(localContext, 280, SparkSQLParser.RULE_computedColumnExpression);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2069;
            this.expression();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public watermarkDefinition(): WatermarkDefinitionContext {
        let localContext = new WatermarkDefinitionContext(this.context, this.state);
        this.enterRule(localContext, 282, SparkSQLParser.RULE_watermarkDefinition);
        try {
            this.state = 2086;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 230, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 2071;
                this.match(SparkSQLParser.KW_WATERMARK);
                this.state = 2072;
                this.match(SparkSQLParser.KW_FOR);
                this.state = 2073;
                this.expression();
                this.state = 2074;
                this.match(SparkSQLParser.KW_AS);
                this.state = 2075;
                this.expression();
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 2077;
                this.match(SparkSQLParser.KW_WATERMARK);
                this.state = 2078;
                this.match(SparkSQLParser.KW_FOR);
                this.state = 2081;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 229, this.context) ) {
                case 1:
                    {
                    this.state = 2079;
                    this.uid();
                    }
                    break;
                case 2:
                    {
                    this.state = 2080;
                    this.expression();
                    }
                    break;
                }
                this.state = 2083;
                this.match(SparkSQLParser.KW_AS);
                this.state = 2084;
                this.uid();
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public tableConstraint(): TableConstraintContext {
        let localContext = new TableConstraintContext(this.context, this.state);
        this.enterRule(localContext, 284, SparkSQLParser.RULE_tableConstraint);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2090;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 246) {
                {
                this.state = 2088;
                this.match(SparkSQLParser.KW_CONSTRAINT);
                this.state = 2089;
                this.constraintName();
                }
            }

            this.state = 2092;
            this.match(SparkSQLParser.KW_PRIMARY);
            this.state = 2093;
            this.match(SparkSQLParser.KW_KEY);
            this.state = 2094;
            this.columnNameList();
            this.state = 2095;
            this.match(SparkSQLParser.KW_NOT);
            this.state = 2096;
            this.match(SparkSQLParser.KW_ENFORCED);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public constraintName(): ConstraintNameContext {
        let localContext = new ConstraintNameContext(this.context, this.state);
        this.enterRule(localContext, 286, SparkSQLParser.RULE_constraintName);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2098;
            this.identifier();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public valuesDefinition(): ValuesDefinitionContext {
        let localContext = new ValuesDefinitionContext(this.context, this.state);
        this.enterRule(localContext, 288, SparkSQLParser.RULE_valuesDefinition);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2100;
            this.match(SparkSQLParser.KW_VALUES);
            this.state = 2101;
            this.valuesRowDefinition();
            this.state = 2106;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 480) {
                {
                {
                this.state = 2102;
                this.match(SparkSQLParser.COMMA);
                this.state = 2103;
                this.valuesRowDefinition();
                }
                }
                this.state = 2108;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public valuesRowDefinition(): ValuesRowDefinitionContext {
        let localContext = new ValuesRowDefinitionContext(this.context, this.state);
        this.enterRule(localContext, 290, SparkSQLParser.RULE_valuesRowDefinition);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2109;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 2110;
            this.constant();
            this.state = 2115;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 480) {
                {
                {
                this.state = 2111;
                this.match(SparkSQLParser.COMMA);
                this.state = 2112;
                this.constant();
                }
                }
                this.state = 2117;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 2118;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public lengthOneDimension(): LengthOneDimensionContext {
        let localContext = new LengthOneDimensionContext(this.context, this.state);
        this.enterRule(localContext, 292, SparkSQLParser.RULE_lengthOneDimension);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2120;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 2121;
            this.decimalLiteral();
            this.state = 2122;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public lengthTwoOptionalDimension(): LengthTwoOptionalDimensionContext {
        let localContext = new LengthTwoOptionalDimensionContext(this.context, this.state);
        this.enterRule(localContext, 294, SparkSQLParser.RULE_lengthTwoOptionalDimension);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2124;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 2125;
            this.decimalLiteral();
            this.state = 2128;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 480) {
                {
                this.state = 2126;
                this.match(SparkSQLParser.COMMA);
                this.state = 2127;
                this.decimalLiteral();
                }
            }

            this.state = 2130;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public lengthTwoStringDimension(): LengthTwoStringDimensionContext {
        let localContext = new LengthTwoStringDimensionContext(this.context, this.state);
        this.enterRule(localContext, 296, SparkSQLParser.RULE_lengthTwoStringDimension);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2132;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 2133;
            this.stringLiteral();
            this.state = 2136;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 480) {
                {
                this.state = 2134;
                this.match(SparkSQLParser.COMMA);
                this.state = 2135;
                this.stringLiteral();
                }
            }

            this.state = 2138;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public lengthOneTypeDimension(): LengthOneTypeDimensionContext {
        let localContext = new LengthOneTypeDimensionContext(this.context, this.state);
        this.enterRule(localContext, 298, SparkSQLParser.RULE_lengthOneTypeDimension);
        let _la: number;
        try {
            localContext = new LengthSymbolsTypeDimensionContext(localContext);
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2140;
            this.match(SparkSQLParser.LESS_SYMBOL);
            this.state = 2141;
            this.columnType();
            this.state = 2146;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 480) {
                {
                {
                this.state = 2142;
                this.match(SparkSQLParser.COMMA);
                this.state = 2143;
                this.columnType();
                }
                }
                this.state = 2148;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 2149;
            this.match(SparkSQLParser.GREATER_SYMBOL);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public mapTypeDimension(): MapTypeDimensionContext {
        let localContext = new MapTypeDimensionContext(this.context, this.state);
        this.enterRule(localContext, 300, SparkSQLParser.RULE_mapTypeDimension);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2151;
            this.match(SparkSQLParser.LESS_SYMBOL);
            this.state = 2152;
            this.columnType();
            {
            this.state = 2153;
            this.match(SparkSQLParser.COMMA);
            this.state = 2154;
            this.columnType();
            }
            this.state = 2156;
            this.match(SparkSQLParser.GREATER_SYMBOL);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public rowTypeDimension(): RowTypeDimensionContext {
        let localContext = new RowTypeDimensionContext(this.context, this.state);
        this.enterRule(localContext, 302, SparkSQLParser.RULE_rowTypeDimension);
        let _la: number;
        try {
            localContext = new RowSymbolsTypeDimensionContext(localContext);
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2158;
            this.match(SparkSQLParser.LESS_SYMBOL);
            this.state = 2159;
            this.columnName();
            this.state = 2160;
            this.columnType();
            this.state = 2167;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 480) {
                {
                {
                this.state = 2161;
                this.match(SparkSQLParser.COMMA);
                this.state = 2162;
                this.columnName();
                this.state = 2163;
                this.columnType();
                }
                }
                this.state = 2169;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 2170;
            this.match(SparkSQLParser.GREATER_SYMBOL);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public structTypeDimension(): StructTypeDimensionContext {
        let localContext = new StructTypeDimensionContext(this.context, this.state);
        this.enterRule(localContext, 304, SparkSQLParser.RULE_structTypeDimension);
        let _la: number;
        try {
            localContext = new StructSymbolsTypeDimensionContext(localContext);
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2172;
            this.match(SparkSQLParser.LESS_SYMBOL);
            this.state = 2173;
            this.columnName();
            this.state = 2174;
            this.match(SparkSQLParser.COLON_SYMB);
            this.state = 2175;
            this.columnType();
            this.state = 2183;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 480) {
                {
                {
                this.state = 2176;
                this.match(SparkSQLParser.COMMA);
                this.state = 2177;
                this.columnName();
                this.state = 2178;
                this.match(SparkSQLParser.COLON_SYMB);
                this.state = 2179;
                this.columnType();
                }
                }
                this.state = 2185;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 2186;
            this.match(SparkSQLParser.GREATER_SYMBOL);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public columnConstraint(): ColumnConstraintContext {
        let localContext = new ColumnConstraintContext(this.context, this.state);
        this.enterRule(localContext, 306, SparkSQLParser.RULE_columnConstraint);
        let _la: number;
        try {
            this.state = 2202;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.KW_CONSTRAINT:
            case SparkSQLParser.KW_PRIMARY:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 2190;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 246) {
                    {
                    this.state = 2188;
                    this.match(SparkSQLParser.KW_CONSTRAINT);
                    this.state = 2189;
                    this.constraintName();
                    }
                }

                this.state = 2192;
                this.match(SparkSQLParser.KW_PRIMARY);
                this.state = 2193;
                this.match(SparkSQLParser.KW_KEY);
                this.state = 2196;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 354) {
                    {
                    this.state = 2194;
                    this.match(SparkSQLParser.KW_NOT);
                    this.state = 2195;
                    this.match(SparkSQLParser.KW_ENFORCED);
                    }
                }

                }
                break;
            case SparkSQLParser.KW_NOT:
            case SparkSQLParser.KW_NULL:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 2199;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 354) {
                    {
                    this.state = 2198;
                    this.match(SparkSQLParser.KW_NOT);
                    }
                }

                this.state = 2201;
                this.match(SparkSQLParser.KW_NULL);
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public commentSpec(): CommentSpecContext {
        let localContext = new CommentSpecContext(this.context, this.state);
        this.enterRule(localContext, 308, SparkSQLParser.RULE_commentSpec);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2204;
            this.match(SparkSQLParser.KW_COMMENT);
            this.state = 2205;
            this.propertyName();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public metadataColumnDefinition(): MetadataColumnDefinitionContext {
        let localContext = new MetadataColumnDefinitionContext(this.context, this.state);
        this.enterRule(localContext, 310, SparkSQLParser.RULE_metadataColumnDefinition);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2207;
            this.columnName();
            this.state = 2208;
            this.columnType();
            this.state = 2209;
            this.match(SparkSQLParser.KW_METADATA);
            this.state = 2212;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 296) {
                {
                this.state = 2210;
                this.match(SparkSQLParser.KW_FROM);
                this.state = 2211;
                this.metadataKey();
                }
            }

            this.state = 2215;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 195) {
                {
                this.state = 2214;
                this.match(SparkSQLParser.KW_VIRTUAL);
                }
            }

            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public metadataKey(): MetadataKeyContext {
        let localContext = new MetadataKeyContext(this.context, this.state);
        this.enterRule(localContext, 312, SparkSQLParser.RULE_metadataKey);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2217;
            this.match(SparkSQLParser.STRING_LITERAL);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public computedColumnDefinition(): ComputedColumnDefinitionContext {
        let localContext = new ComputedColumnDefinitionContext(this.context, this.state);
        this.enterRule(localContext, 314, SparkSQLParser.RULE_computedColumnDefinition);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2219;
            this.columnName();
            this.state = 2220;
            this.match(SparkSQLParser.KW_AS);
            this.state = 2221;
            this.computedColumnExpression();
            this.state = 2223;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 245, this.context) ) {
            case 1:
                {
                this.state = 2222;
                this.commentSpec();
                }
                break;
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public columnName(): ColumnNameContext {
        let localContext = new ColumnNameContext(this.context, this.state);
        this.enterRule(localContext, 316, SparkSQLParser.RULE_columnName);
        try {
            this.state = 2227;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 246, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 2225;
                this.uid();
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 2226;
                this.expression();
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public columnNameList(): ColumnNameListContext {
        let localContext = new ColumnNameListContext(this.context, this.state);
        this.enterRule(localContext, 318, SparkSQLParser.RULE_columnNameList);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2229;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 2230;
            this.columnName();
            this.state = 2232;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 23) {
                {
                this.state = 2231;
                this.commentSpec();
                }
            }

            this.state = 2241;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 480) {
                {
                {
                this.state = 2234;
                this.match(SparkSQLParser.COMMA);
                this.state = 2235;
                this.columnName();
                this.state = 2237;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 23) {
                    {
                    this.state = 2236;
                    this.commentSpec();
                    }
                }

                }
                }
                this.state = 2243;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 2244;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public columnType(): ColumnTypeContext {
        let localContext = new ColumnTypeContext(this.context, this.state);
        this.enterRule(localContext, 320, SparkSQLParser.RULE_columnType);
        let _la: number;
        try {
            this.state = 2321;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.KW_BOOLEAN:
            case SparkSQLParser.KW_DATE:
            case SparkSQLParser.KW_NULL:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 2246;
                localContext._typeName = this.tokenStream.LT(1);
                _la = this.tokenStream.LA(1);
                if(!(_la === 222 || _la === 259 || _la === 357)) {
                    localContext._typeName = this.errorHandler.recoverInline(this);
                }
                else {
                    this.errorHandler.reportMatch(this);
                    this.consume();
                }
                }
                break;
            case SparkSQLParser.KW_BYTES:
            case SparkSQLParser.KW_STRING:
            case SparkSQLParser.KW_TIMESTAMP_LTZ:
            case SparkSQLParser.KW_BIGINT:
            case SparkSQLParser.KW_BINARY:
            case SparkSQLParser.KW_CHAR:
            case SparkSQLParser.KW_DATETIME:
            case SparkSQLParser.KW_INT:
            case SparkSQLParser.KW_INTEGER:
            case SparkSQLParser.KW_SMALLINT:
            case SparkSQLParser.KW_TIME:
            case SparkSQLParser.KW_TINYINT:
            case SparkSQLParser.KW_VARBINARY:
            case SparkSQLParser.KW_VARCHAR:
                this.enterOuterAlt(localContext, 2);
                {
                {
                this.state = 2247;
                localContext._typeName = this.tokenStream.LT(1);
                _la = this.tokenStream.LA(1);
                if(!(_la === 13 || _la === 168 || _la === 175 || ((((_la - 218)) & ~0x1F) === 0 && ((1 << (_la - 218)) & 32771) !== 0) || _la === 260 || _la === 315 || _la === 316 || ((((_la - 410)) & ~0x1F) === 0 && ((1 << (_la - 410)) & 4325377) !== 0) || _la === 448 || _la === 449)) {
                    localContext._typeName = this.errorHandler.recoverInline(this);
                }
                else {
                    this.errorHandler.reportMatch(this);
                    this.consume();
                }
                this.state = 2249;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 476) {
                    {
                    this.state = 2248;
                    this.lengthOneDimension();
                    }
                }

                }
                }
                break;
            case SparkSQLParser.KW_TIMESTAMP:
                this.enterOuterAlt(localContext, 3);
                {
                {
                this.state = 2251;
                localContext._typeName = this.match(SparkSQLParser.KW_TIMESTAMP);
                this.state = 2253;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 476) {
                    {
                    this.state = 2252;
                    this.lengthOneDimension();
                    }
                }

                this.state = 2261;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 453 || _la === 455) {
                    {
                    this.state = 2255;
                    _la = this.tokenStream.LA(1);
                    if(!(_la === 453 || _la === 455)) {
                    this.errorHandler.recoverInline(this);
                    }
                    else {
                        this.errorHandler.reportMatch(this);
                        this.consume();
                    }
                    this.state = 2257;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                    if (_la === 337) {
                        {
                        this.state = 2256;
                        this.match(SparkSQLParser.KW_LOCAL);
                        }
                    }

                    this.state = 2259;
                    this.match(SparkSQLParser.KW_TIME);
                    this.state = 2260;
                    this.match(SparkSQLParser.KW_ZONE);
                    }
                }

                }
                }
                break;
            case SparkSQLParser.KW_TIMESTAMP_3:
                this.enterOuterAlt(localContext, 4);
                {
                {
                this.state = 2263;
                localContext._typeName = this.match(SparkSQLParser.KW_TIMESTAMP_3);
                this.state = 2265;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 476) {
                    {
                    this.state = 2264;
                    this.lengthOneDimension();
                    }
                }

                this.state = 2273;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 453 || _la === 455) {
                    {
                    this.state = 2267;
                    _la = this.tokenStream.LA(1);
                    if(!(_la === 453 || _la === 455)) {
                    this.errorHandler.recoverInline(this);
                    }
                    else {
                        this.errorHandler.reportMatch(this);
                        this.consume();
                    }
                    this.state = 2269;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                    if (_la === 337) {
                        {
                        this.state = 2268;
                        this.match(SparkSQLParser.KW_LOCAL);
                        }
                    }

                    this.state = 2271;
                    this.match(SparkSQLParser.KW_TIME);
                    this.state = 2272;
                    this.match(SparkSQLParser.KW_ZONE);
                    }
                }

                }
                }
                break;
            case SparkSQLParser.KW_TIMESTAMP_6:
                this.enterOuterAlt(localContext, 5);
                {
                {
                this.state = 2275;
                localContext._typeName = this.match(SparkSQLParser.KW_TIMESTAMP_6);
                this.state = 2277;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 476) {
                    {
                    this.state = 2276;
                    this.lengthOneDimension();
                    }
                }

                this.state = 2285;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 453 || _la === 455) {
                    {
                    this.state = 2279;
                    _la = this.tokenStream.LA(1);
                    if(!(_la === 453 || _la === 455)) {
                    this.errorHandler.recoverInline(this);
                    }
                    else {
                        this.errorHandler.reportMatch(this);
                        this.consume();
                    }
                    this.state = 2281;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                    if (_la === 337) {
                        {
                        this.state = 2280;
                        this.match(SparkSQLParser.KW_LOCAL);
                        }
                    }

                    this.state = 2283;
                    this.match(SparkSQLParser.KW_TIME);
                    this.state = 2284;
                    this.match(SparkSQLParser.KW_ZONE);
                    }
                }

                }
                }
                break;
            case SparkSQLParser.KW_TIMESTAMP_9:
                this.enterOuterAlt(localContext, 6);
                {
                {
                this.state = 2287;
                localContext._typeName = this.match(SparkSQLParser.KW_TIMESTAMP_9);
                this.state = 2289;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 476) {
                    {
                    this.state = 2288;
                    this.lengthOneDimension();
                    }
                }

                this.state = 2297;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 453 || _la === 455) {
                    {
                    this.state = 2291;
                    _la = this.tokenStream.LA(1);
                    if(!(_la === 453 || _la === 455)) {
                    this.errorHandler.recoverInline(this);
                    }
                    else {
                        this.errorHandler.reportMatch(this);
                        this.consume();
                    }
                    this.state = 2293;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                    if (_la === 337) {
                        {
                        this.state = 2292;
                        this.match(SparkSQLParser.KW_LOCAL);
                        }
                    }

                    this.state = 2295;
                    this.match(SparkSQLParser.KW_TIME);
                    this.state = 2296;
                    this.match(SparkSQLParser.KW_ZONE);
                    }
                }

                }
                }
                break;
            case SparkSQLParser.KW_DEC:
            case SparkSQLParser.KW_DECIMAL:
            case SparkSQLParser.KW_DOUBLE:
            case SparkSQLParser.KW_FLOAT:
            case SparkSQLParser.KW_NUMERIC:
                this.enterOuterAlt(localContext, 7);
                {
                {
                this.state = 2299;
                localContext._typeName = this.tokenStream.LT(1);
                _la = this.tokenStream.LA(1);
                if(!(((((_la - 262)) & ~0x1F) === 0 && ((1 << (_la - 262)) & 2147491843) !== 0) || _la === 358)) {
                    localContext._typeName = this.errorHandler.recoverInline(this);
                }
                else {
                    this.errorHandler.reportMatch(this);
                    this.consume();
                }
                this.state = 2301;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 476) {
                    {
                    this.state = 2300;
                    this.lengthTwoOptionalDimension();
                    }
                }

                }
                }
                break;
            case SparkSQLParser.KW_ARRAY:
            case SparkSQLParser.KW_MULTISET:
                this.enterOuterAlt(localContext, 8);
                {
                {
                this.state = 2303;
                localContext._type_ = this.tokenStream.LT(1);
                _la = this.tokenStream.LA(1);
                if(!(_la === 211 || _la === 349)) {
                    localContext._type_ = this.errorHandler.recoverInline(this);
                }
                else {
                    this.errorHandler.reportMatch(this);
                    this.consume();
                }
                this.state = 2305;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 471) {
                    {
                    this.state = 2304;
                    this.lengthOneTypeDimension();
                    }
                }

                }
                }
                break;
            case SparkSQLParser.KW_MAP:
                this.enterOuterAlt(localContext, 9);
                {
                {
                this.state = 2307;
                localContext._type_ = this.match(SparkSQLParser.KW_MAP);
                this.state = 2309;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 471) {
                    {
                    this.state = 2308;
                    this.mapTypeDimension();
                    }
                }

                }
                }
                break;
            case SparkSQLParser.KW_ROW:
                this.enterOuterAlt(localContext, 10);
                {
                {
                this.state = 2311;
                localContext._type_ = this.match(SparkSQLParser.KW_ROW);
                this.state = 2313;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 471) {
                    {
                    this.state = 2312;
                    this.rowTypeDimension();
                    }
                }

                }
                }
                break;
            case SparkSQLParser.KW_STRUCT:
                this.enterOuterAlt(localContext, 11);
                {
                {
                this.state = 2315;
                localContext._type_ = this.match(SparkSQLParser.KW_STRUCT);
                this.state = 2316;
                this.structTypeDimension();
                }
                }
                break;
            case SparkSQLParser.KW_RAW:
                this.enterOuterAlt(localContext, 12);
                {
                {
                this.state = 2317;
                localContext._type_ = this.match(SparkSQLParser.KW_RAW);
                this.state = 2319;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 476) {
                    {
                    this.state = 2318;
                    this.lengthTwoStringDimension();
                    }
                }

                }
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public expression(): ExpressionContext {
        let localContext = new ExpressionContext(this.context, this.state);
        this.enterRule(localContext, 322, SparkSQLParser.RULE_expression);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2323;
            this.booleanExpression(0);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }

    public booleanExpression(): BooleanExpressionContext;
    public booleanExpression(_p: number): BooleanExpressionContext;
    public booleanExpression(_p?: number): BooleanExpressionContext {
        if (_p === undefined) {
            _p = 0;
        }

        let parentContext = this.context;
        let parentState = this.state;
        let localContext = new BooleanExpressionContext(this.context, parentState);
        let previousContext = localContext;
        let _startState = 324;
        this.enterRecursionRule(localContext, 324, SparkSQLParser.RULE_booleanExpression, _p);
        let _la: number;
        try {
            let alternative: number;
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2337;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 270, this.context) ) {
            case 1:
                {
                localContext = new LogicalNotContext(localContext);
                this.context = localContext;
                previousContext = localContext;

                this.state = 2326;
                this.match(SparkSQLParser.KW_NOT);
                this.state = 2327;
                this.booleanExpression(6);
                }
                break;
            case 2:
                {
                localContext = new ExistsContext(localContext);
                this.context = localContext;
                previousContext = localContext;
                this.state = 2328;
                this.match(SparkSQLParser.KW_EXISTS);
                this.state = 2329;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 2330;
                this.queryStatement(0);
                this.state = 2331;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case 3:
                {
                localContext = new PredicatedContext(localContext);
                this.context = localContext;
                previousContext = localContext;
                this.state = 2333;
                this.valueExpression(0);
                this.state = 2335;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 269, this.context) ) {
                case 1:
                    {
                    this.state = 2334;
                    this.predicate();
                    }
                    break;
                }
                }
                break;
            }
            this.context!.stop = this.tokenStream.LT(-1);
            this.state = 2353;
            this.errorHandler.sync(this);
            alternative = this.interpreter.adaptivePredict(this.tokenStream, 273, this.context);
            while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {
                if (alternative === 1) {
                    if (this.parseListeners != null) {
                        this.triggerExitRuleEvent();
                    }
                    previousContext = localContext;
                    {
                    this.state = 2351;
                    this.errorHandler.sync(this);
                    switch (this.interpreter.adaptivePredict(this.tokenStream, 272, this.context) ) {
                    case 1:
                        {
                        localContext = new LogicalBinaryContext(new BooleanExpressionContext(parentContext, parentState));
                        (localContext as LogicalBinaryContext)._left = previousContext;
                        this.pushNewRecursionContext(localContext, _startState, SparkSQLParser.RULE_booleanExpression);
                        this.state = 2339;
                        if (!(this.precpred(this.context, 3))) {
                            throw this.createFailedPredicateException("this.precpred(this.context, 3)");
                        }
                        this.state = 2340;
                        (localContext as LogicalBinaryContext)._operator = this.match(SparkSQLParser.KW_AND);
                        this.state = 2341;
                        (localContext as LogicalBinaryContext)._right = this.booleanExpression(4);
                        }
                        break;
                    case 2:
                        {
                        localContext = new LogicalBinaryContext(new BooleanExpressionContext(parentContext, parentState));
                        (localContext as LogicalBinaryContext)._left = previousContext;
                        this.pushNewRecursionContext(localContext, _startState, SparkSQLParser.RULE_booleanExpression);
                        this.state = 2342;
                        if (!(this.precpred(this.context, 2))) {
                            throw this.createFailedPredicateException("this.precpred(this.context, 2)");
                        }
                        this.state = 2343;
                        (localContext as LogicalBinaryContext)._operator = this.match(SparkSQLParser.KW_OR);
                        this.state = 2344;
                        (localContext as LogicalBinaryContext)._right = this.booleanExpression(3);
                        }
                        break;
                    case 3:
                        {
                        localContext = new LogicalNestedContext(new BooleanExpressionContext(parentContext, parentState));
                        this.pushNewRecursionContext(localContext, _startState, SparkSQLParser.RULE_booleanExpression);
                        this.state = 2345;
                        if (!(this.precpred(this.context, 1))) {
                            throw this.createFailedPredicateException("this.precpred(this.context, 1)");
                        }
                        this.state = 2346;
                        this.match(SparkSQLParser.KW_IS);
                        this.state = 2348;
                        this.errorHandler.sync(this);
                        _la = this.tokenStream.LA(1);
                        if (_la === 354) {
                            {
                            this.state = 2347;
                            this.match(SparkSQLParser.KW_NOT);
                            }
                        }

                        this.state = 2350;
                        (localContext as LogicalNestedContext)._kind = this.tokenStream.LT(1);
                        _la = this.tokenStream.LA(1);
                        if(!(_la === 292 || _la === 357 || _la === 435 || _la === 439)) {
                            (localContext as LogicalNestedContext)._kind = this.errorHandler.recoverInline(this);
                        }
                        else {
                            this.errorHandler.reportMatch(this);
                            this.consume();
                        }
                        }
                        break;
                    }
                    }
                }
                this.state = 2355;
                this.errorHandler.sync(this);
                alternative = this.interpreter.adaptivePredict(this.tokenStream, 273, this.context);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.unrollRecursionContexts(parentContext);
        }
        return localContext;
    }
    public predicate(): PredicateContext {
        let localContext = new PredicateContext(this.context, this.state);
        this.enterRule(localContext, 326, SparkSQLParser.RULE_predicate);
        let _la: number;
        try {
            this.state = 2423;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 284, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 2357;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 354) {
                    {
                    this.state = 2356;
                    this.match(SparkSQLParser.KW_NOT);
                    }
                }

                this.state = 2359;
                localContext._kind = this.match(SparkSQLParser.KW_BETWEEN);
                this.state = 2361;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 213 || _la === 418) {
                    {
                    this.state = 2360;
                    _la = this.tokenStream.LA(1);
                    if(!(_la === 213 || _la === 418)) {
                    this.errorHandler.recoverInline(this);
                    }
                    else {
                        this.errorHandler.reportMatch(this);
                        this.consume();
                    }
                    }
                }

                this.state = 2363;
                localContext._lower = this.valueExpression(0);
                this.state = 2364;
                this.match(SparkSQLParser.KW_AND);
                this.state = 2365;
                localContext._upper = this.valueExpression(0);
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 2368;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 354) {
                    {
                    this.state = 2367;
                    this.match(SparkSQLParser.KW_NOT);
                    }
                }

                this.state = 2370;
                localContext._kind = this.match(SparkSQLParser.KW_IN);
                this.state = 2371;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 2372;
                this.expression();
                this.state = 2377;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                while (_la === 480) {
                    {
                    {
                    this.state = 2373;
                    this.match(SparkSQLParser.COMMA);
                    this.state = 2374;
                    this.expression();
                    }
                    }
                    this.state = 2379;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                }
                this.state = 2380;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case 3:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 2383;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 354) {
                    {
                    this.state = 2382;
                    this.match(SparkSQLParser.KW_NOT);
                    }
                }

                this.state = 2385;
                localContext._kind = this.match(SparkSQLParser.KW_IN);
                this.state = 2386;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 2387;
                this.queryStatement(0);
                this.state = 2388;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case 4:
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 2390;
                localContext._kind = this.match(SparkSQLParser.KW_EXISTS);
                this.state = 2391;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 2392;
                this.queryStatement(0);
                this.state = 2393;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case 5:
                this.enterOuterAlt(localContext, 5);
                {
                this.state = 2396;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 354) {
                    {
                    this.state = 2395;
                    this.match(SparkSQLParser.KW_NOT);
                    }
                }

                this.state = 2398;
                localContext._kind = this.match(SparkSQLParser.KW_RLIKE);
                this.state = 2399;
                localContext._pattern = this.valueExpression(0);
                }
                break;
            case 6:
                this.enterOuterAlt(localContext, 6);
                {
                this.state = 2400;
                this.likePredicate();
                }
                break;
            case 7:
                this.enterOuterAlt(localContext, 7);
                {
                this.state = 2401;
                this.match(SparkSQLParser.KW_IS);
                this.state = 2403;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 354) {
                    {
                    this.state = 2402;
                    this.match(SparkSQLParser.KW_NOT);
                    }
                }

                this.state = 2405;
                localContext._kind = this.tokenStream.LT(1);
                _la = this.tokenStream.LA(1);
                if(!(_la === 292 || _la === 357 || _la === 435 || _la === 439)) {
                    localContext._kind = this.errorHandler.recoverInline(this);
                }
                else {
                    this.errorHandler.reportMatch(this);
                    this.consume();
                }
                }
                break;
            case 8:
                this.enterOuterAlt(localContext, 8);
                {
                this.state = 2406;
                this.match(SparkSQLParser.KW_IS);
                this.state = 2408;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 354) {
                    {
                    this.state = 2407;
                    this.match(SparkSQLParser.KW_NOT);
                    }
                }

                this.state = 2410;
                localContext._kind = this.match(SparkSQLParser.KW_DISTINCT);
                this.state = 2411;
                this.match(SparkSQLParser.KW_FROM);
                this.state = 2412;
                localContext._right = this.valueExpression(0);
                }
                break;
            case 9:
                this.enterOuterAlt(localContext, 9);
                {
                this.state = 2414;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 354) {
                    {
                    this.state = 2413;
                    this.match(SparkSQLParser.KW_NOT);
                    }
                }

                this.state = 2416;
                localContext._kind = this.match(SparkSQLParser.KW_SIMILAR);
                this.state = 2417;
                this.match(SparkSQLParser.KW_TO);
                this.state = 2418;
                localContext._right = this.valueExpression(0);
                this.state = 2421;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 283, this.context) ) {
                case 1:
                    {
                    this.state = 2419;
                    this.match(SparkSQLParser.KW_ESCAPE);
                    this.state = 2420;
                    this.stringLiteral();
                    }
                    break;
                }
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public likePredicate(): LikePredicateContext {
        let localContext = new LikePredicateContext(this.context, this.state);
        this.enterRule(localContext, 328, SparkSQLParser.RULE_likePredicate);
        let _la: number;
        try {
            this.state = 2463;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 292, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 2426;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 354) {
                    {
                    this.state = 2425;
                    this.match(SparkSQLParser.KW_NOT);
                    }
                }

                this.state = 2428;
                localContext._kind = this.match(SparkSQLParser.KW_LIKE);
                this.state = 2429;
                localContext._quantifier = this.tokenStream.LT(1);
                _la = this.tokenStream.LA(1);
                if(!(_la === 205 || _la === 209)) {
                    localContext._quantifier = this.errorHandler.recoverInline(this);
                }
                else {
                    this.errorHandler.reportMatch(this);
                    this.consume();
                }
                this.state = 2443;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 287, this.context) ) {
                case 1:
                    {
                    this.state = 2430;
                    this.match(SparkSQLParser.LR_BRACKET);
                    this.state = 2431;
                    this.match(SparkSQLParser.RR_BRACKET);
                    }
                    break;
                case 2:
                    {
                    this.state = 2432;
                    this.match(SparkSQLParser.LR_BRACKET);
                    this.state = 2433;
                    this.expression();
                    this.state = 2438;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                    while (_la === 480) {
                        {
                        {
                        this.state = 2434;
                        this.match(SparkSQLParser.COMMA);
                        this.state = 2435;
                        this.expression();
                        }
                        }
                        this.state = 2440;
                        this.errorHandler.sync(this);
                        _la = this.tokenStream.LA(1);
                    }
                    this.state = 2441;
                    this.match(SparkSQLParser.RR_BRACKET);
                    }
                    break;
                }
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 2446;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 354) {
                    {
                    this.state = 2445;
                    this.match(SparkSQLParser.KW_NOT);
                    }
                }

                this.state = 2448;
                localContext._kind = this.tokenStream.LT(1);
                _la = this.tokenStream.LA(1);
                if(!(_la === 334 || _la === 395)) {
                    localContext._kind = this.errorHandler.recoverInline(this);
                }
                else {
                    this.errorHandler.reportMatch(this);
                    this.consume();
                }
                this.state = 2449;
                localContext._pattern = this.valueExpression(0);
                this.state = 2452;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 289, this.context) ) {
                case 1:
                    {
                    this.state = 2450;
                    this.match(SparkSQLParser.KW_ESCAPE);
                    this.state = 2451;
                    this.stringLiteral();
                    }
                    break;
                }
                }
                break;
            case 3:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 2455;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 354) {
                    {
                    this.state = 2454;
                    this.match(SparkSQLParser.KW_NOT);
                    }
                }

                this.state = 2457;
                _la = this.tokenStream.LA(1);
                if(!(_la === 390 || _la === 395)) {
                this.errorHandler.recoverInline(this);
                }
                else {
                    this.errorHandler.reportMatch(this);
                    this.consume();
                }
                this.state = 2458;
                this.stringLiteral();
                this.state = 2461;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 291, this.context) ) {
                case 1:
                    {
                    this.state = 2459;
                    this.match(SparkSQLParser.KW_ESCAPE);
                    this.state = 2460;
                    this.stringLiteral();
                    }
                    break;
                }
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }

    public valueExpression(): ValueExpressionContext;
    public valueExpression(_p: number): ValueExpressionContext;
    public valueExpression(_p?: number): ValueExpressionContext {
        if (_p === undefined) {
            _p = 0;
        }

        let parentContext = this.context;
        let parentState = this.state;
        let localContext = new ValueExpressionContext(this.context, parentState);
        let previousContext = localContext;
        let _startState = 330;
        this.enterRecursionRule(localContext, 330, SparkSQLParser.RULE_valueExpression, _p);
        let _la: number;
        try {
            let alternative: number;
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2469;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 293, this.context) ) {
            case 1:
                {
                localContext = new ValueExpressionDefaultContext(localContext);
                this.context = localContext;
                previousContext = localContext;

                this.state = 2466;
                this.primaryExpression(0);
                }
                break;
            case 2:
                {
                localContext = new ArithmeticUnaryContext(localContext);
                this.context = localContext;
                previousContext = localContext;
                this.state = 2467;
                (localContext as ArithmeticUnaryContext)._operator = this.tokenStream.LT(1);
                _la = this.tokenStream.LA(1);
                if(!(((((_la - 465)) & ~0x1F) === 0 && ((1 << (_la - 465)) & 100663297) !== 0))) {
                    (localContext as ArithmeticUnaryContext)._operator = this.errorHandler.recoverInline(this);
                }
                else {
                    this.errorHandler.reportMatch(this);
                    this.consume();
                }
                this.state = 2468;
                this.valueExpression(7);
                }
                break;
            }
            this.context!.stop = this.tokenStream.LT(-1);
            this.state = 2492;
            this.errorHandler.sync(this);
            alternative = this.interpreter.adaptivePredict(this.tokenStream, 295, this.context);
            while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {
                if (alternative === 1) {
                    if (this.parseListeners != null) {
                        this.triggerExitRuleEvent();
                    }
                    previousContext = localContext;
                    {
                    this.state = 2490;
                    this.errorHandler.sync(this);
                    switch (this.interpreter.adaptivePredict(this.tokenStream, 294, this.context) ) {
                    case 1:
                        {
                        localContext = new ArithmeticBinaryContext(new ValueExpressionContext(parentContext, parentState));
                        (localContext as ArithmeticBinaryContext)._left = previousContext;
                        this.pushNewRecursionContext(localContext, _startState, SparkSQLParser.RULE_valueExpression);
                        this.state = 2471;
                        if (!(this.precpred(this.context, 6))) {
                            throw this.createFailedPredicateException("this.precpred(this.context, 6)");
                        }
                        this.state = 2472;
                        (localContext as ArithmeticBinaryContext)._operator = this.tokenStream.LT(1);
                        _la = this.tokenStream.LA(1);
                        if(!(_la === 39 || ((((_la - 488)) & ~0x1F) === 0 && ((1 << (_la - 488)) & 145) !== 0))) {
                            (localContext as ArithmeticBinaryContext)._operator = this.errorHandler.recoverInline(this);
                        }
                        else {
                            this.errorHandler.reportMatch(this);
                            this.consume();
                        }
                        this.state = 2473;
                        (localContext as ArithmeticBinaryContext)._right = this.valueExpression(7);
                        }
                        break;
                    case 2:
                        {
                        localContext = new ArithmeticBinaryContext(new ValueExpressionContext(parentContext, parentState));
                        (localContext as ArithmeticBinaryContext)._left = previousContext;
                        this.pushNewRecursionContext(localContext, _startState, SparkSQLParser.RULE_valueExpression);
                        this.state = 2474;
                        if (!(this.precpred(this.context, 5))) {
                            throw this.createFailedPredicateException("this.precpred(this.context, 5)");
                        }
                        this.state = 2475;
                        (localContext as ArithmeticBinaryContext)._operator = this.tokenStream.LT(1);
                        _la = this.tokenStream.LA(1);
                        if(!(((((_la - 490)) & ~0x1F) === 0 && ((1 << (_la - 490)) & 11) !== 0))) {
                            (localContext as ArithmeticBinaryContext)._operator = this.errorHandler.recoverInline(this);
                        }
                        else {
                            this.errorHandler.reportMatch(this);
                            this.consume();
                        }
                        this.state = 2476;
                        (localContext as ArithmeticBinaryContext)._right = this.valueExpression(6);
                        }
                        break;
                    case 3:
                        {
                        localContext = new ArithmeticBinaryContext(new ValueExpressionContext(parentContext, parentState));
                        (localContext as ArithmeticBinaryContext)._left = previousContext;
                        this.pushNewRecursionContext(localContext, _startState, SparkSQLParser.RULE_valueExpression);
                        this.state = 2477;
                        if (!(this.precpred(this.context, 4))) {
                            throw this.createFailedPredicateException("this.precpred(this.context, 4)");
                        }
                        this.state = 2478;
                        (localContext as ArithmeticBinaryContext)._operator = this.match(SparkSQLParser.BIT_AND_OP);
                        this.state = 2479;
                        (localContext as ArithmeticBinaryContext)._right = this.valueExpression(5);
                        }
                        break;
                    case 4:
                        {
                        localContext = new ArithmeticBinaryContext(new ValueExpressionContext(parentContext, parentState));
                        (localContext as ArithmeticBinaryContext)._left = previousContext;
                        this.pushNewRecursionContext(localContext, _startState, SparkSQLParser.RULE_valueExpression);
                        this.state = 2480;
                        if (!(this.precpred(this.context, 3))) {
                            throw this.createFailedPredicateException("this.precpred(this.context, 3)");
                        }
                        this.state = 2481;
                        (localContext as ArithmeticBinaryContext)._operator = this.match(SparkSQLParser.BIT_XOR_OP);
                        this.state = 2482;
                        (localContext as ArithmeticBinaryContext)._right = this.valueExpression(4);
                        }
                        break;
                    case 5:
                        {
                        localContext = new OrContext(new ValueExpressionContext(parentContext, parentState));
                        (localContext as OrContext)._left = previousContext;
                        this.pushNewRecursionContext(localContext, _startState, SparkSQLParser.RULE_valueExpression);
                        this.state = 2483;
                        if (!(this.precpred(this.context, 2))) {
                            throw this.createFailedPredicateException("this.precpred(this.context, 2)");
                        }
                        this.state = 2484;
                        (localContext as OrContext)._operator = this.match(SparkSQLParser.BIT_OR_OP);
                        this.state = 2485;
                        (localContext as OrContext)._right = this.valueExpression(3);
                        }
                        break;
                    case 6:
                        {
                        localContext = new ComparisonContext(new ValueExpressionContext(parentContext, parentState));
                        (localContext as ComparisonContext)._left = previousContext;
                        this.pushNewRecursionContext(localContext, _startState, SparkSQLParser.RULE_valueExpression);
                        this.state = 2486;
                        if (!(this.precpred(this.context, 1))) {
                            throw this.createFailedPredicateException("this.precpred(this.context, 1)");
                        }
                        this.state = 2487;
                        (localContext as ComparisonContext)._operator = this.comparisonOperator();
                        this.state = 2488;
                        (localContext as ComparisonContext)._right = this.valueExpression(2);
                        }
                        break;
                    }
                    }
                }
                this.state = 2494;
                this.errorHandler.sync(this);
                alternative = this.interpreter.adaptivePredict(this.tokenStream, 295, this.context);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.unrollRecursionContexts(parentContext);
        }
        return localContext;
    }

    public primaryExpression(): PrimaryExpressionContext;
    public primaryExpression(_p: number): PrimaryExpressionContext;
    public primaryExpression(_p?: number): PrimaryExpressionContext {
        if (_p === undefined) {
            _p = 0;
        }

        let parentContext = this.context;
        let parentState = this.state;
        let localContext = new PrimaryExpressionContext(this.context, parentState);
        let previousContext = localContext;
        let _startState = 332;
        this.enterRecursionRule(localContext, 332, SparkSQLParser.RULE_primaryExpression, _p);
        let _la: number;
        try {
            let alternative: number;
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2627;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 309, this.context) ) {
            case 1:
                {
                localContext = new SearchedCaseContext(localContext);
                this.context = localContext;
                previousContext = localContext;

                this.state = 2496;
                this.match(SparkSQLParser.KW_CASE);
                this.state = 2498;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                do {
                    {
                    {
                    this.state = 2497;
                    this.whenClause();
                    }
                    }
                    this.state = 2500;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                } while (_la === 450);
                this.state = 2504;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 278) {
                    {
                    this.state = 2502;
                    this.match(SparkSQLParser.KW_ELSE);
                    this.state = 2503;
                    (localContext as SearchedCaseContext)._elseExpression = this.expression();
                    }
                }

                this.state = 2506;
                this.match(SparkSQLParser.KW_END);
                }
                break;
            case 2:
                {
                localContext = new SimpleCaseContext(localContext);
                this.context = localContext;
                previousContext = localContext;
                this.state = 2508;
                this.match(SparkSQLParser.KW_CASE);
                this.state = 2509;
                (localContext as SimpleCaseContext)._value = this.expression();
                this.state = 2511;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                do {
                    {
                    {
                    this.state = 2510;
                    this.whenClause();
                    }
                    }
                    this.state = 2513;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                } while (_la === 450);
                this.state = 2517;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 278) {
                    {
                    this.state = 2515;
                    this.match(SparkSQLParser.KW_ELSE);
                    this.state = 2516;
                    (localContext as SimpleCaseContext)._elseExpression = this.expression();
                    }
                }

                this.state = 2519;
                this.match(SparkSQLParser.KW_END);
                }
                break;
            case 3:
                {
                localContext = new CastContext(localContext);
                this.context = localContext;
                previousContext = localContext;
                this.state = 2521;
                this.match(SparkSQLParser.KW_CAST);
                this.state = 2522;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 2523;
                this.expression();
                this.state = 2524;
                this.match(SparkSQLParser.KW_AS);
                this.state = 2525;
                this.columnType();
                this.state = 2526;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case 4:
                {
                localContext = new FirstContext(localContext);
                this.context = localContext;
                previousContext = localContext;
                this.state = 2528;
                this.match(SparkSQLParser.KW_FIRST);
                this.state = 2529;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 2530;
                this.expression();
                this.state = 2533;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 69) {
                    {
                    this.state = 2531;
                    this.match(SparkSQLParser.KW_IGNORE);
                    this.state = 2532;
                    this.match(SparkSQLParser.KW_NULLS);
                    }
                }

                this.state = 2535;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case 5:
                {
                localContext = new LastContext(localContext);
                this.context = localContext;
                previousContext = localContext;
                this.state = 2537;
                this.match(SparkSQLParser.KW_LAST);
                this.state = 2538;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 2539;
                this.expression();
                this.state = 2542;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 69) {
                    {
                    this.state = 2540;
                    this.match(SparkSQLParser.KW_IGNORE);
                    this.state = 2541;
                    this.match(SparkSQLParser.KW_NULLS);
                    }
                }

                this.state = 2544;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case 6:
                {
                localContext = new PositionContext(localContext);
                this.context = localContext;
                previousContext = localContext;
                this.state = 2546;
                this.match(SparkSQLParser.KW_POSITION);
                this.state = 2547;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 2548;
                (localContext as PositionContext)._substr = this.valueExpression(0);
                this.state = 2549;
                this.match(SparkSQLParser.KW_IN);
                this.state = 2550;
                (localContext as PositionContext)._str = this.valueExpression(0);
                this.state = 2551;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case 7:
                {
                localContext = new ConstantDefaultContext(localContext);
                this.context = localContext;
                previousContext = localContext;
                this.state = 2553;
                this.constant();
                }
                break;
            case 8:
                {
                localContext = new StarContext(localContext);
                this.context = localContext;
                previousContext = localContext;
                this.state = 2554;
                this.match(SparkSQLParser.ASTERISK_SIGN);
                }
                break;
            case 9:
                {
                localContext = new StarContext(localContext);
                this.context = localContext;
                previousContext = localContext;
                this.state = 2555;
                this.uid();
                this.state = 2556;
                this.match(SparkSQLParser.DOT);
                this.state = 2557;
                this.match(SparkSQLParser.ASTERISK_SIGN);
                }
                break;
            case 10:
                {
                localContext = new SubqueryExpressionContext(localContext);
                this.context = localContext;
                previousContext = localContext;
                this.state = 2559;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 2560;
                this.queryStatement(0);
                this.state = 2561;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case 11:
                {
                localContext = new ValuesContext(localContext);
                this.context = localContext;
                previousContext = localContext;
                this.state = 2563;
                this.match(SparkSQLParser.LR_BRACKET);
                {
                this.state = 2564;
                this.functionParam();
                this.state = 2569;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                while (_la === 480) {
                    {
                    {
                    this.state = 2565;
                    this.match(SparkSQLParser.COMMA);
                    this.state = 2566;
                    this.functionParam();
                    }
                    }
                    this.state = 2571;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                }
                }
                this.state = 2572;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case 12:
                {
                localContext = new FunctionCallContext(localContext);
                this.context = localContext;
                previousContext = localContext;
                this.state = 2574;
                this.functionName();
                this.state = 2575;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 2587;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if ((((_la) & ~0x1F) === 0 && ((1 << _la) & 4294684608) !== 0) || ((((_la - 32)) & ~0x1F) === 0 && ((1 << (_la - 32)) & 4293918715) !== 0) || ((((_la - 64)) & ~0x1F) === 0 && ((1 << (_la - 64)) & 4185849791) !== 0) || ((((_la - 96)) & ~0x1F) === 0 && ((1 << (_la - 96)) & 4294967263) !== 0) || ((((_la - 128)) & ~0x1F) === 0 && ((1 << (_la - 128)) & 3757047707) !== 0) || ((((_la - 160)) & ~0x1F) === 0 && ((1 << (_la - 160)) & 4252958679) !== 0) || ((((_la - 192)) & ~0x1F) === 0 && ((1 << (_la - 192)) & 2156412927) !== 0) || ((((_la - 230)) & ~0x1F) === 0 && ((1 << (_la - 230)) & 2685932551) !== 0) || ((((_la - 271)) & ~0x1F) === 0 && ((1 << (_la - 271)) & 70336513) !== 0) || ((((_la - 303)) & ~0x1F) === 0 && ((1 << (_la - 303)) & 2030075921) !== 0) || ((((_la - 338)) & ~0x1F) === 0 && ((1 << (_la - 338)) & 2148205697) !== 0) || ((((_la - 375)) & ~0x1F) === 0 && ((1 << (_la - 375)) & 42494055) !== 0) || ((((_la - 414)) & ~0x1F) === 0 && ((1 << (_la - 414)) & 276029453) !== 0) || ((((_la - 456)) & ~0x1F) === 0 && ((1 << (_la - 456)) & 135266817) !== 0) || ((((_la - 488)) & ~0x1F) === 0 && ((1 << (_la - 488)) & 15373) !== 0)) {
                    {
                    this.state = 2577;
                    this.errorHandler.sync(this);
                    switch (this.interpreter.adaptivePredict(this.tokenStream, 303, this.context) ) {
                    case 1:
                        {
                        this.state = 2576;
                        this.setQuantifier();
                        }
                        break;
                    }
                    this.state = 2579;
                    this.functionParam();
                    this.state = 2584;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                    while (_la === 480) {
                        {
                        {
                        this.state = 2580;
                        this.match(SparkSQLParser.COMMA);
                        this.state = 2581;
                        this.functionParam();
                        }
                        }
                        this.state = 2586;
                        this.errorHandler.sync(this);
                        _la = this.tokenStream.LA(1);
                    }
                    }
                }

                this.state = 2589;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case 13:
                {
                localContext = new FunctionCallContext(localContext);
                this.context = localContext;
                previousContext = localContext;
                this.state = 2591;
                this.functionName();
                this.state = 2592;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 2593;
                this.functionParam();
                this.state = 2594;
                this.match(SparkSQLParser.KW_TO);
                this.state = 2595;
                this.functionParam();
                this.state = 2596;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case 14:
                {
                localContext = new FunctionCallFilterContext(localContext);
                this.context = localContext;
                previousContext = localContext;
                this.state = 2598;
                this.functionName();
                this.state = 2599;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 2601;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 306, this.context) ) {
                case 1:
                    {
                    this.state = 2600;
                    this.setQuantifier();
                    }
                    break;
                }
                this.state = 2603;
                this.functionParam();
                this.state = 2604;
                this.match(SparkSQLParser.RR_BRACKET);
                this.state = 2606;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 307, this.context) ) {
                case 1:
                    {
                    this.state = 2605;
                    this.filterClause();
                    }
                    break;
                }
                }
                break;
            case 15:
                {
                localContext = new AggregateFunctionsContext(localContext);
                this.context = localContext;
                previousContext = localContext;
                this.state = 2608;
                this.funtionBody();
                this.state = 2609;
                this.filterPart();
                }
                break;
            case 16:
                {
                localContext = new OrderSetAggregateFunctionsContext(localContext);
                this.context = localContext;
                previousContext = localContext;
                this.state = 2611;
                this.funtionBody();
                this.state = 2612;
                this.match(SparkSQLParser.KW_WITHIN);
                this.state = 2613;
                this.match(SparkSQLParser.KW_GROUP);
                this.state = 2614;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 2615;
                this.orderByCaluse();
                this.state = 2616;
                this.match(SparkSQLParser.RR_BRACKET);
                this.state = 2618;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 308, this.context) ) {
                case 1:
                    {
                    this.state = 2617;
                    this.filterPart();
                    }
                    break;
                }
                }
                break;
            case 17:
                {
                localContext = new ColumnReferenceContext(localContext);
                this.context = localContext;
                previousContext = localContext;
                this.state = 2620;
                this.identifier();
                }
                break;
            case 18:
                {
                localContext = new UidForColumnNameContext(localContext);
                this.context = localContext;
                previousContext = localContext;
                this.state = 2621;
                this.uid();
                }
                break;
            case 19:
                {
                localContext = new ParenthesizedExpressionContext(localContext);
                this.context = localContext;
                previousContext = localContext;
                this.state = 2622;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 2623;
                this.expression();
                this.state = 2624;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case 20:
                {
                localContext = new ComplexDataTypeFieldExpressionContext(localContext);
                this.context = localContext;
                previousContext = localContext;
                this.state = 2626;
                this.complexDataTypeExpression();
                }
                break;
            }
            this.context!.stop = this.tokenStream.LT(-1);
            this.state = 2636;
            this.errorHandler.sync(this);
            alternative = this.interpreter.adaptivePredict(this.tokenStream, 310, this.context);
            while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {
                if (alternative === 1) {
                    if (this.parseListeners != null) {
                        this.triggerExitRuleEvent();
                    }
                    previousContext = localContext;
                    {
                    {
                    localContext = new SubscriptContext(new PrimaryExpressionContext(parentContext, parentState));
                    (localContext as SubscriptContext)._value = previousContext;
                    this.pushNewRecursionContext(localContext, _startState, SparkSQLParser.RULE_primaryExpression);
                    this.state = 2629;
                    if (!(this.precpred(this.context, 5))) {
                        throw this.createFailedPredicateException("this.precpred(this.context, 5)");
                    }
                    this.state = 2630;
                    this.match(SparkSQLParser.LS_BRACKET);
                    this.state = 2631;
                    (localContext as SubscriptContext)._index = this.valueExpression(0);
                    this.state = 2632;
                    this.match(SparkSQLParser.RS_BRACKET);
                    }
                    }
                }
                this.state = 2638;
                this.errorHandler.sync(this);
                alternative = this.interpreter.adaptivePredict(this.tokenStream, 310, this.context);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.unrollRecursionContexts(parentContext);
        }
        return localContext;
    }
    public complexDataTypeExpression(): ComplexDataTypeExpressionContext {
        let localContext = new ComplexDataTypeExpressionContext(this.context, this.state);
        this.enterRule(localContext, 334, SparkSQLParser.RULE_complexDataTypeExpression);
        try {
            this.state = 2643;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.KW_ARRAY:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 2639;
                this.arrayExpression();
                }
                break;
            case SparkSQLParser.KW_ROW:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 2640;
                this.rowExpression();
                }
                break;
            case SparkSQLParser.KW_MAP:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 2641;
                this.mapExpression();
                }
                break;
            case SparkSQLParser.KW_STRUCT:
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 2642;
                this.structExpression();
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public arrayExpression(): ArrayExpressionContext {
        let localContext = new ArrayExpressionContext(this.context, this.state);
        this.enterRule(localContext, 336, SparkSQLParser.RULE_arrayExpression);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2645;
            this.match(SparkSQLParser.KW_ARRAY);
            this.state = 2646;
            this.match(SparkSQLParser.LS_BRACKET);
            this.state = 2647;
            this.dataTypeExpression();
            this.state = 2652;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 480) {
                {
                {
                this.state = 2648;
                this.match(SparkSQLParser.COMMA);
                this.state = 2649;
                this.dataTypeExpression();
                }
                }
                this.state = 2654;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 2655;
            this.match(SparkSQLParser.RS_BRACKET);
            this.state = 2656;
            this.match(SparkSQLParser.KW_ARRAY);
            this.state = 2657;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 2658;
            this.dataTypeExpression();
            this.state = 2663;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 480) {
                {
                {
                this.state = 2659;
                this.match(SparkSQLParser.COMMA);
                this.state = 2660;
                this.dataTypeExpression();
                }
                }
                this.state = 2665;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 2666;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public structExpression(): StructExpressionContext {
        let localContext = new StructExpressionContext(this.context, this.state);
        this.enterRule(localContext, 338, SparkSQLParser.RULE_structExpression);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2668;
            this.match(SparkSQLParser.KW_STRUCT);
            this.state = 2669;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 2670;
            this.dataTypeExpression();
            this.state = 2675;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 480) {
                {
                {
                this.state = 2671;
                this.match(SparkSQLParser.COMMA);
                this.state = 2672;
                this.dataTypeExpression();
                }
                }
                this.state = 2677;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 2678;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public rowExpression(): RowExpressionContext {
        let localContext = new RowExpressionContext(this.context, this.state);
        this.enterRule(localContext, 340, SparkSQLParser.RULE_rowExpression);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2680;
            this.match(SparkSQLParser.KW_ROW);
            this.state = 2681;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 2682;
            this.dataTypeExpression();
            this.state = 2687;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 480) {
                {
                {
                this.state = 2683;
                this.match(SparkSQLParser.COMMA);
                this.state = 2684;
                this.dataTypeExpression();
                }
                }
                this.state = 2689;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 2690;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public mapExpression(): MapExpressionContext {
        let localContext = new MapExpressionContext(this.context, this.state);
        this.enterRule(localContext, 342, SparkSQLParser.RULE_mapExpression);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2692;
            this.match(SparkSQLParser.KW_MAP);
            this.state = 2693;
            this.match(SparkSQLParser.LS_BRACKET);
            this.state = 2694;
            this.dataTypeExpression();
            this.state = 2695;
            this.match(SparkSQLParser.COMMA);
            this.state = 2696;
            this.dataTypeExpression();
            this.state = 2697;
            this.match(SparkSQLParser.RS_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public dataTypeExpression(): DataTypeExpressionContext {
        let localContext = new DataTypeExpressionContext(this.context, this.state);
        this.enterRule(localContext, 344, SparkSQLParser.RULE_dataTypeExpression);
        try {
            this.state = 2703;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 316, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 2699;
                this.columnAlias();
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 2700;
                this.constant();
                }
                break;
            case 3:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 2701;
                this.complexDataTypeExpression();
                }
                break;
            case 4:
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 2702;
                this.sqlSimpleType();
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public sqlSimpleType(): SqlSimpleTypeContext {
        let localContext = new SqlSimpleTypeContext(this.context, this.state);
        this.enterRule(localContext, 346, SparkSQLParser.RULE_sqlSimpleType);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2705;
            _la = this.tokenStream.LA(1);
            if(!(_la === 12 || _la === 90 || _la === 133 || _la === 157 || _la === 175 || _la === 176 || _la === 218 || _la === 222 || ((((_la - 259)) & ~0x1F) === 0 && ((1 << (_la - 259)) & 65553) !== 0) || ((((_la - 293)) & ~0x1F) === 0 && ((1 << (_la - 293)) & 12582913) !== 0) || _la === 358 || ((((_la - 410)) & ~0x1F) === 0 && ((1 << (_la - 410)) & 4587521) !== 0))) {
            this.errorHandler.recoverInline(this);
            }
            else {
                this.errorHandler.reportMatch(this);
                this.consume();
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public functionName(): FunctionNameContext {
        let localContext = new FunctionNameContext(this.context, this.state);
        this.enterRule(localContext, 348, SparkSQLParser.RULE_functionName);
        try {
            this.state = 2710;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 317, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 2707;
                this.nonReservedKeywords();
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 2708;
                this.uid();
                }
                break;
            case 3:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 2709;
                this.reservedKeywordsUsedAsFuncName();
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public functionParam(): FunctionParamContext {
        let localContext = new FunctionParamContext(this.context, this.state);
        this.enterRule(localContext, 350, SparkSQLParser.RULE_functionParam);
        try {
            this.state = 2718;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 318, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 2712;
                this.reservedKeywordsUsedAsFuncParam();
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 2713;
                this.timeIntervalUnit();
                }
                break;
            case 3:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 2714;
                this.timePointUnit();
                }
                break;
            case 4:
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 2715;
                this.expression();
                }
                break;
            case 5:
                this.enterOuterAlt(localContext, 5);
                {
                this.state = 2716;
                this.filterClause();
                }
                break;
            case 6:
                this.enterOuterAlt(localContext, 6);
                {
                this.state = 2717;
                this.constant();
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public filterClause(): FilterClauseContext {
        let localContext = new FilterClauseContext(this.context, this.state);
        this.enterRule(localContext, 352, SparkSQLParser.RULE_filterClause);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2720;
            this.match(SparkSQLParser.KW_FILTER);
            this.state = 2721;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 2722;
            this.match(SparkSQLParser.KW_WHERE);
            this.state = 2723;
            this.booleanExpression(0);
            this.state = 2724;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public correlationName(): CorrelationNameContext {
        let localContext = new CorrelationNameContext(this.context, this.state);
        this.enterRule(localContext, 354, SparkSQLParser.RULE_correlationName);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2726;
            this.identifier();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public qualifiedName(): QualifiedNameContext {
        let localContext = new QualifiedNameContext(this.context, this.state);
        this.enterRule(localContext, 356, SparkSQLParser.RULE_qualifiedName);
        try {
            this.state = 2731;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 319, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 2728;
                this.identifier();
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 2729;
                this.uid();
                }
                break;
            case 3:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 2730;
                this.unquotedAnyString();
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public timeIntervalExpression(): TimeIntervalExpressionContext {
        let localContext = new TimeIntervalExpressionContext(this.context, this.state);
        this.enterRule(localContext, 358, SparkSQLParser.RULE_timeIntervalExpression);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2733;
            this.match(SparkSQLParser.KW_INTERVAL);
            this.state = 2736;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 320, this.context) ) {
            case 1:
                {
                this.state = 2734;
                this.errorCapturingMultiUnitsInterval();
                }
                break;
            case 2:
                {
                this.state = 2735;
                this.errorCapturingUnitToUnitInterval();
                }
                break;
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public errorCapturingMultiUnitsInterval(): ErrorCapturingMultiUnitsIntervalContext {
        let localContext = new ErrorCapturingMultiUnitsIntervalContext(this.context, this.state);
        this.enterRule(localContext, 360, SparkSQLParser.RULE_errorCapturingMultiUnitsInterval);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2738;
            this.multiUnitsInterval();
            this.state = 2740;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 321, this.context) ) {
            case 1:
                {
                this.state = 2739;
                this.unitToUnitInterval();
                }
                break;
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public multiUnitsInterval(): MultiUnitsIntervalContext {
        let localContext = new MultiUnitsIntervalContext(this.context, this.state);
        this.enterRule(localContext, 362, SparkSQLParser.RULE_multiUnitsInterval);
        try {
            let alternative: number;
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2745;
            this.errorHandler.sync(this);
            alternative = 1;
            do {
                switch (alternative) {
                case 1:
                    {
                    {
                    this.state = 2742;
                    this.intervalValue();
                    this.state = 2743;
                    this.timeIntervalUnit();
                    }
                    }
                    break;
                default:
                    throw new antlr.NoViableAltException(this);
                }
                this.state = 2747;
                this.errorHandler.sync(this);
                alternative = this.interpreter.adaptivePredict(this.tokenStream, 322, this.context);
            } while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public errorCapturingUnitToUnitInterval(): ErrorCapturingUnitToUnitIntervalContext {
        let localContext = new ErrorCapturingUnitToUnitIntervalContext(this.context, this.state);
        this.enterRule(localContext, 364, SparkSQLParser.RULE_errorCapturingUnitToUnitInterval);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2749;
            localContext._body = this.unitToUnitInterval();
            this.state = 2752;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 323, this.context) ) {
            case 1:
                {
                this.state = 2750;
                localContext._error1 = this.multiUnitsInterval();
                }
                break;
            case 2:
                {
                this.state = 2751;
                localContext._error2 = this.unitToUnitInterval();
                }
                break;
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public unitToUnitInterval(): UnitToUnitIntervalContext {
        let localContext = new UnitToUnitIntervalContext(this.context, this.state);
        this.enterRule(localContext, 366, SparkSQLParser.RULE_unitToUnitInterval);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2754;
            localContext._value = this.intervalValue();
            this.state = 2755;
            localContext._from_ = this.timeIntervalUnit();
            this.state = 2756;
            this.match(SparkSQLParser.KW_TO);
            this.state = 2757;
            localContext._to = this.timeIntervalUnit();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public intervalValue(): IntervalValueContext {
        let localContext = new IntervalValueContext(this.context, this.state);
        this.enterRule(localContext, 368, SparkSQLParser.RULE_intervalValue);
        let _la: number;
        try {
            this.state = 2764;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.HYPNEN_SIGN:
            case SparkSQLParser.ADD_SIGN:
            case SparkSQLParser.DIG_LITERAL:
            case SparkSQLParser.REAL_LITERAL:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 2760;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 490 || _la === 491) {
                    {
                    this.state = 2759;
                    _la = this.tokenStream.LA(1);
                    if(!(_la === 490 || _la === 491)) {
                    this.errorHandler.recoverInline(this);
                    }
                    else {
                        this.errorHandler.reportMatch(this);
                        this.consume();
                    }
                    }
                }

                this.state = 2762;
                _la = this.tokenStream.LA(1);
                if(!(_la === 499 || _la === 500)) {
                this.errorHandler.recoverInline(this);
                }
                else {
                    this.errorHandler.reportMatch(this);
                    this.consume();
                }
                }
                break;
            case SparkSQLParser.STRING_LITERAL:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 2763;
                this.match(SparkSQLParser.STRING_LITERAL);
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public columnAlias(): ColumnAliasContext {
        let localContext = new ColumnAliasContext(this.context, this.state);
        this.enterRule(localContext, 370, SparkSQLParser.RULE_columnAlias);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2766;
            this.anyAlias();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public tableAlias(): TableAliasContext {
        let localContext = new TableAliasContext(this.context, this.state);
        this.enterRule(localContext, 372, SparkSQLParser.RULE_tableAlias);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2768;
            this.anyAlias();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public anyAlias(): AnyAliasContext {
        let localContext = new AnyAliasContext(this.context, this.state);
        this.enterRule(localContext, 374, SparkSQLParser.RULE_anyAlias);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2771;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 212) {
                {
                this.state = 2770;
                this.match(SparkSQLParser.KW_AS);
                }
            }

            this.state = 2773;
            this.identifier();
            this.state = 2775;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 327, this.context) ) {
            case 1:
                {
                this.state = 2774;
                this.identifierList();
                }
                break;
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public errorCapturingIdentifier(): ErrorCapturingIdentifierContext {
        let localContext = new ErrorCapturingIdentifierContext(this.context, this.state);
        this.enterRule(localContext, 376, SparkSQLParser.RULE_errorCapturingIdentifier);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2777;
            this.identifier();
            this.state = 2778;
            this.errorCapturingIdentifierExtra();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public errorCapturingIdentifierExtra(): ErrorCapturingIdentifierExtraContext {
        let localContext = new ErrorCapturingIdentifierExtraContext(this.context, this.state);
        this.enterRule(localContext, 378, SparkSQLParser.RULE_errorCapturingIdentifierExtra);
        let _la: number;
        try {
            localContext = new ErrorIdentContext(localContext);
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2784;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 344) {
                {
                {
                this.state = 2780;
                this.match(SparkSQLParser.KW_MINUS);
                this.state = 2781;
                this.identifier();
                }
                }
                this.state = 2786;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public identifierList(): IdentifierListContext {
        let localContext = new IdentifierListContext(this.context, this.state);
        this.enterRule(localContext, 380, SparkSQLParser.RULE_identifierList);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2787;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 2788;
            this.identifierSeq();
            this.state = 2789;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public identifierSeq(): IdentifierSeqContext {
        let localContext = new IdentifierSeqContext(this.context, this.state);
        this.enterRule(localContext, 382, SparkSQLParser.RULE_identifierSeq);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2791;
            this.identifier();
            this.state = 2796;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 480) {
                {
                {
                this.state = 2792;
                this.match(SparkSQLParser.COMMA);
                this.state = 2793;
                this.identifier();
                }
                }
                this.state = 2798;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public identifier(): IdentifierContext {
        let localContext = new IdentifierContext(this.context, this.state);
        this.enterRule(localContext, 384, SparkSQLParser.RULE_identifier);
        try {
            this.state = 2803;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.DIG_LITERAL:
            case SparkSQLParser.ID_LITERAL:
                localContext = new UnquotedIdentifierAlternativeContext(localContext);
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 2799;
                this.unquotedIdentifier();
                }
                break;
            case SparkSQLParser.STRING_LITERAL:
                localContext = new QuotedIdentifierAlternativeContext(localContext);
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 2800;
                this.match(SparkSQLParser.STRING_LITERAL);
                }
                break;
            case SparkSQLParser.KW_ADD:
            case SparkSQLParser.KW_ADMIN:
            case SparkSQLParser.KW_AFTER:
            case SparkSQLParser.KW_ANALYZE:
            case SparkSQLParser.KW_ASC:
            case SparkSQLParser.KW_BEFORE:
            case SparkSQLParser.KW_BYTES:
            case SparkSQLParser.KW_CASCADE:
            case SparkSQLParser.KW_CATALOG:
            case SparkSQLParser.KW_CATALOGS:
            case SparkSQLParser.KW_CENTURY:
            case SparkSQLParser.KW_CHAIN:
            case SparkSQLParser.KW_CHANGELOG_MODE:
            case SparkSQLParser.KW_CHARACTERS:
            case SparkSQLParser.KW_COMMENT:
            case SparkSQLParser.KW_COMPACT:
            case SparkSQLParser.KW_COLUMNS:
            case SparkSQLParser.KW_CONSTRAINTS:
            case SparkSQLParser.KW_CONSTRUCTOR:
            case SparkSQLParser.KW_COMPUTE:
            case SparkSQLParser.KW_CUMULATE:
            case SparkSQLParser.KW_DATA:
            case SparkSQLParser.KW_DATABASE:
            case SparkSQLParser.KW_DATABASES:
            case SparkSQLParser.KW_DAYS:
            case SparkSQLParser.KW_DECADE:
            case SparkSQLParser.KW_DEFINED:
            case SparkSQLParser.KW_DESC:
            case SparkSQLParser.KW_DESCRIPTOR:
            case SparkSQLParser.KW_DIV:
            case SparkSQLParser.KW_ENCODING:
            case SparkSQLParser.KW_ENFORCED:
            case SparkSQLParser.KW_ENGINE:
            case SparkSQLParser.KW_ERROR:
            case SparkSQLParser.KW_ESTIMATED_COST:
            case SparkSQLParser.KW_EXCEPTION:
            case SparkSQLParser.KW_EXCLUDE:
            case SparkSQLParser.KW_EXCLUDING:
            case SparkSQLParser.KW_EXTENDED:
            case SparkSQLParser.KW_FILE:
            case SparkSQLParser.KW_FINAL:
            case SparkSQLParser.KW_FIRST:
            case SparkSQLParser.KW_FOLLOWING:
            case SparkSQLParser.KW_FORMAT:
            case SparkSQLParser.KW_FORTRAN:
            case SparkSQLParser.KW_FOUND:
            case SparkSQLParser.KW_FRAC_SECOND:
            case SparkSQLParser.KW_FUNCTIONS:
            case SparkSQLParser.KW_GENERAL:
            case SparkSQLParser.KW_GENERATED:
            case SparkSQLParser.KW_GO:
            case SparkSQLParser.KW_GOTO:
            case SparkSQLParser.KW_GRANTED:
            case SparkSQLParser.KW_HOP:
            case SparkSQLParser.KW_HOURS:
            case SparkSQLParser.KW_IF:
            case SparkSQLParser.KW_IGNORE:
            case SparkSQLParser.KW_INCREMENT:
            case SparkSQLParser.KW_INPUT:
            case SparkSQLParser.KW_INVOKER:
            case SparkSQLParser.KW_JAR:
            case SparkSQLParser.KW_JARS:
            case SparkSQLParser.KW_JAVA:
            case SparkSQLParser.KW_JSON:
            case SparkSQLParser.KW_JSON_EXECUTION_PLAN:
            case SparkSQLParser.KW_KEY:
            case SparkSQLParser.KW_KEY_MEMBER:
            case SparkSQLParser.KW_KEY_TYPE:
            case SparkSQLParser.KW_LABEL:
            case SparkSQLParser.KW_LAST:
            case SparkSQLParser.KW_LENGTH:
            case SparkSQLParser.KW_LEVEL:
            case SparkSQLParser.KW_LOAD:
            case SparkSQLParser.KW_MAP:
            case SparkSQLParser.KW_MICROSECOND:
            case SparkSQLParser.KW_MILLENNIUM:
            case SparkSQLParser.KW_MILLISECOND:
            case SparkSQLParser.KW_MINUTES:
            case SparkSQLParser.KW_MINVALUE:
            case SparkSQLParser.KW_MODIFY:
            case SparkSQLParser.KW_MODULES:
            case SparkSQLParser.KW_MONTHS:
            case SparkSQLParser.KW_NANOSECOND:
            case SparkSQLParser.KW_NULLS:
            case SparkSQLParser.KW_NUMBER:
            case SparkSQLParser.KW_OPTION:
            case SparkSQLParser.KW_OPTIONS:
            case SparkSQLParser.KW_ORDERING:
            case SparkSQLParser.KW_OUTPUT:
            case SparkSQLParser.KW_OVERWRITE:
            case SparkSQLParser.KW_OVERWRITING:
            case SparkSQLParser.KW_PARTITIONED:
            case SparkSQLParser.KW_PARTITIONS:
            case SparkSQLParser.KW_PASSING:
            case SparkSQLParser.KW_PAST:
            case SparkSQLParser.KW_PATH:
            case SparkSQLParser.KW_PLACING:
            case SparkSQLParser.KW_PLAN:
            case SparkSQLParser.KW_PRECEDING:
            case SparkSQLParser.KW_PRESERVE:
            case SparkSQLParser.KW_PRIOR:
            case SparkSQLParser.KW_PRIVILEGES:
            case SparkSQLParser.KW_PUBLIC:
            case SparkSQLParser.KW_PYTHON:
            case SparkSQLParser.KW_PYTHON_FILES:
            case SparkSQLParser.KW_PYTHON_REQUIREMENTS:
            case SparkSQLParser.KW_PYTHON_DEPENDENCIES:
            case SparkSQLParser.KW_PYTHON_JAR:
            case SparkSQLParser.KW_PYTHON_ARCHIVES:
            case SparkSQLParser.KW_PYTHON_PARAMETER:
            case SparkSQLParser.KW_QUARTER:
            case SparkSQLParser.KW_RAW:
            case SparkSQLParser.KW_READ:
            case SparkSQLParser.KW_RELATIVE:
            case SparkSQLParser.KW_REMOVE:
            case SparkSQLParser.KW_RENAME:
            case SparkSQLParser.KW_REPLACE:
            case SparkSQLParser.KW_RESPECT:
            case SparkSQLParser.KW_RESTART:
            case SparkSQLParser.KW_RESTRICT:
            case SparkSQLParser.KW_ROLE:
            case SparkSQLParser.KW_ROW_COUNT:
            case SparkSQLParser.KW_SCALA:
            case SparkSQLParser.KW_SCALAR:
            case SparkSQLParser.KW_SCALE:
            case SparkSQLParser.KW_SCHEMA:
            case SparkSQLParser.KW_SECONDS:
            case SparkSQLParser.KW_SECTION:
            case SparkSQLParser.KW_SECURITY:
            case SparkSQLParser.KW_SELF:
            case SparkSQLParser.KW_SERVER:
            case SparkSQLParser.KW_SERVER_NAME:
            case SparkSQLParser.KW_SESSION:
            case SparkSQLParser.KW_SETS:
            case SparkSQLParser.KW_SIMPLE:
            case SparkSQLParser.KW_SIZE:
            case SparkSQLParser.KW_SLIDE:
            case SparkSQLParser.KW_SOURCE:
            case SparkSQLParser.KW_SPACE:
            case SparkSQLParser.KW_STATE:
            case SparkSQLParser.KW_STATEMENT:
            case SparkSQLParser.KW_STEP:
            case SparkSQLParser.KW_STRING:
            case SparkSQLParser.KW_STRUCTURE:
            case SparkSQLParser.KW_STYLE:
            case SparkSQLParser.KW_TABLES:
            case SparkSQLParser.KW_TEMPORARY:
            case SparkSQLParser.KW_TIMECOL:
            case SparkSQLParser.KW_FLOOR:
            case SparkSQLParser.KW_TIMESTAMP_LTZ:
            case SparkSQLParser.KW_TIMESTAMPADD:
            case SparkSQLParser.KW_TIMESTAMPDIFF:
            case SparkSQLParser.KW_TOTIMESTAMP:
            case SparkSQLParser.KW_TRANSFORM:
            case SparkSQLParser.KW_TUMBLE:
            case SparkSQLParser.KW_TYPE:
            case SparkSQLParser.KW_UNDER:
            case SparkSQLParser.KW_UNLOAD:
            case SparkSQLParser.KW_USAGE:
            case SparkSQLParser.KW_USE:
            case SparkSQLParser.KW_UTF16:
            case SparkSQLParser.KW_UTF32:
            case SparkSQLParser.KW_UTF8:
            case SparkSQLParser.KW_VERSION:
            case SparkSQLParser.KW_VIEW:
            case SparkSQLParser.KW_VIEWS:
            case SparkSQLParser.KW_VIRTUAL:
            case SparkSQLParser.KW_WATERMARK:
            case SparkSQLParser.KW_WATERMARKS:
            case SparkSQLParser.KW_WEEK:
            case SparkSQLParser.KW_WORK:
            case SparkSQLParser.KW_WRAPPER:
            case SparkSQLParser.KW_YEARS:
            case SparkSQLParser.KW_ZONE:
            case SparkSQLParser.KW_LOCALTIMESTAMP:
                localContext = new NonReservedKeywordsAlternativeContext(localContext);
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 2801;
                this.nonReservedKeywords();
                }
                break;
            case SparkSQLParser.DOLLAR:
                localContext = new UrefVarAlternativeContext(localContext);
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 2802;
                this.refVar();
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public unquotedAnyString(): UnquotedAnyStringContext {
        let localContext = new UnquotedAnyStringContext(this.context, this.state);
        this.enterRule(localContext, 386, SparkSQLParser.RULE_unquotedAnyString);
        try {
            this.state = 2809;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 331, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 2805;
                this.unquotedIdentifier();
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 2806;
                this.reservedKeywordsUsedAsFuncParam();
                }
                break;
            case 3:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 2807;
                this.nonReservedKeywords();
                }
                break;
            case 4:
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 2808;
                this.reservedKeywordsUsedAsFuncName();
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public refVar(): RefVarContext {
        let localContext = new RefVarContext(this.context, this.state);
        this.enterRule(localContext, 388, SparkSQLParser.RULE_refVar);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2811;
            this.match(SparkSQLParser.DOLLAR);
            this.state = 2812;
            this.match(SparkSQLParser.LB_BRACKET);
            this.state = 2813;
            this.unquotedIdentifier();
            this.state = 2814;
            this.match(SparkSQLParser.RB_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public unquotedIdentifier(): UnquotedIdentifierContext {
        let localContext = new UnquotedIdentifierContext(this.context, this.state);
        this.enterRule(localContext, 390, SparkSQLParser.RULE_unquotedIdentifier);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2816;
            _la = this.tokenStream.LA(1);
            if(!(_la === 499 || _la === 501)) {
            this.errorHandler.recoverInline(this);
            }
            else {
                this.errorHandler.reportMatch(this);
                this.consume();
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public whenClause(): WhenClauseContext {
        let localContext = new WhenClauseContext(this.context, this.state);
        this.enterRule(localContext, 392, SparkSQLParser.RULE_whenClause);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2818;
            this.match(SparkSQLParser.KW_WHEN);
            this.state = 2819;
            localContext._condition = this.expression();
            this.state = 2820;
            this.match(SparkSQLParser.KW_THEN);
            this.state = 2821;
            localContext._result = this.expression();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public catalogPath(): CatalogPathContext {
        let localContext = new CatalogPathContext(this.context, this.state);
        this.enterRule(localContext, 394, SparkSQLParser.RULE_catalogPath);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2823;
            this.uid();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public databasePath(): DatabasePathContext {
        let localContext = new DatabasePathContext(this.context, this.state);
        this.enterRule(localContext, 396, SparkSQLParser.RULE_databasePath);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2825;
            this.uid();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public databasePathCreate(): DatabasePathCreateContext {
        let localContext = new DatabasePathCreateContext(this.context, this.state);
        this.enterRule(localContext, 398, SparkSQLParser.RULE_databasePathCreate);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2827;
            this.uid();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public tablePathCreate(): TablePathCreateContext {
        let localContext = new TablePathCreateContext(this.context, this.state);
        this.enterRule(localContext, 400, SparkSQLParser.RULE_tablePathCreate);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2829;
            this.uid();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public tablePath(): TablePathContext {
        let localContext = new TablePathContext(this.context, this.state);
        this.enterRule(localContext, 402, SparkSQLParser.RULE_tablePath);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2831;
            this.uid();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public anonymousWindowsName(): AnonymousWindowsNameContext {
        let localContext = new AnonymousWindowsNameContext(this.context, this.state);
        this.enterRule(localContext, 404, SparkSQLParser.RULE_anonymousWindowsName);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2833;
            this.identifier();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public uid(): UidContext {
        let localContext = new UidContext(this.context, this.state);
        this.enterRule(localContext, 406, SparkSQLParser.RULE_uid);
        try {
            let alternative: number;
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2835;
            this.identifier();
            this.state = 2840;
            this.errorHandler.sync(this);
            alternative = this.interpreter.adaptivePredict(this.tokenStream, 332, this.context);
            while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {
                if (alternative === 1) {
                    {
                    {
                    this.state = 2836;
                    this.match(SparkSQLParser.DOT);
                    this.state = 2837;
                    this.identifier();
                    }
                    }
                }
                this.state = 2842;
                this.errorHandler.sync(this);
                alternative = this.interpreter.adaptivePredict(this.tokenStream, 332, this.context);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public withOption(): WithOptionContext {
        let localContext = new WithOptionContext(this.context, this.state);
        this.enterRule(localContext, 408, SparkSQLParser.RULE_withOption);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2843;
            this.match(SparkSQLParser.KW_WITH);
            this.state = 2845;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 34 || _la === 423) {
                {
                this.state = 2844;
                _la = this.tokenStream.LA(1);
                if(!(_la === 34 || _la === 423)) {
                this.errorHandler.recoverInline(this);
                }
                else {
                    this.errorHandler.reportMatch(this);
                    this.consume();
                }
                }
            }

            this.state = 2847;
            this.tablePropertyList();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public ifNotExists(): IfNotExistsContext {
        let localContext = new IfNotExistsContext(this.context, this.state);
        this.enterRule(localContext, 410, SparkSQLParser.RULE_ifNotExists);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2849;
            this.match(SparkSQLParser.KW_IF);
            this.state = 2850;
            this.match(SparkSQLParser.KW_NOT);
            this.state = 2851;
            this.match(SparkSQLParser.KW_EXISTS);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public ifExists(): IfExistsContext {
        let localContext = new IfExistsContext(this.context, this.state);
        this.enterRule(localContext, 412, SparkSQLParser.RULE_ifExists);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2853;
            this.match(SparkSQLParser.KW_IF);
            this.state = 2854;
            this.match(SparkSQLParser.KW_EXISTS);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public tablePropertyList(): TablePropertyListContext {
        let localContext = new TablePropertyListContext(this.context, this.state);
        this.enterRule(localContext, 414, SparkSQLParser.RULE_tablePropertyList);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2856;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 2857;
            this.tableProperty();
            this.state = 2862;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 480) {
                {
                {
                this.state = 2858;
                this.match(SparkSQLParser.COMMA);
                this.state = 2859;
                this.tableProperty();
                }
                }
                this.state = 2864;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 2865;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public tableProperty(): TablePropertyContext {
        let localContext = new TablePropertyContext(this.context, this.state);
        this.enterRule(localContext, 416, SparkSQLParser.RULE_tableProperty);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2867;
            this.tablePropertyKey();
            this.state = 2868;
            this.match(SparkSQLParser.EQUAL_SYMBOL);
            this.state = 2870;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 259) {
                {
                this.state = 2869;
                this.match(SparkSQLParser.KW_DATE);
                }
            }

            this.state = 2872;
            this.tablePropertyValue();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public tablePropertyKey(): TablePropertyKeyContext {
        let localContext = new TablePropertyKeyContext(this.context, this.state);
        this.enterRule(localContext, 418, SparkSQLParser.RULE_tablePropertyKey);
        try {
            this.state = 2878;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 336, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 2874;
                this.identifier();
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 2875;
                this.uid();
                }
                break;
            case 3:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 2876;
                this.stringLiteral();
                }
                break;
            case 4:
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 2877;
                this.functionParam();
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public propertyName(): PropertyNameContext {
        let localContext = new PropertyNameContext(this.context, this.state);
        this.enterRule(localContext, 420, SparkSQLParser.RULE_propertyName);
        try {
            this.state = 2885;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.SINGLE_QUOTE_SYMB:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 2880;
                this.match(SparkSQLParser.SINGLE_QUOTE_SYMB);
                this.state = 2881;
                this.constant();
                this.state = 2882;
                this.match(SparkSQLParser.SINGLE_QUOTE_SYMB);
                }
                break;
            case SparkSQLParser.KW_MICROSECOND:
            case SparkSQLParser.KW_MILLISECOND:
            case SparkSQLParser.KW_QUARTER:
            case SparkSQLParser.KW_WEEK:
            case SparkSQLParser.KW_DAY:
            case SparkSQLParser.KW_FALSE:
            case SparkSQLParser.KW_HOUR:
            case SparkSQLParser.KW_INTERVAL:
            case SparkSQLParser.KW_MINUTE:
            case SparkSQLParser.KW_MONTH:
            case SparkSQLParser.KW_NOT:
            case SparkSQLParser.KW_NULL:
            case SparkSQLParser.KW_SECOND:
            case SparkSQLParser.KW_TRUE:
            case SparkSQLParser.KW_YEAR:
            case SparkSQLParser.HYPNEN_SIGN:
            case SparkSQLParser.STRING_LITERAL:
            case SparkSQLParser.DIG_LITERAL:
            case SparkSQLParser.REAL_LITERAL:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 2884;
                this.constant();
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public tablePropertyValue(): TablePropertyValueContext {
        let localContext = new TablePropertyValueContext(this.context, this.state);
        this.enterRule(localContext, 422, SparkSQLParser.RULE_tablePropertyValue);
        try {
            this.state = 2897;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 338, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 2887;
                this.match(SparkSQLParser.DIG_LITERAL);
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 2888;
                this.match(SparkSQLParser.REAL_LITERAL);
                }
                break;
            case 3:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 2889;
                this.booleanLiteral();
                }
                break;
            case 4:
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 2890;
                this.uid();
                }
                break;
            case 5:
                this.enterOuterAlt(localContext, 5);
                {
                this.state = 2891;
                this.constant();
                }
                break;
            case 6:
                this.enterOuterAlt(localContext, 6);
                {
                this.state = 2892;
                this.refVar();
                }
                break;
            case 7:
                this.enterOuterAlt(localContext, 7);
                {
                this.state = 2893;
                this.match(SparkSQLParser.SINGLE_QUOTE_SYMB);
                this.state = 2894;
                this.refVar();
                this.state = 2895;
                this.match(SparkSQLParser.SINGLE_QUOTE_SYMB);
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public comparisonOperator(): ComparisonOperatorContext {
        let localContext = new ComparisonOperatorContext(this.context, this.state);
        this.enterRule(localContext, 424, SparkSQLParser.RULE_comparisonOperator);
        try {
            this.state = 2913;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 339, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 2899;
                this.match(SparkSQLParser.EQUAL_SYMBOL);
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 2900;
                this.match(SparkSQLParser.GREATER_SYMBOL);
                }
                break;
            case 3:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 2901;
                this.match(SparkSQLParser.LESS_SYMBOL);
                }
                break;
            case 4:
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 2902;
                this.match(SparkSQLParser.LESS_SYMBOL);
                this.state = 2903;
                this.match(SparkSQLParser.EQUAL_SYMBOL);
                }
                break;
            case 5:
                this.enterOuterAlt(localContext, 5);
                {
                this.state = 2904;
                this.match(SparkSQLParser.GREATER_SYMBOL);
                this.state = 2905;
                this.match(SparkSQLParser.EQUAL_SYMBOL);
                }
                break;
            case 6:
                this.enterOuterAlt(localContext, 6);
                {
                this.state = 2906;
                this.match(SparkSQLParser.LESS_SYMBOL);
                this.state = 2907;
                this.match(SparkSQLParser.GREATER_SYMBOL);
                }
                break;
            case 7:
                this.enterOuterAlt(localContext, 7);
                {
                this.state = 2908;
                this.match(SparkSQLParser.EXCLAMATION_SYMBOL);
                this.state = 2909;
                this.match(SparkSQLParser.EQUAL_SYMBOL);
                }
                break;
            case 8:
                this.enterOuterAlt(localContext, 8);
                {
                this.state = 2910;
                this.match(SparkSQLParser.LESS_SYMBOL);
                this.state = 2911;
                this.match(SparkSQLParser.EQUAL_SYMBOL);
                this.state = 2912;
                this.match(SparkSQLParser.GREATER_SYMBOL);
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public constant(): ConstantContext {
        let localContext = new ConstantContext(this.context, this.state);
        this.enterRule(localContext, 426, SparkSQLParser.RULE_constant);
        let _la: number;
        try {
            this.state = 2928;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.KW_INTERVAL:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 2915;
                this.timeIntervalExpression();
                }
                break;
            case SparkSQLParser.KW_MICROSECOND:
            case SparkSQLParser.KW_MILLISECOND:
            case SparkSQLParser.KW_QUARTER:
            case SparkSQLParser.KW_WEEK:
            case SparkSQLParser.KW_DAY:
            case SparkSQLParser.KW_HOUR:
            case SparkSQLParser.KW_MINUTE:
            case SparkSQLParser.KW_MONTH:
            case SparkSQLParser.KW_SECOND:
            case SparkSQLParser.KW_YEAR:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 2916;
                this.timePointLiteral();
                }
                break;
            case SparkSQLParser.STRING_LITERAL:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 2917;
                this.stringLiteral();
                }
                break;
            case SparkSQLParser.HYPNEN_SIGN:
            case SparkSQLParser.DIG_LITERAL:
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 2919;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 490) {
                    {
                    this.state = 2918;
                    this.match(SparkSQLParser.HYPNEN_SIGN);
                    }
                }

                this.state = 2921;
                this.decimalLiteral();
                }
                break;
            case SparkSQLParser.KW_FALSE:
            case SparkSQLParser.KW_TRUE:
                this.enterOuterAlt(localContext, 5);
                {
                this.state = 2922;
                this.booleanLiteral();
                }
                break;
            case SparkSQLParser.REAL_LITERAL:
                this.enterOuterAlt(localContext, 6);
                {
                this.state = 2923;
                this.match(SparkSQLParser.REAL_LITERAL);
                }
                break;
            case SparkSQLParser.KW_NOT:
            case SparkSQLParser.KW_NULL:
                this.enterOuterAlt(localContext, 7);
                {
                this.state = 2925;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 354) {
                    {
                    this.state = 2924;
                    this.match(SparkSQLParser.KW_NOT);
                    }
                }

                this.state = 2927;
                this.match(SparkSQLParser.KW_NULL);
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public timePointLiteral(): TimePointLiteralContext {
        let localContext = new TimePointLiteralContext(this.context, this.state);
        this.enterRule(localContext, 428, SparkSQLParser.RULE_timePointLiteral);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2930;
            this.timePointUnit();
            this.state = 2931;
            this.stringLiteral();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public stringLiteral(): StringLiteralContext {
        let localContext = new StringLiteralContext(this.context, this.state);
        this.enterRule(localContext, 430, SparkSQLParser.RULE_stringLiteral);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2933;
            this.match(SparkSQLParser.STRING_LITERAL);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public decimalLiteral(): DecimalLiteralContext {
        let localContext = new DecimalLiteralContext(this.context, this.state);
        this.enterRule(localContext, 432, SparkSQLParser.RULE_decimalLiteral);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2935;
            this.match(SparkSQLParser.DIG_LITERAL);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public booleanLiteral(): BooleanLiteralContext {
        let localContext = new BooleanLiteralContext(this.context, this.state);
        this.enterRule(localContext, 434, SparkSQLParser.RULE_booleanLiteral);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2937;
            _la = this.tokenStream.LA(1);
            if(!(_la === 292 || _la === 435)) {
            this.errorHandler.recoverInline(this);
            }
            else {
                this.errorHandler.reportMatch(this);
                this.consume();
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public setQuantifier(): SetQuantifierContext {
        let localContext = new SetQuantifierContext(this.context, this.state);
        this.enterRule(localContext, 436, SparkSQLParser.RULE_setQuantifier);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2939;
            _la = this.tokenStream.LA(1);
            if(!(_la === 205 || _la === 271)) {
            this.errorHandler.recoverInline(this);
            }
            else {
                this.errorHandler.reportMatch(this);
                this.consume();
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public timePointUnit(): TimePointUnitContext {
        let localContext = new TimePointUnitContext(this.context, this.state);
        this.enterRule(localContext, 438, SparkSQLParser.RULE_timePointUnit);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2941;
            _la = this.tokenStream.LA(1);
            if(!(_la === 92 || _la === 94 || _la === 129 || _la === 198 || _la === 261 || _la === 307 || _la === 345 || _la === 348 || _la === 400 || _la === 456)) {
            this.errorHandler.recoverInline(this);
            }
            else {
                this.errorHandler.reportMatch(this);
                this.consume();
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public timeIntervalUnit(): TimeIntervalUnitContext {
        let localContext = new TimeIntervalUnitContext(this.context, this.state);
        this.enterRule(localContext, 440, SparkSQLParser.RULE_timeIntervalUnit);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2943;
            _la = this.tokenStream.LA(1);
            if(!(((((_la - 19)) & ~0x1F) === 0 && ((1 << (_la - 19)) & 16859137) !== 0) || ((((_la - 67)) & ~0x1F) === 0 && ((1 << (_la - 67)) & 503316481) !== 0) || ((((_la - 99)) & ~0x1F) === 0 && ((1 << (_la - 99)) & 1073741827) !== 0) || _la === 149 || ((((_la - 198)) & ~0x1F) === 0 && ((1 << (_la - 198)) & 19) !== 0) || _la === 261 || _la === 307 || _la === 345 || _la === 348 || _la === 400 || _la === 456)) {
            this.errorHandler.recoverInline(this);
            }
            else {
                this.errorHandler.reportMatch(this);
                this.consume();
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public reservedKeywordsUsedAsFuncParam(): ReservedKeywordsUsedAsFuncParamContext {
        let localContext = new ReservedKeywordsUsedAsFuncParamContext(this.context, this.state);
        this.enterRule(localContext, 442, SparkSQLParser.RULE_reservedKeywordsUsedAsFuncParam);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2945;
            _la = this.tokenStream.LA(1);
            if(!(_la === 205 || _la === 223 || _la === 271 || _la === 332 || _la === 434 || _la === 488)) {
            this.errorHandler.recoverInline(this);
            }
            else {
                this.errorHandler.reportMatch(this);
                this.consume();
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public reservedKeywordsUsedAsFuncName(): ReservedKeywordsUsedAsFuncNameContext {
        let localContext = new ReservedKeywordsUsedAsFuncNameContext(this.context, this.state);
        this.enterRule(localContext, 444, SparkSQLParser.RULE_reservedKeywordsUsedAsFuncName);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2947;
            _la = this.tokenStream.LA(1);
            if(!(_la === 68 || _la === 91 || _la === 129 || ((((_la - 198)) & ~0x1F) === 0 && ((1 << (_la - 198)) & 139329) !== 0) || ((((_la - 231)) & ~0x1F) === 0 && ((1 << (_la - 231)) & 269224451) !== 0) || ((((_la - 287)) & ~0x1F) === 0 && ((1 << (_la - 287)) & 1115153) !== 0) || ((((_la - 327)) & ~0x1F) === 0 && ((1 << (_la - 327)) & 270794841) !== 0) || ((((_la - 369)) & ~0x1F) === 0 && ((1 << (_la - 369)) & 2182748609) !== 0) || ((((_la - 416)) & ~0x1F) === 0 && ((1 << (_la - 416)) & 68220931) !== 0) || _la === 456)) {
            this.errorHandler.recoverInline(this);
            }
            else {
                this.errorHandler.reportMatch(this);
                this.consume();
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public nonReservedKeywords(): NonReservedKeywordsContext {
        let localContext = new NonReservedKeywordsContext(this.context, this.state);
        this.enterRule(localContext, 446, SparkSQLParser.RULE_nonReservedKeywords);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2949;
            _la = this.tokenStream.LA(1);
            if(!((((_la) & ~0x1F) === 0 && ((1 << _la) & 4294684608) !== 0) || ((((_la - 32)) & ~0x1F) === 0 && ((1 << (_la - 32)) & 4293654523) !== 0) || ((((_la - 64)) & ~0x1F) === 0 && ((1 << (_la - 64)) & 4185849791) !== 0) || ((((_la - 96)) & ~0x1F) === 0 && ((1 << (_la - 96)) & 4294967263) !== 0) || ((((_la - 128)) & ~0x1F) === 0 && ((1 << (_la - 128)) & 3757047707) !== 0) || ((((_la - 160)) & ~0x1F) === 0 && ((1 << (_la - 160)) & 4252958679) !== 0) || ((((_la - 192)) & ~0x1F) === 0 && ((1 << (_la - 192)) & 3967) !== 0) || _la === 338)) {
            this.errorHandler.recoverInline(this);
            }
            else {
                this.errorHandler.reportMatch(this);
                this.consume();
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public sqlStatement(): SqlStatementContext {
        let localContext = new SqlStatementContext(this.context, this.state);
        this.enterRule(localContext, 448, SparkSQLParser.RULE_sqlStatement);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2953;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.KW_EXECUTE:
            case SparkSQLParser.KW_FROM:
            case SparkSQLParser.KW_INSERT:
            case SparkSQLParser.KW_SELECT:
            case SparkSQLParser.KW_WITH:
            case SparkSQLParser.LR_BRACKET:
                {
                this.state = 2951;
                this.dmlStatement();
                }
                break;
            case SparkSQLParser.KW_CREATE:
                {
                this.state = 2952;
                this.createStatement();
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
            this.state = 2955;
            this.match(SparkSQLParser.SEMICOLON);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public selectStatement(): SelectStatementContext {
        let localContext = new SelectStatementContext(this.context, this.state);
        this.enterRule(localContext, 450, SparkSQLParser.RULE_selectStatement);
        try {
            this.state = 2993;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 352, this.context) ) {
            case 1:
                localContext = new CommonSelectContext(localContext);
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 2957;
                this.selectClause();
                this.state = 2958;
                this.fromClause();
                this.state = 2960;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 344, this.context) ) {
                case 1:
                    {
                    this.state = 2959;
                    this.whereClause();
                    }
                    break;
                }
                this.state = 2963;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 345, this.context) ) {
                case 1:
                    {
                    this.state = 2962;
                    this.someByClause();
                    }
                    break;
                }
                this.state = 2966;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 346, this.context) ) {
                case 1:
                    {
                    this.state = 2965;
                    this.havingClause();
                    }
                    break;
                }
                this.state = 2969;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 347, this.context) ) {
                case 1:
                    {
                    this.state = 2968;
                    this.windowClause();
                    }
                    break;
                }
                }
                break;
            case 2:
                localContext = new SparkStyleSelectContext(localContext);
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 2971;
                this.fromClause();
                this.state = 2972;
                this.selectClause();
                this.state = 2974;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 348, this.context) ) {
                case 1:
                    {
                    this.state = 2973;
                    this.whereClause();
                    }
                    break;
                }
                this.state = 2977;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 349, this.context) ) {
                case 1:
                    {
                    this.state = 2976;
                    this.someByClause();
                    }
                    break;
                }
                this.state = 2980;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 350, this.context) ) {
                case 1:
                    {
                    this.state = 2979;
                    this.havingClause();
                    }
                    break;
                }
                this.state = 2983;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 351, this.context) ) {
                case 1:
                    {
                    this.state = 2982;
                    this.windowClause();
                    }
                    break;
                }
                }
                break;
            case 3:
                localContext = new MatchRecognizeSelectContext(localContext);
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 2985;
                this.selectClause();
                this.state = 2986;
                this.fromClause();
                this.state = 2987;
                this.matchRecognizeClause();
                }
                break;
            case 4:
                localContext = new TableSampleContext(localContext);
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 2989;
                this.selectClause();
                this.state = 2990;
                this.fromClause();
                this.state = 2991;
                this.samplingQueries();
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public projectItemDefinition(): ProjectItemDefinitionContext {
        let localContext = new ProjectItemDefinitionContext(this.context, this.state);
        this.enterRule(localContext, 452, SparkSQLParser.RULE_projectItemDefinition);
        let _la: number;
        try {
            this.state = 3007;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 356, this.context) ) {
            case 1:
                localContext = new WindowsProrjectItemContext(localContext);
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 2995;
                this.overWindowItem();
                this.state = 3000;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 354, this.context) ) {
                case 1:
                    {
                    this.state = 2997;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                    if (_la === 212) {
                        {
                        this.state = 2996;
                        this.match(SparkSQLParser.KW_AS);
                        }
                    }

                    this.state = 2999;
                    this.identifier();
                    }
                    break;
                }
                }
                break;
            case 2:
                localContext = new ExpressionProjectItemContext(localContext);
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 3002;
                this.expression();
                this.state = 3005;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 355, this.context) ) {
                case 1:
                    {
                    this.state = 3003;
                    this.match(SparkSQLParser.KW_AS);
                    this.state = 3004;
                    this.expression();
                    }
                    break;
                }
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }

    public override sempred(localContext: antlr.ParserRuleContext | null, ruleIndex: number, predIndex: number): boolean {
        switch (ruleIndex) {
        case 48:
            return this.queryStatement_sempred(localContext as QueryStatementContext, predIndex);
        case 65:
            return this.tableExpression_sempred(localContext as TableExpressionContext, predIndex);
        case 162:
            return this.booleanExpression_sempred(localContext as BooleanExpressionContext, predIndex);
        case 165:
            return this.valueExpression_sempred(localContext as ValueExpressionContext, predIndex);
        case 166:
            return this.primaryExpression_sempred(localContext as PrimaryExpressionContext, predIndex);
        }
        return true;
    }
    private queryStatement_sempred(localContext: QueryStatementContext | null, predIndex: number): boolean {
        switch (predIndex) {
        case 0:
            return this.precpred(this.context, 2);
        }
        return true;
    }
    private tableExpression_sempred(localContext: TableExpressionContext | null, predIndex: number): boolean {
        switch (predIndex) {
        case 1:
            return this.precpred(this.context, 4);
        }
        return true;
    }
    private booleanExpression_sempred(localContext: BooleanExpressionContext | null, predIndex: number): boolean {
        switch (predIndex) {
        case 2:
            return this.precpred(this.context, 3);
        case 3:
            return this.precpred(this.context, 2);
        case 4:
            return this.precpred(this.context, 1);
        }
        return true;
    }
    private valueExpression_sempred(localContext: ValueExpressionContext | null, predIndex: number): boolean {
        switch (predIndex) {
        case 5:
            return this.precpred(this.context, 6);
        case 6:
            return this.precpred(this.context, 5);
        case 7:
            return this.precpred(this.context, 4);
        case 8:
            return this.precpred(this.context, 3);
        case 9:
            return this.precpred(this.context, 2);
        case 10:
            return this.precpred(this.context, 1);
        }
        return true;
    }
    private primaryExpression_sempred(localContext: PrimaryExpressionContext | null, predIndex: number): boolean {
        switch (predIndex) {
        case 11:
            return this.precpred(this.context, 5);
        }
        return true;
    }

    public static readonly _serializedATN: number[] = [
        4,1,501,3010,2,0,7,0,2,1,7,1,2,2,7,2,2,3,7,3,2,4,7,4,2,5,7,5,2,6,
        7,6,2,7,7,7,2,8,7,8,2,9,7,9,2,10,7,10,2,11,7,11,2,12,7,12,2,13,7,
        13,2,14,7,14,2,15,7,15,2,16,7,16,2,17,7,17,2,18,7,18,2,19,7,19,2,
        20,7,20,2,21,7,21,2,22,7,22,2,23,7,23,2,24,7,24,2,25,7,25,2,26,7,
        26,2,27,7,27,2,28,7,28,2,29,7,29,2,30,7,30,2,31,7,31,2,32,7,32,2,
        33,7,33,2,34,7,34,2,35,7,35,2,36,7,36,2,37,7,37,2,38,7,38,2,39,7,
        39,2,40,7,40,2,41,7,41,2,42,7,42,2,43,7,43,2,44,7,44,2,45,7,45,2,
        46,7,46,2,47,7,47,2,48,7,48,2,49,7,49,2,50,7,50,2,51,7,51,2,52,7,
        52,2,53,7,53,2,54,7,54,2,55,7,55,2,56,7,56,2,57,7,57,2,58,7,58,2,
        59,7,59,2,60,7,60,2,61,7,61,2,62,7,62,2,63,7,63,2,64,7,64,2,65,7,
        65,2,66,7,66,2,67,7,67,2,68,7,68,2,69,7,69,2,70,7,70,2,71,7,71,2,
        72,7,72,2,73,7,73,2,74,7,74,2,75,7,75,2,76,7,76,2,77,7,77,2,78,7,
        78,2,79,7,79,2,80,7,80,2,81,7,81,2,82,7,82,2,83,7,83,2,84,7,84,2,
        85,7,85,2,86,7,86,2,87,7,87,2,88,7,88,2,89,7,89,2,90,7,90,2,91,7,
        91,2,92,7,92,2,93,7,93,2,94,7,94,2,95,7,95,2,96,7,96,2,97,7,97,2,
        98,7,98,2,99,7,99,2,100,7,100,2,101,7,101,2,102,7,102,2,103,7,103,
        2,104,7,104,2,105,7,105,2,106,7,106,2,107,7,107,2,108,7,108,2,109,
        7,109,2,110,7,110,2,111,7,111,2,112,7,112,2,113,7,113,2,114,7,114,
        2,115,7,115,2,116,7,116,2,117,7,117,2,118,7,118,2,119,7,119,2,120,
        7,120,2,121,7,121,2,122,7,122,2,123,7,123,2,124,7,124,2,125,7,125,
        2,126,7,126,2,127,7,127,2,128,7,128,2,129,7,129,2,130,7,130,2,131,
        7,131,2,132,7,132,2,133,7,133,2,134,7,134,2,135,7,135,2,136,7,136,
        2,137,7,137,2,138,7,138,2,139,7,139,2,140,7,140,2,141,7,141,2,142,
        7,142,2,143,7,143,2,144,7,144,2,145,7,145,2,146,7,146,2,147,7,147,
        2,148,7,148,2,149,7,149,2,150,7,150,2,151,7,151,2,152,7,152,2,153,
        7,153,2,154,7,154,2,155,7,155,2,156,7,156,2,157,7,157,2,158,7,158,
        2,159,7,159,2,160,7,160,2,161,7,161,2,162,7,162,2,163,7,163,2,164,
        7,164,2,165,7,165,2,166,7,166,2,167,7,167,2,168,7,168,2,169,7,169,
        2,170,7,170,2,171,7,171,2,172,7,172,2,173,7,173,2,174,7,174,2,175,
        7,175,2,176,7,176,2,177,7,177,2,178,7,178,2,179,7,179,2,180,7,180,
        2,181,7,181,2,182,7,182,2,183,7,183,2,184,7,184,2,185,7,185,2,186,
        7,186,2,187,7,187,2,188,7,188,2,189,7,189,2,190,7,190,2,191,7,191,
        2,192,7,192,2,193,7,193,2,194,7,194,2,195,7,195,2,196,7,196,2,197,
        7,197,2,198,7,198,2,199,7,199,2,200,7,200,2,201,7,201,2,202,7,202,
        2,203,7,203,2,204,7,204,2,205,7,205,2,206,7,206,2,207,7,207,2,208,
        7,208,2,209,7,209,2,210,7,210,2,211,7,211,2,212,7,212,2,213,7,213,
        2,214,7,214,2,215,7,215,2,216,7,216,2,217,7,217,2,218,7,218,2,219,
        7,219,2,220,7,220,2,221,7,221,2,222,7,222,2,223,7,223,2,224,7,224,
        2,225,7,225,2,226,7,226,1,0,1,0,1,0,1,1,1,1,5,1,460,8,1,10,1,12,
        1,463,9,1,1,2,1,2,1,3,1,3,1,4,1,4,3,4,471,8,4,1,5,1,5,1,5,1,5,1,
        5,1,5,3,5,479,8,5,1,6,1,6,3,6,483,8,6,1,6,1,6,3,6,487,8,6,1,6,1,
        6,5,6,491,8,6,10,6,12,6,494,9,6,1,6,1,6,1,6,3,6,499,8,6,1,6,5,6,
        502,8,6,10,6,12,6,505,9,6,1,7,1,7,1,7,1,7,1,7,1,7,1,7,1,7,1,7,1,
        7,1,7,1,7,1,7,1,7,3,7,521,8,7,1,8,1,8,1,8,1,9,1,9,1,9,1,9,1,9,3,
        9,531,8,9,1,9,1,9,1,10,1,10,1,10,3,10,538,8,10,1,10,1,10,1,10,1,
        10,3,10,544,8,10,1,11,1,11,1,11,1,12,1,12,5,12,551,8,12,10,12,12,
        12,554,9,12,1,12,3,12,557,8,12,1,12,1,12,1,12,5,12,562,8,12,10,12,
        12,12,565,9,12,1,13,1,13,1,13,1,13,1,13,1,13,1,13,1,13,1,13,1,13,
        1,13,1,13,1,13,3,13,580,8,13,1,14,1,14,1,14,1,14,5,14,586,8,14,10,
        14,12,14,589,9,14,1,15,1,15,1,15,1,15,1,15,1,15,1,15,3,15,598,8,
        15,1,16,1,16,1,16,1,16,1,16,5,16,605,8,16,10,16,12,16,608,9,16,1,
        17,1,17,1,17,1,17,1,17,1,17,1,17,3,17,617,8,17,1,18,1,18,1,18,1,
        18,1,19,1,19,1,19,1,19,1,19,3,19,628,8,19,1,19,1,19,1,19,3,19,633,
        8,19,5,19,635,8,19,10,19,12,19,638,9,19,1,19,1,19,1,20,1,20,1,20,
        1,20,1,20,1,21,1,21,1,21,1,21,1,21,1,22,1,22,1,22,3,22,655,8,22,
        1,23,1,23,1,23,1,23,3,23,661,8,23,1,24,1,24,3,24,665,8,24,1,25,1,
        25,1,25,1,25,1,26,1,26,1,26,3,26,674,8,26,1,26,1,26,1,26,3,26,679,
        8,26,5,26,681,8,26,10,26,12,26,684,9,26,1,26,1,26,1,26,3,26,689,
        8,26,3,26,691,8,26,1,26,1,26,1,26,3,26,696,8,26,3,26,698,8,26,1,
        26,1,26,1,26,3,26,703,8,26,3,26,705,8,26,1,26,1,26,1,27,1,27,3,27,
        711,8,27,1,27,1,27,3,27,715,8,27,1,27,1,27,5,27,719,8,27,10,27,12,
        27,722,9,27,1,27,1,27,1,27,1,27,1,27,5,27,729,8,27,10,27,12,27,732,
        9,27,1,27,1,27,1,27,1,27,1,27,5,27,739,8,27,10,27,12,27,742,9,27,
        1,27,1,27,1,27,5,27,747,8,27,10,27,12,27,750,9,27,1,27,1,27,5,27,
        754,8,27,10,27,12,27,757,9,27,1,28,1,28,1,28,1,28,1,28,1,28,3,28,
        765,8,28,1,29,1,29,1,29,1,29,3,29,771,8,29,1,29,1,29,5,29,775,8,
        29,10,29,12,29,778,9,29,1,29,1,29,5,29,782,8,29,10,29,12,29,785,
        9,29,1,29,1,29,1,29,1,29,1,29,5,29,792,8,29,10,29,12,29,795,9,29,
        1,29,1,29,1,29,1,29,1,29,5,29,802,8,29,10,29,12,29,805,9,29,1,29,
        1,29,1,29,5,29,810,8,29,10,29,12,29,813,9,29,1,29,1,29,1,29,5,29,
        818,8,29,10,29,12,29,821,9,29,1,30,1,30,1,30,1,30,1,30,1,30,3,30,
        829,8,30,1,31,1,31,1,31,3,31,834,8,31,1,31,1,31,1,31,1,31,3,31,840,
        8,31,1,32,1,32,1,32,1,32,1,32,5,32,847,8,32,10,32,12,32,850,9,32,
        1,32,1,32,1,32,1,32,1,32,1,32,1,32,5,32,859,8,32,10,32,12,32,862,
        9,32,1,32,1,32,1,32,3,32,867,8,32,1,32,1,32,5,32,871,8,32,10,32,
        12,32,874,9,32,1,32,1,32,1,32,1,32,1,32,1,32,1,32,5,32,883,8,32,
        10,32,12,32,886,9,32,1,33,1,33,1,33,1,33,1,33,1,33,1,33,3,33,895,
        8,33,1,34,1,34,1,34,1,34,1,34,1,34,5,34,903,8,34,10,34,12,34,906,
        9,34,1,35,1,35,1,35,3,35,911,8,35,1,36,1,36,1,36,3,36,916,8,36,4,
        36,918,8,36,11,36,12,36,919,3,36,922,8,36,1,37,1,37,3,37,926,8,37,
        1,37,1,37,1,38,1,38,1,38,3,38,933,8,38,1,39,1,39,3,39,937,8,39,1,
        39,1,39,1,39,1,40,1,40,1,40,1,41,1,41,1,41,1,41,1,41,1,41,1,41,3,
        41,952,8,41,1,42,1,42,1,42,1,42,1,43,1,43,1,43,1,43,1,44,1,44,1,
        44,1,45,3,45,966,8,45,1,45,1,45,1,46,1,46,1,46,3,46,973,8,46,1,46,
        1,46,3,46,977,8,46,1,46,3,46,980,8,46,1,46,1,46,1,46,1,46,1,46,1,
        46,1,46,1,46,3,46,990,8,46,1,47,1,47,1,47,1,48,1,48,1,48,1,48,1,
        48,1,48,1,48,1,48,1,48,1,48,3,48,1005,8,48,1,48,3,48,1008,8,48,1,
        48,3,48,1011,8,48,1,48,3,48,1014,8,48,1,48,3,48,1017,8,48,3,48,1019,
        8,48,1,48,1,48,1,48,3,48,1024,8,48,1,48,1,48,3,48,1028,8,48,1,48,
        3,48,1031,8,48,1,48,3,48,1034,8,48,1,48,3,48,1037,8,48,5,48,1039,
        8,48,10,48,12,48,1042,9,48,1,49,1,49,1,49,1,49,5,49,1048,8,49,10,
        49,12,49,1051,9,49,1,50,1,50,1,50,1,50,3,50,1057,8,50,1,50,5,50,
        1060,8,50,10,50,12,50,1063,9,50,1,51,1,51,1,51,1,51,5,51,1069,8,
        51,10,51,12,51,1072,9,51,1,51,1,51,1,52,1,52,1,52,1,52,1,52,5,52,
        1081,8,52,10,52,12,52,1084,9,52,1,52,1,52,3,52,1088,8,52,1,52,1,
        52,1,52,1,52,1,52,1,53,1,53,1,54,1,54,3,54,1099,8,54,1,54,1,54,1,
        54,5,54,1104,8,54,10,54,12,54,1107,9,54,1,55,1,55,1,55,1,55,1,55,
        1,56,1,56,1,56,3,56,1117,8,56,1,56,1,56,3,56,1121,8,56,1,56,1,56,
        3,56,1125,8,56,1,56,1,56,3,56,1129,8,56,1,56,1,56,3,56,1133,8,56,
        1,57,1,57,1,57,1,57,1,57,5,57,1140,8,57,10,57,12,57,1143,9,57,1,
        57,1,57,3,57,1147,8,57,1,58,1,58,1,58,1,58,1,58,5,58,1154,8,58,10,
        58,12,58,1157,9,58,3,58,1159,8,58,1,58,1,58,1,58,3,58,1164,8,58,
        1,59,1,59,3,59,1168,8,59,1,60,1,60,1,61,1,61,1,62,1,62,1,62,1,63,
        1,63,1,63,1,63,1,63,1,63,1,63,3,63,1184,8,63,1,64,1,64,1,64,1,64,
        1,64,1,64,1,64,1,64,1,64,1,64,1,64,1,64,3,64,1198,8,64,1,65,1,65,
        1,65,1,65,5,65,1204,8,65,10,65,12,65,1207,9,65,1,65,1,65,1,65,3,
        65,1212,8,65,1,65,1,65,5,65,1216,8,65,10,65,12,65,1219,9,65,1,65,
        3,65,1222,8,65,1,65,1,65,1,65,3,65,1227,8,65,1,65,3,65,1230,8,65,
        1,65,1,65,3,65,1234,8,65,1,65,3,65,1237,8,65,1,65,3,65,1240,8,65,
        1,65,3,65,1243,8,65,1,65,1,65,1,65,3,65,1248,8,65,1,65,1,65,5,65,
        1252,8,65,10,65,12,65,1255,9,65,5,65,1257,8,65,10,65,12,65,1260,
        9,65,1,66,1,66,1,67,1,67,1,67,1,67,1,67,5,67,1269,8,67,10,67,12,
        67,1272,9,67,1,67,1,67,1,68,1,68,1,68,3,68,1279,8,68,1,68,1,68,3,
        68,1283,8,68,1,68,1,68,1,68,1,68,5,68,1289,8,68,10,68,12,68,1292,
        9,68,1,69,1,69,1,69,1,69,1,69,1,69,1,69,1,69,3,69,1302,8,69,1,69,
        1,69,1,69,1,69,3,69,1308,8,69,1,70,1,70,3,70,1312,8,70,1,71,3,71,
        1315,8,71,1,71,1,71,3,71,1319,8,71,1,71,1,71,1,71,1,71,3,71,1325,
        8,71,1,71,1,71,1,71,1,71,1,71,1,71,3,71,1333,8,71,1,71,1,71,1,71,
        1,71,1,71,1,71,1,71,1,71,1,71,5,71,1344,8,71,10,71,12,71,1347,9,
        71,1,71,1,71,1,71,1,71,1,71,1,71,3,71,1355,8,71,1,72,1,72,1,72,1,
        72,3,72,1361,8,72,1,72,1,72,1,72,3,72,1366,8,72,5,72,1368,8,72,10,
        72,12,72,1371,9,72,1,72,1,72,1,72,1,72,1,72,1,72,3,72,1379,8,72,
        1,72,1,72,1,72,3,72,1384,8,72,5,72,1386,8,72,10,72,12,72,1389,9,
        72,1,72,1,72,1,72,1,72,1,72,1,72,1,72,1,72,5,72,1399,8,72,10,72,
        12,72,1402,9,72,3,72,1404,8,72,1,73,1,73,3,73,1408,8,73,1,73,1,73,
        1,73,1,73,1,73,1,74,1,74,1,74,1,74,1,74,1,74,1,74,3,74,1422,8,74,
        1,74,1,74,1,74,1,75,1,75,1,75,3,75,1430,8,75,1,76,1,76,1,76,1,76,
        5,76,1436,8,76,10,76,12,76,1439,9,76,1,76,1,76,1,77,1,77,1,77,1,
        77,1,77,1,77,1,78,1,78,1,79,1,79,1,79,5,79,1454,8,79,10,79,12,79,
        1457,9,79,1,79,3,79,1460,8,79,1,80,1,80,1,80,1,80,1,80,1,81,1,81,
        1,81,1,81,1,81,5,81,1472,8,81,10,81,12,81,1475,9,81,1,81,1,81,1,
        82,1,82,1,83,1,83,1,83,1,83,1,84,1,84,1,84,1,84,1,85,1,85,1,85,1,
        85,1,85,3,85,1494,8,85,1,86,1,86,1,86,1,86,3,86,1500,8,86,1,86,1,
        86,1,86,3,86,1505,8,86,1,86,1,86,3,86,1509,8,86,1,86,3,86,1512,8,
        86,1,86,1,86,3,86,1516,8,86,1,87,1,87,1,87,3,87,1521,8,87,1,87,1,
        87,1,87,3,87,1526,8,87,5,87,1528,8,87,10,87,12,87,1531,9,87,1,87,
        1,87,1,88,3,88,1536,8,88,1,88,3,88,1539,8,88,1,88,1,88,1,88,1,88,
        3,88,1545,8,88,1,88,1,88,1,88,1,88,3,88,1551,8,88,1,89,1,89,1,89,
        1,89,1,89,1,89,1,89,1,89,1,89,1,89,1,89,1,89,1,89,1,89,1,89,3,89,
        1568,8,89,1,90,1,90,1,91,1,91,1,91,1,91,1,91,1,92,1,92,1,92,1,92,
        1,92,1,92,1,92,5,92,1584,8,92,10,92,12,92,1587,9,92,1,92,1,92,3,
        92,1591,8,92,1,93,1,93,1,93,1,94,1,94,1,94,1,94,1,94,3,94,1601,8,
        94,1,94,1,94,1,94,1,94,1,94,1,94,3,94,1609,8,94,1,94,1,94,1,94,1,
        94,1,94,1,94,1,94,3,94,1618,8,94,1,94,1,94,1,94,1,94,3,94,1624,8,
        94,1,94,3,94,1627,8,94,1,95,1,95,1,95,1,95,3,95,1633,8,95,1,96,1,
        96,1,96,1,96,1,96,5,96,1640,8,96,10,96,12,96,1643,9,96,1,97,1,97,
        1,97,1,97,1,97,5,97,1650,8,97,10,97,12,97,1653,9,97,1,98,1,98,1,
        98,1,98,1,98,5,98,1660,8,98,10,98,12,98,1663,9,98,1,99,1,99,1,99,
        3,99,1668,8,99,1,99,1,99,5,99,1672,8,99,10,99,12,99,1675,9,99,1,
        99,3,99,1678,8,99,1,99,1,99,3,99,1682,8,99,1,100,1,100,1,100,5,100,
        1687,8,100,10,100,12,100,1690,9,100,1,100,1,100,1,100,1,100,1,100,
        1,100,1,100,5,100,1699,8,100,10,100,12,100,1702,9,100,1,100,1,100,
        1,100,1,100,1,100,1,100,1,100,5,100,1711,8,100,10,100,12,100,1714,
        9,100,1,100,1,100,3,100,1718,8,100,1,101,1,101,1,101,1,101,1,101,
        5,101,1725,8,101,10,101,12,101,1728,9,101,1,101,1,101,1,102,1,102,
        1,102,1,103,1,103,1,104,1,104,1,104,1,104,1,104,1,104,1,104,1,105,
        1,105,1,106,1,106,1,107,1,107,1,107,1,108,1,108,1,108,1,108,5,108,
        1755,8,108,10,108,12,108,1758,9,108,1,109,1,109,1,109,1,109,1,110,
        3,110,1765,8,110,1,110,1,110,3,110,1769,8,110,1,110,3,110,1772,8,
        110,1,110,3,110,1775,8,110,1,110,3,110,1778,8,110,1,110,1,110,1,
        111,1,111,1,111,3,111,1785,8,111,1,111,3,111,1788,8,111,1,111,3,
        111,1791,8,111,1,111,3,111,1794,8,111,1,111,3,111,1797,8,111,1,111,
        3,111,1800,8,111,1,111,3,111,1803,8,111,1,111,1,111,1,111,3,111,
        1808,8,111,1,111,3,111,1811,8,111,1,112,1,112,1,112,1,112,1,112,
        5,112,1818,8,112,10,112,12,112,1821,9,112,1,113,1,113,1,113,1,113,
        1,113,5,113,1828,8,113,10,113,12,113,1831,9,113,1,114,1,114,3,114,
        1835,8,114,1,114,1,114,3,114,1839,8,114,1,115,1,115,1,115,3,115,
        1844,8,115,1,116,1,116,1,116,3,116,1849,8,116,1,117,1,117,1,117,
        1,117,1,117,5,117,1856,8,117,10,117,12,117,1859,9,117,1,118,1,118,
        1,118,1,118,1,118,1,118,1,118,1,118,1,118,1,118,1,118,1,118,1,118,
        1,118,1,118,1,118,3,118,1877,8,118,1,119,1,119,1,119,1,119,5,119,
        1883,8,119,10,119,12,119,1886,9,119,1,120,1,120,1,120,4,120,1891,
        8,120,11,120,12,120,1892,1,120,1,120,3,120,1897,8,120,1,121,1,121,
        3,121,1901,8,121,1,122,1,122,1,122,1,122,1,122,1,122,1,122,1,122,
        3,122,1911,8,122,1,123,1,123,1,123,1,123,1,123,1,123,1,123,1,123,
        1,123,1,123,1,123,1,123,1,123,1,123,1,123,1,123,1,123,1,123,1,123,
        1,123,1,123,1,123,1,123,1,123,3,123,1937,8,123,1,124,1,124,1,124,
        1,124,5,124,1943,8,124,10,124,12,124,1946,9,124,1,125,1,125,1,125,
        1,125,1,125,1,125,1,125,1,125,1,125,3,125,1957,8,125,1,126,1,126,
        1,126,1,126,1,126,1,127,1,127,1,127,1,128,1,128,1,128,1,128,1,129,
        1,129,1,129,1,129,1,130,1,130,1,130,3,130,1978,8,130,1,130,1,130,
        1,130,3,130,1983,8,130,5,130,1985,8,130,10,130,12,130,1988,9,130,
        1,130,1,130,1,131,1,131,1,131,1,131,1,131,1,131,5,131,1998,8,131,
        10,131,12,131,2001,9,131,1,131,1,131,3,131,2005,8,131,1,132,1,132,
        3,132,2009,8,132,1,133,1,133,1,133,1,133,5,133,2015,8,133,10,133,
        12,133,2018,9,133,1,133,3,133,2021,8,133,1,134,1,134,1,134,3,134,
        2026,8,134,1,134,1,134,1,134,1,134,3,134,2032,8,134,1,134,3,134,
        2035,8,134,1,135,1,135,1,135,1,136,1,136,1,136,1,136,3,136,2044,
        8,136,1,137,1,137,1,137,3,137,2049,8,137,1,138,1,138,1,138,1,138,
        5,138,2055,8,138,10,138,12,138,2058,9,138,1,138,1,138,1,139,1,139,
        1,139,3,139,2065,8,139,1,139,3,139,2068,8,139,1,140,1,140,1,141,
        1,141,1,141,1,141,1,141,1,141,1,141,1,141,1,141,1,141,3,141,2082,
        8,141,1,141,1,141,1,141,3,141,2087,8,141,1,142,1,142,3,142,2091,
        8,142,1,142,1,142,1,142,1,142,1,142,1,142,1,143,1,143,1,144,1,144,
        1,144,1,144,5,144,2105,8,144,10,144,12,144,2108,9,144,1,145,1,145,
        1,145,1,145,5,145,2114,8,145,10,145,12,145,2117,9,145,1,145,1,145,
        1,146,1,146,1,146,1,146,1,147,1,147,1,147,1,147,3,147,2129,8,147,
        1,147,1,147,1,148,1,148,1,148,1,148,3,148,2137,8,148,1,148,1,148,
        1,149,1,149,1,149,1,149,5,149,2145,8,149,10,149,12,149,2148,9,149,
        1,149,1,149,1,150,1,150,1,150,1,150,1,150,1,150,1,150,1,151,1,151,
        1,151,1,151,1,151,1,151,1,151,5,151,2166,8,151,10,151,12,151,2169,
        9,151,1,151,1,151,1,152,1,152,1,152,1,152,1,152,1,152,1,152,1,152,
        1,152,5,152,2182,8,152,10,152,12,152,2185,9,152,1,152,1,152,1,153,
        1,153,3,153,2191,8,153,1,153,1,153,1,153,1,153,3,153,2197,8,153,
        1,153,3,153,2200,8,153,1,153,3,153,2203,8,153,1,154,1,154,1,154,
        1,155,1,155,1,155,1,155,1,155,3,155,2213,8,155,1,155,3,155,2216,
        8,155,1,156,1,156,1,157,1,157,1,157,1,157,3,157,2224,8,157,1,158,
        1,158,3,158,2228,8,158,1,159,1,159,1,159,3,159,2233,8,159,1,159,
        1,159,1,159,3,159,2238,8,159,5,159,2240,8,159,10,159,12,159,2243,
        9,159,1,159,1,159,1,160,1,160,1,160,3,160,2250,8,160,1,160,1,160,
        3,160,2254,8,160,1,160,1,160,3,160,2258,8,160,1,160,1,160,3,160,
        2262,8,160,1,160,1,160,3,160,2266,8,160,1,160,1,160,3,160,2270,8,
        160,1,160,1,160,3,160,2274,8,160,1,160,1,160,3,160,2278,8,160,1,
        160,1,160,3,160,2282,8,160,1,160,1,160,3,160,2286,8,160,1,160,1,
        160,3,160,2290,8,160,1,160,1,160,3,160,2294,8,160,1,160,1,160,3,
        160,2298,8,160,1,160,1,160,3,160,2302,8,160,1,160,1,160,3,160,2306,
        8,160,1,160,1,160,3,160,2310,8,160,1,160,1,160,3,160,2314,8,160,
        1,160,1,160,1,160,1,160,3,160,2320,8,160,3,160,2322,8,160,1,161,
        1,161,1,162,1,162,1,162,1,162,1,162,1,162,1,162,1,162,1,162,1,162,
        3,162,2336,8,162,3,162,2338,8,162,1,162,1,162,1,162,1,162,1,162,
        1,162,1,162,1,162,1,162,3,162,2349,8,162,1,162,5,162,2352,8,162,
        10,162,12,162,2355,9,162,1,163,3,163,2358,8,163,1,163,1,163,3,163,
        2362,8,163,1,163,1,163,1,163,1,163,1,163,3,163,2369,8,163,1,163,
        1,163,1,163,1,163,1,163,5,163,2376,8,163,10,163,12,163,2379,9,163,
        1,163,1,163,1,163,3,163,2384,8,163,1,163,1,163,1,163,1,163,1,163,
        1,163,1,163,1,163,1,163,1,163,1,163,3,163,2397,8,163,1,163,1,163,
        1,163,1,163,1,163,3,163,2404,8,163,1,163,1,163,1,163,3,163,2409,
        8,163,1,163,1,163,1,163,1,163,3,163,2415,8,163,1,163,1,163,1,163,
        1,163,1,163,3,163,2422,8,163,3,163,2424,8,163,1,164,3,164,2427,8,
        164,1,164,1,164,1,164,1,164,1,164,1,164,1,164,1,164,5,164,2437,8,
        164,10,164,12,164,2440,9,164,1,164,1,164,3,164,2444,8,164,1,164,
        3,164,2447,8,164,1,164,1,164,1,164,1,164,3,164,2453,8,164,1,164,
        3,164,2456,8,164,1,164,1,164,1,164,1,164,3,164,2462,8,164,3,164,
        2464,8,164,1,165,1,165,1,165,1,165,3,165,2470,8,165,1,165,1,165,
        1,165,1,165,1,165,1,165,1,165,1,165,1,165,1,165,1,165,1,165,1,165,
        1,165,1,165,1,165,1,165,1,165,1,165,5,165,2491,8,165,10,165,12,165,
        2494,9,165,1,166,1,166,1,166,4,166,2499,8,166,11,166,12,166,2500,
        1,166,1,166,3,166,2505,8,166,1,166,1,166,1,166,1,166,1,166,4,166,
        2512,8,166,11,166,12,166,2513,1,166,1,166,3,166,2518,8,166,1,166,
        1,166,1,166,1,166,1,166,1,166,1,166,1,166,1,166,1,166,1,166,1,166,
        1,166,1,166,3,166,2534,8,166,1,166,1,166,1,166,1,166,1,166,1,166,
        1,166,3,166,2543,8,166,1,166,1,166,1,166,1,166,1,166,1,166,1,166,
        1,166,1,166,1,166,1,166,1,166,1,166,1,166,1,166,1,166,1,166,1,166,
        1,166,1,166,1,166,1,166,1,166,5,166,2568,8,166,10,166,12,166,2571,
        9,166,1,166,1,166,1,166,1,166,1,166,3,166,2578,8,166,1,166,1,166,
        1,166,5,166,2583,8,166,10,166,12,166,2586,9,166,3,166,2588,8,166,
        1,166,1,166,1,166,1,166,1,166,1,166,1,166,1,166,1,166,1,166,1,166,
        1,166,3,166,2602,8,166,1,166,1,166,1,166,3,166,2607,8,166,1,166,
        1,166,1,166,1,166,1,166,1,166,1,166,1,166,1,166,1,166,3,166,2619,
        8,166,1,166,1,166,1,166,1,166,1,166,1,166,1,166,3,166,2628,8,166,
        1,166,1,166,1,166,1,166,1,166,5,166,2635,8,166,10,166,12,166,2638,
        9,166,1,167,1,167,1,167,1,167,3,167,2644,8,167,1,168,1,168,1,168,
        1,168,1,168,5,168,2651,8,168,10,168,12,168,2654,9,168,1,168,1,168,
        1,168,1,168,1,168,1,168,5,168,2662,8,168,10,168,12,168,2665,9,168,
        1,168,1,168,1,169,1,169,1,169,1,169,1,169,5,169,2674,8,169,10,169,
        12,169,2677,9,169,1,169,1,169,1,170,1,170,1,170,1,170,1,170,5,170,
        2686,8,170,10,170,12,170,2689,9,170,1,170,1,170,1,171,1,171,1,171,
        1,171,1,171,1,171,1,171,1,172,1,172,1,172,1,172,3,172,2704,8,172,
        1,173,1,173,1,174,1,174,1,174,3,174,2711,8,174,1,175,1,175,1,175,
        1,175,1,175,1,175,3,175,2719,8,175,1,176,1,176,1,176,1,176,1,176,
        1,176,1,177,1,177,1,178,1,178,1,178,3,178,2732,8,178,1,179,1,179,
        1,179,3,179,2737,8,179,1,180,1,180,3,180,2741,8,180,1,181,1,181,
        1,181,4,181,2746,8,181,11,181,12,181,2747,1,182,1,182,1,182,3,182,
        2753,8,182,1,183,1,183,1,183,1,183,1,183,1,184,3,184,2761,8,184,
        1,184,1,184,3,184,2765,8,184,1,185,1,185,1,186,1,186,1,187,3,187,
        2772,8,187,1,187,1,187,3,187,2776,8,187,1,188,1,188,1,188,1,189,
        1,189,5,189,2783,8,189,10,189,12,189,2786,9,189,1,190,1,190,1,190,
        1,190,1,191,1,191,1,191,5,191,2795,8,191,10,191,12,191,2798,9,191,
        1,192,1,192,1,192,1,192,3,192,2804,8,192,1,193,1,193,1,193,1,193,
        3,193,2810,8,193,1,194,1,194,1,194,1,194,1,194,1,195,1,195,1,196,
        1,196,1,196,1,196,1,196,1,197,1,197,1,198,1,198,1,199,1,199,1,200,
        1,200,1,201,1,201,1,202,1,202,1,203,1,203,1,203,5,203,2839,8,203,
        10,203,12,203,2842,9,203,1,204,1,204,3,204,2846,8,204,1,204,1,204,
        1,205,1,205,1,205,1,205,1,206,1,206,1,206,1,207,1,207,1,207,1,207,
        5,207,2861,8,207,10,207,12,207,2864,9,207,1,207,1,207,1,208,1,208,
        1,208,3,208,2871,8,208,1,208,1,208,1,209,1,209,1,209,1,209,3,209,
        2879,8,209,1,210,1,210,1,210,1,210,1,210,3,210,2886,8,210,1,211,
        1,211,1,211,1,211,1,211,1,211,1,211,1,211,1,211,1,211,3,211,2898,
        8,211,1,212,1,212,1,212,1,212,1,212,1,212,1,212,1,212,1,212,1,212,
        1,212,1,212,1,212,1,212,3,212,2914,8,212,1,213,1,213,1,213,1,213,
        3,213,2920,8,213,1,213,1,213,1,213,1,213,3,213,2926,8,213,1,213,
        3,213,2929,8,213,1,214,1,214,1,214,1,215,1,215,1,216,1,216,1,217,
        1,217,1,218,1,218,1,219,1,219,1,220,1,220,1,221,1,221,1,222,1,222,
        1,223,1,223,1,224,1,224,3,224,2954,8,224,1,224,1,224,1,225,1,225,
        1,225,3,225,2961,8,225,1,225,3,225,2964,8,225,1,225,3,225,2967,8,
        225,1,225,3,225,2970,8,225,1,225,1,225,1,225,3,225,2975,8,225,1,
        225,3,225,2978,8,225,1,225,3,225,2981,8,225,1,225,3,225,2984,8,225,
        1,225,1,225,1,225,1,225,1,225,1,225,1,225,1,225,3,225,2994,8,225,
        1,226,1,226,3,226,2998,8,226,1,226,3,226,3001,8,226,1,226,1,226,
        1,226,3,226,3006,8,226,3,226,3008,8,226,1,226,0,5,96,130,324,330,
        332,227,0,2,4,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,
        42,44,46,48,50,52,54,56,58,60,62,64,66,68,70,72,74,76,78,80,82,84,
        86,88,90,92,94,96,98,100,102,104,106,108,110,112,114,116,118,120,
        122,124,126,128,130,132,134,136,138,140,142,144,146,148,150,152,
        154,156,158,160,162,164,166,168,170,172,174,176,178,180,182,184,
        186,188,190,192,194,196,198,200,202,204,206,208,210,212,214,216,
        218,220,222,224,226,228,230,232,234,236,238,240,242,244,246,248,
        250,252,254,256,258,260,262,264,266,268,270,272,274,276,278,280,
        282,284,286,288,290,292,294,296,298,300,302,304,306,308,310,312,
        314,316,318,320,322,324,326,328,330,332,334,336,338,340,342,344,
        346,348,350,352,354,356,358,360,362,364,366,368,370,372,374,376,
        378,380,382,384,386,388,390,392,394,396,398,400,402,404,406,408,
        410,412,414,416,418,420,422,424,426,428,430,432,434,436,438,440,
        442,444,446,448,450,452,0,47,2,0,10,10,37,37,4,0,261,261,307,307,
        345,345,400,400,2,0,298,298,461,461,2,0,54,54,84,84,2,0,8,8,11,11,
        2,0,108,108,319,319,4,0,283,283,317,317,344,344,437,437,2,0,205,
        205,271,271,2,0,69,69,139,139,2,0,274,274,371,371,5,0,254,254,291,
        291,327,327,330,331,356,356,4,0,270,270,355,355,375,375,389,389,
        2,0,386,386,399,399,5,0,252,252,298,298,312,312,333,333,394,394,
        2,0,47,47,70,70,3,0,29,29,66,66,181,181,5,0,30,30,159,160,167,167,
        173,173,360,360,2,0,253,253,397,397,3,0,66,66,155,155,181,181,2,
        0,48,48,310,310,3,0,26,26,111,111,205,205,3,0,48,48,109,109,310,
        310,3,0,62,62,105,105,197,197,3,0,222,222,259,259,357,357,11,0,13,
        13,168,168,175,175,218,219,233,233,260,260,315,316,410,410,427,427,
        432,432,448,449,2,0,453,453,455,455,4,0,262,263,275,275,293,293,
        358,358,2,0,211,211,349,349,4,0,292,292,357,357,435,435,439,439,
        2,0,213,213,418,418,2,0,205,205,209,209,2,0,334,334,395,395,2,0,
        390,390,395,395,2,0,465,465,490,491,4,0,39,39,488,488,492,492,495,
        495,2,0,490,491,493,493,16,0,12,12,90,90,133,133,157,157,175,176,
        218,218,222,222,259,259,263,263,275,275,293,293,315,316,358,358,
        410,410,427,428,432,432,1,0,490,491,1,0,499,500,2,0,499,499,501,
        501,2,0,34,34,423,423,2,0,292,292,435,435,10,0,92,92,94,94,129,129,
        198,198,261,261,307,307,345,345,348,348,400,400,456,456,17,0,19,
        19,33,33,35,35,43,43,67,67,92,95,99,100,129,129,149,149,198,199,
        202,202,261,261,307,307,345,345,348,348,400,400,456,456,6,0,205,
        205,223,223,271,271,332,332,434,434,488,488,35,0,68,68,91,91,129,
        129,198,198,204,204,211,211,215,215,231,232,240,240,242,242,249,
        250,259,259,287,287,291,291,297,297,303,303,307,307,327,327,330,
        331,333,333,345,345,348,348,355,355,369,369,375,377,380,381,386,
        386,388,389,394,394,400,400,416,417,427,431,436,436,442,442,456,
        456,24,0,6,11,13,13,15,17,19,33,35,42,44,49,51,51,53,69,71,79,81,
        86,88,88,91,100,102,129,131,132,135,147,149,156,158,162,164,164,
        166,175,177,182,184,184,186,198,200,203,338,338,3290,0,454,1,0,0,
        0,2,461,1,0,0,0,4,464,1,0,0,0,6,466,1,0,0,0,8,470,1,0,0,0,10,478,
        1,0,0,0,12,480,1,0,0,0,14,520,1,0,0,0,16,522,1,0,0,0,18,525,1,0,
        0,0,20,534,1,0,0,0,22,545,1,0,0,0,24,548,1,0,0,0,26,579,1,0,0,0,
        28,581,1,0,0,0,30,597,1,0,0,0,32,599,1,0,0,0,34,616,1,0,0,0,36,618,
        1,0,0,0,38,622,1,0,0,0,40,641,1,0,0,0,42,646,1,0,0,0,44,651,1,0,
        0,0,46,656,1,0,0,0,48,662,1,0,0,0,50,666,1,0,0,0,52,670,1,0,0,0,
        54,708,1,0,0,0,56,764,1,0,0,0,58,766,1,0,0,0,60,828,1,0,0,0,62,830,
        1,0,0,0,64,841,1,0,0,0,66,894,1,0,0,0,68,896,1,0,0,0,70,907,1,0,
        0,0,72,921,1,0,0,0,74,923,1,0,0,0,76,932,1,0,0,0,78,934,1,0,0,0,
        80,941,1,0,0,0,82,944,1,0,0,0,84,953,1,0,0,0,86,957,1,0,0,0,88,961,
        1,0,0,0,90,965,1,0,0,0,92,969,1,0,0,0,94,991,1,0,0,0,96,1018,1,0,
        0,0,98,1043,1,0,0,0,100,1052,1,0,0,0,102,1064,1,0,0,0,104,1075,1,
        0,0,0,106,1094,1,0,0,0,108,1096,1,0,0,0,110,1108,1,0,0,0,112,1113,
        1,0,0,0,114,1134,1,0,0,0,116,1163,1,0,0,0,118,1167,1,0,0,0,120,1169,
        1,0,0,0,122,1171,1,0,0,0,124,1173,1,0,0,0,126,1176,1,0,0,0,128,1197,
        1,0,0,0,130,1229,1,0,0,0,132,1261,1,0,0,0,134,1263,1,0,0,0,136,1275,
        1,0,0,0,138,1307,1,0,0,0,140,1309,1,0,0,0,142,1354,1,0,0,0,144,1403,
        1,0,0,0,146,1407,1,0,0,0,148,1414,1,0,0,0,150,1426,1,0,0,0,152,1431,
        1,0,0,0,154,1442,1,0,0,0,156,1448,1,0,0,0,158,1450,1,0,0,0,160,1461,
        1,0,0,0,162,1466,1,0,0,0,164,1478,1,0,0,0,166,1480,1,0,0,0,168,1484,
        1,0,0,0,170,1488,1,0,0,0,172,1499,1,0,0,0,174,1517,1,0,0,0,176,1535,
        1,0,0,0,178,1567,1,0,0,0,180,1569,1,0,0,0,182,1571,1,0,0,0,184,1590,
        1,0,0,0,186,1592,1,0,0,0,188,1626,1,0,0,0,190,1632,1,0,0,0,192,1634,
        1,0,0,0,194,1644,1,0,0,0,196,1654,1,0,0,0,198,1664,1,0,0,0,200,1717,
        1,0,0,0,202,1719,1,0,0,0,204,1731,1,0,0,0,206,1734,1,0,0,0,208,1736,
        1,0,0,0,210,1743,1,0,0,0,212,1745,1,0,0,0,214,1747,1,0,0,0,216,1750,
        1,0,0,0,218,1759,1,0,0,0,220,1764,1,0,0,0,222,1781,1,0,0,0,224,1812,
        1,0,0,0,226,1822,1,0,0,0,228,1832,1,0,0,0,230,1840,1,0,0,0,232,1845,
        1,0,0,0,234,1850,1,0,0,0,236,1876,1,0,0,0,238,1878,1,0,0,0,240,1887,
        1,0,0,0,242,1898,1,0,0,0,244,1910,1,0,0,0,246,1936,1,0,0,0,248,1938,
        1,0,0,0,250,1956,1,0,0,0,252,1958,1,0,0,0,254,1963,1,0,0,0,256,1966,
        1,0,0,0,258,1970,1,0,0,0,260,1974,1,0,0,0,262,2004,1,0,0,0,264,2008,
        1,0,0,0,266,2010,1,0,0,0,268,2022,1,0,0,0,270,2036,1,0,0,0,272,2043,
        1,0,0,0,274,2048,1,0,0,0,276,2050,1,0,0,0,278,2061,1,0,0,0,280,2069,
        1,0,0,0,282,2086,1,0,0,0,284,2090,1,0,0,0,286,2098,1,0,0,0,288,2100,
        1,0,0,0,290,2109,1,0,0,0,292,2120,1,0,0,0,294,2124,1,0,0,0,296,2132,
        1,0,0,0,298,2140,1,0,0,0,300,2151,1,0,0,0,302,2158,1,0,0,0,304,2172,
        1,0,0,0,306,2202,1,0,0,0,308,2204,1,0,0,0,310,2207,1,0,0,0,312,2217,
        1,0,0,0,314,2219,1,0,0,0,316,2227,1,0,0,0,318,2229,1,0,0,0,320,2321,
        1,0,0,0,322,2323,1,0,0,0,324,2337,1,0,0,0,326,2423,1,0,0,0,328,2463,
        1,0,0,0,330,2469,1,0,0,0,332,2627,1,0,0,0,334,2643,1,0,0,0,336,2645,
        1,0,0,0,338,2668,1,0,0,0,340,2680,1,0,0,0,342,2692,1,0,0,0,344,2703,
        1,0,0,0,346,2705,1,0,0,0,348,2710,1,0,0,0,350,2718,1,0,0,0,352,2720,
        1,0,0,0,354,2726,1,0,0,0,356,2731,1,0,0,0,358,2733,1,0,0,0,360,2738,
        1,0,0,0,362,2745,1,0,0,0,364,2749,1,0,0,0,366,2754,1,0,0,0,368,2764,
        1,0,0,0,370,2766,1,0,0,0,372,2768,1,0,0,0,374,2771,1,0,0,0,376,2777,
        1,0,0,0,378,2784,1,0,0,0,380,2787,1,0,0,0,382,2791,1,0,0,0,384,2803,
        1,0,0,0,386,2809,1,0,0,0,388,2811,1,0,0,0,390,2816,1,0,0,0,392,2818,
        1,0,0,0,394,2823,1,0,0,0,396,2825,1,0,0,0,398,2827,1,0,0,0,400,2829,
        1,0,0,0,402,2831,1,0,0,0,404,2833,1,0,0,0,406,2835,1,0,0,0,408,2843,
        1,0,0,0,410,2849,1,0,0,0,412,2853,1,0,0,0,414,2856,1,0,0,0,416,2867,
        1,0,0,0,418,2878,1,0,0,0,420,2885,1,0,0,0,422,2897,1,0,0,0,424,2913,
        1,0,0,0,426,2928,1,0,0,0,428,2930,1,0,0,0,430,2933,1,0,0,0,432,2935,
        1,0,0,0,434,2937,1,0,0,0,436,2939,1,0,0,0,438,2941,1,0,0,0,440,2943,
        1,0,0,0,442,2945,1,0,0,0,444,2947,1,0,0,0,446,2949,1,0,0,0,448,2953,
        1,0,0,0,450,2993,1,0,0,0,452,3007,1,0,0,0,454,455,3,2,1,0,455,456,
        5,0,0,1,456,1,1,0,0,0,457,460,3,448,224,0,458,460,3,4,2,0,459,457,
        1,0,0,0,459,458,1,0,0,0,460,463,1,0,0,0,461,459,1,0,0,0,461,462,
        1,0,0,0,462,3,1,0,0,0,463,461,1,0,0,0,464,465,5,481,0,0,465,5,1,
        0,0,0,466,467,3,10,5,0,467,7,1,0,0,0,468,471,3,96,48,0,469,471,3,
        90,45,0,470,468,1,0,0,0,470,469,1,0,0,0,471,9,1,0,0,0,472,479,3,
        12,6,0,473,479,3,62,31,0,474,479,3,64,32,0,475,479,3,54,27,0,476,
        479,3,58,29,0,477,479,3,20,10,0,478,472,1,0,0,0,478,473,1,0,0,0,
        478,474,1,0,0,0,478,475,1,0,0,0,478,476,1,0,0,0,478,477,1,0,0,0,
        479,11,1,0,0,0,480,482,5,251,0,0,481,483,5,172,0,0,482,481,1,0,0,
        0,482,483,1,0,0,0,483,484,1,0,0,0,484,486,5,422,0,0,485,487,3,410,
        205,0,486,485,1,0,0,0,486,487,1,0,0,0,487,488,1,0,0,0,488,492,3,
        400,200,0,489,491,3,14,7,0,490,489,1,0,0,0,491,494,1,0,0,0,492,490,
        1,0,0,0,492,493,1,0,0,0,493,498,1,0,0,0,494,492,1,0,0,0,495,499,
        3,52,26,0,496,497,5,334,0,0,497,499,3,402,201,0,498,495,1,0,0,0,
        498,496,1,0,0,0,499,503,1,0,0,0,500,502,3,14,7,0,501,500,1,0,0,0,
        502,505,1,0,0,0,503,501,1,0,0,0,503,504,1,0,0,0,504,13,1,0,0,0,505,
        503,1,0,0,0,506,521,3,258,129,0,507,521,3,408,204,0,508,521,3,266,
        133,0,509,521,3,268,134,0,510,521,3,190,95,0,511,521,3,36,18,0,512,
        521,3,44,22,0,513,521,3,38,19,0,514,521,3,18,9,0,515,521,3,166,83,
        0,516,521,3,42,21,0,517,521,3,270,135,0,518,521,3,16,8,0,519,521,
        3,22,11,0,520,506,1,0,0,0,520,507,1,0,0,0,520,508,1,0,0,0,520,509,
        1,0,0,0,520,510,1,0,0,0,520,511,1,0,0,0,520,512,1,0,0,0,520,513,
        1,0,0,0,520,514,1,0,0,0,520,515,1,0,0,0,520,516,1,0,0,0,520,517,
        1,0,0,0,520,518,1,0,0,0,520,519,1,0,0,0,521,15,1,0,0,0,522,523,5,
        89,0,0,523,524,3,72,36,0,524,17,1,0,0,0,525,526,5,409,0,0,526,527,
        5,226,0,0,527,528,5,476,0,0,528,530,3,384,192,0,529,531,7,0,0,0,
        530,529,1,0,0,0,530,531,1,0,0,0,531,532,1,0,0,0,532,533,5,477,0,
        0,533,19,1,0,0,0,534,535,5,251,0,0,535,537,5,422,0,0,536,538,3,410,
        205,0,537,536,1,0,0,0,537,538,1,0,0,0,538,539,1,0,0,0,539,543,3,
        400,200,0,540,544,3,28,14,0,541,544,3,32,16,0,542,544,3,24,12,0,
        543,540,1,0,0,0,543,541,1,0,0,0,543,542,1,0,0,0,544,21,1,0,0,0,545,
        546,5,423,0,0,546,547,3,414,207,0,547,23,1,0,0,0,548,552,3,270,135,
        0,549,551,3,26,13,0,550,549,1,0,0,0,551,554,1,0,0,0,552,550,1,0,
        0,0,552,553,1,0,0,0,553,556,1,0,0,0,554,552,1,0,0,0,555,557,5,212,
        0,0,556,555,1,0,0,0,556,557,1,0,0,0,557,558,1,0,0,0,558,559,3,96,
        48,0,559,563,1,0,0,0,560,562,3,26,13,0,561,560,1,0,0,0,562,565,1,
        0,0,0,563,561,1,0,0,0,563,564,1,0,0,0,564,25,1,0,0,0,565,563,1,0,
        0,0,566,580,3,258,129,0,567,568,5,105,0,0,568,580,3,414,207,0,569,
        580,3,22,11,0,570,580,3,190,95,0,571,580,3,36,18,0,572,573,5,453,
        0,0,573,574,3,372,186,0,574,575,5,478,0,0,575,576,3,96,48,0,576,
        577,5,477,0,0,577,580,1,0,0,0,578,580,3,308,154,0,579,566,1,0,0,
        0,579,567,1,0,0,0,579,569,1,0,0,0,579,570,1,0,0,0,579,571,1,0,0,
        0,579,572,1,0,0,0,579,578,1,0,0,0,580,27,1,0,0,0,581,582,3,52,26,
        0,582,583,3,270,135,0,583,587,1,0,0,0,584,586,3,30,15,0,585,584,
        1,0,0,0,586,589,1,0,0,0,587,585,1,0,0,0,587,588,1,0,0,0,588,29,1,
        0,0,0,589,587,1,0,0,0,590,598,3,258,129,0,591,592,5,105,0,0,592,
        598,3,414,207,0,593,598,3,22,11,0,594,598,3,190,95,0,595,598,3,36,
        18,0,596,598,3,308,154,0,597,590,1,0,0,0,597,591,1,0,0,0,597,593,
        1,0,0,0,597,594,1,0,0,0,597,595,1,0,0,0,597,596,1,0,0,0,598,31,1,
        0,0,0,599,600,3,270,135,0,600,601,5,212,0,0,601,602,3,96,48,0,602,
        606,1,0,0,0,603,605,3,34,17,0,604,603,1,0,0,0,605,608,1,0,0,0,606,
        604,1,0,0,0,606,607,1,0,0,0,607,33,1,0,0,0,608,606,1,0,0,0,609,617,
        3,258,129,0,610,611,5,105,0,0,611,617,3,414,207,0,612,617,3,22,11,
        0,613,617,3,190,95,0,614,617,3,36,18,0,615,617,3,308,154,0,616,609,
        1,0,0,0,616,610,1,0,0,0,616,612,1,0,0,0,616,613,1,0,0,0,616,614,
        1,0,0,0,616,615,1,0,0,0,617,35,1,0,0,0,618,619,5,319,0,0,619,620,
        5,499,0,0,620,621,5,225,0,0,621,37,1,0,0,0,622,623,5,110,0,0,623,
        624,5,226,0,0,624,625,5,476,0,0,625,627,5,501,0,0,626,628,3,346,
        173,0,627,626,1,0,0,0,627,628,1,0,0,0,628,636,1,0,0,0,629,630,5,
        480,0,0,630,632,5,501,0,0,631,633,3,346,173,0,632,631,1,0,0,0,632,
        633,1,0,0,0,633,635,1,0,0,0,634,629,1,0,0,0,635,638,1,0,0,0,636,
        634,1,0,0,0,636,637,1,0,0,0,637,639,1,0,0,0,638,636,1,0,0,0,639,
        640,5,477,0,0,640,39,1,0,0,0,641,642,5,398,0,0,642,643,5,56,0,0,
        643,644,5,404,0,0,644,645,3,430,215,0,645,41,1,0,0,0,646,647,5,294,
        0,0,647,648,5,425,0,0,648,649,5,226,0,0,649,650,3,430,215,0,650,
        43,1,0,0,0,651,652,5,408,0,0,652,654,5,212,0,0,653,655,3,384,192,
        0,654,653,1,0,0,0,654,655,1,0,0,0,655,45,1,0,0,0,656,657,5,408,0,
        0,657,658,5,212,0,0,658,660,5,311,0,0,659,661,3,384,192,0,660,659,
        1,0,0,0,660,661,1,0,0,0,661,47,1,0,0,0,662,664,5,367,0,0,663,665,
        3,384,192,0,664,663,1,0,0,0,664,665,1,0,0,0,665,49,1,0,0,0,666,667,
        5,398,0,0,667,668,5,56,0,0,668,669,5,268,0,0,669,51,1,0,0,0,670,
        671,5,476,0,0,671,673,3,274,137,0,672,674,3,308,154,0,673,672,1,
        0,0,0,673,674,1,0,0,0,674,682,1,0,0,0,675,676,5,480,0,0,676,678,
        3,274,137,0,677,679,3,308,154,0,678,677,1,0,0,0,678,679,1,0,0,0,
        679,681,1,0,0,0,680,675,1,0,0,0,681,684,1,0,0,0,682,680,1,0,0,0,
        682,683,1,0,0,0,683,690,1,0,0,0,684,682,1,0,0,0,685,686,5,480,0,
        0,686,688,3,282,141,0,687,689,3,308,154,0,688,687,1,0,0,0,688,689,
        1,0,0,0,689,691,1,0,0,0,690,685,1,0,0,0,690,691,1,0,0,0,691,697,
        1,0,0,0,692,693,5,480,0,0,693,695,3,284,142,0,694,696,3,308,154,
        0,695,694,1,0,0,0,695,696,1,0,0,0,696,698,1,0,0,0,697,692,1,0,0,
        0,697,698,1,0,0,0,698,704,1,0,0,0,699,700,5,480,0,0,700,702,3,256,
        128,0,701,703,3,308,154,0,702,701,1,0,0,0,702,703,1,0,0,0,703,705,
        1,0,0,0,704,699,1,0,0,0,704,705,1,0,0,0,705,706,1,0,0,0,706,707,
        5,477,0,0,707,53,1,0,0,0,708,710,5,251,0,0,709,711,5,172,0,0,710,
        709,1,0,0,0,710,711,1,0,0,0,711,712,1,0,0,0,712,714,5,422,0,0,713,
        715,3,410,205,0,714,713,1,0,0,0,714,715,1,0,0,0,715,716,1,0,0,0,
        716,720,3,400,200,0,717,719,3,56,28,0,718,717,1,0,0,0,719,722,1,
        0,0,0,720,718,1,0,0,0,720,721,1,0,0,0,721,723,1,0,0,0,722,720,1,
        0,0,0,723,724,5,398,0,0,724,725,5,56,0,0,725,726,5,404,0,0,726,730,
        3,418,209,0,727,729,3,56,28,0,728,727,1,0,0,0,729,732,1,0,0,0,730,
        728,1,0,0,0,730,731,1,0,0,0,731,733,1,0,0,0,732,730,1,0,0,0,733,
        734,5,409,0,0,734,735,5,212,0,0,735,736,5,311,0,0,736,740,3,418,
        209,0,737,739,3,56,28,0,738,737,1,0,0,0,739,742,1,0,0,0,740,738,
        1,0,0,0,740,741,1,0,0,0,741,743,1,0,0,0,742,740,1,0,0,0,743,744,
        5,367,0,0,744,748,3,418,209,0,745,747,3,56,28,0,746,745,1,0,0,0,
        747,750,1,0,0,0,748,746,1,0,0,0,748,749,1,0,0,0,749,751,1,0,0,0,
        750,748,1,0,0,0,751,755,3,22,11,0,752,754,3,56,28,0,753,752,1,0,
        0,0,754,757,1,0,0,0,755,753,1,0,0,0,755,756,1,0,0,0,756,55,1,0,0,
        0,757,755,1,0,0,0,758,765,3,52,26,0,759,765,3,308,154,0,760,765,
        3,258,129,0,761,765,3,408,204,0,762,765,3,266,133,0,763,765,3,268,
        134,0,764,758,1,0,0,0,764,759,1,0,0,0,764,760,1,0,0,0,764,761,1,
        0,0,0,764,762,1,0,0,0,764,763,1,0,0,0,765,57,1,0,0,0,766,767,5,251,
        0,0,767,768,5,289,0,0,768,770,5,422,0,0,769,771,3,410,205,0,770,
        769,1,0,0,0,770,771,1,0,0,0,771,772,1,0,0,0,772,776,3,400,200,0,
        773,775,3,60,30,0,774,773,1,0,0,0,775,778,1,0,0,0,776,774,1,0,0,
        0,776,777,1,0,0,0,777,779,1,0,0,0,778,776,1,0,0,0,779,783,3,52,26,
        0,780,782,3,60,30,0,781,780,1,0,0,0,782,785,1,0,0,0,783,781,1,0,
        0,0,783,784,1,0,0,0,784,786,1,0,0,0,785,783,1,0,0,0,786,787,5,398,
        0,0,787,788,5,56,0,0,788,789,5,404,0,0,789,793,3,418,209,0,790,792,
        3,60,30,0,791,790,1,0,0,0,792,795,1,0,0,0,793,791,1,0,0,0,793,794,
        1,0,0,0,794,796,1,0,0,0,795,793,1,0,0,0,796,797,5,409,0,0,797,798,
        5,212,0,0,798,799,5,311,0,0,799,803,3,418,209,0,800,802,3,60,30,
        0,801,800,1,0,0,0,802,805,1,0,0,0,803,801,1,0,0,0,803,804,1,0,0,
        0,804,806,1,0,0,0,805,803,1,0,0,0,806,807,5,367,0,0,807,811,3,418,
        209,0,808,810,3,60,30,0,809,808,1,0,0,0,810,813,1,0,0,0,811,809,
        1,0,0,0,811,812,1,0,0,0,812,814,1,0,0,0,813,811,1,0,0,0,814,815,
        5,89,0,0,815,819,3,72,36,0,816,818,3,60,30,0,817,816,1,0,0,0,818,
        821,1,0,0,0,819,817,1,0,0,0,819,820,1,0,0,0,820,59,1,0,0,0,821,819,
        1,0,0,0,822,829,3,308,154,0,823,829,3,258,129,0,824,829,3,408,204,
        0,825,829,3,266,133,0,826,829,3,268,134,0,827,829,3,22,11,0,828,
        822,1,0,0,0,828,823,1,0,0,0,828,824,1,0,0,0,828,825,1,0,0,0,828,
        826,1,0,0,0,828,827,1,0,0,0,829,61,1,0,0,0,830,831,5,251,0,0,831,
        833,5,422,0,0,832,834,3,410,205,0,833,832,1,0,0,0,833,834,1,0,0,
        0,834,835,1,0,0,0,835,836,3,400,200,0,836,839,3,408,204,0,837,838,
        5,212,0,0,838,840,3,96,48,0,839,837,1,0,0,0,839,840,1,0,0,0,840,
        63,1,0,0,0,841,842,5,251,0,0,842,843,5,457,0,0,843,844,5,422,0,0,
        844,848,3,400,200,0,845,847,3,66,33,0,846,845,1,0,0,0,847,850,1,
        0,0,0,848,846,1,0,0,0,848,849,1,0,0,0,849,851,1,0,0,0,850,848,1,
        0,0,0,851,852,5,476,0,0,852,853,5,384,0,0,853,854,5,79,0,0,854,855,
        5,476,0,0,855,860,3,384,192,0,856,857,5,480,0,0,857,859,3,384,192,
        0,858,856,1,0,0,0,859,862,1,0,0,0,860,858,1,0,0,0,860,861,1,0,0,
        0,861,863,1,0,0,0,862,860,1,0,0,0,863,866,5,477,0,0,864,865,5,354,
        0,0,865,867,5,41,0,0,866,864,1,0,0,0,866,867,1,0,0,0,867,868,1,0,
        0,0,868,872,5,477,0,0,869,871,3,66,33,0,870,869,1,0,0,0,871,874,
        1,0,0,0,872,870,1,0,0,0,872,873,1,0,0,0,873,875,1,0,0,0,874,872,
        1,0,0,0,875,876,5,458,0,0,876,877,5,469,0,0,877,878,5,318,0,0,878,
        879,3,384,192,0,879,880,7,1,0,0,880,884,1,0,0,0,881,883,3,66,33,
        0,882,881,1,0,0,0,883,886,1,0,0,0,884,882,1,0,0,0,884,885,1,0,0,
        0,885,65,1,0,0,0,886,884,1,0,0,0,887,895,3,258,129,0,888,895,3,408,
        204,0,889,890,5,459,0,0,890,891,5,469,0,0,891,895,7,2,0,0,892,893,
        5,212,0,0,893,895,3,96,48,0,894,887,1,0,0,0,894,888,1,0,0,0,894,
        889,1,0,0,0,894,892,1,0,0,0,895,67,1,0,0,0,896,897,5,445,0,0,897,
        898,5,74,0,0,898,904,3,70,35,0,899,900,5,480,0,0,900,901,5,74,0,
        0,901,903,3,70,35,0,902,899,1,0,0,0,903,906,1,0,0,0,904,902,1,0,
        0,0,904,905,1,0,0,0,905,69,1,0,0,0,906,904,1,0,0,0,907,910,3,72,
        36,0,908,909,5,473,0,0,909,911,5,74,0,0,910,908,1,0,0,0,910,911,
        1,0,0,0,911,71,1,0,0,0,912,922,5,498,0,0,913,915,5,495,0,0,914,916,
        5,501,0,0,915,914,1,0,0,0,915,916,1,0,0,0,916,918,1,0,0,0,917,913,
        1,0,0,0,918,919,1,0,0,0,919,917,1,0,0,0,919,920,1,0,0,0,920,922,
        1,0,0,0,921,912,1,0,0,0,921,917,1,0,0,0,922,73,1,0,0,0,923,925,5,
        68,0,0,924,926,5,354,0,0,925,924,1,0,0,0,925,926,1,0,0,0,926,927,
        1,0,0,0,927,928,5,285,0,0,928,75,1,0,0,0,929,933,7,3,0,0,930,931,
        7,4,0,0,931,933,3,406,203,0,932,929,1,0,0,0,932,930,1,0,0,0,933,
        77,1,0,0,0,934,936,5,137,0,0,935,937,3,406,203,0,936,935,1,0,0,0,
        936,937,1,0,0,0,937,938,1,0,0,0,938,939,5,433,0,0,939,940,3,406,
        203,0,940,79,1,0,0,0,941,942,5,403,0,0,942,943,3,414,207,0,943,81,
        1,0,0,0,944,945,5,6,0,0,945,946,5,246,0,0,946,947,3,286,143,0,947,
        948,5,384,0,0,948,949,5,79,0,0,949,951,3,318,159,0,950,952,3,88,
        44,0,951,950,1,0,0,0,951,952,1,0,0,0,952,83,1,0,0,0,953,954,5,276,
        0,0,954,955,5,246,0,0,955,956,3,286,143,0,956,85,1,0,0,0,957,958,
        5,6,0,0,958,959,5,438,0,0,959,960,3,318,159,0,960,87,1,0,0,0,961,
        962,5,354,0,0,962,963,5,41,0,0,963,89,1,0,0,0,964,966,5,284,0,0,
        965,964,1,0,0,0,965,966,1,0,0,0,966,967,1,0,0,0,967,968,3,92,46,
        0,968,91,1,0,0,0,969,970,5,314,0,0,970,972,7,5,0,0,971,973,5,422,
        0,0,972,971,1,0,0,0,972,973,1,0,0,0,973,974,1,0,0,0,974,976,3,402,
        201,0,975,977,3,94,47,0,976,975,1,0,0,0,976,977,1,0,0,0,977,979,
        1,0,0,0,978,980,3,318,159,0,979,978,1,0,0,0,979,980,1,0,0,0,980,
        989,1,0,0,0,981,990,3,96,48,0,982,990,3,288,144,0,983,984,5,138,
        0,0,984,985,3,186,93,0,985,986,3,450,225,0,986,990,1,0,0,0,987,988,
        5,422,0,0,988,990,3,402,201,0,989,981,1,0,0,0,989,982,1,0,0,0,989,
        983,1,0,0,0,989,987,1,0,0,0,990,93,1,0,0,0,991,992,5,371,0,0,992,
        993,3,414,207,0,993,95,1,0,0,0,994,995,6,48,-1,0,995,996,3,98,49,
        0,996,997,3,96,48,4,997,1019,1,0,0,0,998,999,5,476,0,0,999,1000,
        3,96,48,0,1000,1001,5,477,0,0,1001,1019,1,0,0,0,1002,1005,3,108,
        54,0,1003,1005,3,450,225,0,1004,1002,1,0,0,0,1004,1003,1,0,0,0,1005,
        1007,1,0,0,0,1006,1008,3,226,113,0,1007,1006,1,0,0,0,1007,1008,1,
        0,0,0,1008,1010,1,0,0,0,1009,1011,3,224,112,0,1010,1009,1,0,0,0,
        1010,1011,1,0,0,0,1011,1013,1,0,0,0,1012,1014,3,230,115,0,1013,1012,
        1,0,0,0,1013,1014,1,0,0,0,1014,1016,1,0,0,0,1015,1017,3,232,116,
        0,1016,1015,1,0,0,0,1016,1017,1,0,0,0,1017,1019,1,0,0,0,1018,994,
        1,0,0,0,1018,998,1,0,0,0,1018,1004,1,0,0,0,1019,1040,1,0,0,0,1020,
        1021,10,2,0,0,1021,1023,7,6,0,0,1022,1024,7,7,0,0,1023,1022,1,0,
        0,0,1023,1024,1,0,0,0,1024,1025,1,0,0,0,1025,1027,3,96,48,0,1026,
        1028,3,226,113,0,1027,1026,1,0,0,0,1027,1028,1,0,0,0,1028,1030,1,
        0,0,0,1029,1031,3,224,112,0,1030,1029,1,0,0,0,1030,1031,1,0,0,0,
        1031,1033,1,0,0,0,1032,1034,3,230,115,0,1033,1032,1,0,0,0,1033,1034,
        1,0,0,0,1034,1036,1,0,0,0,1035,1037,3,232,116,0,1036,1035,1,0,0,
        0,1036,1037,1,0,0,0,1037,1039,1,0,0,0,1038,1020,1,0,0,0,1039,1042,
        1,0,0,0,1040,1038,1,0,0,0,1040,1041,1,0,0,0,1041,97,1,0,0,0,1042,
        1040,1,0,0,0,1043,1044,5,453,0,0,1044,1049,3,104,52,0,1045,1046,
        5,480,0,0,1046,1048,3,104,52,0,1047,1045,1,0,0,0,1048,1051,1,0,0,
        0,1049,1047,1,0,0,0,1049,1050,1,0,0,0,1050,99,1,0,0,0,1051,1049,
        1,0,0,0,1052,1053,5,447,0,0,1053,1061,3,102,51,0,1054,1057,5,480,
        0,0,1055,1057,3,372,186,0,1056,1054,1,0,0,0,1056,1055,1,0,0,0,1057,
        1058,1,0,0,0,1058,1060,3,102,51,0,1059,1056,1,0,0,0,1060,1063,1,
        0,0,0,1061,1059,1,0,0,0,1061,1062,1,0,0,0,1062,101,1,0,0,0,1063,
        1061,1,0,0,0,1064,1065,5,476,0,0,1065,1070,3,322,161,0,1066,1067,
        5,480,0,0,1067,1069,3,322,161,0,1068,1066,1,0,0,0,1069,1072,1,0,
        0,0,1070,1068,1,0,0,0,1070,1071,1,0,0,0,1071,1073,1,0,0,0,1072,1070,
        1,0,0,0,1073,1074,5,477,0,0,1074,103,1,0,0,0,1075,1087,3,106,53,
        0,1076,1077,5,476,0,0,1077,1082,3,316,158,0,1078,1079,5,480,0,0,
        1079,1081,3,316,158,0,1080,1078,1,0,0,0,1081,1084,1,0,0,0,1082,1080,
        1,0,0,0,1082,1083,1,0,0,0,1083,1085,1,0,0,0,1084,1082,1,0,0,0,1085,
        1086,5,477,0,0,1086,1088,1,0,0,0,1087,1076,1,0,0,0,1087,1088,1,0,
        0,0,1088,1089,1,0,0,0,1089,1090,5,212,0,0,1090,1091,5,476,0,0,1091,
        1092,3,96,48,0,1092,1093,5,477,0,0,1093,105,1,0,0,0,1094,1095,3,
        384,192,0,1095,107,1,0,0,0,1096,1098,5,401,0,0,1097,1099,3,436,218,
        0,1098,1097,1,0,0,0,1098,1099,1,0,0,0,1099,1100,1,0,0,0,1100,1105,
        3,452,226,0,1101,1102,5,480,0,0,1102,1104,3,452,226,0,1103,1101,
        1,0,0,0,1104,1107,1,0,0,0,1105,1103,1,0,0,0,1105,1106,1,0,0,0,1106,
        109,1,0,0,0,1107,1105,1,0,0,0,1108,1109,5,50,0,0,1109,1110,5,476,
        0,0,1110,1111,3,186,93,0,1111,1112,5,477,0,0,1112,111,1,0,0,0,1113,
        1116,3,116,58,0,1114,1115,7,8,0,0,1115,1117,5,102,0,0,1116,1114,
        1,0,0,0,1116,1117,1,0,0,0,1117,1118,1,0,0,0,1118,1120,5,368,0,0,
        1119,1121,3,404,202,0,1120,1119,1,0,0,0,1120,1121,1,0,0,0,1121,1132,
        1,0,0,0,1122,1124,5,476,0,0,1123,1125,3,114,57,0,1124,1123,1,0,0,
        0,1124,1125,1,0,0,0,1125,1126,1,0,0,0,1126,1128,3,224,112,0,1127,
        1129,3,126,63,0,1128,1127,1,0,0,0,1128,1129,1,0,0,0,1129,1130,1,
        0,0,0,1130,1131,5,477,0,0,1131,1133,1,0,0,0,1132,1122,1,0,0,0,1132,
        1133,1,0,0,0,1133,113,1,0,0,0,1134,1135,7,9,0,0,1135,1136,5,226,
        0,0,1136,1141,3,316,158,0,1137,1138,5,480,0,0,1138,1140,3,316,158,
        0,1139,1137,1,0,0,0,1140,1143,1,0,0,0,1141,1139,1,0,0,0,1141,1142,
        1,0,0,0,1142,1146,1,0,0,0,1143,1141,1,0,0,0,1144,1145,5,469,0,0,
        1145,1147,3,322,161,0,1146,1144,1,0,0,0,1146,1147,1,0,0,0,1147,115,
        1,0,0,0,1148,1149,3,118,59,0,1149,1158,5,476,0,0,1150,1155,3,350,
        175,0,1151,1152,5,480,0,0,1152,1154,3,350,175,0,1153,1151,1,0,0,
        0,1154,1157,1,0,0,0,1155,1153,1,0,0,0,1155,1156,1,0,0,0,1156,1159,
        1,0,0,0,1157,1155,1,0,0,0,1158,1150,1,0,0,0,1158,1159,1,0,0,0,1159,
        1160,1,0,0,0,1160,1161,5,477,0,0,1161,1164,1,0,0,0,1162,1164,3,332,
        166,0,1163,1148,1,0,0,0,1163,1162,1,0,0,0,1164,117,1,0,0,0,1165,
        1168,3,122,61,0,1166,1168,3,120,60,0,1167,1165,1,0,0,0,1167,1166,
        1,0,0,0,1168,119,1,0,0,0,1169,1170,7,10,0,0,1170,121,1,0,0,0,1171,
        1172,7,11,0,0,1172,123,1,0,0,0,1173,1174,5,296,0,0,1174,1175,3,130,
        65,0,1175,125,1,0,0,0,1176,1183,7,12,0,0,1177,1184,3,128,64,0,1178,
        1179,5,217,0,0,1179,1180,3,128,64,0,1180,1181,5,208,0,0,1181,1182,
        3,128,64,0,1182,1184,1,0,0,0,1183,1177,1,0,0,0,1183,1178,1,0,0,0,
        1184,127,1,0,0,0,1185,1186,5,185,0,0,1186,1198,5,117,0,0,1187,1188,
        3,322,161,0,1188,1189,5,117,0,0,1189,1198,1,0,0,0,1190,1191,5,255,
        0,0,1191,1198,5,398,0,0,1192,1193,3,322,161,0,1193,1194,5,55,0,0,
        1194,1198,1,0,0,0,1195,1196,5,185,0,0,1196,1198,5,55,0,0,1197,1185,
        1,0,0,0,1197,1187,1,0,0,0,1197,1190,1,0,0,0,1197,1192,1,0,0,0,1197,
        1195,1,0,0,0,1198,129,1,0,0,0,1199,1200,6,65,-1,0,1200,1205,3,140,
        70,0,1201,1202,5,480,0,0,1202,1204,3,140,70,0,1203,1201,1,0,0,0,
        1204,1207,1,0,0,0,1205,1203,1,0,0,0,1205,1206,1,0,0,0,1206,1230,
        1,0,0,0,1207,1205,1,0,0,0,1208,1209,3,140,70,0,1209,1211,3,138,69,
        0,1210,1212,3,372,186,0,1211,1210,1,0,0,0,1211,1212,1,0,0,0,1212,
        1230,1,0,0,0,1213,1217,3,140,70,0,1214,1216,3,136,68,0,1215,1214,
        1,0,0,0,1216,1219,1,0,0,0,1217,1215,1,0,0,0,1217,1218,1,0,0,0,1218,
        1221,1,0,0,0,1219,1217,1,0,0,0,1220,1222,3,372,186,0,1221,1220,1,
        0,0,0,1221,1222,1,0,0,0,1222,1230,1,0,0,0,1223,1230,3,100,50,0,1224,
        1226,3,132,66,0,1225,1227,3,372,186,0,1226,1225,1,0,0,0,1226,1227,
        1,0,0,0,1227,1230,1,0,0,0,1228,1230,3,160,80,0,1229,1199,1,0,0,0,
        1229,1208,1,0,0,0,1229,1213,1,0,0,0,1229,1223,1,0,0,0,1229,1224,
        1,0,0,0,1229,1228,1,0,0,0,1230,1258,1,0,0,0,1231,1233,10,4,0,0,1232,
        1234,5,350,0,0,1233,1232,1,0,0,0,1233,1234,1,0,0,0,1234,1236,1,0,
        0,0,1235,1237,7,13,0,0,1236,1235,1,0,0,0,1236,1237,1,0,0,0,1237,
        1239,1,0,0,0,1238,1240,5,366,0,0,1239,1238,1,0,0,0,1239,1240,1,0,
        0,0,1240,1242,1,0,0,0,1241,1243,5,402,0,0,1242,1241,1,0,0,0,1242,
        1243,1,0,0,0,1243,1244,1,0,0,0,1244,1245,5,325,0,0,1245,1247,3,130,
        65,0,1246,1248,3,184,92,0,1247,1246,1,0,0,0,1247,1248,1,0,0,0,1248,
        1253,1,0,0,0,1249,1250,5,480,0,0,1250,1252,3,140,70,0,1251,1249,
        1,0,0,0,1252,1255,1,0,0,0,1253,1251,1,0,0,0,1253,1254,1,0,0,0,1254,
        1257,1,0,0,0,1255,1253,1,0,0,0,1256,1231,1,0,0,0,1257,1260,1,0,0,
        0,1258,1256,1,0,0,0,1258,1259,1,0,0,0,1259,131,1,0,0,0,1260,1258,
        1,0,0,0,1261,1262,3,134,67,0,1262,133,1,0,0,0,1263,1264,5,386,0,
        0,1264,1265,5,476,0,0,1265,1270,3,322,161,0,1266,1267,5,480,0,0,
        1267,1269,3,322,161,0,1268,1266,1,0,0,0,1269,1272,1,0,0,0,1270,1268,
        1,0,0,0,1270,1271,1,0,0,0,1271,1273,1,0,0,0,1272,1270,1,0,0,0,1273,
        1274,5,477,0,0,1274,135,1,0,0,0,1275,1276,5,329,0,0,1276,1278,5,
        193,0,0,1277,1279,5,366,0,0,1278,1277,1,0,0,0,1278,1279,1,0,0,0,
        1279,1280,1,0,0,0,1280,1282,3,144,72,0,1281,1283,3,372,186,0,1282,
        1281,1,0,0,0,1282,1283,1,0,0,0,1283,1284,1,0,0,0,1284,1285,5,212,
        0,0,1285,1290,3,370,185,0,1286,1287,5,480,0,0,1287,1289,3,370,185,
        0,1288,1286,1,0,0,0,1289,1292,1,0,0,0,1290,1288,1,0,0,0,1290,1291,
        1,0,0,0,1291,137,1,0,0,0,1292,1290,1,0,0,0,1293,1294,5,379,0,0,1294,
        1295,5,476,0,0,1295,1296,3,148,74,0,1296,1297,5,477,0,0,1297,1308,
        1,0,0,0,1298,1301,5,441,0,0,1299,1300,7,14,0,0,1300,1302,5,102,0,
        0,1301,1299,1,0,0,0,1301,1302,1,0,0,0,1302,1303,1,0,0,0,1303,1304,
        5,476,0,0,1304,1305,3,146,73,0,1305,1306,5,477,0,0,1306,1308,1,0,
        0,0,1307,1293,1,0,0,0,1307,1298,1,0,0,0,1308,139,1,0,0,0,1309,1311,
        3,142,71,0,1310,1312,3,372,186,0,1311,1310,1,0,0,0,1311,1312,1,0,
        0,0,1312,141,1,0,0,0,1313,1315,5,422,0,0,1314,1313,1,0,0,0,1314,
        1315,1,0,0,0,1315,1316,1,0,0,0,1316,1318,3,402,201,0,1317,1319,3,
        154,77,0,1318,1317,1,0,0,0,1318,1319,1,0,0,0,1319,1355,1,0,0,0,1320,
        1321,5,329,0,0,1321,1324,5,422,0,0,1322,1325,3,144,72,0,1323,1325,
        3,334,167,0,1324,1322,1,0,0,0,1324,1323,1,0,0,0,1325,1355,1,0,0,
        0,1326,1327,5,329,0,0,1327,1328,5,422,0,0,1328,1329,5,287,0,0,1329,
        1332,5,476,0,0,1330,1333,3,144,72,0,1331,1333,3,334,167,0,1332,1330,
        1,0,0,0,1332,1331,1,0,0,0,1333,1334,1,0,0,0,1334,1335,5,477,0,0,
        1335,1355,1,0,0,0,1336,1337,5,329,0,0,1337,1338,5,476,0,0,1338,1339,
        3,96,48,0,1339,1340,5,477,0,0,1340,1355,1,0,0,0,1341,1345,5,476,
        0,0,1342,1344,3,96,48,0,1343,1342,1,0,0,0,1344,1347,1,0,0,0,1345,
        1343,1,0,0,0,1345,1346,1,0,0,0,1346,1348,1,0,0,0,1347,1345,1,0,0,
        0,1348,1355,5,477,0,0,1349,1350,5,440,0,0,1350,1351,5,476,0,0,1351,
        1352,3,322,161,0,1352,1353,5,477,0,0,1353,1355,1,0,0,0,1354,1314,
        1,0,0,0,1354,1320,1,0,0,0,1354,1326,1,0,0,0,1354,1336,1,0,0,0,1354,
        1341,1,0,0,0,1354,1349,1,0,0,0,1355,143,1,0,0,0,1356,1357,3,348,
        174,0,1357,1360,5,476,0,0,1358,1361,3,144,72,0,1359,1361,3,350,175,
        0,1360,1358,1,0,0,0,1360,1359,1,0,0,0,1361,1369,1,0,0,0,1362,1365,
        5,480,0,0,1363,1366,3,144,72,0,1364,1366,3,350,175,0,1365,1363,1,
        0,0,0,1365,1364,1,0,0,0,1366,1368,1,0,0,0,1367,1362,1,0,0,0,1368,
        1371,1,0,0,0,1369,1367,1,0,0,0,1369,1370,1,0,0,0,1370,1372,1,0,0,
        0,1371,1369,1,0,0,0,1372,1373,5,477,0,0,1373,1404,1,0,0,0,1374,1375,
        3,348,174,0,1375,1378,5,476,0,0,1376,1379,3,144,72,0,1377,1379,3,
        350,175,0,1378,1376,1,0,0,0,1378,1377,1,0,0,0,1379,1387,1,0,0,0,
        1380,1383,5,480,0,0,1381,1384,3,144,72,0,1382,1384,3,350,175,0,1383,
        1381,1,0,0,0,1383,1382,1,0,0,0,1384,1386,1,0,0,0,1385,1380,1,0,0,
        0,1386,1389,1,0,0,0,1387,1385,1,0,0,0,1387,1388,1,0,0,0,1388,1390,
        1,0,0,0,1389,1387,1,0,0,0,1390,1391,5,477,0,0,1391,1392,5,476,0,
        0,1392,1393,5,212,0,0,1393,1394,3,372,186,0,1394,1395,5,477,0,0,
        1395,1400,3,452,226,0,1396,1397,5,480,0,0,1397,1399,3,452,226,0,
        1398,1396,1,0,0,0,1399,1402,1,0,0,0,1400,1398,1,0,0,0,1400,1401,
        1,0,0,0,1401,1404,1,0,0,0,1402,1400,1,0,0,0,1403,1356,1,0,0,0,1403,
        1374,1,0,0,0,1404,145,1,0,0,0,1405,1408,3,316,158,0,1406,1408,3,
        318,159,0,1407,1405,1,0,0,0,1407,1406,1,0,0,0,1408,1409,1,0,0,0,
        1409,1410,5,295,0,0,1410,1411,3,316,158,0,1411,1412,5,309,0,0,1412,
        1413,3,152,76,0,1413,147,1,0,0,0,1414,1415,3,150,75,0,1415,1416,
        5,480,0,0,1416,1417,3,150,75,0,1417,1418,1,0,0,0,1418,1421,5,295,
        0,0,1419,1422,3,316,158,0,1420,1422,3,318,159,0,1421,1419,1,0,0,
        0,1421,1420,1,0,0,0,1422,1423,1,0,0,0,1423,1424,5,309,0,0,1424,1425,
        3,152,76,0,1425,149,1,0,0,0,1426,1429,3,322,161,0,1427,1428,5,212,
        0,0,1428,1430,3,370,185,0,1429,1427,1,0,0,0,1429,1430,1,0,0,0,1430,
        151,1,0,0,0,1431,1432,5,476,0,0,1432,1437,3,150,75,0,1433,1434,5,
        480,0,0,1434,1436,3,150,75,0,1435,1433,1,0,0,0,1436,1439,1,0,0,0,
        1437,1435,1,0,0,0,1437,1438,1,0,0,0,1438,1440,1,0,0,0,1439,1437,
        1,0,0,0,1440,1441,5,477,0,0,1441,153,1,0,0,0,1442,1443,5,295,0,0,
        1443,1444,5,420,0,0,1444,1445,5,212,0,0,1445,1446,5,359,0,0,1446,
        1447,3,156,78,0,1447,155,1,0,0,0,1448,1449,3,322,161,0,1449,157,
        1,0,0,0,1450,1455,3,322,161,0,1451,1452,5,480,0,0,1452,1454,3,322,
        161,0,1453,1451,1,0,0,0,1454,1457,1,0,0,0,1455,1453,1,0,0,0,1455,
        1456,1,0,0,0,1456,1459,1,0,0,0,1457,1455,1,0,0,0,1458,1460,3,372,
        186,0,1459,1458,1,0,0,0,1459,1460,1,0,0,0,1460,159,1,0,0,0,1461,
        1462,5,422,0,0,1462,1463,5,476,0,0,1463,1464,3,162,81,0,1464,1465,
        5,477,0,0,1465,161,1,0,0,0,1466,1467,3,164,82,0,1467,1468,5,476,
        0,0,1468,1473,3,178,89,0,1469,1470,5,480,0,0,1470,1472,3,178,89,
        0,1471,1469,1,0,0,0,1472,1475,1,0,0,0,1473,1471,1,0,0,0,1473,1474,
        1,0,0,0,1474,1476,1,0,0,0,1475,1473,1,0,0,0,1476,1477,5,477,0,0,
        1477,163,1,0,0,0,1478,1479,7,15,0,0,1479,165,1,0,0,0,1480,1481,3,
        176,88,0,1481,1482,3,170,85,0,1482,1483,3,176,88,0,1483,167,1,0,
        0,0,1484,1485,3,172,86,0,1485,1486,3,170,85,0,1486,1487,3,172,86,
        0,1487,169,1,0,0,0,1488,1489,5,445,0,0,1489,1490,3,430,215,0,1490,
        1493,5,212,0,0,1491,1494,3,318,159,0,1492,1494,3,276,138,0,1493,
        1491,1,0,0,0,1493,1492,1,0,0,0,1493,1494,1,0,0,0,1494,171,1,0,0,
        0,1495,1496,5,398,0,0,1496,1497,5,56,0,0,1497,1498,5,404,0,0,1498,
        1500,3,430,215,0,1499,1495,1,0,0,0,1499,1500,1,0,0,0,1500,1504,1,
        0,0,0,1501,1502,5,453,0,0,1502,1503,5,163,0,0,1503,1505,3,174,87,
        0,1504,1501,1,0,0,0,1504,1505,1,0,0,0,1505,1508,1,0,0,0,1506,1507,
        5,387,0,0,1507,1509,3,430,215,0,1508,1506,1,0,0,0,1508,1509,1,0,
        0,0,1509,1511,1,0,0,0,1510,1512,3,42,21,0,1511,1510,1,0,0,0,1511,
        1512,1,0,0,0,1512,1515,1,0,0,0,1513,1514,5,134,0,0,1514,1516,3,430,
        215,0,1515,1513,1,0,0,0,1515,1516,1,0,0,0,1516,173,1,0,0,0,1517,
        1520,5,476,0,0,1518,1521,3,416,208,0,1519,1521,3,418,209,0,1520,
        1518,1,0,0,0,1520,1519,1,0,0,0,1521,1529,1,0,0,0,1522,1525,5,480,
        0,0,1523,1526,3,416,208,0,1524,1526,3,418,209,0,1525,1523,1,0,0,
        0,1525,1524,1,0,0,0,1526,1528,1,0,0,0,1527,1522,1,0,0,0,1528,1531,
        1,0,0,0,1529,1527,1,0,0,0,1529,1530,1,0,0,0,1530,1532,1,0,0,0,1531,
        1529,1,0,0,0,1532,1533,5,477,0,0,1533,175,1,0,0,0,1534,1536,3,50,
        25,0,1535,1534,1,0,0,0,1535,1536,1,0,0,0,1536,1538,1,0,0,0,1537,
        1539,3,42,21,0,1538,1537,1,0,0,0,1538,1539,1,0,0,0,1539,1544,1,0,
        0,0,1540,1541,5,335,0,0,1541,1542,5,425,0,0,1542,1543,5,226,0,0,
        1543,1545,3,430,215,0,1544,1540,1,0,0,0,1544,1545,1,0,0,0,1545,1550,
        1,0,0,0,1546,1547,5,357,0,0,1547,1548,5,36,0,0,1548,1549,5,212,0,
        0,1549,1551,3,430,215,0,1550,1546,1,0,0,0,1550,1551,1,0,0,0,1551,
        177,1,0,0,0,1552,1553,5,422,0,0,1553,1568,3,212,106,0,1554,1568,
        3,182,91,0,1555,1568,3,358,179,0,1556,1557,5,30,0,0,1557,1558,5,
        497,0,0,1558,1559,5,422,0,0,1559,1568,3,212,106,0,1560,1561,5,173,
        0,0,1561,1562,5,497,0,0,1562,1568,3,182,91,0,1563,1564,3,180,90,
        0,1564,1565,5,497,0,0,1565,1566,3,358,179,0,1566,1568,1,0,0,0,1567,
        1552,1,0,0,0,1567,1554,1,0,0,0,1567,1555,1,0,0,0,1567,1556,1,0,0,
        0,1567,1560,1,0,0,0,1567,1563,1,0,0,0,1568,179,1,0,0,0,1569,1570,
        7,16,0,0,1570,181,1,0,0,0,1571,1572,5,38,0,0,1572,1573,5,476,0,0,
        1573,1574,3,406,203,0,1574,1575,5,477,0,0,1575,183,1,0,0,0,1576,
        1577,5,361,0,0,1577,1591,3,324,162,0,1578,1579,5,445,0,0,1579,1580,
        5,476,0,0,1580,1585,3,406,203,0,1581,1582,5,480,0,0,1582,1584,3,
        406,203,0,1583,1581,1,0,0,0,1584,1587,1,0,0,0,1585,1583,1,0,0,0,
        1585,1586,1,0,0,0,1586,1588,1,0,0,0,1587,1585,1,0,0,0,1588,1589,
        5,477,0,0,1589,1591,1,0,0,0,1590,1576,1,0,0,0,1590,1578,1,0,0,0,
        1591,185,1,0,0,0,1592,1593,5,451,0,0,1593,1594,3,324,162,0,1594,
        187,1,0,0,0,1595,1596,5,424,0,0,1596,1600,5,476,0,0,1597,1601,3,
        432,216,0,1598,1601,5,499,0,0,1599,1601,3,322,161,0,1600,1597,1,
        0,0,0,1600,1598,1,0,0,0,1600,1599,1,0,0,0,1601,1602,1,0,0,0,1602,
        1603,5,374,0,0,1603,1627,5,477,0,0,1604,1605,5,424,0,0,1605,1608,
        5,476,0,0,1606,1609,5,499,0,0,1607,1609,3,322,161,0,1608,1606,1,
        0,0,0,1608,1607,1,0,0,0,1609,1610,1,0,0,0,1610,1611,5,399,0,0,1611,
        1627,5,477,0,0,1612,1613,5,424,0,0,1613,1614,5,476,0,0,1614,1617,
        5,224,0,0,1615,1618,5,499,0,0,1616,1618,3,322,161,0,1617,1615,1,
        0,0,0,1617,1616,1,0,0,0,1618,1619,1,0,0,0,1619,1620,5,365,0,0,1620,
        1623,5,359,0,0,1621,1624,5,499,0,0,1622,1624,3,322,161,0,1623,1621,
        1,0,0,0,1623,1622,1,0,0,0,1624,1625,1,0,0,0,1625,1627,5,477,0,0,
        1626,1595,1,0,0,0,1626,1604,1,0,0,0,1626,1612,1,0,0,0,1627,189,1,
        0,0,0,1628,1633,3,194,97,0,1629,1633,3,192,96,0,1630,1633,3,196,
        98,0,1631,1633,3,198,99,0,1632,1628,1,0,0,0,1632,1629,1,0,0,0,1632,
        1630,1,0,0,0,1632,1631,1,0,0,0,1633,191,1,0,0,0,1634,1635,5,238,
        0,0,1635,1636,5,226,0,0,1636,1641,3,200,100,0,1637,1638,5,480,0,
        0,1638,1640,3,200,100,0,1639,1637,1,0,0,0,1640,1643,1,0,0,0,1641,
        1639,1,0,0,0,1641,1642,1,0,0,0,1642,193,1,0,0,0,1643,1641,1,0,0,
        0,1644,1645,5,239,0,0,1645,1646,5,226,0,0,1646,1651,3,200,100,0,
        1647,1648,5,480,0,0,1648,1650,3,200,100,0,1649,1647,1,0,0,0,1650,
        1653,1,0,0,0,1651,1649,1,0,0,0,1651,1652,1,0,0,0,1652,195,1,0,0,
        0,1653,1651,1,0,0,0,1654,1655,5,274,0,0,1655,1656,5,226,0,0,1656,
        1661,3,200,100,0,1657,1658,5,480,0,0,1658,1660,3,200,100,0,1659,
        1657,1,0,0,0,1660,1663,1,0,0,0,1661,1659,1,0,0,0,1661,1662,1,0,0,
        0,1662,197,1,0,0,0,1663,1661,1,0,0,0,1664,1665,5,302,0,0,1665,1667,
        5,226,0,0,1666,1668,3,200,100,0,1667,1666,1,0,0,0,1667,1668,1,0,
        0,0,1668,1673,1,0,0,0,1669,1670,5,480,0,0,1670,1672,3,200,100,0,
        1671,1669,1,0,0,0,1672,1675,1,0,0,0,1673,1671,1,0,0,0,1673,1674,
        1,0,0,0,1674,1677,1,0,0,0,1675,1673,1,0,0,0,1676,1678,3,202,101,
        0,1677,1676,1,0,0,0,1677,1678,1,0,0,0,1678,1681,1,0,0,0,1679,1680,
        5,453,0,0,1680,1682,3,206,103,0,1681,1679,1,0,0,0,1681,1682,1,0,
        0,0,1682,199,1,0,0,0,1683,1688,3,322,161,0,1684,1685,5,480,0,0,1685,
        1687,3,322,161,0,1686,1684,1,0,0,0,1687,1690,1,0,0,0,1688,1686,1,
        0,0,0,1688,1689,1,0,0,0,1689,1718,1,0,0,0,1690,1688,1,0,0,0,1691,
        1718,3,208,104,0,1692,1693,5,476,0,0,1693,1718,5,477,0,0,1694,1695,
        5,476,0,0,1695,1700,3,322,161,0,1696,1697,5,480,0,0,1697,1699,3,
        322,161,0,1698,1696,1,0,0,0,1699,1702,1,0,0,0,1700,1698,1,0,0,0,
        1700,1701,1,0,0,0,1701,1703,1,0,0,0,1702,1700,1,0,0,0,1703,1704,
        5,477,0,0,1704,1718,1,0,0,0,1705,1706,3,206,103,0,1706,1707,5,476,
        0,0,1707,1712,3,322,161,0,1708,1709,5,480,0,0,1709,1711,3,322,161,
        0,1710,1708,1,0,0,0,1711,1714,1,0,0,0,1712,1710,1,0,0,0,1712,1713,
        1,0,0,0,1713,1715,1,0,0,0,1714,1712,1,0,0,0,1715,1716,5,477,0,0,
        1716,1718,1,0,0,0,1717,1683,1,0,0,0,1717,1691,1,0,0,0,1717,1692,
        1,0,0,0,1717,1694,1,0,0,0,1717,1705,1,0,0,0,1718,201,1,0,0,0,1719,
        1720,3,204,102,0,1720,1721,5,476,0,0,1721,1726,3,200,100,0,1722,
        1723,5,480,0,0,1723,1725,3,200,100,0,1724,1722,1,0,0,0,1725,1728,
        1,0,0,0,1726,1724,1,0,0,0,1726,1727,1,0,0,0,1727,1729,1,0,0,0,1728,
        1726,1,0,0,0,1729,1730,5,477,0,0,1730,203,1,0,0,0,1731,1732,5,303,
        0,0,1732,1733,5,156,0,0,1733,205,1,0,0,0,1734,1735,7,17,0,0,1735,
        207,1,0,0,0,1736,1737,3,210,105,0,1737,1738,5,476,0,0,1738,1739,
        3,212,106,0,1739,1740,5,480,0,0,1740,1741,3,358,179,0,1741,1742,
        5,477,0,0,1742,209,1,0,0,0,1743,1744,7,18,0,0,1744,211,1,0,0,0,1745,
        1746,3,406,203,0,1746,213,1,0,0,0,1747,1748,5,306,0,0,1748,1749,
        3,324,162,0,1749,215,1,0,0,0,1750,1751,5,452,0,0,1751,1756,3,218,
        109,0,1752,1753,5,480,0,0,1753,1755,3,218,109,0,1754,1752,1,0,0,
        0,1755,1758,1,0,0,0,1756,1754,1,0,0,0,1756,1757,1,0,0,0,1757,217,
        1,0,0,0,1758,1756,1,0,0,0,1759,1760,3,376,188,0,1760,1761,5,212,
        0,0,1761,1762,3,220,110,0,1762,219,1,0,0,0,1763,1765,3,376,188,0,
        1764,1763,1,0,0,0,1764,1765,1,0,0,0,1765,1766,1,0,0,0,1766,1768,
        5,476,0,0,1767,1769,3,234,117,0,1768,1767,1,0,0,0,1768,1769,1,0,
        0,0,1769,1771,1,0,0,0,1770,1772,3,226,113,0,1771,1770,1,0,0,0,1771,
        1772,1,0,0,0,1772,1774,1,0,0,0,1773,1775,3,224,112,0,1774,1773,1,
        0,0,0,1774,1775,1,0,0,0,1775,1777,1,0,0,0,1776,1778,3,250,125,0,
        1777,1776,1,0,0,0,1777,1778,1,0,0,0,1778,1779,1,0,0,0,1779,1780,
        5,477,0,0,1780,221,1,0,0,0,1781,1782,5,340,0,0,1782,1784,5,476,0,
        0,1783,1785,3,234,117,0,1784,1783,1,0,0,0,1784,1785,1,0,0,0,1785,
        1787,1,0,0,0,1786,1788,3,226,113,0,1787,1786,1,0,0,0,1787,1788,1,
        0,0,0,1788,1790,1,0,0,0,1789,1791,3,224,112,0,1790,1789,1,0,0,0,
        1790,1791,1,0,0,0,1791,1793,1,0,0,0,1792,1794,3,238,119,0,1793,1792,
        1,0,0,0,1793,1794,1,0,0,0,1794,1796,1,0,0,0,1795,1797,3,244,122,
        0,1796,1795,1,0,0,0,1796,1797,1,0,0,0,1797,1799,1,0,0,0,1798,1800,
        3,246,123,0,1799,1798,1,0,0,0,1799,1800,1,0,0,0,1800,1802,1,0,0,
        0,1801,1803,3,240,120,0,1802,1801,1,0,0,0,1802,1803,1,0,0,0,1803,
        1804,1,0,0,0,1804,1805,3,248,124,0,1805,1810,5,477,0,0,1806,1808,
        5,212,0,0,1807,1806,1,0,0,0,1807,1808,1,0,0,0,1808,1809,1,0,0,0,
        1809,1811,3,384,192,0,1810,1807,1,0,0,0,1810,1811,1,0,0,0,1811,223,
        1,0,0,0,1812,1813,5,364,0,0,1813,1814,5,226,0,0,1814,1819,3,228,
        114,0,1815,1816,5,480,0,0,1816,1818,3,228,114,0,1817,1815,1,0,0,
        0,1818,1821,1,0,0,0,1819,1817,1,0,0,0,1819,1820,1,0,0,0,1820,225,
        1,0,0,0,1821,1819,1,0,0,0,1822,1823,5,415,0,0,1823,1824,5,226,0,
        0,1824,1829,3,228,114,0,1825,1826,5,480,0,0,1826,1828,3,228,114,
        0,1827,1825,1,0,0,0,1828,1831,1,0,0,0,1829,1827,1,0,0,0,1829,1830,
        1,0,0,0,1830,227,1,0,0,0,1831,1829,1,0,0,0,1832,1834,3,322,161,0,
        1833,1835,7,0,0,0,1834,1833,1,0,0,0,1834,1835,1,0,0,0,1835,1838,
        1,0,0,0,1836,1837,5,102,0,0,1837,1839,7,3,0,0,1838,1836,1,0,0,0,
        1838,1839,1,0,0,0,1839,229,1,0,0,0,1840,1843,5,336,0,0,1841,1844,
        5,205,0,0,1842,1844,3,322,161,0,1843,1841,1,0,0,0,1843,1842,1,0,
        0,0,1844,231,1,0,0,0,1845,1848,5,360,0,0,1846,1849,5,499,0,0,1847,
        1849,3,322,161,0,1848,1846,1,0,0,0,1848,1847,1,0,0,0,1849,233,1,
        0,0,0,1850,1851,5,371,0,0,1851,1852,5,226,0,0,1852,1857,3,322,161,
        0,1853,1854,5,480,0,0,1854,1856,3,322,161,0,1855,1853,1,0,0,0,1856,
        1859,1,0,0,0,1857,1855,1,0,0,0,1857,1858,1,0,0,0,1858,235,1,0,0,
        0,1859,1857,1,0,0,0,1860,1877,5,488,0,0,1861,1877,5,491,0,0,1862,
        1877,5,496,0,0,1863,1864,5,478,0,0,1864,1865,5,499,0,0,1865,1866,
        5,480,0,0,1866,1867,5,499,0,0,1867,1877,5,479,0,0,1868,1869,5,478,
        0,0,1869,1870,5,499,0,0,1870,1871,5,480,0,0,1871,1877,5,479,0,0,
        1872,1873,5,478,0,0,1873,1874,5,480,0,0,1874,1875,5,499,0,0,1875,
        1877,5,479,0,0,1876,1860,1,0,0,0,1876,1861,1,0,0,0,1876,1862,1,0,
        0,0,1876,1863,1,0,0,0,1876,1868,1,0,0,0,1876,1872,1,0,0,0,1877,237,
        1,0,0,0,1878,1879,5,341,0,0,1879,1884,3,452,226,0,1880,1881,5,480,
        0,0,1881,1883,3,452,226,0,1882,1880,1,0,0,0,1883,1886,1,0,0,0,1884,
        1882,1,0,0,0,1884,1885,1,0,0,0,1885,239,1,0,0,0,1886,1884,1,0,0,
        0,1887,1888,5,372,0,0,1888,1890,5,476,0,0,1889,1891,3,242,121,0,
        1890,1889,1,0,0,0,1891,1892,1,0,0,0,1892,1890,1,0,0,0,1892,1893,
        1,0,0,0,1893,1894,1,0,0,0,1894,1896,5,477,0,0,1895,1897,3,254,127,
        0,1896,1895,1,0,0,0,1896,1897,1,0,0,0,1897,241,1,0,0,0,1898,1900,
        3,390,195,0,1899,1901,3,236,118,0,1900,1899,1,0,0,0,1900,1901,1,
        0,0,0,1901,243,1,0,0,0,1902,1903,5,205,0,0,1903,1904,5,399,0,0,1904,
        1905,5,373,0,0,1905,1911,5,339,0,0,1906,1907,5,362,0,0,1907,1908,
        5,398,0,0,1908,1909,5,373,0,0,1909,1911,5,339,0,0,1910,1902,1,0,
        0,0,1910,1906,1,0,0,0,1911,245,1,0,0,0,1912,1913,5,8,0,0,1913,1914,
        5,339,0,0,1914,1915,5,407,0,0,1915,1916,5,113,0,0,1916,1917,5,84,
        0,0,1917,1937,5,398,0,0,1918,1919,5,8,0,0,1919,1920,5,339,0,0,1920,
        1921,5,407,0,0,1921,1922,5,433,0,0,1922,1923,5,351,0,0,1923,1937,
        5,398,0,0,1924,1925,5,8,0,0,1925,1926,5,339,0,0,1926,1927,5,407,
        0,0,1927,1928,5,433,0,0,1928,1929,5,84,0,0,1929,1937,3,390,195,0,
        1930,1931,5,8,0,0,1931,1932,5,339,0,0,1932,1933,5,407,0,0,1933,1934,
        5,433,0,0,1934,1935,5,54,0,0,1935,1937,3,390,195,0,1936,1912,1,0,
        0,0,1936,1918,1,0,0,0,1936,1924,1,0,0,0,1936,1930,1,0,0,0,1937,247,
        1,0,0,0,1938,1939,5,266,0,0,1939,1944,3,452,226,0,1940,1941,5,480,
        0,0,1941,1943,3,452,226,0,1942,1940,1,0,0,0,1943,1946,1,0,0,0,1944,
        1942,1,0,0,0,1944,1945,1,0,0,0,1945,249,1,0,0,0,1946,1944,1,0,0,
        0,1947,1948,5,386,0,0,1948,1949,5,217,0,0,1949,1950,3,358,179,0,
        1950,1951,3,252,126,0,1951,1957,1,0,0,0,1952,1953,5,399,0,0,1953,
        1954,5,217,0,0,1954,1955,5,499,0,0,1955,1957,3,252,126,0,1956,1947,
        1,0,0,0,1956,1952,1,0,0,0,1957,251,1,0,0,0,1958,1959,5,117,0,0,1959,
        1960,5,208,0,0,1960,1961,5,255,0,0,1961,1962,5,398,0,0,1962,253,
        1,0,0,0,1963,1964,5,454,0,0,1964,1965,3,358,179,0,1965,255,1,0,0,
        0,1966,1967,5,378,0,0,1967,1968,5,295,0,0,1968,1969,5,420,0,0,1969,
        257,1,0,0,0,1970,1971,5,110,0,0,1971,1972,5,226,0,0,1972,1973,3,
        260,130,0,1973,259,1,0,0,0,1974,1975,5,476,0,0,1975,1977,3,262,131,
        0,1976,1978,3,344,172,0,1977,1976,1,0,0,0,1977,1978,1,0,0,0,1978,
        1986,1,0,0,0,1979,1980,5,480,0,0,1980,1982,3,262,131,0,1981,1983,
        3,344,172,0,1982,1981,1,0,0,0,1982,1983,1,0,0,0,1983,1985,1,0,0,
        0,1984,1979,1,0,0,0,1985,1988,1,0,0,0,1986,1984,1,0,0,0,1986,1987,
        1,0,0,0,1987,1989,1,0,0,0,1988,1986,1,0,0,0,1989,1990,5,477,0,0,
        1990,261,1,0,0,0,1991,2005,3,356,178,0,1992,1993,3,384,192,0,1993,
        1994,5,476,0,0,1994,1999,3,264,132,0,1995,1996,5,480,0,0,1996,1998,
        3,264,132,0,1997,1995,1,0,0,0,1998,2001,1,0,0,0,1999,1997,1,0,0,
        0,1999,2000,1,0,0,0,2000,2002,1,0,0,0,2001,1999,1,0,0,0,2002,2003,
        5,477,0,0,2003,2005,1,0,0,0,2004,1991,1,0,0,0,2004,1992,1,0,0,0,
        2005,263,1,0,0,0,2006,2009,3,356,178,0,2007,2009,3,426,213,0,2008,
        2006,1,0,0,0,2008,2007,1,0,0,0,2009,265,1,0,0,0,2010,2011,5,334,
        0,0,2011,2020,3,402,201,0,2012,2016,5,476,0,0,2013,2015,3,272,136,
        0,2014,2013,1,0,0,0,2015,2018,1,0,0,0,2016,2014,1,0,0,0,2016,2017,
        1,0,0,0,2017,2019,1,0,0,0,2018,2016,1,0,0,0,2019,2021,5,477,0,0,
        2020,2012,1,0,0,0,2020,2021,1,0,0,0,2021,267,1,0,0,0,2022,2031,5,
        273,0,0,2023,2025,5,226,0,0,2024,2026,5,305,0,0,2025,2024,1,0,0,
        0,2025,2026,1,0,0,0,2026,2027,1,0,0,0,2027,2028,5,476,0,0,2028,2029,
        3,384,192,0,2029,2030,5,477,0,0,2030,2032,1,0,0,0,2031,2023,1,0,
        0,0,2031,2032,1,0,0,0,2032,2034,1,0,0,0,2033,2035,3,36,18,0,2034,
        2033,1,0,0,0,2034,2035,1,0,0,0,2035,269,1,0,0,0,2036,2037,5,445,
        0,0,2037,2038,5,501,0,0,2038,271,1,0,0,0,2039,2040,7,19,0,0,2040,
        2044,7,20,0,0,2041,2042,7,21,0,0,2042,2044,7,22,0,0,2043,2039,1,
        0,0,0,2043,2041,1,0,0,0,2044,273,1,0,0,0,2045,2049,3,278,139,0,2046,
        2049,3,310,155,0,2047,2049,3,314,157,0,2048,2045,1,0,0,0,2048,2046,
        1,0,0,0,2048,2047,1,0,0,0,2049,275,1,0,0,0,2050,2051,5,476,0,0,2051,
        2056,3,278,139,0,2052,2053,5,480,0,0,2053,2055,3,278,139,0,2054,
        2052,1,0,0,0,2055,2058,1,0,0,0,2056,2054,1,0,0,0,2056,2057,1,0,0,
        0,2057,2059,1,0,0,0,2058,2056,1,0,0,0,2059,2060,5,477,0,0,2060,277,
        1,0,0,0,2061,2062,3,316,158,0,2062,2064,3,320,160,0,2063,2065,3,
        306,153,0,2064,2063,1,0,0,0,2064,2065,1,0,0,0,2065,2067,1,0,0,0,
        2066,2068,3,308,154,0,2067,2066,1,0,0,0,2067,2068,1,0,0,0,2068,279,
        1,0,0,0,2069,2070,3,322,161,0,2070,281,1,0,0,0,2071,2072,5,196,0,
        0,2072,2073,5,295,0,0,2073,2074,3,322,161,0,2074,2075,5,212,0,0,
        2075,2076,3,322,161,0,2076,2087,1,0,0,0,2077,2078,5,196,0,0,2078,
        2081,5,295,0,0,2079,2082,3,406,203,0,2080,2082,3,322,161,0,2081,
        2079,1,0,0,0,2081,2080,1,0,0,0,2082,2083,1,0,0,0,2083,2084,5,212,
        0,0,2084,2085,3,406,203,0,2085,2087,1,0,0,0,2086,2071,1,0,0,0,2086,
        2077,1,0,0,0,2087,283,1,0,0,0,2088,2089,5,246,0,0,2089,2091,3,286,
        143,0,2090,2088,1,0,0,0,2090,2091,1,0,0,0,2091,2092,1,0,0,0,2092,
        2093,5,384,0,0,2093,2094,5,79,0,0,2094,2095,3,318,159,0,2095,2096,
        5,354,0,0,2096,2097,5,41,0,0,2097,285,1,0,0,0,2098,2099,3,384,192,
        0,2099,287,1,0,0,0,2100,2101,5,447,0,0,2101,2106,3,290,145,0,2102,
        2103,5,480,0,0,2103,2105,3,290,145,0,2104,2102,1,0,0,0,2105,2108,
        1,0,0,0,2106,2104,1,0,0,0,2106,2107,1,0,0,0,2107,289,1,0,0,0,2108,
        2106,1,0,0,0,2109,2110,5,476,0,0,2110,2115,3,426,213,0,2111,2112,
        5,480,0,0,2112,2114,3,426,213,0,2113,2111,1,0,0,0,2114,2117,1,0,
        0,0,2115,2113,1,0,0,0,2115,2116,1,0,0,0,2116,2118,1,0,0,0,2117,2115,
        1,0,0,0,2118,2119,5,477,0,0,2119,291,1,0,0,0,2120,2121,5,476,0,0,
        2121,2122,3,432,216,0,2122,2123,5,477,0,0,2123,293,1,0,0,0,2124,
        2125,5,476,0,0,2125,2128,3,432,216,0,2126,2127,5,480,0,0,2127,2129,
        3,432,216,0,2128,2126,1,0,0,0,2128,2129,1,0,0,0,2129,2130,1,0,0,
        0,2130,2131,5,477,0,0,2131,295,1,0,0,0,2132,2133,5,476,0,0,2133,
        2136,3,430,215,0,2134,2135,5,480,0,0,2135,2137,3,430,215,0,2136,
        2134,1,0,0,0,2136,2137,1,0,0,0,2137,2138,1,0,0,0,2138,2139,5,477,
        0,0,2139,297,1,0,0,0,2140,2141,5,471,0,0,2141,2146,3,320,160,0,2142,
        2143,5,480,0,0,2143,2145,3,320,160,0,2144,2142,1,0,0,0,2145,2148,
        1,0,0,0,2146,2144,1,0,0,0,2146,2147,1,0,0,0,2147,2149,1,0,0,0,2148,
        2146,1,0,0,0,2149,2150,5,470,0,0,2150,299,1,0,0,0,2151,2152,5,471,
        0,0,2152,2153,3,320,160,0,2153,2154,5,480,0,0,2154,2155,3,320,160,
        0,2155,2156,1,0,0,0,2156,2157,5,470,0,0,2157,301,1,0,0,0,2158,2159,
        5,471,0,0,2159,2160,3,316,158,0,2160,2167,3,320,160,0,2161,2162,
        5,480,0,0,2162,2163,3,316,158,0,2163,2164,3,320,160,0,2164,2166,
        1,0,0,0,2165,2161,1,0,0,0,2166,2169,1,0,0,0,2167,2165,1,0,0,0,2167,
        2168,1,0,0,0,2168,2170,1,0,0,0,2169,2167,1,0,0,0,2170,2171,5,470,
        0,0,2171,303,1,0,0,0,2172,2173,5,471,0,0,2173,2174,3,316,158,0,2174,
        2175,5,487,0,0,2175,2183,3,320,160,0,2176,2177,5,480,0,0,2177,2178,
        3,316,158,0,2178,2179,5,487,0,0,2179,2180,3,320,160,0,2180,2182,
        1,0,0,0,2181,2176,1,0,0,0,2182,2185,1,0,0,0,2183,2181,1,0,0,0,2183,
        2184,1,0,0,0,2184,2186,1,0,0,0,2185,2183,1,0,0,0,2186,2187,5,470,
        0,0,2187,305,1,0,0,0,2188,2189,5,246,0,0,2189,2191,3,286,143,0,2190,
        2188,1,0,0,0,2190,2191,1,0,0,0,2191,2192,1,0,0,0,2192,2193,5,384,
        0,0,2193,2196,5,79,0,0,2194,2195,5,354,0,0,2195,2197,5,41,0,0,2196,
        2194,1,0,0,0,2196,2197,1,0,0,0,2197,2203,1,0,0,0,2198,2200,5,354,
        0,0,2199,2198,1,0,0,0,2199,2200,1,0,0,0,2200,2201,1,0,0,0,2201,2203,
        5,357,0,0,2202,2190,1,0,0,0,2202,2199,1,0,0,0,2203,307,1,0,0,0,2204,
        2205,5,23,0,0,2205,2206,3,420,210,0,2206,309,1,0,0,0,2207,2208,3,
        316,158,0,2208,2209,3,320,160,0,2209,2212,5,343,0,0,2210,2211,5,
        296,0,0,2211,2213,3,312,156,0,2212,2210,1,0,0,0,2212,2213,1,0,0,
        0,2213,2215,1,0,0,0,2214,2216,5,195,0,0,2215,2214,1,0,0,0,2215,2216,
        1,0,0,0,2216,311,1,0,0,0,2217,2218,5,498,0,0,2218,313,1,0,0,0,2219,
        2220,3,316,158,0,2220,2221,5,212,0,0,2221,2223,3,280,140,0,2222,
        2224,3,308,154,0,2223,2222,1,0,0,0,2223,2224,1,0,0,0,2224,315,1,
        0,0,0,2225,2228,3,406,203,0,2226,2228,3,322,161,0,2227,2225,1,0,
        0,0,2227,2226,1,0,0,0,2228,317,1,0,0,0,2229,2230,5,476,0,0,2230,
        2232,3,316,158,0,2231,2233,3,308,154,0,2232,2231,1,0,0,0,2232,2233,
        1,0,0,0,2233,2241,1,0,0,0,2234,2235,5,480,0,0,2235,2237,3,316,158,
        0,2236,2238,3,308,154,0,2237,2236,1,0,0,0,2237,2238,1,0,0,0,2238,
        2240,1,0,0,0,2239,2234,1,0,0,0,2240,2243,1,0,0,0,2241,2239,1,0,0,
        0,2241,2242,1,0,0,0,2242,2244,1,0,0,0,2243,2241,1,0,0,0,2244,2245,
        5,477,0,0,2245,319,1,0,0,0,2246,2322,7,23,0,0,2247,2249,7,24,0,0,
        2248,2250,3,292,146,0,2249,2248,1,0,0,0,2249,2250,1,0,0,0,2250,2322,
        1,0,0,0,2251,2253,5,428,0,0,2252,2254,3,292,146,0,2253,2252,1,0,
        0,0,2253,2254,1,0,0,0,2254,2261,1,0,0,0,2255,2257,7,25,0,0,2256,
        2258,5,337,0,0,2257,2256,1,0,0,0,2257,2258,1,0,0,0,2258,2259,1,0,
        0,0,2259,2260,5,427,0,0,2260,2262,5,203,0,0,2261,2255,1,0,0,0,2261,
        2262,1,0,0,0,2262,2322,1,0,0,0,2263,2265,5,429,0,0,2264,2266,3,292,
        146,0,2265,2264,1,0,0,0,2265,2266,1,0,0,0,2266,2273,1,0,0,0,2267,
        2269,7,25,0,0,2268,2270,5,337,0,0,2269,2268,1,0,0,0,2269,2270,1,
        0,0,0,2270,2271,1,0,0,0,2271,2272,5,427,0,0,2272,2274,5,203,0,0,
        2273,2267,1,0,0,0,2273,2274,1,0,0,0,2274,2322,1,0,0,0,2275,2277,
        5,430,0,0,2276,2278,3,292,146,0,2277,2276,1,0,0,0,2277,2278,1,0,
        0,0,2278,2285,1,0,0,0,2279,2281,7,25,0,0,2280,2282,5,337,0,0,2281,
        2280,1,0,0,0,2281,2282,1,0,0,0,2282,2283,1,0,0,0,2283,2284,5,427,
        0,0,2284,2286,5,203,0,0,2285,2279,1,0,0,0,2285,2286,1,0,0,0,2286,
        2322,1,0,0,0,2287,2289,5,431,0,0,2288,2290,3,292,146,0,2289,2288,
        1,0,0,0,2289,2290,1,0,0,0,2290,2297,1,0,0,0,2291,2293,7,25,0,0,2292,
        2294,5,337,0,0,2293,2292,1,0,0,0,2293,2294,1,0,0,0,2294,2295,1,0,
        0,0,2295,2296,5,427,0,0,2296,2298,5,203,0,0,2297,2291,1,0,0,0,2297,
        2298,1,0,0,0,2298,2322,1,0,0,0,2299,2301,7,26,0,0,2300,2302,3,294,
        147,0,2301,2300,1,0,0,0,2301,2302,1,0,0,0,2302,2322,1,0,0,0,2303,
        2305,7,27,0,0,2304,2306,3,298,149,0,2305,2304,1,0,0,0,2305,2306,
        1,0,0,0,2306,2322,1,0,0,0,2307,2309,5,91,0,0,2308,2310,3,300,150,
        0,2309,2308,1,0,0,0,2309,2310,1,0,0,0,2310,2322,1,0,0,0,2311,2313,
        5,398,0,0,2312,2314,3,302,151,0,2313,2312,1,0,0,0,2313,2314,1,0,
        0,0,2314,2322,1,0,0,0,2315,2316,5,414,0,0,2316,2322,3,304,152,0,
        2317,2319,5,131,0,0,2318,2320,3,296,148,0,2319,2318,1,0,0,0,2319,
        2320,1,0,0,0,2320,2322,1,0,0,0,2321,2246,1,0,0,0,2321,2247,1,0,0,
        0,2321,2251,1,0,0,0,2321,2263,1,0,0,0,2321,2275,1,0,0,0,2321,2287,
        1,0,0,0,2321,2299,1,0,0,0,2321,2303,1,0,0,0,2321,2307,1,0,0,0,2321,
        2311,1,0,0,0,2321,2315,1,0,0,0,2321,2317,1,0,0,0,2322,321,1,0,0,
        0,2323,2324,3,324,162,0,2324,323,1,0,0,0,2325,2326,6,162,-1,0,2326,
        2327,5,354,0,0,2327,2338,3,324,162,6,2328,2329,5,285,0,0,2329,2330,
        5,476,0,0,2330,2331,3,96,48,0,2331,2332,5,477,0,0,2332,2338,1,0,
        0,0,2333,2335,3,330,165,0,2334,2336,3,326,163,0,2335,2334,1,0,0,
        0,2335,2336,1,0,0,0,2336,2338,1,0,0,0,2337,2325,1,0,0,0,2337,2328,
        1,0,0,0,2337,2333,1,0,0,0,2338,2353,1,0,0,0,2339,2340,10,3,0,0,2340,
        2341,5,208,0,0,2341,2352,3,324,162,4,2342,2343,10,2,0,0,2343,2344,
        5,363,0,0,2344,2352,3,324,162,3,2345,2346,10,1,0,0,2346,2348,5,324,
        0,0,2347,2349,5,354,0,0,2348,2347,1,0,0,0,2348,2349,1,0,0,0,2349,
        2350,1,0,0,0,2350,2352,7,28,0,0,2351,2339,1,0,0,0,2351,2342,1,0,
        0,0,2351,2345,1,0,0,0,2352,2355,1,0,0,0,2353,2351,1,0,0,0,2353,2354,
        1,0,0,0,2354,325,1,0,0,0,2355,2353,1,0,0,0,2356,2358,5,354,0,0,2357,
        2356,1,0,0,0,2357,2358,1,0,0,0,2358,2359,1,0,0,0,2359,2361,5,217,
        0,0,2360,2362,7,29,0,0,2361,2360,1,0,0,0,2361,2362,1,0,0,0,2362,
        2363,1,0,0,0,2363,2364,3,330,165,0,2364,2365,5,208,0,0,2365,2366,
        3,330,165,0,2366,2424,1,0,0,0,2367,2369,5,354,0,0,2368,2367,1,0,
        0,0,2368,2369,1,0,0,0,2369,2370,1,0,0,0,2370,2371,5,309,0,0,2371,
        2372,5,476,0,0,2372,2377,3,322,161,0,2373,2374,5,480,0,0,2374,2376,
        3,322,161,0,2375,2373,1,0,0,0,2376,2379,1,0,0,0,2377,2375,1,0,0,
        0,2377,2378,1,0,0,0,2378,2380,1,0,0,0,2379,2377,1,0,0,0,2380,2381,
        5,477,0,0,2381,2424,1,0,0,0,2382,2384,5,354,0,0,2383,2382,1,0,0,
        0,2383,2384,1,0,0,0,2384,2385,1,0,0,0,2385,2386,5,309,0,0,2386,2387,
        5,476,0,0,2387,2388,3,96,48,0,2388,2389,5,477,0,0,2389,2424,1,0,
        0,0,2390,2391,5,285,0,0,2391,2392,5,476,0,0,2392,2393,3,96,48,0,
        2393,2394,5,477,0,0,2394,2424,1,0,0,0,2395,2397,5,354,0,0,2396,2395,
        1,0,0,0,2396,2397,1,0,0,0,2397,2398,1,0,0,0,2398,2399,5,395,0,0,
        2399,2424,3,330,165,0,2400,2424,3,328,164,0,2401,2403,5,324,0,0,
        2402,2404,5,354,0,0,2403,2402,1,0,0,0,2403,2404,1,0,0,0,2404,2405,
        1,0,0,0,2405,2424,7,28,0,0,2406,2408,5,324,0,0,2407,2409,5,354,0,
        0,2408,2407,1,0,0,0,2408,2409,1,0,0,0,2409,2410,1,0,0,0,2410,2411,
        5,271,0,0,2411,2412,5,296,0,0,2412,2424,3,330,165,0,2413,2415,5,
        354,0,0,2414,2413,1,0,0,0,2414,2415,1,0,0,0,2415,2416,1,0,0,0,2416,
        2417,5,406,0,0,2417,2418,5,433,0,0,2418,2421,3,330,165,0,2419,2420,
        5,281,0,0,2420,2422,3,430,215,0,2421,2419,1,0,0,0,2421,2422,1,0,
        0,0,2422,2424,1,0,0,0,2423,2357,1,0,0,0,2423,2368,1,0,0,0,2423,2383,
        1,0,0,0,2423,2390,1,0,0,0,2423,2396,1,0,0,0,2423,2400,1,0,0,0,2423,
        2401,1,0,0,0,2423,2406,1,0,0,0,2423,2414,1,0,0,0,2424,327,1,0,0,
        0,2425,2427,5,354,0,0,2426,2425,1,0,0,0,2426,2427,1,0,0,0,2427,2428,
        1,0,0,0,2428,2429,5,334,0,0,2429,2443,7,30,0,0,2430,2431,5,476,0,
        0,2431,2444,5,477,0,0,2432,2433,5,476,0,0,2433,2438,3,322,161,0,
        2434,2435,5,480,0,0,2435,2437,3,322,161,0,2436,2434,1,0,0,0,2437,
        2440,1,0,0,0,2438,2436,1,0,0,0,2438,2439,1,0,0,0,2439,2441,1,0,0,
        0,2440,2438,1,0,0,0,2441,2442,5,477,0,0,2442,2444,1,0,0,0,2443,2430,
        1,0,0,0,2443,2432,1,0,0,0,2444,2464,1,0,0,0,2445,2447,5,354,0,0,
        2446,2445,1,0,0,0,2446,2447,1,0,0,0,2447,2448,1,0,0,0,2448,2449,
        7,31,0,0,2449,2452,3,330,165,0,2450,2451,5,281,0,0,2451,2453,3,430,
        215,0,2452,2450,1,0,0,0,2452,2453,1,0,0,0,2453,2464,1,0,0,0,2454,
        2456,5,354,0,0,2455,2454,1,0,0,0,2455,2456,1,0,0,0,2456,2457,1,0,
        0,0,2457,2458,7,32,0,0,2458,2461,3,430,215,0,2459,2460,5,281,0,0,
        2460,2462,3,430,215,0,2461,2459,1,0,0,0,2461,2462,1,0,0,0,2462,2464,
        1,0,0,0,2463,2426,1,0,0,0,2463,2446,1,0,0,0,2463,2455,1,0,0,0,2464,
        329,1,0,0,0,2465,2466,6,165,-1,0,2466,2470,3,332,166,0,2467,2468,
        7,33,0,0,2468,2470,3,330,165,7,2469,2465,1,0,0,0,2469,2467,1,0,0,
        0,2470,2492,1,0,0,0,2471,2472,10,6,0,0,2472,2473,7,34,0,0,2473,2491,
        3,330,165,7,2474,2475,10,5,0,0,2475,2476,7,35,0,0,2476,2491,3,330,
        165,6,2477,2478,10,4,0,0,2478,2479,5,467,0,0,2479,2491,3,330,165,
        5,2480,2481,10,3,0,0,2481,2482,5,468,0,0,2482,2491,3,330,165,4,2483,
        2484,10,2,0,0,2484,2485,5,466,0,0,2485,2491,3,330,165,3,2486,2487,
        10,1,0,0,2487,2488,3,424,212,0,2488,2489,3,330,165,2,2489,2491,1,
        0,0,0,2490,2471,1,0,0,0,2490,2474,1,0,0,0,2490,2477,1,0,0,0,2490,
        2480,1,0,0,0,2490,2483,1,0,0,0,2490,2486,1,0,0,0,2491,2494,1,0,0,
        0,2492,2490,1,0,0,0,2492,2493,1,0,0,0,2493,331,1,0,0,0,2494,2492,
        1,0,0,0,2495,2496,6,166,-1,0,2496,2498,5,230,0,0,2497,2499,3,392,
        196,0,2498,2497,1,0,0,0,2499,2500,1,0,0,0,2500,2498,1,0,0,0,2500,
        2501,1,0,0,0,2501,2504,1,0,0,0,2502,2503,5,278,0,0,2503,2505,3,322,
        161,0,2504,2502,1,0,0,0,2504,2505,1,0,0,0,2505,2506,1,0,0,0,2506,
        2507,5,279,0,0,2507,2628,1,0,0,0,2508,2509,5,230,0,0,2509,2511,3,
        322,161,0,2510,2512,3,392,196,0,2511,2510,1,0,0,0,2512,2513,1,0,
        0,0,2513,2511,1,0,0,0,2513,2514,1,0,0,0,2514,2517,1,0,0,0,2515,2516,
        5,278,0,0,2516,2518,3,322,161,0,2517,2515,1,0,0,0,2517,2518,1,0,
        0,0,2518,2519,1,0,0,0,2519,2520,5,279,0,0,2520,2628,1,0,0,0,2521,
        2522,5,231,0,0,2522,2523,5,476,0,0,2523,2524,3,322,161,0,2524,2525,
        5,212,0,0,2525,2526,3,320,160,0,2526,2527,5,477,0,0,2527,2628,1,
        0,0,0,2528,2529,5,54,0,0,2529,2530,5,476,0,0,2530,2533,3,322,161,
        0,2531,2532,5,69,0,0,2532,2534,5,102,0,0,2533,2531,1,0,0,0,2533,
        2534,1,0,0,0,2534,2535,1,0,0,0,2535,2536,5,477,0,0,2536,2628,1,0,
        0,0,2537,2538,5,84,0,0,2538,2539,5,476,0,0,2539,2542,3,322,161,0,
        2540,2541,5,69,0,0,2541,2543,5,102,0,0,2542,2540,1,0,0,0,2542,2543,
        1,0,0,0,2543,2544,1,0,0,0,2544,2545,5,477,0,0,2545,2628,1,0,0,0,
        2546,2547,5,380,0,0,2547,2548,5,476,0,0,2548,2549,3,330,165,0,2549,
        2550,5,309,0,0,2550,2551,3,330,165,0,2551,2552,5,477,0,0,2552,2628,
        1,0,0,0,2553,2628,3,426,213,0,2554,2628,5,488,0,0,2555,2556,3,406,
        203,0,2556,2557,5,473,0,0,2557,2558,5,488,0,0,2558,2628,1,0,0,0,
        2559,2560,5,476,0,0,2560,2561,3,96,48,0,2561,2562,5,477,0,0,2562,
        2628,1,0,0,0,2563,2564,5,476,0,0,2564,2569,3,350,175,0,2565,2566,
        5,480,0,0,2566,2568,3,350,175,0,2567,2565,1,0,0,0,2568,2571,1,0,
        0,0,2569,2567,1,0,0,0,2569,2570,1,0,0,0,2570,2572,1,0,0,0,2571,2569,
        1,0,0,0,2572,2573,5,477,0,0,2573,2628,1,0,0,0,2574,2575,3,348,174,
        0,2575,2587,5,476,0,0,2576,2578,3,436,218,0,2577,2576,1,0,0,0,2577,
        2578,1,0,0,0,2578,2579,1,0,0,0,2579,2584,3,350,175,0,2580,2581,5,
        480,0,0,2581,2583,3,350,175,0,2582,2580,1,0,0,0,2583,2586,1,0,0,
        0,2584,2582,1,0,0,0,2584,2585,1,0,0,0,2585,2588,1,0,0,0,2586,2584,
        1,0,0,0,2587,2577,1,0,0,0,2587,2588,1,0,0,0,2588,2589,1,0,0,0,2589,
        2590,5,477,0,0,2590,2628,1,0,0,0,2591,2592,3,348,174,0,2592,2593,
        5,476,0,0,2593,2594,3,350,175,0,2594,2595,5,433,0,0,2595,2596,3,
        350,175,0,2596,2597,5,477,0,0,2597,2628,1,0,0,0,2598,2599,3,348,
        174,0,2599,2601,5,476,0,0,2600,2602,3,436,218,0,2601,2600,1,0,0,
        0,2601,2602,1,0,0,0,2602,2603,1,0,0,0,2603,2604,3,350,175,0,2604,
        2606,5,477,0,0,2605,2607,3,352,176,0,2606,2605,1,0,0,0,2606,2607,
        1,0,0,0,2607,2628,1,0,0,0,2608,2609,3,144,72,0,2609,2610,3,110,55,
        0,2610,2628,1,0,0,0,2611,2612,3,144,72,0,2612,2613,5,454,0,0,2613,
        2614,5,302,0,0,2614,2615,5,476,0,0,2615,2616,3,224,112,0,2616,2618,
        5,477,0,0,2617,2619,3,110,55,0,2618,2617,1,0,0,0,2618,2619,1,0,0,
        0,2619,2628,1,0,0,0,2620,2628,3,384,192,0,2621,2628,3,406,203,0,
        2622,2623,5,476,0,0,2623,2624,3,322,161,0,2624,2625,5,477,0,0,2625,
        2628,1,0,0,0,2626,2628,3,334,167,0,2627,2495,1,0,0,0,2627,2508,1,
        0,0,0,2627,2521,1,0,0,0,2627,2528,1,0,0,0,2627,2537,1,0,0,0,2627,
        2546,1,0,0,0,2627,2553,1,0,0,0,2627,2554,1,0,0,0,2627,2555,1,0,0,
        0,2627,2559,1,0,0,0,2627,2563,1,0,0,0,2627,2574,1,0,0,0,2627,2591,
        1,0,0,0,2627,2598,1,0,0,0,2627,2608,1,0,0,0,2627,2611,1,0,0,0,2627,
        2620,1,0,0,0,2627,2621,1,0,0,0,2627,2622,1,0,0,0,2627,2626,1,0,0,
        0,2628,2636,1,0,0,0,2629,2630,10,5,0,0,2630,2631,5,474,0,0,2631,
        2632,3,330,165,0,2632,2633,5,475,0,0,2633,2635,1,0,0,0,2634,2629,
        1,0,0,0,2635,2638,1,0,0,0,2636,2634,1,0,0,0,2636,2637,1,0,0,0,2637,
        333,1,0,0,0,2638,2636,1,0,0,0,2639,2644,3,336,168,0,2640,2644,3,
        340,170,0,2641,2644,3,342,171,0,2642,2644,3,338,169,0,2643,2639,
        1,0,0,0,2643,2640,1,0,0,0,2643,2641,1,0,0,0,2643,2642,1,0,0,0,2644,
        335,1,0,0,0,2645,2646,5,211,0,0,2646,2647,5,474,0,0,2647,2652,3,
        344,172,0,2648,2649,5,480,0,0,2649,2651,3,344,172,0,2650,2648,1,
        0,0,0,2651,2654,1,0,0,0,2652,2650,1,0,0,0,2652,2653,1,0,0,0,2653,
        2655,1,0,0,0,2654,2652,1,0,0,0,2655,2656,5,475,0,0,2656,2657,5,211,
        0,0,2657,2658,5,476,0,0,2658,2663,3,344,172,0,2659,2660,5,480,0,
        0,2660,2662,3,344,172,0,2661,2659,1,0,0,0,2662,2665,1,0,0,0,2663,
        2661,1,0,0,0,2663,2664,1,0,0,0,2664,2666,1,0,0,0,2665,2663,1,0,0,
        0,2666,2667,5,477,0,0,2667,337,1,0,0,0,2668,2669,5,414,0,0,2669,
        2670,5,476,0,0,2670,2675,3,344,172,0,2671,2672,5,480,0,0,2672,2674,
        3,344,172,0,2673,2671,1,0,0,0,2674,2677,1,0,0,0,2675,2673,1,0,0,
        0,2675,2676,1,0,0,0,2676,2678,1,0,0,0,2677,2675,1,0,0,0,2678,2679,
        5,477,0,0,2679,339,1,0,0,0,2680,2681,5,398,0,0,2681,2682,5,476,0,
        0,2682,2687,3,344,172,0,2683,2684,5,480,0,0,2684,2686,3,344,172,
        0,2685,2683,1,0,0,0,2686,2689,1,0,0,0,2687,2685,1,0,0,0,2687,2688,
        1,0,0,0,2688,2690,1,0,0,0,2689,2687,1,0,0,0,2690,2691,5,477,0,0,
        2691,341,1,0,0,0,2692,2693,5,91,0,0,2693,2694,5,474,0,0,2694,2695,
        3,344,172,0,2695,2696,5,480,0,0,2696,2697,3,344,172,0,2697,2698,
        5,475,0,0,2698,343,1,0,0,0,2699,2704,3,370,185,0,2700,2704,3,426,
        213,0,2701,2704,3,334,167,0,2702,2704,3,346,173,0,2703,2699,1,0,
        0,0,2703,2700,1,0,0,0,2703,2701,1,0,0,0,2703,2702,1,0,0,0,2704,345,
        1,0,0,0,2705,2706,7,36,0,0,2706,347,1,0,0,0,2707,2711,3,446,223,
        0,2708,2711,3,406,203,0,2709,2711,3,444,222,0,2710,2707,1,0,0,0,
        2710,2708,1,0,0,0,2710,2709,1,0,0,0,2711,349,1,0,0,0,2712,2719,3,
        442,221,0,2713,2719,3,440,220,0,2714,2719,3,438,219,0,2715,2719,
        3,322,161,0,2716,2719,3,352,176,0,2717,2719,3,426,213,0,2718,2712,
        1,0,0,0,2718,2713,1,0,0,0,2718,2714,1,0,0,0,2718,2715,1,0,0,0,2718,
        2716,1,0,0,0,2718,2717,1,0,0,0,2719,351,1,0,0,0,2720,2721,5,50,0,
        0,2721,2722,5,476,0,0,2722,2723,5,451,0,0,2723,2724,3,324,162,0,
        2724,2725,5,477,0,0,2725,353,1,0,0,0,2726,2727,3,384,192,0,2727,
        355,1,0,0,0,2728,2732,3,384,192,0,2729,2732,3,406,203,0,2730,2732,
        3,386,193,0,2731,2728,1,0,0,0,2731,2729,1,0,0,0,2731,2730,1,0,0,
        0,2732,357,1,0,0,0,2733,2736,5,318,0,0,2734,2737,3,360,180,0,2735,
        2737,3,364,182,0,2736,2734,1,0,0,0,2736,2735,1,0,0,0,2736,2737,1,
        0,0,0,2737,359,1,0,0,0,2738,2740,3,362,181,0,2739,2741,3,366,183,
        0,2740,2739,1,0,0,0,2740,2741,1,0,0,0,2741,361,1,0,0,0,2742,2743,
        3,368,184,0,2743,2744,3,440,220,0,2744,2746,1,0,0,0,2745,2742,1,
        0,0,0,2746,2747,1,0,0,0,2747,2745,1,0,0,0,2747,2748,1,0,0,0,2748,
        363,1,0,0,0,2749,2752,3,366,183,0,2750,2753,3,362,181,0,2751,2753,
        3,366,183,0,2752,2750,1,0,0,0,2752,2751,1,0,0,0,2752,2753,1,0,0,
        0,2753,365,1,0,0,0,2754,2755,3,368,184,0,2755,2756,3,440,220,0,2756,
        2757,5,433,0,0,2757,2758,3,440,220,0,2758,367,1,0,0,0,2759,2761,
        7,37,0,0,2760,2759,1,0,0,0,2760,2761,1,0,0,0,2761,2762,1,0,0,0,2762,
        2765,7,38,0,0,2763,2765,5,498,0,0,2764,2760,1,0,0,0,2764,2763,1,
        0,0,0,2765,369,1,0,0,0,2766,2767,3,374,187,0,2767,371,1,0,0,0,2768,
        2769,3,374,187,0,2769,373,1,0,0,0,2770,2772,5,212,0,0,2771,2770,
        1,0,0,0,2771,2772,1,0,0,0,2772,2773,1,0,0,0,2773,2775,3,384,192,
        0,2774,2776,3,380,190,0,2775,2774,1,0,0,0,2775,2776,1,0,0,0,2776,
        375,1,0,0,0,2777,2778,3,384,192,0,2778,2779,3,378,189,0,2779,377,
        1,0,0,0,2780,2781,5,344,0,0,2781,2783,3,384,192,0,2782,2780,1,0,
        0,0,2783,2786,1,0,0,0,2784,2782,1,0,0,0,2784,2785,1,0,0,0,2785,379,
        1,0,0,0,2786,2784,1,0,0,0,2787,2788,5,476,0,0,2788,2789,3,382,191,
        0,2789,2790,5,477,0,0,2790,381,1,0,0,0,2791,2796,3,384,192,0,2792,
        2793,5,480,0,0,2793,2795,3,384,192,0,2794,2792,1,0,0,0,2795,2798,
        1,0,0,0,2796,2794,1,0,0,0,2796,2797,1,0,0,0,2797,383,1,0,0,0,2798,
        2796,1,0,0,0,2799,2804,3,390,195,0,2800,2804,5,498,0,0,2801,2804,
        3,446,223,0,2802,2804,3,388,194,0,2803,2799,1,0,0,0,2803,2800,1,
        0,0,0,2803,2801,1,0,0,0,2803,2802,1,0,0,0,2804,385,1,0,0,0,2805,
        2810,3,390,195,0,2806,2810,3,442,221,0,2807,2810,3,446,223,0,2808,
        2810,3,444,222,0,2809,2805,1,0,0,0,2809,2806,1,0,0,0,2809,2807,1,
        0,0,0,2809,2808,1,0,0,0,2810,387,1,0,0,0,2811,2812,5,483,0,0,2812,
        2813,5,478,0,0,2813,2814,3,390,195,0,2814,2815,5,479,0,0,2815,389,
        1,0,0,0,2816,2817,7,39,0,0,2817,391,1,0,0,0,2818,2819,5,450,0,0,
        2819,2820,3,322,161,0,2820,2821,5,426,0,0,2821,2822,3,322,161,0,
        2822,393,1,0,0,0,2823,2824,3,406,203,0,2824,395,1,0,0,0,2825,2826,
        3,406,203,0,2826,397,1,0,0,0,2827,2828,3,406,203,0,2828,399,1,0,
        0,0,2829,2830,3,406,203,0,2830,401,1,0,0,0,2831,2832,3,406,203,0,
        2832,403,1,0,0,0,2833,2834,3,384,192,0,2834,405,1,0,0,0,2835,2840,
        3,384,192,0,2836,2837,5,473,0,0,2837,2839,3,384,192,0,2838,2836,
        1,0,0,0,2839,2842,1,0,0,0,2840,2838,1,0,0,0,2840,2841,1,0,0,0,2841,
        407,1,0,0,0,2842,2840,1,0,0,0,2843,2845,5,453,0,0,2844,2846,7,40,
        0,0,2845,2844,1,0,0,0,2845,2846,1,0,0,0,2846,2847,1,0,0,0,2847,2848,
        3,414,207,0,2848,409,1,0,0,0,2849,2850,5,68,0,0,2850,2851,5,354,
        0,0,2851,2852,5,285,0,0,2852,411,1,0,0,0,2853,2854,5,68,0,0,2854,
        2855,5,285,0,0,2855,413,1,0,0,0,2856,2857,5,476,0,0,2857,2862,3,
        416,208,0,2858,2859,5,480,0,0,2859,2861,3,416,208,0,2860,2858,1,
        0,0,0,2861,2864,1,0,0,0,2862,2860,1,0,0,0,2862,2863,1,0,0,0,2863,
        2865,1,0,0,0,2864,2862,1,0,0,0,2865,2866,5,477,0,0,2866,415,1,0,
        0,0,2867,2868,3,418,209,0,2868,2870,5,469,0,0,2869,2871,5,259,0,
        0,2870,2869,1,0,0,0,2870,2871,1,0,0,0,2871,2872,1,0,0,0,2872,2873,
        3,422,211,0,2873,417,1,0,0,0,2874,2879,3,384,192,0,2875,2879,3,406,
        203,0,2876,2879,3,430,215,0,2877,2879,3,350,175,0,2878,2874,1,0,
        0,0,2878,2875,1,0,0,0,2878,2876,1,0,0,0,2878,2877,1,0,0,0,2879,419,
        1,0,0,0,2880,2881,5,484,0,0,2881,2882,3,426,213,0,2882,2883,5,484,
        0,0,2883,2886,1,0,0,0,2884,2886,3,426,213,0,2885,2880,1,0,0,0,2885,
        2884,1,0,0,0,2886,421,1,0,0,0,2887,2898,5,499,0,0,2888,2898,5,500,
        0,0,2889,2898,3,434,217,0,2890,2898,3,406,203,0,2891,2898,3,426,
        213,0,2892,2898,3,388,194,0,2893,2894,5,484,0,0,2894,2895,3,388,
        194,0,2895,2896,5,484,0,0,2896,2898,1,0,0,0,2897,2887,1,0,0,0,2897,
        2888,1,0,0,0,2897,2889,1,0,0,0,2897,2890,1,0,0,0,2897,2891,1,0,0,
        0,2897,2892,1,0,0,0,2897,2893,1,0,0,0,2898,423,1,0,0,0,2899,2914,
        5,469,0,0,2900,2914,5,470,0,0,2901,2914,5,471,0,0,2902,2903,5,471,
        0,0,2903,2914,5,469,0,0,2904,2905,5,470,0,0,2905,2914,5,469,0,0,
        2906,2907,5,471,0,0,2907,2914,5,470,0,0,2908,2909,5,472,0,0,2909,
        2914,5,469,0,0,2910,2911,5,471,0,0,2911,2912,5,469,0,0,2912,2914,
        5,470,0,0,2913,2899,1,0,0,0,2913,2900,1,0,0,0,2913,2901,1,0,0,0,
        2913,2902,1,0,0,0,2913,2904,1,0,0,0,2913,2906,1,0,0,0,2913,2908,
        1,0,0,0,2913,2910,1,0,0,0,2914,425,1,0,0,0,2915,2929,3,358,179,0,
        2916,2929,3,428,214,0,2917,2929,3,430,215,0,2918,2920,5,490,0,0,
        2919,2918,1,0,0,0,2919,2920,1,0,0,0,2920,2921,1,0,0,0,2921,2929,
        3,432,216,0,2922,2929,3,434,217,0,2923,2929,5,500,0,0,2924,2926,
        5,354,0,0,2925,2924,1,0,0,0,2925,2926,1,0,0,0,2926,2927,1,0,0,0,
        2927,2929,5,357,0,0,2928,2915,1,0,0,0,2928,2916,1,0,0,0,2928,2917,
        1,0,0,0,2928,2919,1,0,0,0,2928,2922,1,0,0,0,2928,2923,1,0,0,0,2928,
        2925,1,0,0,0,2929,427,1,0,0,0,2930,2931,3,438,219,0,2931,2932,3,
        430,215,0,2932,429,1,0,0,0,2933,2934,5,498,0,0,2934,431,1,0,0,0,
        2935,2936,5,499,0,0,2936,433,1,0,0,0,2937,2938,7,41,0,0,2938,435,
        1,0,0,0,2939,2940,7,7,0,0,2940,437,1,0,0,0,2941,2942,7,42,0,0,2942,
        439,1,0,0,0,2943,2944,7,43,0,0,2944,441,1,0,0,0,2945,2946,7,44,0,
        0,2946,443,1,0,0,0,2947,2948,7,45,0,0,2948,445,1,0,0,0,2949,2950,
        7,46,0,0,2950,447,1,0,0,0,2951,2954,3,8,4,0,2952,2954,3,6,3,0,2953,
        2951,1,0,0,0,2953,2952,1,0,0,0,2954,2955,1,0,0,0,2955,2956,5,481,
        0,0,2956,449,1,0,0,0,2957,2958,3,108,54,0,2958,2960,3,124,62,0,2959,
        2961,3,186,93,0,2960,2959,1,0,0,0,2960,2961,1,0,0,0,2961,2963,1,
        0,0,0,2962,2964,3,190,95,0,2963,2962,1,0,0,0,2963,2964,1,0,0,0,2964,
        2966,1,0,0,0,2965,2967,3,214,107,0,2966,2965,1,0,0,0,2966,2967,1,
        0,0,0,2967,2969,1,0,0,0,2968,2970,3,216,108,0,2969,2968,1,0,0,0,
        2969,2970,1,0,0,0,2970,2994,1,0,0,0,2971,2972,3,124,62,0,2972,2974,
        3,108,54,0,2973,2975,3,186,93,0,2974,2973,1,0,0,0,2974,2975,1,0,
        0,0,2975,2977,1,0,0,0,2976,2978,3,190,95,0,2977,2976,1,0,0,0,2977,
        2978,1,0,0,0,2978,2980,1,0,0,0,2979,2981,3,214,107,0,2980,2979,1,
        0,0,0,2980,2981,1,0,0,0,2981,2983,1,0,0,0,2982,2984,3,216,108,0,
        2983,2982,1,0,0,0,2983,2984,1,0,0,0,2984,2994,1,0,0,0,2985,2986,
        3,108,54,0,2986,2987,3,124,62,0,2987,2988,3,222,111,0,2988,2994,
        1,0,0,0,2989,2990,3,108,54,0,2990,2991,3,124,62,0,2991,2992,3,188,
        94,0,2992,2994,1,0,0,0,2993,2957,1,0,0,0,2993,2971,1,0,0,0,2993,
        2985,1,0,0,0,2993,2989,1,0,0,0,2994,451,1,0,0,0,2995,3000,3,112,
        56,0,2996,2998,5,212,0,0,2997,2996,1,0,0,0,2997,2998,1,0,0,0,2998,
        2999,1,0,0,0,2999,3001,3,384,192,0,3000,2997,1,0,0,0,3000,3001,1,
        0,0,0,3001,3008,1,0,0,0,3002,3005,3,322,161,0,3003,3004,5,212,0,
        0,3004,3006,3,322,161,0,3005,3003,1,0,0,0,3005,3006,1,0,0,0,3006,
        3008,1,0,0,0,3007,2995,1,0,0,0,3007,3002,1,0,0,0,3008,453,1,0,0,
        0,357,459,461,470,478,482,486,492,498,503,520,530,537,543,552,556,
        563,579,587,597,606,616,627,632,636,654,660,664,673,678,682,688,
        690,695,697,702,704,710,714,720,730,740,748,755,764,770,776,783,
        793,803,811,819,828,833,839,848,860,866,872,884,894,904,910,915,
        919,921,925,932,936,951,965,972,976,979,989,1004,1007,1010,1013,
        1016,1018,1023,1027,1030,1033,1036,1040,1049,1056,1061,1070,1082,
        1087,1098,1105,1116,1120,1124,1128,1132,1141,1146,1155,1158,1163,
        1167,1183,1197,1205,1211,1217,1221,1226,1229,1233,1236,1239,1242,
        1247,1253,1258,1270,1278,1282,1290,1301,1307,1311,1314,1318,1324,
        1332,1345,1354,1360,1365,1369,1378,1383,1387,1400,1403,1407,1421,
        1429,1437,1455,1459,1473,1493,1499,1504,1508,1511,1515,1520,1525,
        1529,1535,1538,1544,1550,1567,1585,1590,1600,1608,1617,1623,1626,
        1632,1641,1651,1661,1667,1673,1677,1681,1688,1700,1712,1717,1726,
        1756,1764,1768,1771,1774,1777,1784,1787,1790,1793,1796,1799,1802,
        1807,1810,1819,1829,1834,1838,1843,1848,1857,1876,1884,1892,1896,
        1900,1910,1936,1944,1956,1977,1982,1986,1999,2004,2008,2016,2020,
        2025,2031,2034,2043,2048,2056,2064,2067,2081,2086,2090,2106,2115,
        2128,2136,2146,2167,2183,2190,2196,2199,2202,2212,2215,2223,2227,
        2232,2237,2241,2249,2253,2257,2261,2265,2269,2273,2277,2281,2285,
        2289,2293,2297,2301,2305,2309,2313,2319,2321,2335,2337,2348,2351,
        2353,2357,2361,2368,2377,2383,2396,2403,2408,2414,2421,2423,2426,
        2438,2443,2446,2452,2455,2461,2463,2469,2490,2492,2500,2504,2513,
        2517,2533,2542,2569,2577,2584,2587,2601,2606,2618,2627,2636,2643,
        2652,2663,2675,2687,2703,2710,2718,2731,2736,2740,2747,2752,2760,
        2764,2771,2775,2784,2796,2803,2809,2840,2845,2862,2870,2878,2885,
        2897,2913,2919,2925,2928,2953,2960,2963,2966,2969,2974,2977,2980,
        2983,2993,2997,3000,3005,3007
    ];

    private static __ATN: antlr.ATN;
    public static get _ATN(): antlr.ATN {
        if (!SparkSQLParser.__ATN) {
            SparkSQLParser.__ATN = new antlr.ATNDeserializer().deserialize(SparkSQLParser._serializedATN);
        }

        return SparkSQLParser.__ATN;
    }


    private static readonly vocabulary = new antlr.Vocabulary(SparkSQLParser.literalNames, SparkSQLParser.symbolicNames, []);

    public override get vocabulary(): antlr.Vocabulary {
        return SparkSQLParser.vocabulary;
    }

    private static readonly decisionsToDFA = SparkSQLParser._ATN.decisionToState.map( (ds: antlr.DecisionState, index: number) => new antlr.DFA(ds, index) );
}

export class StatementContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public sqlStatements(): SqlStatementsContext {
        return this.getRuleContext(0, SqlStatementsContext)!;
    }
    public EOF(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.EOF, 0)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_statement;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterStatement) {
             listener.enterStatement(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitStatement) {
             listener.exitStatement(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitStatement) {
            return visitor.visitStatement(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class SqlStatementsContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public sqlStatement(): SqlStatementContext[];
    public sqlStatement(i: number): SqlStatementContext | null;
    public sqlStatement(i?: number): SqlStatementContext[] | SqlStatementContext | null {
        if (i === undefined) {
            return this.getRuleContexts(SqlStatementContext);
        }

        return this.getRuleContext(i, SqlStatementContext);
    }
    public emptyStatement(): EmptyStatementContext[];
    public emptyStatement(i: number): EmptyStatementContext | null;
    public emptyStatement(i?: number): EmptyStatementContext[] | EmptyStatementContext | null {
        if (i === undefined) {
            return this.getRuleContexts(EmptyStatementContext);
        }

        return this.getRuleContext(i, EmptyStatementContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_sqlStatements;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterSqlStatements) {
             listener.enterSqlStatements(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitSqlStatements) {
             listener.exitSqlStatements(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitSqlStatements) {
            return visitor.visitSqlStatements(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class EmptyStatementContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public SEMICOLON(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.SEMICOLON, 0)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_emptyStatement;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterEmptyStatement) {
             listener.enterEmptyStatement(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitEmptyStatement) {
             listener.exitEmptyStatement(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitEmptyStatement) {
            return visitor.visitEmptyStatement(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class CreateStatementContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public createTable(): CreateTableContext {
        return this.getRuleContext(0, CreateTableContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_createStatement;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterCreateStatement) {
             listener.enterCreateStatement(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitCreateStatement) {
             listener.exitCreateStatement(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitCreateStatement) {
            return visitor.visitCreateStatement(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class DmlStatementContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public queryStatement(): QueryStatementContext | null {
        return this.getRuleContext(0, QueryStatementContext);
    }
    public insertStatement(): InsertStatementContext | null {
        return this.getRuleContext(0, InsertStatementContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_dmlStatement;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterDmlStatement) {
             listener.enterDmlStatement(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitDmlStatement) {
             listener.exitDmlStatement(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitDmlStatement) {
            return visitor.visitDmlStatement(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class CreateTableContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_createTable;
    }
    public override copyFrom(ctx: CreateTableContext): void {
        super.copyFrom(ctx);
    }
}
export class Using_createContext extends CreateTableContext {
    public constructor(ctx: CreateTableContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public usingCreate(): UsingCreateContext {
        return this.getRuleContext(0, UsingCreateContext)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterUsing_create) {
             listener.enterUsing_create(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitUsing_create) {
             listener.exitUsing_create(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitUsing_create) {
            return visitor.visitUsing_create(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class MaterializedContext extends CreateTableContext {
    public constructor(ctx: CreateTableContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public createMaterializedTableAsSelect(): CreateMaterializedTableAsSelectContext {
        return this.getRuleContext(0, CreateMaterializedTableAsSelectContext)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterMaterialized) {
             listener.enterMaterialized(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitMaterialized) {
             listener.exitMaterialized(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitMaterialized) {
            return visitor.visitMaterialized(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class SimpleContext extends CreateTableContext {
    public constructor(ctx: CreateTableContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public simpleCreateTable(): SimpleCreateTableContext {
        return this.getRuleContext(0, SimpleCreateTableContext)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterSimple) {
             listener.enterSimple(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitSimple) {
             listener.exitSimple(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitSimple) {
            return visitor.visitSimple(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class AsSelectContext extends CreateTableContext {
    public constructor(ctx: CreateTableContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public createTableAsSelect(): CreateTableAsSelectContext {
        return this.getRuleContext(0, CreateTableAsSelectContext)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterAsSelect) {
             listener.enterAsSelect(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitAsSelect) {
             listener.exitAsSelect(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitAsSelect) {
            return visitor.visitAsSelect(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class CustomSerdeContext extends CreateTableContext {
    public constructor(ctx: CreateTableContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public createCustomSerde(): CreateCustomSerdeContext {
        return this.getRuleContext(0, CreateCustomSerdeContext)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterCustomSerde) {
             listener.enterCustomSerde(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitCustomSerde) {
             listener.exitCustomSerde(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitCustomSerde) {
            return visitor.visitCustomSerde(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class CustomSerdeExternalContext extends CreateTableContext {
    public constructor(ctx: CreateTableContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public createCustomSerdeExternal(): CreateCustomSerdeExternalContext {
        return this.getRuleContext(0, CreateCustomSerdeExternalContext)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterCustomSerdeExternal) {
             listener.enterCustomSerdeExternal(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitCustomSerdeExternal) {
             listener.exitCustomSerdeExternal(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitCustomSerdeExternal) {
            return visitor.visitCustomSerdeExternal(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class SimpleCreateTableContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_CREATE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_CREATE, 0)!;
    }
    public KW_TABLE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_TABLE, 0)!;
    }
    public tablePathCreate(): TablePathCreateContext {
        return this.getRuleContext(0, TablePathCreateContext)!;
    }
    public columnsBody(): ColumnsBodyContext | null {
        return this.getRuleContext(0, ColumnsBodyContext);
    }
    public KW_TEMPORARY(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TEMPORARY, 0);
    }
    public ifNotExists(): IfNotExistsContext | null {
        return this.getRuleContext(0, IfNotExistsContext);
    }
    public simpleCreateTableNoSortElement(): SimpleCreateTableNoSortElementContext[];
    public simpleCreateTableNoSortElement(i: number): SimpleCreateTableNoSortElementContext | null;
    public simpleCreateTableNoSortElement(i?: number): SimpleCreateTableNoSortElementContext[] | SimpleCreateTableNoSortElementContext | null {
        if (i === undefined) {
            return this.getRuleContexts(SimpleCreateTableNoSortElementContext);
        }

        return this.getRuleContext(i, SimpleCreateTableNoSortElementContext);
    }
    public KW_LIKE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LIKE, 0);
    }
    public tablePath(): TablePathContext | null {
        return this.getRuleContext(0, TablePathContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_simpleCreateTable;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterSimpleCreateTable) {
             listener.enterSimpleCreateTable(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitSimpleCreateTable) {
             listener.exitSimpleCreateTable(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitSimpleCreateTable) {
            return visitor.visitSimpleCreateTable(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class SimpleCreateTableNoSortElementContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public partitionDefinition(): PartitionDefinitionContext | null {
        return this.getRuleContext(0, PartitionDefinitionContext);
    }
    public withOption(): WithOptionContext | null {
        return this.getRuleContext(0, WithOptionContext);
    }
    public likeDefinition(): LikeDefinitionContext | null {
        return this.getRuleContext(0, LikeDefinitionContext);
    }
    public distribution(): DistributionContext | null {
        return this.getRuleContext(0, DistributionContext);
    }
    public someByClause(): SomeByClauseContext | null {
        return this.getRuleContext(0, SomeByClauseContext);
    }
    public intoBuckets(): IntoBucketsContext | null {
        return this.getRuleContext(0, IntoBucketsContext);
    }
    public storedAs(): StoredAsContext | null {
        return this.getRuleContext(0, StoredAsContext);
    }
    public hiveFormatpartitionDefinition(): HiveFormatpartitionDefinitionContext | null {
        return this.getRuleContext(0, HiveFormatpartitionDefinitionContext);
    }
    public sortedBy(): SortedByContext | null {
        return this.getRuleContext(0, SortedByContext);
    }
    public rowFormatDelimited(): RowFormatDelimitedContext | null {
        return this.getRuleContext(0, RowFormatDelimitedContext);
    }
    public fieldsTerminatedBy(): FieldsTerminatedByContext | null {
        return this.getRuleContext(0, FieldsTerminatedByContext);
    }
    public using(): UsingContext | null {
        return this.getRuleContext(0, UsingContext);
    }
    public location(): LocationContext | null {
        return this.getRuleContext(0, LocationContext);
    }
    public tblProperties(): TblPropertiesContext | null {
        return this.getRuleContext(0, TblPropertiesContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_simpleCreateTableNoSortElement;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterSimpleCreateTableNoSortElement) {
             listener.enterSimpleCreateTableNoSortElement(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitSimpleCreateTableNoSortElement) {
             listener.exitSimpleCreateTableNoSortElement(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitSimpleCreateTableNoSortElement) {
            return visitor.visitSimpleCreateTableNoSortElement(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class LocationContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_LOCATION(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_LOCATION, 0)!;
    }
    public filePath(): FilePathContext {
        return this.getRuleContext(0, FilePathContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_location;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterLocation) {
             listener.enterLocation(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitLocation) {
             listener.exitLocation(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitLocation) {
            return visitor.visitLocation(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class SortedByContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_SORTED(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_SORTED, 0)!;
    }
    public KW_BY(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_BY, 0)!;
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public identifier(): IdentifierContext {
        return this.getRuleContext(0, IdentifierContext)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public KW_ASC(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ASC, 0);
    }
    public KW_DESC(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DESC, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_sortedBy;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterSortedBy) {
             listener.enterSortedBy(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitSortedBy) {
             listener.exitSortedBy(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitSortedBy) {
            return visitor.visitSortedBy(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class UsingCreateContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_CREATE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_CREATE, 0)!;
    }
    public KW_TABLE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_TABLE, 0)!;
    }
    public tablePathCreate(): TablePathCreateContext {
        return this.getRuleContext(0, TablePathCreateContext)!;
    }
    public columnUsing(): ColumnUsingContext | null {
        return this.getRuleContext(0, ColumnUsingContext);
    }
    public usingByQuery(): UsingByQueryContext | null {
        return this.getRuleContext(0, UsingByQueryContext);
    }
    public defaultColumnUsing(): DefaultColumnUsingContext | null {
        return this.getRuleContext(0, DefaultColumnUsingContext);
    }
    public ifNotExists(): IfNotExistsContext | null {
        return this.getRuleContext(0, IfNotExistsContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_usingCreate;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterUsingCreate) {
             listener.enterUsingCreate(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitUsingCreate) {
             listener.exitUsingCreate(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitUsingCreate) {
            return visitor.visitUsingCreate(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class TblPropertiesContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_TBLPROPERTIES(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_TBLPROPERTIES, 0)!;
    }
    public tablePropertyList(): TablePropertyListContext {
        return this.getRuleContext(0, TablePropertyListContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_tblProperties;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterTblProperties) {
             listener.enterTblProperties(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitTblProperties) {
             listener.exitTblProperties(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitTblProperties) {
            return visitor.visitTblProperties(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class DefaultColumnUsingContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public using(): UsingContext {
        return this.getRuleContext(0, UsingContext)!;
    }
    public queryStatement(): QueryStatementContext | null {
        return this.getRuleContext(0, QueryStatementContext);
    }
    public defaultColumnUsingNoSortElement(): DefaultColumnUsingNoSortElementContext[];
    public defaultColumnUsingNoSortElement(i: number): DefaultColumnUsingNoSortElementContext | null;
    public defaultColumnUsingNoSortElement(i?: number): DefaultColumnUsingNoSortElementContext[] | DefaultColumnUsingNoSortElementContext | null {
        if (i === undefined) {
            return this.getRuleContexts(DefaultColumnUsingNoSortElementContext);
        }

        return this.getRuleContext(i, DefaultColumnUsingNoSortElementContext);
    }
    public KW_AS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_AS, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_defaultColumnUsing;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterDefaultColumnUsing) {
             listener.enterDefaultColumnUsing(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitDefaultColumnUsing) {
             listener.exitDefaultColumnUsing(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitDefaultColumnUsing) {
            return visitor.visitDefaultColumnUsing(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class DefaultColumnUsingNoSortElementContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public partitionDefinition(): PartitionDefinitionContext | null {
        return this.getRuleContext(0, PartitionDefinitionContext);
    }
    public KW_OPTIONS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_OPTIONS, 0);
    }
    public tablePropertyList(): TablePropertyListContext | null {
        return this.getRuleContext(0, TablePropertyListContext);
    }
    public tblProperties(): TblPropertiesContext | null {
        return this.getRuleContext(0, TblPropertiesContext);
    }
    public someByClause(): SomeByClauseContext | null {
        return this.getRuleContext(0, SomeByClauseContext);
    }
    public intoBuckets(): IntoBucketsContext | null {
        return this.getRuleContext(0, IntoBucketsContext);
    }
    public KW_WITH(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_WITH, 0);
    }
    public tableAlias(): TableAliasContext | null {
        return this.getRuleContext(0, TableAliasContext);
    }
    public LB_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.LB_BRACKET, 0);
    }
    public queryStatement(): QueryStatementContext | null {
        return this.getRuleContext(0, QueryStatementContext);
    }
    public RR_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0);
    }
    public commentSpec(): CommentSpecContext | null {
        return this.getRuleContext(0, CommentSpecContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_defaultColumnUsingNoSortElement;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterDefaultColumnUsingNoSortElement) {
             listener.enterDefaultColumnUsingNoSortElement(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitDefaultColumnUsingNoSortElement) {
             listener.exitDefaultColumnUsingNoSortElement(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitDefaultColumnUsingNoSortElement) {
            return visitor.visitDefaultColumnUsingNoSortElement(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ColumnUsingContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public columnsBody(): ColumnsBodyContext | null {
        return this.getRuleContext(0, ColumnsBodyContext);
    }
    public using(): UsingContext | null {
        return this.getRuleContext(0, UsingContext);
    }
    public columnUsingNoSortElement(): ColumnUsingNoSortElementContext[];
    public columnUsingNoSortElement(i: number): ColumnUsingNoSortElementContext | null;
    public columnUsingNoSortElement(i?: number): ColumnUsingNoSortElementContext[] | ColumnUsingNoSortElementContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ColumnUsingNoSortElementContext);
        }

        return this.getRuleContext(i, ColumnUsingNoSortElementContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_columnUsing;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterColumnUsing) {
             listener.enterColumnUsing(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitColumnUsing) {
             listener.exitColumnUsing(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitColumnUsing) {
            return visitor.visitColumnUsing(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ColumnUsingNoSortElementContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public partitionDefinition(): PartitionDefinitionContext | null {
        return this.getRuleContext(0, PartitionDefinitionContext);
    }
    public KW_OPTIONS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_OPTIONS, 0);
    }
    public tablePropertyList(): TablePropertyListContext | null {
        return this.getRuleContext(0, TablePropertyListContext);
    }
    public tblProperties(): TblPropertiesContext | null {
        return this.getRuleContext(0, TblPropertiesContext);
    }
    public someByClause(): SomeByClauseContext | null {
        return this.getRuleContext(0, SomeByClauseContext);
    }
    public intoBuckets(): IntoBucketsContext | null {
        return this.getRuleContext(0, IntoBucketsContext);
    }
    public commentSpec(): CommentSpecContext | null {
        return this.getRuleContext(0, CommentSpecContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_columnUsingNoSortElement;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterColumnUsingNoSortElement) {
             listener.enterColumnUsingNoSortElement(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitColumnUsingNoSortElement) {
             listener.exitColumnUsingNoSortElement(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitColumnUsingNoSortElement) {
            return visitor.visitColumnUsingNoSortElement(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class UsingByQueryContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public using(): UsingContext | null {
        return this.getRuleContext(0, UsingContext);
    }
    public KW_AS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_AS, 0);
    }
    public queryStatement(): QueryStatementContext | null {
        return this.getRuleContext(0, QueryStatementContext);
    }
    public usingByQueryNoSortElement(): UsingByQueryNoSortElementContext[];
    public usingByQueryNoSortElement(i: number): UsingByQueryNoSortElementContext | null;
    public usingByQueryNoSortElement(i?: number): UsingByQueryNoSortElementContext[] | UsingByQueryNoSortElementContext | null {
        if (i === undefined) {
            return this.getRuleContexts(UsingByQueryNoSortElementContext);
        }

        return this.getRuleContext(i, UsingByQueryNoSortElementContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_usingByQuery;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterUsingByQuery) {
             listener.enterUsingByQuery(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitUsingByQuery) {
             listener.exitUsingByQuery(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitUsingByQuery) {
            return visitor.visitUsingByQuery(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class UsingByQueryNoSortElementContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public partitionDefinition(): PartitionDefinitionContext | null {
        return this.getRuleContext(0, PartitionDefinitionContext);
    }
    public KW_OPTIONS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_OPTIONS, 0);
    }
    public tablePropertyList(): TablePropertyListContext | null {
        return this.getRuleContext(0, TablePropertyListContext);
    }
    public tblProperties(): TblPropertiesContext | null {
        return this.getRuleContext(0, TblPropertiesContext);
    }
    public someByClause(): SomeByClauseContext | null {
        return this.getRuleContext(0, SomeByClauseContext);
    }
    public intoBuckets(): IntoBucketsContext | null {
        return this.getRuleContext(0, IntoBucketsContext);
    }
    public commentSpec(): CommentSpecContext | null {
        return this.getRuleContext(0, CommentSpecContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_usingByQueryNoSortElement;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterUsingByQueryNoSortElement) {
             listener.enterUsingByQueryNoSortElement(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitUsingByQueryNoSortElement) {
             listener.exitUsingByQueryNoSortElement(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitUsingByQueryNoSortElement) {
            return visitor.visitUsingByQueryNoSortElement(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class IntoBucketsContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_INTO(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_INTO, 0)!;
    }
    public DIG_LITERAL(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.DIG_LITERAL, 0)!;
    }
    public KW_BUCKETS(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_BUCKETS, 0)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_intoBuckets;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterIntoBuckets) {
             listener.enterIntoBuckets(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitIntoBuckets) {
             listener.exitIntoBuckets(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitIntoBuckets) {
            return visitor.visitIntoBuckets(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class HiveFormatpartitionDefinitionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_PARTITIONED(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_PARTITIONED, 0)!;
    }
    public KW_BY(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_BY, 0)!;
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public ID_LITERAL(): antlr.TerminalNode[];
    public ID_LITERAL(i: number): antlr.TerminalNode | null;
    public ID_LITERAL(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.ID_LITERAL);
    	} else {
    		return this.getToken(SparkSQLParser.ID_LITERAL, i);
    	}
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public sqlSimpleType(): SqlSimpleTypeContext[];
    public sqlSimpleType(i: number): SqlSimpleTypeContext | null;
    public sqlSimpleType(i?: number): SqlSimpleTypeContext[] | SqlSimpleTypeContext | null {
        if (i === undefined) {
            return this.getRuleContexts(SqlSimpleTypeContext);
        }

        return this.getRuleContext(i, SqlSimpleTypeContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_hiveFormatpartitionDefinition;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterHiveFormatpartitionDefinition) {
             listener.enterHiveFormatpartitionDefinition(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitHiveFormatpartitionDefinition) {
             listener.exitHiveFormatpartitionDefinition(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitHiveFormatpartitionDefinition) {
            return visitor.visitHiveFormatpartitionDefinition(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class RowFormatSerdeContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_ROW(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_ROW, 0)!;
    }
    public KW_FORMAT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_FORMAT, 0)!;
    }
    public KW_SERDE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_SERDE, 0)!;
    }
    public stringLiteral(): StringLiteralContext {
        return this.getRuleContext(0, StringLiteralContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_rowFormatSerde;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterRowFormatSerde) {
             listener.enterRowFormatSerde(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitRowFormatSerde) {
             listener.exitRowFormatSerde(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitRowFormatSerde) {
            return visitor.visitRowFormatSerde(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class FieldsTerminatedByContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_FIELDS(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_FIELDS, 0)!;
    }
    public KW_TERMINATED(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_TERMINATED, 0)!;
    }
    public KW_BY(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_BY, 0)!;
    }
    public stringLiteral(): StringLiteralContext {
        return this.getRuleContext(0, StringLiteralContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_fieldsTerminatedBy;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterFieldsTerminatedBy) {
             listener.enterFieldsTerminatedBy(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitFieldsTerminatedBy) {
             listener.exitFieldsTerminatedBy(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitFieldsTerminatedBy) {
            return visitor.visitFieldsTerminatedBy(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class StoredAsContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_STORED(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_STORED, 0)!;
    }
    public KW_AS(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_AS, 0)!;
    }
    public identifier(): IdentifierContext | null {
        return this.getRuleContext(0, IdentifierContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_storedAs;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterStoredAs) {
             listener.enterStoredAs(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitStoredAs) {
             listener.exitStoredAs(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitStoredAs) {
            return visitor.visitStoredAs(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class StoredAsInputformatContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_STORED(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_STORED, 0)!;
    }
    public KW_AS(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_AS, 0)!;
    }
    public KW_INPUTFORMAT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_INPUTFORMAT, 0)!;
    }
    public identifier(): IdentifierContext | null {
        return this.getRuleContext(0, IdentifierContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_storedAsInputformat;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterStoredAsInputformat) {
             listener.enterStoredAsInputformat(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitStoredAsInputformat) {
             listener.exitStoredAsInputformat(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitStoredAsInputformat) {
            return visitor.visitStoredAsInputformat(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class OutputformatContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_OUTPUTFORMAT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_OUTPUTFORMAT, 0)!;
    }
    public identifier(): IdentifierContext | null {
        return this.getRuleContext(0, IdentifierContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_outputformat;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterOutputformat) {
             listener.enterOutputformat(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitOutputformat) {
             listener.exitOutputformat(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitOutputformat) {
            return visitor.visitOutputformat(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class RowFormatDelimtedContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_ROW(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_ROW, 0)!;
    }
    public KW_FORMAT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_FORMAT, 0)!;
    }
    public KW_DELIMITED(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_DELIMITED, 0)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_rowFormatDelimted;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterRowFormatDelimted) {
             listener.enterRowFormatDelimted(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitRowFormatDelimted) {
             listener.exitRowFormatDelimted(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitRowFormatDelimted) {
            return visitor.visitRowFormatDelimted(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ColumnsBodyContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public columnOptionDefinition(): ColumnOptionDefinitionContext[];
    public columnOptionDefinition(i: number): ColumnOptionDefinitionContext | null;
    public columnOptionDefinition(i?: number): ColumnOptionDefinitionContext[] | ColumnOptionDefinitionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ColumnOptionDefinitionContext);
        }

        return this.getRuleContext(i, ColumnOptionDefinitionContext);
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public commentSpec(): CommentSpecContext[];
    public commentSpec(i: number): CommentSpecContext | null;
    public commentSpec(i?: number): CommentSpecContext[] | CommentSpecContext | null {
        if (i === undefined) {
            return this.getRuleContexts(CommentSpecContext);
        }

        return this.getRuleContext(i, CommentSpecContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public watermarkDefinition(): WatermarkDefinitionContext | null {
        return this.getRuleContext(0, WatermarkDefinitionContext);
    }
    public tableConstraint(): TableConstraintContext | null {
        return this.getRuleContext(0, TableConstraintContext);
    }
    public selfDefinitionClause(): SelfDefinitionClauseContext | null {
        return this.getRuleContext(0, SelfDefinitionClauseContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_columnsBody;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterColumnsBody) {
             listener.enterColumnsBody(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitColumnsBody) {
             listener.exitColumnsBody(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitColumnsBody) {
            return visitor.visitColumnsBody(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class CreateCustomSerdeContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_CREATE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_CREATE, 0)!;
    }
    public KW_TABLE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_TABLE, 0)!;
    }
    public tablePathCreate(): TablePathCreateContext {
        return this.getRuleContext(0, TablePathCreateContext)!;
    }
    public KW_ROW(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_ROW, 0)!;
    }
    public KW_FORMAT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_FORMAT, 0)!;
    }
    public KW_SERDE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_SERDE, 0)!;
    }
    public tablePropertyKey(): TablePropertyKeyContext[];
    public tablePropertyKey(i: number): TablePropertyKeyContext | null;
    public tablePropertyKey(i?: number): TablePropertyKeyContext[] | TablePropertyKeyContext | null {
        if (i === undefined) {
            return this.getRuleContexts(TablePropertyKeyContext);
        }

        return this.getRuleContext(i, TablePropertyKeyContext);
    }
    public KW_SORTED(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_SORTED, 0)!;
    }
    public KW_AS(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_AS, 0)!;
    }
    public KW_INPUTFORMAT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_INPUTFORMAT, 0)!;
    }
    public KW_OUTPUTFORMAT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_OUTPUTFORMAT, 0)!;
    }
    public tblProperties(): TblPropertiesContext {
        return this.getRuleContext(0, TblPropertiesContext)!;
    }
    public KW_TEMPORARY(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TEMPORARY, 0);
    }
    public ifNotExists(): IfNotExistsContext | null {
        return this.getRuleContext(0, IfNotExistsContext);
    }
    public createCustomSerdeNoSortElement(): CreateCustomSerdeNoSortElementContext[];
    public createCustomSerdeNoSortElement(i: number): CreateCustomSerdeNoSortElementContext | null;
    public createCustomSerdeNoSortElement(i?: number): CreateCustomSerdeNoSortElementContext[] | CreateCustomSerdeNoSortElementContext | null {
        if (i === undefined) {
            return this.getRuleContexts(CreateCustomSerdeNoSortElementContext);
        }

        return this.getRuleContext(i, CreateCustomSerdeNoSortElementContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_createCustomSerde;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterCreateCustomSerde) {
             listener.enterCreateCustomSerde(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitCreateCustomSerde) {
             listener.exitCreateCustomSerde(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitCreateCustomSerde) {
            return visitor.visitCreateCustomSerde(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class CreateCustomSerdeNoSortElementContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public columnsBody(): ColumnsBodyContext | null {
        return this.getRuleContext(0, ColumnsBodyContext);
    }
    public commentSpec(): CommentSpecContext | null {
        return this.getRuleContext(0, CommentSpecContext);
    }
    public partitionDefinition(): PartitionDefinitionContext | null {
        return this.getRuleContext(0, PartitionDefinitionContext);
    }
    public withOption(): WithOptionContext | null {
        return this.getRuleContext(0, WithOptionContext);
    }
    public likeDefinition(): LikeDefinitionContext | null {
        return this.getRuleContext(0, LikeDefinitionContext);
    }
    public distribution(): DistributionContext | null {
        return this.getRuleContext(0, DistributionContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_createCustomSerdeNoSortElement;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterCreateCustomSerdeNoSortElement) {
             listener.enterCreateCustomSerdeNoSortElement(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitCreateCustomSerdeNoSortElement) {
             listener.exitCreateCustomSerdeNoSortElement(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitCreateCustomSerdeNoSortElement) {
            return visitor.visitCreateCustomSerdeNoSortElement(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class CreateCustomSerdeExternalContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_CREATE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_CREATE, 0)!;
    }
    public KW_EXTERNAL(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_EXTERNAL, 0)!;
    }
    public KW_TABLE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_TABLE, 0)!;
    }
    public tablePathCreate(): TablePathCreateContext {
        return this.getRuleContext(0, TablePathCreateContext)!;
    }
    public columnsBody(): ColumnsBodyContext {
        return this.getRuleContext(0, ColumnsBodyContext)!;
    }
    public KW_ROW(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_ROW, 0)!;
    }
    public KW_FORMAT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_FORMAT, 0)!;
    }
    public KW_SERDE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_SERDE, 0)!;
    }
    public tablePropertyKey(): TablePropertyKeyContext[];
    public tablePropertyKey(i: number): TablePropertyKeyContext | null;
    public tablePropertyKey(i?: number): TablePropertyKeyContext[] | TablePropertyKeyContext | null {
        if (i === undefined) {
            return this.getRuleContexts(TablePropertyKeyContext);
        }

        return this.getRuleContext(i, TablePropertyKeyContext);
    }
    public KW_SORTED(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_SORTED, 0)!;
    }
    public KW_AS(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_AS, 0)!;
    }
    public KW_INPUTFORMAT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_INPUTFORMAT, 0)!;
    }
    public KW_OUTPUTFORMAT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_OUTPUTFORMAT, 0)!;
    }
    public KW_LOCATION(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_LOCATION, 0)!;
    }
    public filePath(): FilePathContext {
        return this.getRuleContext(0, FilePathContext)!;
    }
    public ifNotExists(): IfNotExistsContext | null {
        return this.getRuleContext(0, IfNotExistsContext);
    }
    public createCustomSerdeExternalNoSortElement(): CreateCustomSerdeExternalNoSortElementContext[];
    public createCustomSerdeExternalNoSortElement(i: number): CreateCustomSerdeExternalNoSortElementContext | null;
    public createCustomSerdeExternalNoSortElement(i?: number): CreateCustomSerdeExternalNoSortElementContext[] | CreateCustomSerdeExternalNoSortElementContext | null {
        if (i === undefined) {
            return this.getRuleContexts(CreateCustomSerdeExternalNoSortElementContext);
        }

        return this.getRuleContext(i, CreateCustomSerdeExternalNoSortElementContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_createCustomSerdeExternal;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterCreateCustomSerdeExternal) {
             listener.enterCreateCustomSerdeExternal(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitCreateCustomSerdeExternal) {
             listener.exitCreateCustomSerdeExternal(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitCreateCustomSerdeExternal) {
            return visitor.visitCreateCustomSerdeExternal(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class CreateCustomSerdeExternalNoSortElementContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public commentSpec(): CommentSpecContext | null {
        return this.getRuleContext(0, CommentSpecContext);
    }
    public partitionDefinition(): PartitionDefinitionContext | null {
        return this.getRuleContext(0, PartitionDefinitionContext);
    }
    public withOption(): WithOptionContext | null {
        return this.getRuleContext(0, WithOptionContext);
    }
    public likeDefinition(): LikeDefinitionContext | null {
        return this.getRuleContext(0, LikeDefinitionContext);
    }
    public distribution(): DistributionContext | null {
        return this.getRuleContext(0, DistributionContext);
    }
    public tblProperties(): TblPropertiesContext | null {
        return this.getRuleContext(0, TblPropertiesContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_createCustomSerdeExternalNoSortElement;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterCreateCustomSerdeExternalNoSortElement) {
             listener.enterCreateCustomSerdeExternalNoSortElement(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitCreateCustomSerdeExternalNoSortElement) {
             listener.exitCreateCustomSerdeExternalNoSortElement(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitCreateCustomSerdeExternalNoSortElement) {
            return visitor.visitCreateCustomSerdeExternalNoSortElement(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class CreateTableAsSelectContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_CREATE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_CREATE, 0)!;
    }
    public KW_TABLE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_TABLE, 0)!;
    }
    public tablePathCreate(): TablePathCreateContext {
        return this.getRuleContext(0, TablePathCreateContext)!;
    }
    public withOption(): WithOptionContext {
        return this.getRuleContext(0, WithOptionContext)!;
    }
    public ifNotExists(): IfNotExistsContext | null {
        return this.getRuleContext(0, IfNotExistsContext);
    }
    public KW_AS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_AS, 0);
    }
    public queryStatement(): QueryStatementContext | null {
        return this.getRuleContext(0, QueryStatementContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_createTableAsSelect;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterCreateTableAsSelect) {
             listener.enterCreateTableAsSelect(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitCreateTableAsSelect) {
             listener.exitCreateTableAsSelect(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitCreateTableAsSelect) {
            return visitor.visitCreateTableAsSelect(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class CreateMaterializedTableAsSelectContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_CREATE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_CREATE, 0)!;
    }
    public KW_MATERIALIZED(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_MATERIALIZED, 0)!;
    }
    public KW_TABLE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_TABLE, 0)!;
    }
    public tablePathCreate(): TablePathCreateContext {
        return this.getRuleContext(0, TablePathCreateContext)!;
    }
    public LR_BRACKET(): antlr.TerminalNode[];
    public LR_BRACKET(i: number): antlr.TerminalNode | null;
    public LR_BRACKET(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.LR_BRACKET);
    	} else {
    		return this.getToken(SparkSQLParser.LR_BRACKET, i);
    	}
    }
    public KW_PRIMARY(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_PRIMARY, 0)!;
    }
    public KW_KEY(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_KEY, 0)!;
    }
    public identifier(): IdentifierContext[];
    public identifier(i: number): IdentifierContext | null;
    public identifier(i?: number): IdentifierContext[] | IdentifierContext | null {
        if (i === undefined) {
            return this.getRuleContexts(IdentifierContext);
        }

        return this.getRuleContext(i, IdentifierContext);
    }
    public RR_BRACKET(): antlr.TerminalNode[];
    public RR_BRACKET(i: number): antlr.TerminalNode | null;
    public RR_BRACKET(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.RR_BRACKET);
    	} else {
    		return this.getToken(SparkSQLParser.RR_BRACKET, i);
    	}
    }
    public KW_FRESHNESS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FRESHNESS, 0);
    }
    public EQUAL_SYMBOL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.EQUAL_SYMBOL, 0);
    }
    public KW_INTERVAL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_INTERVAL, 0);
    }
    public createMaterializedTableAsSelectNoSortElement(): CreateMaterializedTableAsSelectNoSortElementContext[];
    public createMaterializedTableAsSelectNoSortElement(i: number): CreateMaterializedTableAsSelectNoSortElementContext | null;
    public createMaterializedTableAsSelectNoSortElement(i?: number): CreateMaterializedTableAsSelectNoSortElementContext[] | CreateMaterializedTableAsSelectNoSortElementContext | null {
        if (i === undefined) {
            return this.getRuleContexts(CreateMaterializedTableAsSelectNoSortElementContext);
        }

        return this.getRuleContext(i, CreateMaterializedTableAsSelectNoSortElementContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public KW_NOT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NOT, 0);
    }
    public KW_ENFORCED(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ENFORCED, 0);
    }
    public KW_SECOND(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SECOND, 0);
    }
    public KW_MINUTE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MINUTE, 0);
    }
    public KW_HOUR(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_HOUR, 0);
    }
    public KW_DAY(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DAY, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_createMaterializedTableAsSelect;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterCreateMaterializedTableAsSelect) {
             listener.enterCreateMaterializedTableAsSelect(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitCreateMaterializedTableAsSelect) {
             listener.exitCreateMaterializedTableAsSelect(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitCreateMaterializedTableAsSelect) {
            return visitor.visitCreateMaterializedTableAsSelect(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class CreateMaterializedTableAsSelectNoSortElementContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public partitionDefinition(): PartitionDefinitionContext | null {
        return this.getRuleContext(0, PartitionDefinitionContext);
    }
    public withOption(): WithOptionContext | null {
        return this.getRuleContext(0, WithOptionContext);
    }
    public KW_REFRESH_MODE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_REFRESH_MODE, 0);
    }
    public EQUAL_SYMBOL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.EQUAL_SYMBOL, 0);
    }
    public KW_FULL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FULL, 0);
    }
    public KW_CONTINUOUS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_CONTINUOUS, 0);
    }
    public KW_AS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_AS, 0);
    }
    public queryStatement(): QueryStatementContext | null {
        return this.getRuleContext(0, QueryStatementContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_createMaterializedTableAsSelectNoSortElement;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterCreateMaterializedTableAsSelectNoSortElement) {
             listener.enterCreateMaterializedTableAsSelectNoSortElement(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitCreateMaterializedTableAsSelectNoSortElement) {
             listener.exitCreateMaterializedTableAsSelectNoSortElement(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitCreateMaterializedTableAsSelectNoSortElement) {
            return visitor.visitCreateMaterializedTableAsSelectNoSortElement(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class UsingClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_USING(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_USING, 0)!;
    }
    public KW_JAR(): antlr.TerminalNode[];
    public KW_JAR(i: number): antlr.TerminalNode | null;
    public KW_JAR(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.KW_JAR);
    	} else {
    		return this.getToken(SparkSQLParser.KW_JAR, i);
    	}
    }
    public jarFileName(): JarFileNameContext[];
    public jarFileName(i: number): JarFileNameContext | null;
    public jarFileName(i?: number): JarFileNameContext[] | JarFileNameContext | null {
        if (i === undefined) {
            return this.getRuleContexts(JarFileNameContext);
        }

        return this.getRuleContext(i, JarFileNameContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_usingClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterUsingClause) {
             listener.enterUsingClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitUsingClause) {
             listener.exitUsingClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitUsingClause) {
            return visitor.visitUsingClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class JarFileNameContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public filePath(): FilePathContext {
        return this.getRuleContext(0, FilePathContext)!;
    }
    public DOT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.DOT, 0);
    }
    public KW_JAR(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_JAR, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_jarFileName;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterJarFileName) {
             listener.enterJarFileName(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitJarFileName) {
             listener.exitJarFileName(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitJarFileName) {
            return visitor.visitJarFileName(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class FilePathContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public STRING_LITERAL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.STRING_LITERAL, 0);
    }
    public SLASH_SIGN(): antlr.TerminalNode[];
    public SLASH_SIGN(i: number): antlr.TerminalNode | null;
    public SLASH_SIGN(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.SLASH_SIGN);
    	} else {
    		return this.getToken(SparkSQLParser.SLASH_SIGN, i);
    	}
    }
    public ID_LITERAL(): antlr.TerminalNode[];
    public ID_LITERAL(i: number): antlr.TerminalNode | null;
    public ID_LITERAL(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.ID_LITERAL);
    	} else {
    		return this.getToken(SparkSQLParser.ID_LITERAL, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_filePath;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterFilePath) {
             listener.enterFilePath(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitFilePath) {
             listener.exitFilePath(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitFilePath) {
            return visitor.visitFilePath(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class IfExistsPartContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_IF(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_IF, 0)!;
    }
    public KW_EXISTS(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_EXISTS, 0)!;
    }
    public KW_NOT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NOT, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_ifExistsPart;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterIfExistsPart) {
             listener.enterIfExistsPart(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitIfExistsPart) {
             listener.exitIfExistsPart(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitIfExistsPart) {
            return visitor.visitIfExistsPart(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ColumnPositionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_FIRST(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FIRST, 0);
    }
    public KW_LAST(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LAST, 0);
    }
    public uid(): UidContext | null {
        return this.getRuleContext(0, UidContext);
    }
    public KW_BEFORE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_BEFORE, 0);
    }
    public KW_AFTER(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_AFTER, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_columnPosition;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterColumnPosition) {
             listener.enterColumnPosition(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitColumnPosition) {
             listener.exitColumnPosition(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitColumnPosition) {
            return visitor.visitColumnPosition(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class RenameDefinitionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_RENAME(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_RENAME, 0)!;
    }
    public KW_TO(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_TO, 0)!;
    }
    public uid(): UidContext[];
    public uid(i: number): UidContext | null;
    public uid(i?: number): UidContext[] | UidContext | null {
        if (i === undefined) {
            return this.getRuleContexts(UidContext);
        }

        return this.getRuleContext(i, UidContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_renameDefinition;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterRenameDefinition) {
             listener.enterRenameDefinition(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitRenameDefinition) {
             listener.exitRenameDefinition(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitRenameDefinition) {
            return visitor.visitRenameDefinition(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class SetKeyValueDefinitionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_SET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_SET, 0)!;
    }
    public tablePropertyList(): TablePropertyListContext {
        return this.getRuleContext(0, TablePropertyListContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_setKeyValueDefinition;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterSetKeyValueDefinition) {
             listener.enterSetKeyValueDefinition(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitSetKeyValueDefinition) {
             listener.exitSetKeyValueDefinition(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitSetKeyValueDefinition) {
            return visitor.visitSetKeyValueDefinition(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class AddConstraintContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_ADD(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_ADD, 0)!;
    }
    public KW_CONSTRAINT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_CONSTRAINT, 0)!;
    }
    public constraintName(): ConstraintNameContext {
        return this.getRuleContext(0, ConstraintNameContext)!;
    }
    public KW_PRIMARY(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_PRIMARY, 0)!;
    }
    public KW_KEY(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_KEY, 0)!;
    }
    public columnNameList(): ColumnNameListContext {
        return this.getRuleContext(0, ColumnNameListContext)!;
    }
    public notForced(): NotForcedContext | null {
        return this.getRuleContext(0, NotForcedContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_addConstraint;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterAddConstraint) {
             listener.enterAddConstraint(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitAddConstraint) {
             listener.exitAddConstraint(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitAddConstraint) {
            return visitor.visitAddConstraint(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class DropConstraintContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_DROP(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_DROP, 0)!;
    }
    public KW_CONSTRAINT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_CONSTRAINT, 0)!;
    }
    public constraintName(): ConstraintNameContext {
        return this.getRuleContext(0, ConstraintNameContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_dropConstraint;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterDropConstraint) {
             listener.enterDropConstraint(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitDropConstraint) {
             listener.exitDropConstraint(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitDropConstraint) {
            return visitor.visitDropConstraint(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class AddUniqueContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_ADD(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_ADD, 0)!;
    }
    public KW_UNIQUE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_UNIQUE, 0)!;
    }
    public columnNameList(): ColumnNameListContext {
        return this.getRuleContext(0, ColumnNameListContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_addUnique;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterAddUnique) {
             listener.enterAddUnique(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitAddUnique) {
             listener.exitAddUnique(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitAddUnique) {
            return visitor.visitAddUnique(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class NotForcedContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_NOT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_NOT, 0)!;
    }
    public KW_ENFORCED(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_ENFORCED, 0)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_notForced;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterNotForced) {
             listener.enterNotForced(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitNotForced) {
             listener.exitNotForced(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitNotForced) {
            return visitor.visitNotForced(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class InsertStatementContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public insertSimpleStatement(): InsertSimpleStatementContext {
        return this.getRuleContext(0, InsertSimpleStatementContext)!;
    }
    public KW_EXECUTE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_EXECUTE, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_insertStatement;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterInsertStatement) {
             listener.enterInsertStatement(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitInsertStatement) {
             listener.exitInsertStatement(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitInsertStatement) {
            return visitor.visitInsertStatement(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class InsertSimpleStatementContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_INSERT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_INSERT, 0)!;
    }
    public tablePath(): TablePathContext[];
    public tablePath(i: number): TablePathContext | null;
    public tablePath(i?: number): TablePathContext[] | TablePathContext | null {
        if (i === undefined) {
            return this.getRuleContexts(TablePathContext);
        }

        return this.getRuleContext(i, TablePathContext);
    }
    public KW_INTO(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_INTO, 0);
    }
    public KW_OVERWRITE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_OVERWRITE, 0);
    }
    public queryStatement(): QueryStatementContext | null {
        return this.getRuleContext(0, QueryStatementContext);
    }
    public valuesDefinition(): ValuesDefinitionContext | null {
        return this.getRuleContext(0, ValuesDefinitionContext);
    }
    public KW_TABLE(): antlr.TerminalNode[];
    public KW_TABLE(i: number): antlr.TerminalNode | null;
    public KW_TABLE(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.KW_TABLE);
    	} else {
    		return this.getToken(SparkSQLParser.KW_TABLE, i);
    	}
    }
    public insertPartitionDefinition(): InsertPartitionDefinitionContext | null {
        return this.getRuleContext(0, InsertPartitionDefinitionContext);
    }
    public columnNameList(): ColumnNameListContext | null {
        return this.getRuleContext(0, ColumnNameListContext);
    }
    public KW_REPLACE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_REPLACE, 0);
    }
    public whereClause(): WhereClauseContext | null {
        return this.getRuleContext(0, WhereClauseContext);
    }
    public selectStatement(): SelectStatementContext | null {
        return this.getRuleContext(0, SelectStatementContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_insertSimpleStatement;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterInsertSimpleStatement) {
             listener.enterInsertSimpleStatement(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitInsertSimpleStatement) {
             listener.exitInsertSimpleStatement(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitInsertSimpleStatement) {
            return visitor.visitInsertSimpleStatement(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class InsertPartitionDefinitionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_PARTITION(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_PARTITION, 0)!;
    }
    public tablePropertyList(): TablePropertyListContext {
        return this.getRuleContext(0, TablePropertyListContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_insertPartitionDefinition;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterInsertPartitionDefinition) {
             listener.enterInsertPartitionDefinition(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitInsertPartitionDefinition) {
             listener.exitInsertPartitionDefinition(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitInsertPartitionDefinition) {
            return visitor.visitInsertPartitionDefinition(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class QueryStatementContext extends antlr.ParserRuleContext {
    public _left?: QueryStatementContext;
    public _operator?: Token | null;
    public _right?: QueryStatementContext;
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public withClause(): WithClauseContext | null {
        return this.getRuleContext(0, WithClauseContext);
    }
    public queryStatement(): QueryStatementContext[];
    public queryStatement(i: number): QueryStatementContext | null;
    public queryStatement(i?: number): QueryStatementContext[] | QueryStatementContext | null {
        if (i === undefined) {
            return this.getRuleContexts(QueryStatementContext);
        }

        return this.getRuleContext(i, QueryStatementContext);
    }
    public LR_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0);
    }
    public RR_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0);
    }
    public selectClause(): SelectClauseContext | null {
        return this.getRuleContext(0, SelectClauseContext);
    }
    public selectStatement(): SelectStatementContext | null {
        return this.getRuleContext(0, SelectStatementContext);
    }
    public sortByCaluse(): SortByCaluseContext | null {
        return this.getRuleContext(0, SortByCaluseContext);
    }
    public orderByCaluse(): OrderByCaluseContext | null {
        return this.getRuleContext(0, OrderByCaluseContext);
    }
    public limitClause(): LimitClauseContext | null {
        return this.getRuleContext(0, LimitClauseContext);
    }
    public offsetClause(): OffsetClauseContext | null {
        return this.getRuleContext(0, OffsetClauseContext);
    }
    public KW_INTERSECT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_INTERSECT, 0);
    }
    public KW_UNION(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_UNION, 0);
    }
    public KW_EXCEPT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_EXCEPT, 0);
    }
    public KW_MINUS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MINUS, 0);
    }
    public KW_ALL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ALL, 0);
    }
    public KW_DISTINCT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DISTINCT, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_queryStatement;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterQueryStatement) {
             listener.enterQueryStatement(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitQueryStatement) {
             listener.exitQueryStatement(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitQueryStatement) {
            return visitor.visitQueryStatement(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class WithClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_WITH(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_WITH, 0)!;
    }
    public withItem(): WithItemContext[];
    public withItem(i: number): WithItemContext | null;
    public withItem(i?: number): WithItemContext[] | WithItemContext | null {
        if (i === undefined) {
            return this.getRuleContexts(WithItemContext);
        }

        return this.getRuleContext(i, WithItemContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_withClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterWithClause) {
             listener.enterWithClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitWithClause) {
             listener.exitWithClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitWithClause) {
            return visitor.visitWithClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ValuesCaluseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_VALUES(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_VALUES, 0);
    }
    public inlineBody(): InlineBodyContext[];
    public inlineBody(i: number): InlineBodyContext | null;
    public inlineBody(i?: number): InlineBodyContext[] | InlineBodyContext | null {
        if (i === undefined) {
            return this.getRuleContexts(InlineBodyContext);
        }

        return this.getRuleContext(i, InlineBodyContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public tableAlias(): TableAliasContext[];
    public tableAlias(i: number): TableAliasContext | null;
    public tableAlias(i?: number): TableAliasContext[] | TableAliasContext | null {
        if (i === undefined) {
            return this.getRuleContexts(TableAliasContext);
        }

        return this.getRuleContext(i, TableAliasContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_valuesCaluse;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterValuesCaluse) {
             listener.enterValuesCaluse(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitValuesCaluse) {
             listener.exitValuesCaluse(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitValuesCaluse) {
            return visitor.visitValuesCaluse(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class InlineBodyContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public expression(): ExpressionContext[];
    public expression(i: number): ExpressionContext | null;
    public expression(i?: number): ExpressionContext[] | ExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ExpressionContext);
        }

        return this.getRuleContext(i, ExpressionContext);
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_inlineBody;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterInlineBody) {
             listener.enterInlineBody(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitInlineBody) {
             listener.exitInlineBody(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitInlineBody) {
            return visitor.visitInlineBody(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class WithItemContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public withItemName(): WithItemNameContext {
        return this.getRuleContext(0, WithItemNameContext)!;
    }
    public KW_AS(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_AS, 0)!;
    }
    public LR_BRACKET(): antlr.TerminalNode[];
    public LR_BRACKET(i: number): antlr.TerminalNode | null;
    public LR_BRACKET(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.LR_BRACKET);
    	} else {
    		return this.getToken(SparkSQLParser.LR_BRACKET, i);
    	}
    }
    public queryStatement(): QueryStatementContext {
        return this.getRuleContext(0, QueryStatementContext)!;
    }
    public RR_BRACKET(): antlr.TerminalNode[];
    public RR_BRACKET(i: number): antlr.TerminalNode | null;
    public RR_BRACKET(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.RR_BRACKET);
    	} else {
    		return this.getToken(SparkSQLParser.RR_BRACKET, i);
    	}
    }
    public columnName(): ColumnNameContext[];
    public columnName(i: number): ColumnNameContext | null;
    public columnName(i?: number): ColumnNameContext[] | ColumnNameContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ColumnNameContext);
        }

        return this.getRuleContext(i, ColumnNameContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_withItem;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterWithItem) {
             listener.enterWithItem(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitWithItem) {
             listener.exitWithItem(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitWithItem) {
            return visitor.visitWithItem(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class WithItemNameContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public identifier(): IdentifierContext {
        return this.getRuleContext(0, IdentifierContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_withItemName;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterWithItemName) {
             listener.enterWithItemName(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitWithItemName) {
             listener.exitWithItemName(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitWithItemName) {
            return visitor.visitWithItemName(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class SelectClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_SELECT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_SELECT, 0)!;
    }
    public projectItemDefinition(): ProjectItemDefinitionContext[];
    public projectItemDefinition(i: number): ProjectItemDefinitionContext | null;
    public projectItemDefinition(i?: number): ProjectItemDefinitionContext[] | ProjectItemDefinitionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ProjectItemDefinitionContext);
        }

        return this.getRuleContext(i, ProjectItemDefinitionContext);
    }
    public setQuantifier(): SetQuantifierContext | null {
        return this.getRuleContext(0, SetQuantifierContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_selectClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterSelectClause) {
             listener.enterSelectClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitSelectClause) {
             listener.exitSelectClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitSelectClause) {
            return visitor.visitSelectClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class FilterPartContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_FILTER(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_FILTER, 0)!;
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public whereClause(): WhereClauseContext {
        return this.getRuleContext(0, WhereClauseContext)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_filterPart;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterFilterPart) {
             listener.enterFilterPart(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitFilterPart) {
             listener.exitFilterPart(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitFilterPart) {
            return visitor.visitFilterPart(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class OverWindowItemContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public windowFunctioPart(): WindowFunctioPartContext {
        return this.getRuleContext(0, WindowFunctioPartContext)!;
    }
    public KW_OVER(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_OVER, 0)!;
    }
    public KW_NULLS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NULLS, 0);
    }
    public anonymousWindowsName(): AnonymousWindowsNameContext | null {
        return this.getRuleContext(0, AnonymousWindowsNameContext);
    }
    public LR_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0);
    }
    public orderByCaluse(): OrderByCaluseContext | null {
        return this.getRuleContext(0, OrderByCaluseContext);
    }
    public RR_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0);
    }
    public KW_IGNORE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_IGNORE, 0);
    }
    public KW_RESPECT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_RESPECT, 0);
    }
    public overClause(): OverClauseContext | null {
        return this.getRuleContext(0, OverClauseContext);
    }
    public windowFrameForWindowsQuery(): WindowFrameForWindowsQueryContext | null {
        return this.getRuleContext(0, WindowFrameForWindowsQueryContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_overWindowItem;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterOverWindowItem) {
             listener.enterOverWindowItem(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitOverWindowItem) {
             listener.exitOverWindowItem(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitOverWindowItem) {
            return visitor.visitOverWindowItem(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class OverClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_BY(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_BY, 0)!;
    }
    public columnName(): ColumnNameContext[];
    public columnName(i: number): ColumnNameContext | null;
    public columnName(i?: number): ColumnNameContext[] | ColumnNameContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ColumnNameContext);
        }

        return this.getRuleContext(i, ColumnNameContext);
    }
    public KW_PARTITION(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PARTITION, 0);
    }
    public KW_DISTRIBUTE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DISTRIBUTE, 0);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public EQUAL_SYMBOL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.EQUAL_SYMBOL, 0);
    }
    public expression(): ExpressionContext | null {
        return this.getRuleContext(0, ExpressionContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_overClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterOverClause) {
             listener.enterOverClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitOverClause) {
             listener.exitOverClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitOverClause) {
            return visitor.visitOverClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class WindowFunctioPartContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public windowFunctionName(): WindowFunctionNameContext | null {
        return this.getRuleContext(0, WindowFunctionNameContext);
    }
    public LR_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0);
    }
    public RR_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0);
    }
    public functionParam(): FunctionParamContext[];
    public functionParam(i: number): FunctionParamContext | null;
    public functionParam(i?: number): FunctionParamContext[] | FunctionParamContext | null {
        if (i === undefined) {
            return this.getRuleContexts(FunctionParamContext);
        }

        return this.getRuleContext(i, FunctionParamContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public primaryExpression(): PrimaryExpressionContext | null {
        return this.getRuleContext(0, PrimaryExpressionContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_windowFunctioPart;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterWindowFunctioPart) {
             listener.enterWindowFunctioPart(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitWindowFunctioPart) {
             listener.exitWindowFunctioPart(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitWindowFunctioPart) {
            return visitor.visitWindowFunctioPart(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class WindowFunctionNameContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public rangkingFunction(): RangkingFunctionContext | null {
        return this.getRuleContext(0, RangkingFunctionContext);
    }
    public analyticFunction(): AnalyticFunctionContext | null {
        return this.getRuleContext(0, AnalyticFunctionContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_windowFunctionName;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterWindowFunctionName) {
             listener.enterWindowFunctionName(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitWindowFunctionName) {
             listener.exitWindowFunctionName(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitWindowFunctionName) {
            return visitor.visitWindowFunctionName(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class AnalyticFunctionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_CUME_DIST(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_CUME_DIST, 0);
    }
    public KW_LAG(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LAG, 0);
    }
    public KW_LEAD(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LEAD, 0);
    }
    public KW_NTH_VALUE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NTH_VALUE, 0);
    }
    public KW_FIRST_VALUE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FIRST_VALUE, 0);
    }
    public KW_LAST_VALUE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LAST_VALUE, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_analyticFunction;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterAnalyticFunction) {
             listener.enterAnalyticFunction(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitAnalyticFunction) {
             listener.exitAnalyticFunction(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitAnalyticFunction) {
            return visitor.visitAnalyticFunction(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class RangkingFunctionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_RANK(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_RANK, 0);
    }
    public KW_DENSE_RANK(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DENSE_RANK, 0);
    }
    public KW_PERCENT_RANK(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PERCENT_RANK, 0);
    }
    public KW_NTILE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NTILE, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_rangkingFunction;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterRangkingFunction) {
             listener.enterRangkingFunction(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitRangkingFunction) {
             listener.exitRangkingFunction(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitRangkingFunction) {
            return visitor.visitRangkingFunction(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class FromClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_FROM(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_FROM, 0)!;
    }
    public tableExpression(): TableExpressionContext {
        return this.getRuleContext(0, TableExpressionContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_fromClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterFromClause) {
             listener.enterFromClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitFromClause) {
             listener.exitFromClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitFromClause) {
            return visitor.visitFromClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class WindowFrameForWindowsQueryContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_RANGE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_RANGE, 0);
    }
    public KW_ROWS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ROWS, 0);
    }
    public frameExpession(): FrameExpessionContext[];
    public frameExpession(i: number): FrameExpessionContext | null;
    public frameExpession(i?: number): FrameExpessionContext[] | FrameExpessionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(FrameExpessionContext);
        }

        return this.getRuleContext(i, FrameExpessionContext);
    }
    public KW_BETWEEN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_BETWEEN, 0);
    }
    public KW_AND(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_AND, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_windowFrameForWindowsQuery;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterWindowFrameForWindowsQuery) {
             listener.enterWindowFrameForWindowsQuery(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitWindowFrameForWindowsQuery) {
             listener.exitWindowFrameForWindowsQuery(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitWindowFrameForWindowsQuery) {
            return visitor.visitWindowFrameForWindowsQuery(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class FrameExpessionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_UNBOUNDED(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_UNBOUNDED, 0);
    }
    public KW_PRECEDING(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PRECEDING, 0);
    }
    public expression(): ExpressionContext | null {
        return this.getRuleContext(0, ExpressionContext);
    }
    public KW_CURRENT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_CURRENT, 0);
    }
    public KW_ROW(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ROW, 0);
    }
    public KW_FOLLOWING(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FOLLOWING, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_frameExpession;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterFrameExpession) {
             listener.enterFrameExpession(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitFrameExpession) {
             listener.exitFrameExpession(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitFrameExpession) {
            return visitor.visitFrameExpession(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class TableExpressionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public tableReference(): TableReferenceContext[];
    public tableReference(i: number): TableReferenceContext | null;
    public tableReference(i?: number): TableReferenceContext[] | TableReferenceContext | null {
        if (i === undefined) {
            return this.getRuleContexts(TableReferenceContext);
        }

        return this.getRuleContext(i, TableReferenceContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public pivotReference(): PivotReferenceContext | null {
        return this.getRuleContext(0, PivotReferenceContext);
    }
    public tableAlias(): TableAliasContext | null {
        return this.getRuleContext(0, TableAliasContext);
    }
    public viewReference(): ViewReferenceContext[];
    public viewReference(i: number): ViewReferenceContext | null;
    public viewReference(i?: number): ViewReferenceContext[] | ViewReferenceContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ViewReferenceContext);
        }

        return this.getRuleContext(i, ViewReferenceContext);
    }
    public valuesCaluse(): ValuesCaluseContext | null {
        return this.getRuleContext(0, ValuesCaluseContext);
    }
    public tvfClause(): TvfClauseContext | null {
        return this.getRuleContext(0, TvfClauseContext);
    }
    public windowTVFClause(): WindowTVFClauseContext | null {
        return this.getRuleContext(0, WindowTVFClauseContext);
    }
    public tableExpression(): TableExpressionContext[];
    public tableExpression(i: number): TableExpressionContext | null;
    public tableExpression(i?: number): TableExpressionContext[] | TableExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(TableExpressionContext);
        }

        return this.getRuleContext(i, TableExpressionContext);
    }
    public KW_JOIN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_JOIN, 0);
    }
    public KW_NATURAL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NATURAL, 0);
    }
    public KW_OUTER(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_OUTER, 0);
    }
    public KW_SEMI(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SEMI, 0);
    }
    public joinCondition(): JoinConditionContext | null {
        return this.getRuleContext(0, JoinConditionContext);
    }
    public KW_LEFT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LEFT, 0);
    }
    public KW_RIGHT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_RIGHT, 0);
    }
    public KW_FULL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FULL, 0);
    }
    public KW_INNER(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_INNER, 0);
    }
    public KW_CROSS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_CROSS, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_tableExpression;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterTableExpression) {
             listener.enterTableExpression(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitTableExpression) {
             listener.exitTableExpression(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitTableExpression) {
            return visitor.visitTableExpression(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class TvfClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public rangeClause(): RangeClauseContext {
        return this.getRuleContext(0, RangeClauseContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_tvfClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterTvfClause) {
             listener.enterTvfClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitTvfClause) {
             listener.exitTvfClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitTvfClause) {
            return visitor.visitTvfClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class RangeClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_RANGE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_RANGE, 0)!;
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public expression(): ExpressionContext[];
    public expression(i: number): ExpressionContext | null;
    public expression(i?: number): ExpressionContext[] | ExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ExpressionContext);
        }

        return this.getRuleContext(i, ExpressionContext);
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_rangeClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterRangeClause) {
             listener.enterRangeClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitRangeClause) {
             listener.exitRangeClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitRangeClause) {
            return visitor.visitRangeClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ViewReferenceContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_LATERAL(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_LATERAL, 0)!;
    }
    public KW_VIEW(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_VIEW, 0)!;
    }
    public funtionBody(): FuntionBodyContext {
        return this.getRuleContext(0, FuntionBodyContext)!;
    }
    public KW_AS(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_AS, 0)!;
    }
    public columnAlias(): ColumnAliasContext[];
    public columnAlias(i: number): ColumnAliasContext | null;
    public columnAlias(i?: number): ColumnAliasContext[] | ColumnAliasContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ColumnAliasContext);
        }

        return this.getRuleContext(i, ColumnAliasContext);
    }
    public KW_OUTER(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_OUTER, 0);
    }
    public tableAlias(): TableAliasContext | null {
        return this.getRuleContext(0, TableAliasContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_viewReference;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterViewReference) {
             listener.enterViewReference(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitViewReference) {
             listener.exitViewReference(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitViewReference) {
            return visitor.visitViewReference(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class PivotReferenceContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_PIVOT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PIVOT, 0);
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public pivotBody(): PivotBodyContext | null {
        return this.getRuleContext(0, PivotBodyContext);
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public KW_UNPIVOT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_UNPIVOT, 0);
    }
    public unpivotBody(): UnpivotBodyContext | null {
        return this.getRuleContext(0, UnpivotBodyContext);
    }
    public KW_NULLS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NULLS, 0);
    }
    public KW_INCLUDE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_INCLUDE, 0);
    }
    public KW_EXCLUDE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_EXCLUDE, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_pivotReference;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterPivotReference) {
             listener.enterPivotReference(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitPivotReference) {
             listener.exitPivotReference(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitPivotReference) {
            return visitor.visitPivotReference(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class TableReferenceContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public tablePrimary(): TablePrimaryContext {
        return this.getRuleContext(0, TablePrimaryContext)!;
    }
    public tableAlias(): TableAliasContext | null {
        return this.getRuleContext(0, TableAliasContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_tableReference;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterTableReference) {
             listener.enterTableReference(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitTableReference) {
             listener.exitTableReference(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitTableReference) {
            return visitor.visitTableReference(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class TablePrimaryContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public tablePath(): TablePathContext | null {
        return this.getRuleContext(0, TablePathContext);
    }
    public KW_TABLE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TABLE, 0);
    }
    public systemTimePeriod(): SystemTimePeriodContext | null {
        return this.getRuleContext(0, SystemTimePeriodContext);
    }
    public KW_LATERAL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LATERAL, 0);
    }
    public funtionBody(): FuntionBodyContext | null {
        return this.getRuleContext(0, FuntionBodyContext);
    }
    public complexDataTypeExpression(): ComplexDataTypeExpressionContext | null {
        return this.getRuleContext(0, ComplexDataTypeExpressionContext);
    }
    public KW_EXPLODE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_EXPLODE, 0);
    }
    public LR_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0);
    }
    public RR_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0);
    }
    public queryStatement(): QueryStatementContext[];
    public queryStatement(i: number): QueryStatementContext | null;
    public queryStatement(i?: number): QueryStatementContext[] | QueryStatementContext | null {
        if (i === undefined) {
            return this.getRuleContexts(QueryStatementContext);
        }

        return this.getRuleContext(i, QueryStatementContext);
    }
    public KW_UNSET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_UNSET, 0);
    }
    public expression(): ExpressionContext | null {
        return this.getRuleContext(0, ExpressionContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_tablePrimary;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterTablePrimary) {
             listener.enterTablePrimary(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitTablePrimary) {
             listener.exitTablePrimary(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitTablePrimary) {
            return visitor.visitTablePrimary(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class FuntionBodyContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public functionName(): FunctionNameContext {
        return this.getRuleContext(0, FunctionNameContext)!;
    }
    public LR_BRACKET(): antlr.TerminalNode[];
    public LR_BRACKET(i: number): antlr.TerminalNode | null;
    public LR_BRACKET(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.LR_BRACKET);
    	} else {
    		return this.getToken(SparkSQLParser.LR_BRACKET, i);
    	}
    }
    public RR_BRACKET(): antlr.TerminalNode[];
    public RR_BRACKET(i: number): antlr.TerminalNode | null;
    public RR_BRACKET(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.RR_BRACKET);
    	} else {
    		return this.getToken(SparkSQLParser.RR_BRACKET, i);
    	}
    }
    public funtionBody(): FuntionBodyContext[];
    public funtionBody(i: number): FuntionBodyContext | null;
    public funtionBody(i?: number): FuntionBodyContext[] | FuntionBodyContext | null {
        if (i === undefined) {
            return this.getRuleContexts(FuntionBodyContext);
        }

        return this.getRuleContext(i, FuntionBodyContext);
    }
    public functionParam(): FunctionParamContext[];
    public functionParam(i: number): FunctionParamContext | null;
    public functionParam(i?: number): FunctionParamContext[] | FunctionParamContext | null {
        if (i === undefined) {
            return this.getRuleContexts(FunctionParamContext);
        }

        return this.getRuleContext(i, FunctionParamContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public KW_AS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_AS, 0);
    }
    public tableAlias(): TableAliasContext | null {
        return this.getRuleContext(0, TableAliasContext);
    }
    public projectItemDefinition(): ProjectItemDefinitionContext[];
    public projectItemDefinition(i: number): ProjectItemDefinitionContext | null;
    public projectItemDefinition(i?: number): ProjectItemDefinitionContext[] | ProjectItemDefinitionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ProjectItemDefinitionContext);
        }

        return this.getRuleContext(i, ProjectItemDefinitionContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_funtionBody;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterFuntionBody) {
             listener.enterFuntionBody(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitFuntionBody) {
             listener.exitFuntionBody(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitFuntionBody) {
            return visitor.visitFuntionBody(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class UnpivotBodyContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_FOR(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_FOR, 0)!;
    }
    public columnName(): ColumnNameContext[];
    public columnName(i: number): ColumnNameContext | null;
    public columnName(i?: number): ColumnNameContext[] | ColumnNameContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ColumnNameContext);
        }

        return this.getRuleContext(i, ColumnNameContext);
    }
    public KW_IN(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_IN, 0)!;
    }
    public expressionAsAliasList(): ExpressionAsAliasListContext {
        return this.getRuleContext(0, ExpressionAsAliasListContext)!;
    }
    public columnNameList(): ColumnNameListContext | null {
        return this.getRuleContext(0, ColumnNameListContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_unpivotBody;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterUnpivotBody) {
             listener.enterUnpivotBody(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitUnpivotBody) {
             listener.exitUnpivotBody(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitUnpivotBody) {
            return visitor.visitUnpivotBody(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class PivotBodyContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public expressionAsAlias(): ExpressionAsAliasContext[];
    public expressionAsAlias(i: number): ExpressionAsAliasContext | null;
    public expressionAsAlias(i?: number): ExpressionAsAliasContext[] | ExpressionAsAliasContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ExpressionAsAliasContext);
        }

        return this.getRuleContext(i, ExpressionAsAliasContext);
    }
    public KW_FOR(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_FOR, 0)!;
    }
    public KW_IN(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_IN, 0)!;
    }
    public expressionAsAliasList(): ExpressionAsAliasListContext {
        return this.getRuleContext(0, ExpressionAsAliasListContext)!;
    }
    public COMMA(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.COMMA, 0);
    }
    public columnName(): ColumnNameContext | null {
        return this.getRuleContext(0, ColumnNameContext);
    }
    public columnNameList(): ColumnNameListContext | null {
        return this.getRuleContext(0, ColumnNameListContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_pivotBody;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterPivotBody) {
             listener.enterPivotBody(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitPivotBody) {
             listener.exitPivotBody(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitPivotBody) {
            return visitor.visitPivotBody(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ExpressionAsAliasContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public expression(): ExpressionContext {
        return this.getRuleContext(0, ExpressionContext)!;
    }
    public KW_AS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_AS, 0);
    }
    public columnAlias(): ColumnAliasContext | null {
        return this.getRuleContext(0, ColumnAliasContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_expressionAsAlias;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterExpressionAsAlias) {
             listener.enterExpressionAsAlias(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitExpressionAsAlias) {
             listener.exitExpressionAsAlias(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitExpressionAsAlias) {
            return visitor.visitExpressionAsAlias(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ExpressionAsAliasListContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public expressionAsAlias(): ExpressionAsAliasContext[];
    public expressionAsAlias(i: number): ExpressionAsAliasContext | null;
    public expressionAsAlias(i?: number): ExpressionAsAliasContext[] | ExpressionAsAliasContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ExpressionAsAliasContext);
        }

        return this.getRuleContext(i, ExpressionAsAliasContext);
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_expressionAsAliasList;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterExpressionAsAliasList) {
             listener.enterExpressionAsAliasList(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitExpressionAsAliasList) {
             listener.exitExpressionAsAliasList(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitExpressionAsAliasList) {
            return visitor.visitExpressionAsAliasList(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class SystemTimePeriodContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_FOR(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_FOR, 0)!;
    }
    public KW_SYSTEM_TIME(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_SYSTEM_TIME, 0)!;
    }
    public KW_AS(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_AS, 0)!;
    }
    public KW_OF(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_OF, 0)!;
    }
    public dateTimeExpression(): DateTimeExpressionContext {
        return this.getRuleContext(0, DateTimeExpressionContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_systemTimePeriod;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterSystemTimePeriod) {
             listener.enterSystemTimePeriod(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitSystemTimePeriod) {
             listener.exitSystemTimePeriod(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitSystemTimePeriod) {
            return visitor.visitSystemTimePeriod(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class DateTimeExpressionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public expression(): ExpressionContext {
        return this.getRuleContext(0, ExpressionContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_dateTimeExpression;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterDateTimeExpression) {
             listener.enterDateTimeExpression(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitDateTimeExpression) {
             listener.exitDateTimeExpression(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitDateTimeExpression) {
            return visitor.visitDateTimeExpression(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class InlineDataValueClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public expression(): ExpressionContext[];
    public expression(i: number): ExpressionContext | null;
    public expression(i?: number): ExpressionContext[] | ExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ExpressionContext);
        }

        return this.getRuleContext(i, ExpressionContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public tableAlias(): TableAliasContext | null {
        return this.getRuleContext(0, TableAliasContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_inlineDataValueClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterInlineDataValueClause) {
             listener.enterInlineDataValueClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitInlineDataValueClause) {
             listener.exitInlineDataValueClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitInlineDataValueClause) {
            return visitor.visitInlineDataValueClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class WindowTVFClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_TABLE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_TABLE, 0)!;
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public windowTVFExpression(): WindowTVFExpressionContext {
        return this.getRuleContext(0, WindowTVFExpressionContext)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_windowTVFClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterWindowTVFClause) {
             listener.enterWindowTVFClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitWindowTVFClause) {
             listener.exitWindowTVFClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitWindowTVFClause) {
            return visitor.visitWindowTVFClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class WindowTVFExpressionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public windowTVFName(): WindowTVFNameContext {
        return this.getRuleContext(0, WindowTVFNameContext)!;
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public windowTVFParam(): WindowTVFParamContext[];
    public windowTVFParam(i: number): WindowTVFParamContext | null;
    public windowTVFParam(i?: number): WindowTVFParamContext[] | WindowTVFParamContext | null {
        if (i === undefined) {
            return this.getRuleContexts(WindowTVFParamContext);
        }

        return this.getRuleContext(i, WindowTVFParamContext);
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_windowTVFExpression;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterWindowTVFExpression) {
             listener.enterWindowTVFExpression(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitWindowTVFExpression) {
             listener.exitWindowTVFExpression(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitWindowTVFExpression) {
            return visitor.visitWindowTVFExpression(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class WindowTVFNameContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_TUMBLE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TUMBLE, 0);
    }
    public KW_HOP(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_HOP, 0);
    }
    public KW_CUMULATE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_CUMULATE, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_windowTVFName;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterWindowTVFName) {
             listener.enterWindowTVFName(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitWindowTVFName) {
             listener.exitWindowTVFName(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitWindowTVFName) {
            return visitor.visitWindowTVFName(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class RowFormatDelimitedContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public sparkRecordWriterPart(): SparkRecordWriterPartContext[];
    public sparkRecordWriterPart(i: number): SparkRecordWriterPartContext | null;
    public sparkRecordWriterPart(i?: number): SparkRecordWriterPartContext[] | SparkRecordWriterPartContext | null {
        if (i === undefined) {
            return this.getRuleContexts(SparkRecordWriterPartContext);
        }

        return this.getRuleContext(i, SparkRecordWriterPartContext);
    }
    public usingAsColumnPart(): UsingAsColumnPartContext {
        return this.getRuleContext(0, UsingAsColumnPartContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_rowFormatDelimited;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterRowFormatDelimited) {
             listener.enterRowFormatDelimited(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitRowFormatDelimited) {
             listener.exitRowFormatDelimited(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitRowFormatDelimited) {
            return visitor.visitRowFormatDelimited(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class HiveSerdeContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public hiveSerdePart(): HiveSerdePartContext[];
    public hiveSerdePart(i: number): HiveSerdePartContext | null;
    public hiveSerdePart(i?: number): HiveSerdePartContext[] | HiveSerdePartContext | null {
        if (i === undefined) {
            return this.getRuleContexts(HiveSerdePartContext);
        }

        return this.getRuleContext(i, HiveSerdePartContext);
    }
    public usingAsColumnPart(): UsingAsColumnPartContext {
        return this.getRuleContext(0, UsingAsColumnPartContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_hiveSerde;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterHiveSerde) {
             listener.enterHiveSerde(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitHiveSerde) {
             listener.exitHiveSerde(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitHiveSerde) {
            return visitor.visitHiveSerde(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class UsingAsColumnPartContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_USING(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_USING, 0)!;
    }
    public stringLiteral(): StringLiteralContext {
        return this.getRuleContext(0, StringLiteralContext)!;
    }
    public KW_AS(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_AS, 0)!;
    }
    public columnNameList(): ColumnNameListContext | null {
        return this.getRuleContext(0, ColumnNameListContext);
    }
    public physicalColumnDefinitionList(): PhysicalColumnDefinitionListContext | null {
        return this.getRuleContext(0, PhysicalColumnDefinitionListContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_usingAsColumnPart;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterUsingAsColumnPart) {
             listener.enterUsingAsColumnPart(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitUsingAsColumnPart) {
             listener.exitUsingAsColumnPart(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitUsingAsColumnPart) {
            return visitor.visitUsingAsColumnPart(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class HiveSerdePartContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_ROW(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ROW, 0);
    }
    public KW_FORMAT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FORMAT, 0);
    }
    public KW_SERDE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SERDE, 0);
    }
    public stringLiteral(): StringLiteralContext[];
    public stringLiteral(i: number): StringLiteralContext | null;
    public stringLiteral(i?: number): StringLiteralContext[] | StringLiteralContext | null {
        if (i === undefined) {
            return this.getRuleContexts(StringLiteralContext);
        }

        return this.getRuleContext(i, StringLiteralContext);
    }
    public KW_WITH(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_WITH, 0);
    }
    public KW_SERDEPROPERTIES(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SERDEPROPERTIES, 0);
    }
    public tableCanHasKeyPropertyList(): TableCanHasKeyPropertyListContext | null {
        return this.getRuleContext(0, TableCanHasKeyPropertyListContext);
    }
    public KW_RECORDWRITER(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_RECORDWRITER, 0);
    }
    public fieldsTerminatedBy(): FieldsTerminatedByContext | null {
        return this.getRuleContext(0, FieldsTerminatedByContext);
    }
    public KW_RECORDREADER(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_RECORDREADER, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_hiveSerdePart;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterHiveSerdePart) {
             listener.enterHiveSerdePart(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitHiveSerdePart) {
             listener.exitHiveSerdePart(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitHiveSerdePart) {
            return visitor.visitHiveSerdePart(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class TableCanHasKeyPropertyListContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public tableProperty(): TablePropertyContext[];
    public tableProperty(i: number): TablePropertyContext | null;
    public tableProperty(i?: number): TablePropertyContext[] | TablePropertyContext | null {
        if (i === undefined) {
            return this.getRuleContexts(TablePropertyContext);
        }

        return this.getRuleContext(i, TablePropertyContext);
    }
    public tablePropertyKey(): TablePropertyKeyContext[];
    public tablePropertyKey(i: number): TablePropertyKeyContext | null;
    public tablePropertyKey(i?: number): TablePropertyKeyContext[] | TablePropertyKeyContext | null {
        if (i === undefined) {
            return this.getRuleContexts(TablePropertyKeyContext);
        }

        return this.getRuleContext(i, TablePropertyKeyContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_tableCanHasKeyPropertyList;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterTableCanHasKeyPropertyList) {
             listener.enterTableCanHasKeyPropertyList(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitTableCanHasKeyPropertyList) {
             listener.exitTableCanHasKeyPropertyList(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitTableCanHasKeyPropertyList) {
            return visitor.visitTableCanHasKeyPropertyList(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class SparkRecordWriterPartContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public rowFormatDelimted(): RowFormatDelimtedContext | null {
        return this.getRuleContext(0, RowFormatDelimtedContext);
    }
    public fieldsTerminatedBy(): FieldsTerminatedByContext | null {
        return this.getRuleContext(0, FieldsTerminatedByContext);
    }
    public KW_LINES(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LINES, 0);
    }
    public KW_TERMINATED(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TERMINATED, 0);
    }
    public KW_BY(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_BY, 0);
    }
    public stringLiteral(): StringLiteralContext[];
    public stringLiteral(i: number): StringLiteralContext | null;
    public stringLiteral(i?: number): StringLiteralContext[] | StringLiteralContext | null {
        if (i === undefined) {
            return this.getRuleContexts(StringLiteralContext);
        }

        return this.getRuleContext(i, StringLiteralContext);
    }
    public KW_NULL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NULL, 0);
    }
    public KW_DEFINED(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DEFINED, 0);
    }
    public KW_AS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_AS, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_sparkRecordWriterPart;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterSparkRecordWriterPart) {
             listener.enterSparkRecordWriterPart(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitSparkRecordWriterPart) {
             listener.exitSparkRecordWriterPart(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitSparkRecordWriterPart) {
            return visitor.visitSparkRecordWriterPart(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class WindowTVFParamContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_TABLE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TABLE, 0);
    }
    public timeAttrColumn(): TimeAttrColumnContext | null {
        return this.getRuleContext(0, TimeAttrColumnContext);
    }
    public columnDescriptor(): ColumnDescriptorContext | null {
        return this.getRuleContext(0, ColumnDescriptorContext);
    }
    public timeIntervalExpression(): TimeIntervalExpressionContext | null {
        return this.getRuleContext(0, TimeIntervalExpressionContext);
    }
    public KW_DATA(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DATA, 0);
    }
    public DOUBLE_RIGHT_ARROW(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.DOUBLE_RIGHT_ARROW, 0);
    }
    public KW_TIMECOL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TIMECOL, 0);
    }
    public timeIntervalParamName(): TimeIntervalParamNameContext | null {
        return this.getRuleContext(0, TimeIntervalParamNameContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_windowTVFParam;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterWindowTVFParam) {
             listener.enterWindowTVFParam(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitWindowTVFParam) {
             listener.exitWindowTVFParam(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitWindowTVFParam) {
            return visitor.visitWindowTVFParam(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class TimeIntervalParamNameContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_DATA(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DATA, 0);
    }
    public KW_TIMECOL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TIMECOL, 0);
    }
    public KW_SIZE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SIZE, 0);
    }
    public KW_OFFSET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_OFFSET, 0);
    }
    public KW_STEP(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_STEP, 0);
    }
    public KW_SLIDE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SLIDE, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_timeIntervalParamName;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterTimeIntervalParamName) {
             listener.enterTimeIntervalParamName(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitTimeIntervalParamName) {
             listener.exitTimeIntervalParamName(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitTimeIntervalParamName) {
            return visitor.visitTimeIntervalParamName(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ColumnDescriptorContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_DESCRIPTOR(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_DESCRIPTOR, 0)!;
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public uid(): UidContext {
        return this.getRuleContext(0, UidContext)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_columnDescriptor;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterColumnDescriptor) {
             listener.enterColumnDescriptor(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitColumnDescriptor) {
             listener.exitColumnDescriptor(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitColumnDescriptor) {
            return visitor.visitColumnDescriptor(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class JoinConditionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_ON(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ON, 0);
    }
    public booleanExpression(): BooleanExpressionContext | null {
        return this.getRuleContext(0, BooleanExpressionContext);
    }
    public KW_USING(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_USING, 0);
    }
    public LR_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0);
    }
    public uid(): UidContext[];
    public uid(i: number): UidContext | null;
    public uid(i?: number): UidContext[] | UidContext | null {
        if (i === undefined) {
            return this.getRuleContexts(UidContext);
        }

        return this.getRuleContext(i, UidContext);
    }
    public RR_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_joinCondition;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterJoinCondition) {
             listener.enterJoinCondition(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitJoinCondition) {
             listener.exitJoinCondition(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitJoinCondition) {
            return visitor.visitJoinCondition(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class WhereClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_WHERE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_WHERE, 0)!;
    }
    public booleanExpression(): BooleanExpressionContext {
        return this.getRuleContext(0, BooleanExpressionContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_whereClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterWhereClause) {
             listener.enterWhereClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitWhereClause) {
             listener.exitWhereClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitWhereClause) {
            return visitor.visitWhereClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class SamplingQueriesContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_TABLESAMPLE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_TABLESAMPLE, 0)!;
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public KW_PERCENT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PERCENT, 0);
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public decimalLiteral(): DecimalLiteralContext | null {
        return this.getRuleContext(0, DecimalLiteralContext);
    }
    public DIG_LITERAL(): antlr.TerminalNode[];
    public DIG_LITERAL(i: number): antlr.TerminalNode | null;
    public DIG_LITERAL(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.DIG_LITERAL);
    	} else {
    		return this.getToken(SparkSQLParser.DIG_LITERAL, i);
    	}
    }
    public expression(): ExpressionContext[];
    public expression(i: number): ExpressionContext | null;
    public expression(i?: number): ExpressionContext[] | ExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ExpressionContext);
        }

        return this.getRuleContext(i, ExpressionContext);
    }
    public KW_ROWS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ROWS, 0);
    }
    public KW_BUCKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_BUCKET, 0);
    }
    public KW_OUT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_OUT, 0);
    }
    public KW_OF(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_OF, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_samplingQueries;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterSamplingQueries) {
             listener.enterSamplingQueries(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitSamplingQueries) {
             listener.exitSamplingQueries(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitSamplingQueries) {
            return visitor.visitSamplingQueries(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class SomeByClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public clusteredByClause(): ClusteredByClauseContext | null {
        return this.getRuleContext(0, ClusteredByClauseContext);
    }
    public clusterByClause(): ClusterByClauseContext | null {
        return this.getRuleContext(0, ClusterByClauseContext);
    }
    public distributeByClause(): DistributeByClauseContext | null {
        return this.getRuleContext(0, DistributeByClauseContext);
    }
    public groupByClause(): GroupByClauseContext | null {
        return this.getRuleContext(0, GroupByClauseContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_someByClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterSomeByClause) {
             listener.enterSomeByClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitSomeByClause) {
             listener.exitSomeByClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitSomeByClause) {
            return visitor.visitSomeByClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ClusterByClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_CLUSTER(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_CLUSTER, 0)!;
    }
    public KW_BY(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_BY, 0)!;
    }
    public groupItemDefinition(): GroupItemDefinitionContext[];
    public groupItemDefinition(i: number): GroupItemDefinitionContext | null;
    public groupItemDefinition(i?: number): GroupItemDefinitionContext[] | GroupItemDefinitionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(GroupItemDefinitionContext);
        }

        return this.getRuleContext(i, GroupItemDefinitionContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_clusterByClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterClusterByClause) {
             listener.enterClusterByClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitClusterByClause) {
             listener.exitClusterByClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitClusterByClause) {
            return visitor.visitClusterByClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ClusteredByClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_CLUSTERED(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_CLUSTERED, 0)!;
    }
    public KW_BY(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_BY, 0)!;
    }
    public groupItemDefinition(): GroupItemDefinitionContext[];
    public groupItemDefinition(i: number): GroupItemDefinitionContext | null;
    public groupItemDefinition(i?: number): GroupItemDefinitionContext[] | GroupItemDefinitionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(GroupItemDefinitionContext);
        }

        return this.getRuleContext(i, GroupItemDefinitionContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_clusteredByClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterClusteredByClause) {
             listener.enterClusteredByClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitClusteredByClause) {
             listener.exitClusteredByClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitClusteredByClause) {
            return visitor.visitClusteredByClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class DistributeByClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_DISTRIBUTE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_DISTRIBUTE, 0)!;
    }
    public KW_BY(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_BY, 0)!;
    }
    public groupItemDefinition(): GroupItemDefinitionContext[];
    public groupItemDefinition(i: number): GroupItemDefinitionContext | null;
    public groupItemDefinition(i?: number): GroupItemDefinitionContext[] | GroupItemDefinitionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(GroupItemDefinitionContext);
        }

        return this.getRuleContext(i, GroupItemDefinitionContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_distributeByClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterDistributeByClause) {
             listener.enterDistributeByClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitDistributeByClause) {
             listener.exitDistributeByClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitDistributeByClause) {
            return visitor.visitDistributeByClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class GroupByClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_GROUP(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_GROUP, 0)!;
    }
    public KW_BY(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_BY, 0)!;
    }
    public groupingSet(): GroupingSetContext | null {
        return this.getRuleContext(0, GroupingSetContext);
    }
    public KW_WITH(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_WITH, 0);
    }
    public groupingSetsNotionName(): GroupingSetsNotionNameContext | null {
        return this.getRuleContext(0, GroupingSetsNotionNameContext);
    }
    public groupItemDefinition(): GroupItemDefinitionContext[];
    public groupItemDefinition(i: number): GroupItemDefinitionContext | null;
    public groupItemDefinition(i?: number): GroupItemDefinitionContext[] | GroupItemDefinitionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(GroupItemDefinitionContext);
        }

        return this.getRuleContext(i, GroupItemDefinitionContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_groupByClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterGroupByClause) {
             listener.enterGroupByClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitGroupByClause) {
             listener.exitGroupByClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitGroupByClause) {
            return visitor.visitGroupByClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class GroupItemDefinitionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public expression(): ExpressionContext[];
    public expression(i: number): ExpressionContext | null;
    public expression(i?: number): ExpressionContext[] | ExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ExpressionContext);
        }

        return this.getRuleContext(i, ExpressionContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public groupWindowFunction(): GroupWindowFunctionContext | null {
        return this.getRuleContext(0, GroupWindowFunctionContext);
    }
    public LR_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0);
    }
    public RR_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0);
    }
    public groupingSetsNotionName(): GroupingSetsNotionNameContext | null {
        return this.getRuleContext(0, GroupingSetsNotionNameContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_groupItemDefinition;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterGroupItemDefinition) {
             listener.enterGroupItemDefinition(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitGroupItemDefinition) {
             listener.exitGroupItemDefinition(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitGroupItemDefinition) {
            return visitor.visitGroupItemDefinition(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class GroupingSetContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public groupingSets(): GroupingSetsContext {
        return this.getRuleContext(0, GroupingSetsContext)!;
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public groupItemDefinition(): GroupItemDefinitionContext[];
    public groupItemDefinition(i: number): GroupItemDefinitionContext | null;
    public groupItemDefinition(i?: number): GroupItemDefinitionContext[] | GroupItemDefinitionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(GroupItemDefinitionContext);
        }

        return this.getRuleContext(i, GroupItemDefinitionContext);
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_groupingSet;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterGroupingSet) {
             listener.enterGroupingSet(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitGroupingSet) {
             listener.exitGroupingSet(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitGroupingSet) {
            return visitor.visitGroupingSet(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class GroupingSetsContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_GROUPING(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_GROUPING, 0)!;
    }
    public KW_SETS(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_SETS, 0)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_groupingSets;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterGroupingSets) {
             listener.enterGroupingSets(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitGroupingSets) {
             listener.exitGroupingSets(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitGroupingSets) {
            return visitor.visitGroupingSets(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class GroupingSetsNotionNameContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_CUBE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_CUBE, 0);
    }
    public KW_ROLLUP(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ROLLUP, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_groupingSetsNotionName;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterGroupingSetsNotionName) {
             listener.enterGroupingSetsNotionName(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitGroupingSetsNotionName) {
             listener.exitGroupingSetsNotionName(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitGroupingSetsNotionName) {
            return visitor.visitGroupingSetsNotionName(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class GroupWindowFunctionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public groupWindowFunctionName(): GroupWindowFunctionNameContext {
        return this.getRuleContext(0, GroupWindowFunctionNameContext)!;
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public timeAttrColumn(): TimeAttrColumnContext {
        return this.getRuleContext(0, TimeAttrColumnContext)!;
    }
    public COMMA(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.COMMA, 0)!;
    }
    public timeIntervalExpression(): TimeIntervalExpressionContext {
        return this.getRuleContext(0, TimeIntervalExpressionContext)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_groupWindowFunction;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterGroupWindowFunction) {
             listener.enterGroupWindowFunction(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitGroupWindowFunction) {
             listener.exitGroupWindowFunction(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitGroupWindowFunction) {
            return visitor.visitGroupWindowFunction(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class GroupWindowFunctionNameContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_TUMBLE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TUMBLE, 0);
    }
    public KW_HOP(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_HOP, 0);
    }
    public KW_SESSION(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SESSION, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_groupWindowFunctionName;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterGroupWindowFunctionName) {
             listener.enterGroupWindowFunctionName(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitGroupWindowFunctionName) {
             listener.exitGroupWindowFunctionName(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitGroupWindowFunctionName) {
            return visitor.visitGroupWindowFunctionName(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class TimeAttrColumnContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public uid(): UidContext {
        return this.getRuleContext(0, UidContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_timeAttrColumn;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterTimeAttrColumn) {
             listener.enterTimeAttrColumn(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitTimeAttrColumn) {
             listener.exitTimeAttrColumn(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitTimeAttrColumn) {
            return visitor.visitTimeAttrColumn(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class HavingClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_HAVING(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_HAVING, 0)!;
    }
    public booleanExpression(): BooleanExpressionContext {
        return this.getRuleContext(0, BooleanExpressionContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_havingClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterHavingClause) {
             listener.enterHavingClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitHavingClause) {
             listener.exitHavingClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitHavingClause) {
            return visitor.visitHavingClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class WindowClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_WINDOW(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_WINDOW, 0)!;
    }
    public namedWindow(): NamedWindowContext[];
    public namedWindow(i: number): NamedWindowContext | null;
    public namedWindow(i?: number): NamedWindowContext[] | NamedWindowContext | null {
        if (i === undefined) {
            return this.getRuleContexts(NamedWindowContext);
        }

        return this.getRuleContext(i, NamedWindowContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_windowClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterWindowClause) {
             listener.enterWindowClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitWindowClause) {
             listener.exitWindowClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitWindowClause) {
            return visitor.visitWindowClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class NamedWindowContext extends antlr.ParserRuleContext {
    public _name?: ErrorCapturingIdentifierContext;
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_AS(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_AS, 0)!;
    }
    public windowSpec(): WindowSpecContext {
        return this.getRuleContext(0, WindowSpecContext)!;
    }
    public errorCapturingIdentifier(): ErrorCapturingIdentifierContext {
        return this.getRuleContext(0, ErrorCapturingIdentifierContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_namedWindow;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterNamedWindow) {
             listener.enterNamedWindow(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitNamedWindow) {
             listener.exitNamedWindow(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitNamedWindow) {
            return visitor.visitNamedWindow(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class WindowSpecContext extends antlr.ParserRuleContext {
    public _name?: ErrorCapturingIdentifierContext;
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public partitionByClause(): PartitionByClauseContext | null {
        return this.getRuleContext(0, PartitionByClauseContext);
    }
    public sortByCaluse(): SortByCaluseContext | null {
        return this.getRuleContext(0, SortByCaluseContext);
    }
    public orderByCaluse(): OrderByCaluseContext | null {
        return this.getRuleContext(0, OrderByCaluseContext);
    }
    public windowFrame(): WindowFrameContext | null {
        return this.getRuleContext(0, WindowFrameContext);
    }
    public errorCapturingIdentifier(): ErrorCapturingIdentifierContext | null {
        return this.getRuleContext(0, ErrorCapturingIdentifierContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_windowSpec;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterWindowSpec) {
             listener.enterWindowSpec(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitWindowSpec) {
             listener.exitWindowSpec(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitWindowSpec) {
            return visitor.visitWindowSpec(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class MatchRecognizeClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_MATCH_RECOGNIZE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_MATCH_RECOGNIZE, 0)!;
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public patternVariablesDefinition(): PatternVariablesDefinitionContext {
        return this.getRuleContext(0, PatternVariablesDefinitionContext)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public partitionByClause(): PartitionByClauseContext | null {
        return this.getRuleContext(0, PartitionByClauseContext);
    }
    public sortByCaluse(): SortByCaluseContext | null {
        return this.getRuleContext(0, SortByCaluseContext);
    }
    public orderByCaluse(): OrderByCaluseContext | null {
        return this.getRuleContext(0, OrderByCaluseContext);
    }
    public measuresClause(): MeasuresClauseContext | null {
        return this.getRuleContext(0, MeasuresClauseContext);
    }
    public outputMode(): OutputModeContext | null {
        return this.getRuleContext(0, OutputModeContext);
    }
    public afterMatchStrategy(): AfterMatchStrategyContext | null {
        return this.getRuleContext(0, AfterMatchStrategyContext);
    }
    public patternDefinition(): PatternDefinitionContext | null {
        return this.getRuleContext(0, PatternDefinitionContext);
    }
    public identifier(): IdentifierContext | null {
        return this.getRuleContext(0, IdentifierContext);
    }
    public KW_AS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_AS, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_matchRecognizeClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterMatchRecognizeClause) {
             listener.enterMatchRecognizeClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitMatchRecognizeClause) {
             listener.exitMatchRecognizeClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitMatchRecognizeClause) {
            return visitor.visitMatchRecognizeClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class OrderByCaluseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_ORDER(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_ORDER, 0)!;
    }
    public KW_BY(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_BY, 0)!;
    }
    public orderItemDefinition(): OrderItemDefinitionContext[];
    public orderItemDefinition(i: number): OrderItemDefinitionContext | null;
    public orderItemDefinition(i?: number): OrderItemDefinitionContext[] | OrderItemDefinitionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(OrderItemDefinitionContext);
        }

        return this.getRuleContext(i, OrderItemDefinitionContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_orderByCaluse;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterOrderByCaluse) {
             listener.enterOrderByCaluse(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitOrderByCaluse) {
             listener.exitOrderByCaluse(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitOrderByCaluse) {
            return visitor.visitOrderByCaluse(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class SortByCaluseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_SORT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_SORT, 0)!;
    }
    public KW_BY(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_BY, 0)!;
    }
    public orderItemDefinition(): OrderItemDefinitionContext[];
    public orderItemDefinition(i: number): OrderItemDefinitionContext | null;
    public orderItemDefinition(i?: number): OrderItemDefinitionContext[] | OrderItemDefinitionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(OrderItemDefinitionContext);
        }

        return this.getRuleContext(i, OrderItemDefinitionContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_sortByCaluse;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterSortByCaluse) {
             listener.enterSortByCaluse(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitSortByCaluse) {
             listener.exitSortByCaluse(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitSortByCaluse) {
            return visitor.visitSortByCaluse(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class OrderItemDefinitionContext extends antlr.ParserRuleContext {
    public _ordering?: Token | null;
    public _nullOrder?: Token | null;
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public expression(): ExpressionContext {
        return this.getRuleContext(0, ExpressionContext)!;
    }
    public KW_NULLS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NULLS, 0);
    }
    public KW_ASC(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ASC, 0);
    }
    public KW_DESC(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DESC, 0);
    }
    public KW_LAST(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LAST, 0);
    }
    public KW_FIRST(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FIRST, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_orderItemDefinition;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterOrderItemDefinition) {
             listener.enterOrderItemDefinition(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitOrderItemDefinition) {
             listener.exitOrderItemDefinition(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitOrderItemDefinition) {
            return visitor.visitOrderItemDefinition(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class LimitClauseContext extends antlr.ParserRuleContext {
    public _limit?: ExpressionContext;
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_LIMIT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_LIMIT, 0)!;
    }
    public KW_ALL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ALL, 0);
    }
    public expression(): ExpressionContext | null {
        return this.getRuleContext(0, ExpressionContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_limitClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterLimitClause) {
             listener.enterLimitClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitLimitClause) {
             listener.exitLimitClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitLimitClause) {
            return visitor.visitLimitClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class OffsetClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_OFFSET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_OFFSET, 0)!;
    }
    public DIG_LITERAL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.DIG_LITERAL, 0);
    }
    public expression(): ExpressionContext | null {
        return this.getRuleContext(0, ExpressionContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_offsetClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterOffsetClause) {
             listener.enterOffsetClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitOffsetClause) {
             listener.exitOffsetClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitOffsetClause) {
            return visitor.visitOffsetClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class PartitionByClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_PARTITION(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_PARTITION, 0)!;
    }
    public KW_BY(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_BY, 0)!;
    }
    public expression(): ExpressionContext[];
    public expression(i: number): ExpressionContext | null;
    public expression(i?: number): ExpressionContext[] | ExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ExpressionContext);
        }

        return this.getRuleContext(i, ExpressionContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_partitionByClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterPartitionByClause) {
             listener.enterPartitionByClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitPartitionByClause) {
             listener.exitPartitionByClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitPartitionByClause) {
            return visitor.visitPartitionByClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class QuantifiersContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public ASTERISK_SIGN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.ASTERISK_SIGN, 0);
    }
    public ADD_SIGN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.ADD_SIGN, 0);
    }
    public QUESTION_MARK_SIGN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.QUESTION_MARK_SIGN, 0);
    }
    public LB_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.LB_BRACKET, 0);
    }
    public DIG_LITERAL(): antlr.TerminalNode[];
    public DIG_LITERAL(i: number): antlr.TerminalNode | null;
    public DIG_LITERAL(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.DIG_LITERAL);
    	} else {
    		return this.getToken(SparkSQLParser.DIG_LITERAL, i);
    	}
    }
    public COMMA(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.COMMA, 0);
    }
    public RB_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.RB_BRACKET, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_quantifiers;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterQuantifiers) {
             listener.enterQuantifiers(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitQuantifiers) {
             listener.exitQuantifiers(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitQuantifiers) {
            return visitor.visitQuantifiers(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class MeasuresClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_MEASURES(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_MEASURES, 0)!;
    }
    public projectItemDefinition(): ProjectItemDefinitionContext[];
    public projectItemDefinition(i: number): ProjectItemDefinitionContext | null;
    public projectItemDefinition(i?: number): ProjectItemDefinitionContext[] | ProjectItemDefinitionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ProjectItemDefinitionContext);
        }

        return this.getRuleContext(i, ProjectItemDefinitionContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_measuresClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterMeasuresClause) {
             listener.enterMeasuresClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitMeasuresClause) {
             listener.exitMeasuresClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitMeasuresClause) {
            return visitor.visitMeasuresClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class PatternDefinitionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_PATTERN(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_PATTERN, 0)!;
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public patternVariable(): PatternVariableContext[];
    public patternVariable(i: number): PatternVariableContext | null;
    public patternVariable(i?: number): PatternVariableContext[] | PatternVariableContext | null {
        if (i === undefined) {
            return this.getRuleContexts(PatternVariableContext);
        }

        return this.getRuleContext(i, PatternVariableContext);
    }
    public withinClause(): WithinClauseContext | null {
        return this.getRuleContext(0, WithinClauseContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_patternDefinition;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterPatternDefinition) {
             listener.enterPatternDefinition(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitPatternDefinition) {
             listener.exitPatternDefinition(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitPatternDefinition) {
            return visitor.visitPatternDefinition(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class PatternVariableContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public unquotedIdentifier(): UnquotedIdentifierContext {
        return this.getRuleContext(0, UnquotedIdentifierContext)!;
    }
    public quantifiers(): QuantifiersContext | null {
        return this.getRuleContext(0, QuantifiersContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_patternVariable;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterPatternVariable) {
             listener.enterPatternVariable(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitPatternVariable) {
             listener.exitPatternVariable(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitPatternVariable) {
            return visitor.visitPatternVariable(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class OutputModeContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_ALL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ALL, 0);
    }
    public KW_ROWS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ROWS, 0);
    }
    public KW_PER(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_PER, 0)!;
    }
    public KW_MATCH(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_MATCH, 0)!;
    }
    public KW_ONE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ONE, 0);
    }
    public KW_ROW(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ROW, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_outputMode;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterOutputMode) {
             listener.enterOutputMode(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitOutputMode) {
             listener.exitOutputMode(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitOutputMode) {
            return visitor.visitOutputMode(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class AfterMatchStrategyContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_AFTER(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_AFTER, 0)!;
    }
    public KW_MATCH(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_MATCH, 0)!;
    }
    public KW_SKIP(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_SKIP, 0)!;
    }
    public KW_PAST(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PAST, 0);
    }
    public KW_LAST(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LAST, 0);
    }
    public KW_ROW(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ROW, 0);
    }
    public KW_TO(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TO, 0);
    }
    public KW_NEXT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NEXT, 0);
    }
    public unquotedIdentifier(): UnquotedIdentifierContext | null {
        return this.getRuleContext(0, UnquotedIdentifierContext);
    }
    public KW_FIRST(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FIRST, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_afterMatchStrategy;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterAfterMatchStrategy) {
             listener.enterAfterMatchStrategy(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitAfterMatchStrategy) {
             listener.exitAfterMatchStrategy(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitAfterMatchStrategy) {
            return visitor.visitAfterMatchStrategy(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class PatternVariablesDefinitionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_DEFINE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_DEFINE, 0)!;
    }
    public projectItemDefinition(): ProjectItemDefinitionContext[];
    public projectItemDefinition(i: number): ProjectItemDefinitionContext | null;
    public projectItemDefinition(i?: number): ProjectItemDefinitionContext[] | ProjectItemDefinitionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ProjectItemDefinitionContext);
        }

        return this.getRuleContext(i, ProjectItemDefinitionContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_patternVariablesDefinition;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterPatternVariablesDefinition) {
             listener.enterPatternVariablesDefinition(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitPatternVariablesDefinition) {
             listener.exitPatternVariablesDefinition(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitPatternVariablesDefinition) {
            return visitor.visitPatternVariablesDefinition(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class WindowFrameContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_RANGE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_RANGE, 0);
    }
    public KW_BETWEEN(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_BETWEEN, 0)!;
    }
    public timeIntervalExpression(): TimeIntervalExpressionContext | null {
        return this.getRuleContext(0, TimeIntervalExpressionContext);
    }
    public frameBound(): FrameBoundContext {
        return this.getRuleContext(0, FrameBoundContext)!;
    }
    public KW_ROWS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ROWS, 0);
    }
    public DIG_LITERAL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.DIG_LITERAL, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_windowFrame;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterWindowFrame) {
             listener.enterWindowFrame(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitWindowFrame) {
             listener.exitWindowFrame(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitWindowFrame) {
            return visitor.visitWindowFrame(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class FrameBoundContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_PRECEDING(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_PRECEDING, 0)!;
    }
    public KW_AND(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_AND, 0)!;
    }
    public KW_CURRENT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_CURRENT, 0)!;
    }
    public KW_ROW(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_ROW, 0)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_frameBound;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterFrameBound) {
             listener.enterFrameBound(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitFrameBound) {
             listener.exitFrameBound(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitFrameBound) {
            return visitor.visitFrameBound(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class WithinClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_WITHIN(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_WITHIN, 0)!;
    }
    public timeIntervalExpression(): TimeIntervalExpressionContext {
        return this.getRuleContext(0, TimeIntervalExpressionContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_withinClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterWithinClause) {
             listener.enterWithinClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitWithinClause) {
             listener.exitWithinClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitWithinClause) {
            return visitor.visitWithinClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class SelfDefinitionClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_PERIOD(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_PERIOD, 0)!;
    }
    public KW_FOR(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_FOR, 0)!;
    }
    public KW_SYSTEM_TIME(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_SYSTEM_TIME, 0)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_selfDefinitionClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterSelfDefinitionClause) {
             listener.enterSelfDefinitionClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitSelfDefinitionClause) {
             listener.exitSelfDefinitionClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitSelfDefinitionClause) {
            return visitor.visitSelfDefinitionClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class PartitionDefinitionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_PARTITIONED(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_PARTITIONED, 0)!;
    }
    public KW_BY(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_BY, 0)!;
    }
    public transformList(): TransformListContext {
        return this.getRuleContext(0, TransformListContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_partitionDefinition;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterPartitionDefinition) {
             listener.enterPartitionDefinition(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitPartitionDefinition) {
             listener.exitPartitionDefinition(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitPartitionDefinition) {
            return visitor.visitPartitionDefinition(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class TransformListContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public transform(): TransformContext[];
    public transform(i: number): TransformContext | null;
    public transform(i?: number): TransformContext[] | TransformContext | null {
        if (i === undefined) {
            return this.getRuleContexts(TransformContext);
        }

        return this.getRuleContext(i, TransformContext);
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public dataTypeExpression(): DataTypeExpressionContext[];
    public dataTypeExpression(i: number): DataTypeExpressionContext | null;
    public dataTypeExpression(i?: number): DataTypeExpressionContext[] | DataTypeExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(DataTypeExpressionContext);
        }

        return this.getRuleContext(i, DataTypeExpressionContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_transformList;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterTransformList) {
             listener.enterTransformList(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitTransformList) {
             listener.exitTransformList(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitTransformList) {
            return visitor.visitTransformList(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class TransformContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_transform;
    }
    public override copyFrom(ctx: TransformContext): void {
        super.copyFrom(ctx);
    }
}
export class IdentityTransformContext extends TransformContext {
    public constructor(ctx: TransformContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public qualifiedName(): QualifiedNameContext {
        return this.getRuleContext(0, QualifiedNameContext)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterIdentityTransform) {
             listener.enterIdentityTransform(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitIdentityTransform) {
             listener.exitIdentityTransform(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitIdentityTransform) {
            return visitor.visitIdentityTransform(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class ApplyTransformContext extends TransformContext {
    public _transformName?: IdentifierContext;
    public constructor(ctx: TransformContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public transformArgument(): TransformArgumentContext[];
    public transformArgument(i: number): TransformArgumentContext | null;
    public transformArgument(i?: number): TransformArgumentContext[] | TransformArgumentContext | null {
        if (i === undefined) {
            return this.getRuleContexts(TransformArgumentContext);
        }

        return this.getRuleContext(i, TransformArgumentContext);
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public identifier(): IdentifierContext {
        return this.getRuleContext(0, IdentifierContext)!;
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterApplyTransform) {
             listener.enterApplyTransform(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitApplyTransform) {
             listener.exitApplyTransform(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitApplyTransform) {
            return visitor.visitApplyTransform(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class TransformArgumentContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public qualifiedName(): QualifiedNameContext | null {
        return this.getRuleContext(0, QualifiedNameContext);
    }
    public constant(): ConstantContext | null {
        return this.getRuleContext(0, ConstantContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_transformArgument;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterTransformArgument) {
             listener.enterTransformArgument(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitTransformArgument) {
             listener.exitTransformArgument(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitTransformArgument) {
            return visitor.visitTransformArgument(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class LikeDefinitionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_LIKE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_LIKE, 0)!;
    }
    public tablePath(): TablePathContext {
        return this.getRuleContext(0, TablePathContext)!;
    }
    public LR_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0);
    }
    public RR_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0);
    }
    public likeOption(): LikeOptionContext[];
    public likeOption(i: number): LikeOptionContext | null;
    public likeOption(i?: number): LikeOptionContext[] | LikeOptionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(LikeOptionContext);
        }

        return this.getRuleContext(i, LikeOptionContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_likeDefinition;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterLikeDefinition) {
             listener.enterLikeDefinition(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitLikeDefinition) {
             listener.exitLikeDefinition(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitLikeDefinition) {
            return visitor.visitLikeDefinition(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class DistributionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_DISTRIBUTED(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_DISTRIBUTED, 0)!;
    }
    public KW_BY(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_BY, 0);
    }
    public LR_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0);
    }
    public identifier(): IdentifierContext | null {
        return this.getRuleContext(0, IdentifierContext);
    }
    public RR_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0);
    }
    public intoBuckets(): IntoBucketsContext | null {
        return this.getRuleContext(0, IntoBucketsContext);
    }
    public KW_HASH(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_HASH, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_distribution;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterDistribution) {
             listener.enterDistribution(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitDistribution) {
             listener.exitDistribution(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitDistribution) {
            return visitor.visitDistribution(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class UsingContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_USING(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_USING, 0)!;
    }
    public ID_LITERAL(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.ID_LITERAL, 0)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_using;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterUsing) {
             listener.enterUsing(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitUsing) {
             listener.exitUsing(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitUsing) {
            return visitor.visitUsing(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class LikeOptionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_INCLUDING(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_INCLUDING, 0);
    }
    public KW_EXCLUDING(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_EXCLUDING, 0);
    }
    public KW_ALL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ALL, 0);
    }
    public KW_CONSTRAINTS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_CONSTRAINTS, 0);
    }
    public KW_PARTITIONS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PARTITIONS, 0);
    }
    public KW_OVERWRITING(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_OVERWRITING, 0);
    }
    public KW_GENERATED(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_GENERATED, 0);
    }
    public KW_OPTIONS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_OPTIONS, 0);
    }
    public KW_WATERMARKS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_WATERMARKS, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_likeOption;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterLikeOption) {
             listener.enterLikeOption(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitLikeOption) {
             listener.exitLikeOption(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitLikeOption) {
            return visitor.visitLikeOption(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ColumnOptionDefinitionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public physicalColumnDefinition(): PhysicalColumnDefinitionContext | null {
        return this.getRuleContext(0, PhysicalColumnDefinitionContext);
    }
    public metadataColumnDefinition(): MetadataColumnDefinitionContext | null {
        return this.getRuleContext(0, MetadataColumnDefinitionContext);
    }
    public computedColumnDefinition(): ComputedColumnDefinitionContext | null {
        return this.getRuleContext(0, ComputedColumnDefinitionContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_columnOptionDefinition;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterColumnOptionDefinition) {
             listener.enterColumnOptionDefinition(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitColumnOptionDefinition) {
             listener.exitColumnOptionDefinition(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitColumnOptionDefinition) {
            return visitor.visitColumnOptionDefinition(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class PhysicalColumnDefinitionListContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public physicalColumnDefinition(): PhysicalColumnDefinitionContext[];
    public physicalColumnDefinition(i: number): PhysicalColumnDefinitionContext | null;
    public physicalColumnDefinition(i?: number): PhysicalColumnDefinitionContext[] | PhysicalColumnDefinitionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(PhysicalColumnDefinitionContext);
        }

        return this.getRuleContext(i, PhysicalColumnDefinitionContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_physicalColumnDefinitionList;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterPhysicalColumnDefinitionList) {
             listener.enterPhysicalColumnDefinitionList(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitPhysicalColumnDefinitionList) {
             listener.exitPhysicalColumnDefinitionList(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitPhysicalColumnDefinitionList) {
            return visitor.visitPhysicalColumnDefinitionList(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class PhysicalColumnDefinitionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public columnName(): ColumnNameContext {
        return this.getRuleContext(0, ColumnNameContext)!;
    }
    public columnType(): ColumnTypeContext {
        return this.getRuleContext(0, ColumnTypeContext)!;
    }
    public columnConstraint(): ColumnConstraintContext | null {
        return this.getRuleContext(0, ColumnConstraintContext);
    }
    public commentSpec(): CommentSpecContext | null {
        return this.getRuleContext(0, CommentSpecContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_physicalColumnDefinition;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterPhysicalColumnDefinition) {
             listener.enterPhysicalColumnDefinition(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitPhysicalColumnDefinition) {
             listener.exitPhysicalColumnDefinition(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitPhysicalColumnDefinition) {
            return visitor.visitPhysicalColumnDefinition(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ComputedColumnExpressionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public expression(): ExpressionContext {
        return this.getRuleContext(0, ExpressionContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_computedColumnExpression;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterComputedColumnExpression) {
             listener.enterComputedColumnExpression(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitComputedColumnExpression) {
             listener.exitComputedColumnExpression(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitComputedColumnExpression) {
            return visitor.visitComputedColumnExpression(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class WatermarkDefinitionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_WATERMARK(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_WATERMARK, 0)!;
    }
    public KW_FOR(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_FOR, 0)!;
    }
    public expression(): ExpressionContext[];
    public expression(i: number): ExpressionContext | null;
    public expression(i?: number): ExpressionContext[] | ExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ExpressionContext);
        }

        return this.getRuleContext(i, ExpressionContext);
    }
    public KW_AS(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_AS, 0)!;
    }
    public uid(): UidContext[];
    public uid(i: number): UidContext | null;
    public uid(i?: number): UidContext[] | UidContext | null {
        if (i === undefined) {
            return this.getRuleContexts(UidContext);
        }

        return this.getRuleContext(i, UidContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_watermarkDefinition;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterWatermarkDefinition) {
             listener.enterWatermarkDefinition(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitWatermarkDefinition) {
             listener.exitWatermarkDefinition(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitWatermarkDefinition) {
            return visitor.visitWatermarkDefinition(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class TableConstraintContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_PRIMARY(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_PRIMARY, 0)!;
    }
    public KW_KEY(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_KEY, 0)!;
    }
    public columnNameList(): ColumnNameListContext {
        return this.getRuleContext(0, ColumnNameListContext)!;
    }
    public KW_NOT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_NOT, 0)!;
    }
    public KW_ENFORCED(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_ENFORCED, 0)!;
    }
    public KW_CONSTRAINT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_CONSTRAINT, 0);
    }
    public constraintName(): ConstraintNameContext | null {
        return this.getRuleContext(0, ConstraintNameContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_tableConstraint;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterTableConstraint) {
             listener.enterTableConstraint(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitTableConstraint) {
             listener.exitTableConstraint(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitTableConstraint) {
            return visitor.visitTableConstraint(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ConstraintNameContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public identifier(): IdentifierContext {
        return this.getRuleContext(0, IdentifierContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_constraintName;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterConstraintName) {
             listener.enterConstraintName(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitConstraintName) {
             listener.exitConstraintName(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitConstraintName) {
            return visitor.visitConstraintName(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ValuesDefinitionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_VALUES(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_VALUES, 0)!;
    }
    public valuesRowDefinition(): ValuesRowDefinitionContext[];
    public valuesRowDefinition(i: number): ValuesRowDefinitionContext | null;
    public valuesRowDefinition(i?: number): ValuesRowDefinitionContext[] | ValuesRowDefinitionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ValuesRowDefinitionContext);
        }

        return this.getRuleContext(i, ValuesRowDefinitionContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_valuesDefinition;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterValuesDefinition) {
             listener.enterValuesDefinition(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitValuesDefinition) {
             listener.exitValuesDefinition(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitValuesDefinition) {
            return visitor.visitValuesDefinition(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ValuesRowDefinitionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public constant(): ConstantContext[];
    public constant(i: number): ConstantContext | null;
    public constant(i?: number): ConstantContext[] | ConstantContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ConstantContext);
        }

        return this.getRuleContext(i, ConstantContext);
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_valuesRowDefinition;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterValuesRowDefinition) {
             listener.enterValuesRowDefinition(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitValuesRowDefinition) {
             listener.exitValuesRowDefinition(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitValuesRowDefinition) {
            return visitor.visitValuesRowDefinition(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class LengthOneDimensionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public decimalLiteral(): DecimalLiteralContext {
        return this.getRuleContext(0, DecimalLiteralContext)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_lengthOneDimension;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterLengthOneDimension) {
             listener.enterLengthOneDimension(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitLengthOneDimension) {
             listener.exitLengthOneDimension(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitLengthOneDimension) {
            return visitor.visitLengthOneDimension(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class LengthTwoOptionalDimensionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public decimalLiteral(): DecimalLiteralContext[];
    public decimalLiteral(i: number): DecimalLiteralContext | null;
    public decimalLiteral(i?: number): DecimalLiteralContext[] | DecimalLiteralContext | null {
        if (i === undefined) {
            return this.getRuleContexts(DecimalLiteralContext);
        }

        return this.getRuleContext(i, DecimalLiteralContext);
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public COMMA(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.COMMA, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_lengthTwoOptionalDimension;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterLengthTwoOptionalDimension) {
             listener.enterLengthTwoOptionalDimension(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitLengthTwoOptionalDimension) {
             listener.exitLengthTwoOptionalDimension(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitLengthTwoOptionalDimension) {
            return visitor.visitLengthTwoOptionalDimension(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class LengthTwoStringDimensionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public stringLiteral(): StringLiteralContext[];
    public stringLiteral(i: number): StringLiteralContext | null;
    public stringLiteral(i?: number): StringLiteralContext[] | StringLiteralContext | null {
        if (i === undefined) {
            return this.getRuleContexts(StringLiteralContext);
        }

        return this.getRuleContext(i, StringLiteralContext);
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public COMMA(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.COMMA, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_lengthTwoStringDimension;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterLengthTwoStringDimension) {
             listener.enterLengthTwoStringDimension(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitLengthTwoStringDimension) {
             listener.exitLengthTwoStringDimension(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitLengthTwoStringDimension) {
            return visitor.visitLengthTwoStringDimension(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class LengthOneTypeDimensionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_lengthOneTypeDimension;
    }
    public override copyFrom(ctx: LengthOneTypeDimensionContext): void {
        super.copyFrom(ctx);
    }
}
export class LengthSymbolsTypeDimensionContext extends LengthOneTypeDimensionContext {
    public constructor(ctx: LengthOneTypeDimensionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public LESS_SYMBOL(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LESS_SYMBOL, 0)!;
    }
    public columnType(): ColumnTypeContext[];
    public columnType(i: number): ColumnTypeContext | null;
    public columnType(i?: number): ColumnTypeContext[] | ColumnTypeContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ColumnTypeContext);
        }

        return this.getRuleContext(i, ColumnTypeContext);
    }
    public GREATER_SYMBOL(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.GREATER_SYMBOL, 0)!;
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterLengthSymbolsTypeDimension) {
             listener.enterLengthSymbolsTypeDimension(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitLengthSymbolsTypeDimension) {
             listener.exitLengthSymbolsTypeDimension(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitLengthSymbolsTypeDimension) {
            return visitor.visitLengthSymbolsTypeDimension(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class MapTypeDimensionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public LESS_SYMBOL(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LESS_SYMBOL, 0)!;
    }
    public columnType(): ColumnTypeContext[];
    public columnType(i: number): ColumnTypeContext | null;
    public columnType(i?: number): ColumnTypeContext[] | ColumnTypeContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ColumnTypeContext);
        }

        return this.getRuleContext(i, ColumnTypeContext);
    }
    public GREATER_SYMBOL(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.GREATER_SYMBOL, 0)!;
    }
    public COMMA(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.COMMA, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_mapTypeDimension;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterMapTypeDimension) {
             listener.enterMapTypeDimension(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitMapTypeDimension) {
             listener.exitMapTypeDimension(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitMapTypeDimension) {
            return visitor.visitMapTypeDimension(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class RowTypeDimensionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_rowTypeDimension;
    }
    public override copyFrom(ctx: RowTypeDimensionContext): void {
        super.copyFrom(ctx);
    }
}
export class RowSymbolsTypeDimensionContext extends RowTypeDimensionContext {
    public constructor(ctx: RowTypeDimensionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public LESS_SYMBOL(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LESS_SYMBOL, 0)!;
    }
    public columnName(): ColumnNameContext[];
    public columnName(i: number): ColumnNameContext | null;
    public columnName(i?: number): ColumnNameContext[] | ColumnNameContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ColumnNameContext);
        }

        return this.getRuleContext(i, ColumnNameContext);
    }
    public columnType(): ColumnTypeContext[];
    public columnType(i: number): ColumnTypeContext | null;
    public columnType(i?: number): ColumnTypeContext[] | ColumnTypeContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ColumnTypeContext);
        }

        return this.getRuleContext(i, ColumnTypeContext);
    }
    public GREATER_SYMBOL(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.GREATER_SYMBOL, 0)!;
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterRowSymbolsTypeDimension) {
             listener.enterRowSymbolsTypeDimension(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitRowSymbolsTypeDimension) {
             listener.exitRowSymbolsTypeDimension(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitRowSymbolsTypeDimension) {
            return visitor.visitRowSymbolsTypeDimension(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class StructTypeDimensionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_structTypeDimension;
    }
    public override copyFrom(ctx: StructTypeDimensionContext): void {
        super.copyFrom(ctx);
    }
}
export class StructSymbolsTypeDimensionContext extends StructTypeDimensionContext {
    public constructor(ctx: StructTypeDimensionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public LESS_SYMBOL(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LESS_SYMBOL, 0)!;
    }
    public columnName(): ColumnNameContext[];
    public columnName(i: number): ColumnNameContext | null;
    public columnName(i?: number): ColumnNameContext[] | ColumnNameContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ColumnNameContext);
        }

        return this.getRuleContext(i, ColumnNameContext);
    }
    public COLON_SYMB(): antlr.TerminalNode[];
    public COLON_SYMB(i: number): antlr.TerminalNode | null;
    public COLON_SYMB(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COLON_SYMB);
    	} else {
    		return this.getToken(SparkSQLParser.COLON_SYMB, i);
    	}
    }
    public columnType(): ColumnTypeContext[];
    public columnType(i: number): ColumnTypeContext | null;
    public columnType(i?: number): ColumnTypeContext[] | ColumnTypeContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ColumnTypeContext);
        }

        return this.getRuleContext(i, ColumnTypeContext);
    }
    public GREATER_SYMBOL(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.GREATER_SYMBOL, 0)!;
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterStructSymbolsTypeDimension) {
             listener.enterStructSymbolsTypeDimension(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitStructSymbolsTypeDimension) {
             listener.exitStructSymbolsTypeDimension(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitStructSymbolsTypeDimension) {
            return visitor.visitStructSymbolsTypeDimension(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ColumnConstraintContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_PRIMARY(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PRIMARY, 0);
    }
    public KW_KEY(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_KEY, 0);
    }
    public KW_CONSTRAINT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_CONSTRAINT, 0);
    }
    public constraintName(): ConstraintNameContext | null {
        return this.getRuleContext(0, ConstraintNameContext);
    }
    public KW_NOT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NOT, 0);
    }
    public KW_ENFORCED(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ENFORCED, 0);
    }
    public KW_NULL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NULL, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_columnConstraint;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterColumnConstraint) {
             listener.enterColumnConstraint(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitColumnConstraint) {
             listener.exitColumnConstraint(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitColumnConstraint) {
            return visitor.visitColumnConstraint(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class CommentSpecContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_COMMENT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_COMMENT, 0)!;
    }
    public propertyName(): PropertyNameContext {
        return this.getRuleContext(0, PropertyNameContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_commentSpec;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterCommentSpec) {
             listener.enterCommentSpec(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitCommentSpec) {
             listener.exitCommentSpec(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitCommentSpec) {
            return visitor.visitCommentSpec(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class MetadataColumnDefinitionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public columnName(): ColumnNameContext {
        return this.getRuleContext(0, ColumnNameContext)!;
    }
    public columnType(): ColumnTypeContext {
        return this.getRuleContext(0, ColumnTypeContext)!;
    }
    public KW_METADATA(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_METADATA, 0)!;
    }
    public KW_FROM(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FROM, 0);
    }
    public metadataKey(): MetadataKeyContext | null {
        return this.getRuleContext(0, MetadataKeyContext);
    }
    public KW_VIRTUAL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_VIRTUAL, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_metadataColumnDefinition;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterMetadataColumnDefinition) {
             listener.enterMetadataColumnDefinition(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitMetadataColumnDefinition) {
             listener.exitMetadataColumnDefinition(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitMetadataColumnDefinition) {
            return visitor.visitMetadataColumnDefinition(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class MetadataKeyContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public STRING_LITERAL(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.STRING_LITERAL, 0)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_metadataKey;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterMetadataKey) {
             listener.enterMetadataKey(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitMetadataKey) {
             listener.exitMetadataKey(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitMetadataKey) {
            return visitor.visitMetadataKey(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ComputedColumnDefinitionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public columnName(): ColumnNameContext {
        return this.getRuleContext(0, ColumnNameContext)!;
    }
    public KW_AS(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_AS, 0)!;
    }
    public computedColumnExpression(): ComputedColumnExpressionContext {
        return this.getRuleContext(0, ComputedColumnExpressionContext)!;
    }
    public commentSpec(): CommentSpecContext | null {
        return this.getRuleContext(0, CommentSpecContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_computedColumnDefinition;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterComputedColumnDefinition) {
             listener.enterComputedColumnDefinition(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitComputedColumnDefinition) {
             listener.exitComputedColumnDefinition(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitComputedColumnDefinition) {
            return visitor.visitComputedColumnDefinition(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ColumnNameContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public uid(): UidContext | null {
        return this.getRuleContext(0, UidContext);
    }
    public expression(): ExpressionContext | null {
        return this.getRuleContext(0, ExpressionContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_columnName;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterColumnName) {
             listener.enterColumnName(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitColumnName) {
             listener.exitColumnName(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitColumnName) {
            return visitor.visitColumnName(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ColumnNameListContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public columnName(): ColumnNameContext[];
    public columnName(i: number): ColumnNameContext | null;
    public columnName(i?: number): ColumnNameContext[] | ColumnNameContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ColumnNameContext);
        }

        return this.getRuleContext(i, ColumnNameContext);
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public commentSpec(): CommentSpecContext[];
    public commentSpec(i: number): CommentSpecContext | null;
    public commentSpec(i?: number): CommentSpecContext[] | CommentSpecContext | null {
        if (i === undefined) {
            return this.getRuleContexts(CommentSpecContext);
        }

        return this.getRuleContext(i, CommentSpecContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_columnNameList;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterColumnNameList) {
             listener.enterColumnNameList(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitColumnNameList) {
             listener.exitColumnNameList(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitColumnNameList) {
            return visitor.visitColumnNameList(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ColumnTypeContext extends antlr.ParserRuleContext {
    public _typeName?: Token | null;
    public _type_?: Token | null;
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_DATE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DATE, 0);
    }
    public KW_BOOLEAN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_BOOLEAN, 0);
    }
    public KW_NULL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NULL, 0);
    }
    public KW_CHAR(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_CHAR, 0);
    }
    public KW_VARCHAR(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_VARCHAR, 0);
    }
    public KW_STRING(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_STRING, 0);
    }
    public KW_BINARY(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_BINARY, 0);
    }
    public KW_VARBINARY(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_VARBINARY, 0);
    }
    public KW_BYTES(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_BYTES, 0);
    }
    public KW_TINYINT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TINYINT, 0);
    }
    public KW_SMALLINT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SMALLINT, 0);
    }
    public KW_INT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_INT, 0);
    }
    public KW_INTEGER(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_INTEGER, 0);
    }
    public KW_BIGINT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_BIGINT, 0);
    }
    public KW_TIME(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TIME, 0);
    }
    public KW_TIMESTAMP_LTZ(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TIMESTAMP_LTZ, 0);
    }
    public KW_DATETIME(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DATETIME, 0);
    }
    public lengthOneDimension(): LengthOneDimensionContext | null {
        return this.getRuleContext(0, LengthOneDimensionContext);
    }
    public KW_TIMESTAMP(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TIMESTAMP, 0);
    }
    public KW_ZONE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ZONE, 0);
    }
    public KW_WITHOUT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_WITHOUT, 0);
    }
    public KW_WITH(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_WITH, 0);
    }
    public KW_LOCAL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LOCAL, 0);
    }
    public KW_TIMESTAMP_3(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TIMESTAMP_3, 0);
    }
    public KW_TIMESTAMP_6(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TIMESTAMP_6, 0);
    }
    public KW_TIMESTAMP_9(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TIMESTAMP_9, 0);
    }
    public KW_DECIMAL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DECIMAL, 0);
    }
    public KW_DEC(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DEC, 0);
    }
    public KW_NUMERIC(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NUMERIC, 0);
    }
    public KW_FLOAT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FLOAT, 0);
    }
    public KW_DOUBLE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DOUBLE, 0);
    }
    public lengthTwoOptionalDimension(): LengthTwoOptionalDimensionContext | null {
        return this.getRuleContext(0, LengthTwoOptionalDimensionContext);
    }
    public KW_ARRAY(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ARRAY, 0);
    }
    public KW_MULTISET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MULTISET, 0);
    }
    public lengthOneTypeDimension(): LengthOneTypeDimensionContext | null {
        return this.getRuleContext(0, LengthOneTypeDimensionContext);
    }
    public KW_MAP(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MAP, 0);
    }
    public mapTypeDimension(): MapTypeDimensionContext | null {
        return this.getRuleContext(0, MapTypeDimensionContext);
    }
    public KW_ROW(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ROW, 0);
    }
    public rowTypeDimension(): RowTypeDimensionContext | null {
        return this.getRuleContext(0, RowTypeDimensionContext);
    }
    public structTypeDimension(): StructTypeDimensionContext | null {
        return this.getRuleContext(0, StructTypeDimensionContext);
    }
    public KW_STRUCT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_STRUCT, 0);
    }
    public KW_RAW(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_RAW, 0);
    }
    public lengthTwoStringDimension(): LengthTwoStringDimensionContext | null {
        return this.getRuleContext(0, LengthTwoStringDimensionContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_columnType;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterColumnType) {
             listener.enterColumnType(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitColumnType) {
             listener.exitColumnType(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitColumnType) {
            return visitor.visitColumnType(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ExpressionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public booleanExpression(): BooleanExpressionContext {
        return this.getRuleContext(0, BooleanExpressionContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_expression;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterExpression) {
             listener.enterExpression(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitExpression) {
             listener.exitExpression(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitExpression) {
            return visitor.visitExpression(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class BooleanExpressionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_booleanExpression;
    }
    public override copyFrom(ctx: BooleanExpressionContext): void {
        super.copyFrom(ctx);
    }
}
export class LogicalNotContext extends BooleanExpressionContext {
    public constructor(ctx: BooleanExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public KW_NOT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_NOT, 0)!;
    }
    public booleanExpression(): BooleanExpressionContext {
        return this.getRuleContext(0, BooleanExpressionContext)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterLogicalNot) {
             listener.enterLogicalNot(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitLogicalNot) {
             listener.exitLogicalNot(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitLogicalNot) {
            return visitor.visitLogicalNot(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class PredicatedContext extends BooleanExpressionContext {
    public constructor(ctx: BooleanExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public valueExpression(): ValueExpressionContext {
        return this.getRuleContext(0, ValueExpressionContext)!;
    }
    public predicate(): PredicateContext | null {
        return this.getRuleContext(0, PredicateContext);
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterPredicated) {
             listener.enterPredicated(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitPredicated) {
             listener.exitPredicated(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitPredicated) {
            return visitor.visitPredicated(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class ExistsContext extends BooleanExpressionContext {
    public constructor(ctx: BooleanExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public KW_EXISTS(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_EXISTS, 0)!;
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public queryStatement(): QueryStatementContext {
        return this.getRuleContext(0, QueryStatementContext)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterExists) {
             listener.enterExists(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitExists) {
             listener.exitExists(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitExists) {
            return visitor.visitExists(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class LogicalNestedContext extends BooleanExpressionContext {
    public _kind?: Token | null;
    public constructor(ctx: BooleanExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public booleanExpression(): BooleanExpressionContext {
        return this.getRuleContext(0, BooleanExpressionContext)!;
    }
    public KW_IS(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_IS, 0)!;
    }
    public KW_TRUE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TRUE, 0);
    }
    public KW_FALSE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FALSE, 0);
    }
    public KW_UNKNOWN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_UNKNOWN, 0);
    }
    public KW_NULL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NULL, 0);
    }
    public KW_NOT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NOT, 0);
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterLogicalNested) {
             listener.enterLogicalNested(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitLogicalNested) {
             listener.exitLogicalNested(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitLogicalNested) {
            return visitor.visitLogicalNested(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class LogicalBinaryContext extends BooleanExpressionContext {
    public _left?: BooleanExpressionContext;
    public _operator?: Token | null;
    public _right?: BooleanExpressionContext;
    public constructor(ctx: BooleanExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public booleanExpression(): BooleanExpressionContext[];
    public booleanExpression(i: number): BooleanExpressionContext | null;
    public booleanExpression(i?: number): BooleanExpressionContext[] | BooleanExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(BooleanExpressionContext);
        }

        return this.getRuleContext(i, BooleanExpressionContext);
    }
    public KW_AND(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_AND, 0);
    }
    public KW_OR(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_OR, 0);
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterLogicalBinary) {
             listener.enterLogicalBinary(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitLogicalBinary) {
             listener.exitLogicalBinary(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitLogicalBinary) {
            return visitor.visitLogicalBinary(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class PredicateContext extends antlr.ParserRuleContext {
    public _kind?: Token | null;
    public _lower?: ValueExpressionContext;
    public _upper?: ValueExpressionContext;
    public _pattern?: ValueExpressionContext;
    public _right?: ValueExpressionContext;
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_AND(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_AND, 0);
    }
    public KW_BETWEEN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_BETWEEN, 0);
    }
    public valueExpression(): ValueExpressionContext[];
    public valueExpression(i: number): ValueExpressionContext | null;
    public valueExpression(i?: number): ValueExpressionContext[] | ValueExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ValueExpressionContext);
        }

        return this.getRuleContext(i, ValueExpressionContext);
    }
    public KW_NOT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NOT, 0);
    }
    public KW_ASYMMETRIC(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ASYMMETRIC, 0);
    }
    public KW_SYMMETRIC(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SYMMETRIC, 0);
    }
    public LR_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0);
    }
    public expression(): ExpressionContext[];
    public expression(i: number): ExpressionContext | null;
    public expression(i?: number): ExpressionContext[] | ExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ExpressionContext);
        }

        return this.getRuleContext(i, ExpressionContext);
    }
    public RR_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0);
    }
    public KW_IN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_IN, 0);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public queryStatement(): QueryStatementContext | null {
        return this.getRuleContext(0, QueryStatementContext);
    }
    public KW_EXISTS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_EXISTS, 0);
    }
    public KW_RLIKE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_RLIKE, 0);
    }
    public likePredicate(): LikePredicateContext | null {
        return this.getRuleContext(0, LikePredicateContext);
    }
    public KW_IS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_IS, 0);
    }
    public KW_TRUE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TRUE, 0);
    }
    public KW_FALSE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FALSE, 0);
    }
    public KW_UNKNOWN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_UNKNOWN, 0);
    }
    public KW_NULL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NULL, 0);
    }
    public KW_FROM(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FROM, 0);
    }
    public KW_DISTINCT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DISTINCT, 0);
    }
    public KW_TO(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TO, 0);
    }
    public KW_SIMILAR(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SIMILAR, 0);
    }
    public KW_ESCAPE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ESCAPE, 0);
    }
    public stringLiteral(): StringLiteralContext | null {
        return this.getRuleContext(0, StringLiteralContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_predicate;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterPredicate) {
             listener.enterPredicate(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitPredicate) {
             listener.exitPredicate(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitPredicate) {
            return visitor.visitPredicate(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class LikePredicateContext extends antlr.ParserRuleContext {
    public _kind?: Token | null;
    public _quantifier?: Token | null;
    public _pattern?: ValueExpressionContext;
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_LIKE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LIKE, 0);
    }
    public KW_ANY(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ANY, 0);
    }
    public KW_ALL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ALL, 0);
    }
    public LR_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0);
    }
    public RR_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0);
    }
    public expression(): ExpressionContext[];
    public expression(i: number): ExpressionContext | null;
    public expression(i?: number): ExpressionContext[] | ExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ExpressionContext);
        }

        return this.getRuleContext(i, ExpressionContext);
    }
    public KW_NOT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NOT, 0);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public valueExpression(): ValueExpressionContext | null {
        return this.getRuleContext(0, ValueExpressionContext);
    }
    public KW_RLIKE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_RLIKE, 0);
    }
    public KW_ESCAPE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ESCAPE, 0);
    }
    public stringLiteral(): StringLiteralContext[];
    public stringLiteral(i: number): StringLiteralContext | null;
    public stringLiteral(i?: number): StringLiteralContext[] | StringLiteralContext | null {
        if (i === undefined) {
            return this.getRuleContexts(StringLiteralContext);
        }

        return this.getRuleContext(i, StringLiteralContext);
    }
    public KW_REGEXP(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_REGEXP, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_likePredicate;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterLikePredicate) {
             listener.enterLikePredicate(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitLikePredicate) {
             listener.exitLikePredicate(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitLikePredicate) {
            return visitor.visitLikePredicate(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ValueExpressionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_valueExpression;
    }
    public override copyFrom(ctx: ValueExpressionContext): void {
        super.copyFrom(ctx);
    }
}
export class ValueExpressionDefaultContext extends ValueExpressionContext {
    public constructor(ctx: ValueExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public primaryExpression(): PrimaryExpressionContext {
        return this.getRuleContext(0, PrimaryExpressionContext)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterValueExpressionDefault) {
             listener.enterValueExpressionDefault(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitValueExpressionDefault) {
             listener.exitValueExpressionDefault(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitValueExpressionDefault) {
            return visitor.visitValueExpressionDefault(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class OrContext extends ValueExpressionContext {
    public _left?: ValueExpressionContext;
    public _operator?: Token | null;
    public _right?: ValueExpressionContext;
    public constructor(ctx: ValueExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public valueExpression(): ValueExpressionContext[];
    public valueExpression(i: number): ValueExpressionContext | null;
    public valueExpression(i?: number): ValueExpressionContext[] | ValueExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ValueExpressionContext);
        }

        return this.getRuleContext(i, ValueExpressionContext);
    }
    public BIT_OR_OP(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.BIT_OR_OP, 0)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterOr) {
             listener.enterOr(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitOr) {
             listener.exitOr(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitOr) {
            return visitor.visitOr(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class ComparisonContext extends ValueExpressionContext {
    public _left?: ValueExpressionContext;
    public _operator?: ComparisonOperatorContext;
    public _right?: ValueExpressionContext;
    public constructor(ctx: ValueExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public valueExpression(): ValueExpressionContext[];
    public valueExpression(i: number): ValueExpressionContext | null;
    public valueExpression(i?: number): ValueExpressionContext[] | ValueExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ValueExpressionContext);
        }

        return this.getRuleContext(i, ValueExpressionContext);
    }
    public comparisonOperator(): ComparisonOperatorContext {
        return this.getRuleContext(0, ComparisonOperatorContext)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterComparison) {
             listener.enterComparison(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitComparison) {
             listener.exitComparison(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitComparison) {
            return visitor.visitComparison(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class ArithmeticBinaryContext extends ValueExpressionContext {
    public _left?: ValueExpressionContext;
    public _operator?: Token | null;
    public _right?: ValueExpressionContext;
    public constructor(ctx: ValueExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public valueExpression(): ValueExpressionContext[];
    public valueExpression(i: number): ValueExpressionContext | null;
    public valueExpression(i?: number): ValueExpressionContext[] | ValueExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ValueExpressionContext);
        }

        return this.getRuleContext(i, ValueExpressionContext);
    }
    public ASTERISK_SIGN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.ASTERISK_SIGN, 0);
    }
    public SLASH_SIGN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.SLASH_SIGN, 0);
    }
    public PENCENT_SIGN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.PENCENT_SIGN, 0);
    }
    public KW_DIV(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DIV, 0);
    }
    public ADD_SIGN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.ADD_SIGN, 0);
    }
    public HYPNEN_SIGN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.HYPNEN_SIGN, 0);
    }
    public DOUBLE_VERTICAL_SIGN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.DOUBLE_VERTICAL_SIGN, 0);
    }
    public BIT_AND_OP(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.BIT_AND_OP, 0);
    }
    public BIT_XOR_OP(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.BIT_XOR_OP, 0);
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterArithmeticBinary) {
             listener.enterArithmeticBinary(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitArithmeticBinary) {
             listener.exitArithmeticBinary(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitArithmeticBinary) {
            return visitor.visitArithmeticBinary(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class ArithmeticUnaryContext extends ValueExpressionContext {
    public _operator?: Token | null;
    public constructor(ctx: ValueExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public valueExpression(): ValueExpressionContext {
        return this.getRuleContext(0, ValueExpressionContext)!;
    }
    public HYPNEN_SIGN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.HYPNEN_SIGN, 0);
    }
    public ADD_SIGN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.ADD_SIGN, 0);
    }
    public BIT_NOT_OP(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.BIT_NOT_OP, 0);
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterArithmeticUnary) {
             listener.enterArithmeticUnary(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitArithmeticUnary) {
             listener.exitArithmeticUnary(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitArithmeticUnary) {
            return visitor.visitArithmeticUnary(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class PrimaryExpressionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_primaryExpression;
    }
    public override copyFrom(ctx: PrimaryExpressionContext): void {
        super.copyFrom(ctx);
    }
}
export class SimpleCaseContext extends PrimaryExpressionContext {
    public _value?: ExpressionContext;
    public _elseExpression?: ExpressionContext;
    public constructor(ctx: PrimaryExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public KW_CASE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_CASE, 0)!;
    }
    public KW_END(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_END, 0)!;
    }
    public expression(): ExpressionContext[];
    public expression(i: number): ExpressionContext | null;
    public expression(i?: number): ExpressionContext[] | ExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ExpressionContext);
        }

        return this.getRuleContext(i, ExpressionContext);
    }
    public whenClause(): WhenClauseContext[];
    public whenClause(i: number): WhenClauseContext | null;
    public whenClause(i?: number): WhenClauseContext[] | WhenClauseContext | null {
        if (i === undefined) {
            return this.getRuleContexts(WhenClauseContext);
        }

        return this.getRuleContext(i, WhenClauseContext);
    }
    public KW_ELSE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ELSE, 0);
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterSimpleCase) {
             listener.enterSimpleCase(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitSimpleCase) {
             listener.exitSimpleCase(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitSimpleCase) {
            return visitor.visitSimpleCase(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class ColumnReferenceContext extends PrimaryExpressionContext {
    public constructor(ctx: PrimaryExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public identifier(): IdentifierContext {
        return this.getRuleContext(0, IdentifierContext)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterColumnReference) {
             listener.enterColumnReference(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitColumnReference) {
             listener.exitColumnReference(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitColumnReference) {
            return visitor.visitColumnReference(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class LastContext extends PrimaryExpressionContext {
    public constructor(ctx: PrimaryExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public KW_LAST(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_LAST, 0)!;
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public expression(): ExpressionContext {
        return this.getRuleContext(0, ExpressionContext)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public KW_IGNORE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_IGNORE, 0);
    }
    public KW_NULLS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NULLS, 0);
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterLast) {
             listener.enterLast(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitLast) {
             listener.exitLast(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitLast) {
            return visitor.visitLast(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class StarContext extends PrimaryExpressionContext {
    public constructor(ctx: PrimaryExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public ASTERISK_SIGN(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.ASTERISK_SIGN, 0)!;
    }
    public uid(): UidContext | null {
        return this.getRuleContext(0, UidContext);
    }
    public DOT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.DOT, 0);
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterStar) {
             listener.enterStar(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitStar) {
             listener.exitStar(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitStar) {
            return visitor.visitStar(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class AggregateFunctionsContext extends PrimaryExpressionContext {
    public constructor(ctx: PrimaryExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public funtionBody(): FuntionBodyContext {
        return this.getRuleContext(0, FuntionBodyContext)!;
    }
    public filterPart(): FilterPartContext {
        return this.getRuleContext(0, FilterPartContext)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterAggregateFunctions) {
             listener.enterAggregateFunctions(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitAggregateFunctions) {
             listener.exitAggregateFunctions(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitAggregateFunctions) {
            return visitor.visitAggregateFunctions(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class SubscriptContext extends PrimaryExpressionContext {
    public _value?: PrimaryExpressionContext;
    public _index?: ValueExpressionContext;
    public constructor(ctx: PrimaryExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public LS_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LS_BRACKET, 0)!;
    }
    public RS_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RS_BRACKET, 0)!;
    }
    public primaryExpression(): PrimaryExpressionContext {
        return this.getRuleContext(0, PrimaryExpressionContext)!;
    }
    public valueExpression(): ValueExpressionContext {
        return this.getRuleContext(0, ValueExpressionContext)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterSubscript) {
             listener.enterSubscript(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitSubscript) {
             listener.exitSubscript(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitSubscript) {
            return visitor.visitSubscript(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class ValuesContext extends PrimaryExpressionContext {
    public constructor(ctx: PrimaryExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public functionParam(): FunctionParamContext[];
    public functionParam(i: number): FunctionParamContext | null;
    public functionParam(i?: number): FunctionParamContext[] | FunctionParamContext | null {
        if (i === undefined) {
            return this.getRuleContexts(FunctionParamContext);
        }

        return this.getRuleContext(i, FunctionParamContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterValues) {
             listener.enterValues(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitValues) {
             listener.exitValues(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitValues) {
            return visitor.visitValues(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class FunctionCallFilterContext extends PrimaryExpressionContext {
    public constructor(ctx: PrimaryExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public functionName(): FunctionNameContext {
        return this.getRuleContext(0, FunctionNameContext)!;
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public functionParam(): FunctionParamContext {
        return this.getRuleContext(0, FunctionParamContext)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public setQuantifier(): SetQuantifierContext | null {
        return this.getRuleContext(0, SetQuantifierContext);
    }
    public filterClause(): FilterClauseContext | null {
        return this.getRuleContext(0, FilterClauseContext);
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterFunctionCallFilter) {
             listener.enterFunctionCallFilter(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitFunctionCallFilter) {
             listener.exitFunctionCallFilter(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitFunctionCallFilter) {
            return visitor.visitFunctionCallFilter(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class OrderSetAggregateFunctionsContext extends PrimaryExpressionContext {
    public constructor(ctx: PrimaryExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public funtionBody(): FuntionBodyContext {
        return this.getRuleContext(0, FuntionBodyContext)!;
    }
    public KW_WITHIN(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_WITHIN, 0)!;
    }
    public KW_GROUP(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_GROUP, 0)!;
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public orderByCaluse(): OrderByCaluseContext {
        return this.getRuleContext(0, OrderByCaluseContext)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public filterPart(): FilterPartContext | null {
        return this.getRuleContext(0, FilterPartContext);
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterOrderSetAggregateFunctions) {
             listener.enterOrderSetAggregateFunctions(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitOrderSetAggregateFunctions) {
             listener.exitOrderSetAggregateFunctions(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitOrderSetAggregateFunctions) {
            return visitor.visitOrderSetAggregateFunctions(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class SubqueryExpressionContext extends PrimaryExpressionContext {
    public constructor(ctx: PrimaryExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public queryStatement(): QueryStatementContext {
        return this.getRuleContext(0, QueryStatementContext)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterSubqueryExpression) {
             listener.enterSubqueryExpression(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitSubqueryExpression) {
             listener.exitSubqueryExpression(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitSubqueryExpression) {
            return visitor.visitSubqueryExpression(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class CastContext extends PrimaryExpressionContext {
    public constructor(ctx: PrimaryExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public KW_CAST(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_CAST, 0)!;
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public expression(): ExpressionContext {
        return this.getRuleContext(0, ExpressionContext)!;
    }
    public KW_AS(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_AS, 0)!;
    }
    public columnType(): ColumnTypeContext {
        return this.getRuleContext(0, ColumnTypeContext)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterCast) {
             listener.enterCast(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitCast) {
             listener.exitCast(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitCast) {
            return visitor.visitCast(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class ConstantDefaultContext extends PrimaryExpressionContext {
    public constructor(ctx: PrimaryExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public constant(): ConstantContext {
        return this.getRuleContext(0, ConstantContext)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterConstantDefault) {
             listener.enterConstantDefault(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitConstantDefault) {
             listener.exitConstantDefault(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitConstantDefault) {
            return visitor.visitConstantDefault(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class ParenthesizedExpressionContext extends PrimaryExpressionContext {
    public constructor(ctx: PrimaryExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public expression(): ExpressionContext {
        return this.getRuleContext(0, ExpressionContext)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterParenthesizedExpression) {
             listener.enterParenthesizedExpression(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitParenthesizedExpression) {
             listener.exitParenthesizedExpression(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitParenthesizedExpression) {
            return visitor.visitParenthesizedExpression(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class ComplexDataTypeFieldExpressionContext extends PrimaryExpressionContext {
    public constructor(ctx: PrimaryExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public complexDataTypeExpression(): ComplexDataTypeExpressionContext {
        return this.getRuleContext(0, ComplexDataTypeExpressionContext)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterComplexDataTypeFieldExpression) {
             listener.enterComplexDataTypeFieldExpression(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitComplexDataTypeFieldExpression) {
             listener.exitComplexDataTypeFieldExpression(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitComplexDataTypeFieldExpression) {
            return visitor.visitComplexDataTypeFieldExpression(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class FunctionCallContext extends PrimaryExpressionContext {
    public constructor(ctx: PrimaryExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public functionName(): FunctionNameContext {
        return this.getRuleContext(0, FunctionNameContext)!;
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public functionParam(): FunctionParamContext[];
    public functionParam(i: number): FunctionParamContext | null;
    public functionParam(i?: number): FunctionParamContext[] | FunctionParamContext | null {
        if (i === undefined) {
            return this.getRuleContexts(FunctionParamContext);
        }

        return this.getRuleContext(i, FunctionParamContext);
    }
    public setQuantifier(): SetQuantifierContext | null {
        return this.getRuleContext(0, SetQuantifierContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public KW_TO(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TO, 0);
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterFunctionCall) {
             listener.enterFunctionCall(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitFunctionCall) {
             listener.exitFunctionCall(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitFunctionCall) {
            return visitor.visitFunctionCall(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class UidForColumnNameContext extends PrimaryExpressionContext {
    public constructor(ctx: PrimaryExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public uid(): UidContext {
        return this.getRuleContext(0, UidContext)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterUidForColumnName) {
             listener.enterUidForColumnName(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitUidForColumnName) {
             listener.exitUidForColumnName(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitUidForColumnName) {
            return visitor.visitUidForColumnName(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class SearchedCaseContext extends PrimaryExpressionContext {
    public _elseExpression?: ExpressionContext;
    public constructor(ctx: PrimaryExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public KW_CASE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_CASE, 0)!;
    }
    public KW_END(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_END, 0)!;
    }
    public whenClause(): WhenClauseContext[];
    public whenClause(i: number): WhenClauseContext | null;
    public whenClause(i?: number): WhenClauseContext[] | WhenClauseContext | null {
        if (i === undefined) {
            return this.getRuleContexts(WhenClauseContext);
        }

        return this.getRuleContext(i, WhenClauseContext);
    }
    public KW_ELSE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ELSE, 0);
    }
    public expression(): ExpressionContext | null {
        return this.getRuleContext(0, ExpressionContext);
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterSearchedCase) {
             listener.enterSearchedCase(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitSearchedCase) {
             listener.exitSearchedCase(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitSearchedCase) {
            return visitor.visitSearchedCase(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class PositionContext extends PrimaryExpressionContext {
    public _substr?: ValueExpressionContext;
    public _str?: ValueExpressionContext;
    public constructor(ctx: PrimaryExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public KW_POSITION(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_POSITION, 0)!;
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public KW_IN(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_IN, 0)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public valueExpression(): ValueExpressionContext[];
    public valueExpression(i: number): ValueExpressionContext | null;
    public valueExpression(i?: number): ValueExpressionContext[] | ValueExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ValueExpressionContext);
        }

        return this.getRuleContext(i, ValueExpressionContext);
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterPosition) {
             listener.enterPosition(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitPosition) {
             listener.exitPosition(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitPosition) {
            return visitor.visitPosition(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class FirstContext extends PrimaryExpressionContext {
    public constructor(ctx: PrimaryExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public KW_FIRST(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_FIRST, 0)!;
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public expression(): ExpressionContext {
        return this.getRuleContext(0, ExpressionContext)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public KW_IGNORE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_IGNORE, 0);
    }
    public KW_NULLS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NULLS, 0);
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterFirst) {
             listener.enterFirst(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitFirst) {
             listener.exitFirst(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitFirst) {
            return visitor.visitFirst(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ComplexDataTypeExpressionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public arrayExpression(): ArrayExpressionContext | null {
        return this.getRuleContext(0, ArrayExpressionContext);
    }
    public rowExpression(): RowExpressionContext | null {
        return this.getRuleContext(0, RowExpressionContext);
    }
    public mapExpression(): MapExpressionContext | null {
        return this.getRuleContext(0, MapExpressionContext);
    }
    public structExpression(): StructExpressionContext | null {
        return this.getRuleContext(0, StructExpressionContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_complexDataTypeExpression;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterComplexDataTypeExpression) {
             listener.enterComplexDataTypeExpression(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitComplexDataTypeExpression) {
             listener.exitComplexDataTypeExpression(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitComplexDataTypeExpression) {
            return visitor.visitComplexDataTypeExpression(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ArrayExpressionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_ARRAY(): antlr.TerminalNode[];
    public KW_ARRAY(i: number): antlr.TerminalNode | null;
    public KW_ARRAY(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.KW_ARRAY);
    	} else {
    		return this.getToken(SparkSQLParser.KW_ARRAY, i);
    	}
    }
    public LS_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LS_BRACKET, 0)!;
    }
    public dataTypeExpression(): DataTypeExpressionContext[];
    public dataTypeExpression(i: number): DataTypeExpressionContext | null;
    public dataTypeExpression(i?: number): DataTypeExpressionContext[] | DataTypeExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(DataTypeExpressionContext);
        }

        return this.getRuleContext(i, DataTypeExpressionContext);
    }
    public RS_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RS_BRACKET, 0)!;
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_arrayExpression;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterArrayExpression) {
             listener.enterArrayExpression(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitArrayExpression) {
             listener.exitArrayExpression(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitArrayExpression) {
            return visitor.visitArrayExpression(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class StructExpressionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_STRUCT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_STRUCT, 0)!;
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public dataTypeExpression(): DataTypeExpressionContext[];
    public dataTypeExpression(i: number): DataTypeExpressionContext | null;
    public dataTypeExpression(i?: number): DataTypeExpressionContext[] | DataTypeExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(DataTypeExpressionContext);
        }

        return this.getRuleContext(i, DataTypeExpressionContext);
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_structExpression;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterStructExpression) {
             listener.enterStructExpression(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitStructExpression) {
             listener.exitStructExpression(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitStructExpression) {
            return visitor.visitStructExpression(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class RowExpressionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_ROW(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_ROW, 0)!;
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public dataTypeExpression(): DataTypeExpressionContext[];
    public dataTypeExpression(i: number): DataTypeExpressionContext | null;
    public dataTypeExpression(i?: number): DataTypeExpressionContext[] | DataTypeExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(DataTypeExpressionContext);
        }

        return this.getRuleContext(i, DataTypeExpressionContext);
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_rowExpression;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterRowExpression) {
             listener.enterRowExpression(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitRowExpression) {
             listener.exitRowExpression(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitRowExpression) {
            return visitor.visitRowExpression(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class MapExpressionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_MAP(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_MAP, 0)!;
    }
    public LS_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LS_BRACKET, 0)!;
    }
    public dataTypeExpression(): DataTypeExpressionContext[];
    public dataTypeExpression(i: number): DataTypeExpressionContext | null;
    public dataTypeExpression(i?: number): DataTypeExpressionContext[] | DataTypeExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(DataTypeExpressionContext);
        }

        return this.getRuleContext(i, DataTypeExpressionContext);
    }
    public COMMA(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.COMMA, 0)!;
    }
    public RS_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RS_BRACKET, 0)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_mapExpression;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterMapExpression) {
             listener.enterMapExpression(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitMapExpression) {
             listener.exitMapExpression(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitMapExpression) {
            return visitor.visitMapExpression(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class DataTypeExpressionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public columnAlias(): ColumnAliasContext | null {
        return this.getRuleContext(0, ColumnAliasContext);
    }
    public constant(): ConstantContext | null {
        return this.getRuleContext(0, ConstantContext);
    }
    public complexDataTypeExpression(): ComplexDataTypeExpressionContext | null {
        return this.getRuleContext(0, ComplexDataTypeExpressionContext);
    }
    public sqlSimpleType(): SqlSimpleTypeContext | null {
        return this.getRuleContext(0, SqlSimpleTypeContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_dataTypeExpression;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterDataTypeExpression) {
             listener.enterDataTypeExpression(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitDataTypeExpression) {
             listener.exitDataTypeExpression(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitDataTypeExpression) {
            return visitor.visitDataTypeExpression(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class SqlSimpleTypeContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_BOOLEAN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_BOOLEAN, 0);
    }
    public KW_BIGINT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_BIGINT, 0);
    }
    public KW_BYTE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_BYTE, 0);
    }
    public KW_TINYINT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TINYINT, 0);
    }
    public KW_SMALLINT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SMALLINT, 0);
    }
    public KW_INT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_INT, 0);
    }
    public KW_INTEGER(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_INTEGER, 0);
    }
    public KW_FLOAT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FLOAT, 0);
    }
    public KW_DOUBLE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DOUBLE, 0);
    }
    public KW_DATE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DATE, 0);
    }
    public KW_LONG(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LONG, 0);
    }
    public KW_DECIMAL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DECIMAL, 0);
    }
    public KW_NUMERIC(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NUMERIC, 0);
    }
    public KW_TIME(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TIME, 0);
    }
    public KW_TIMESTAMP(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TIMESTAMP, 0);
    }
    public KW_TIMESTAMP_LTZ(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TIMESTAMP_LTZ, 0);
    }
    public KW_TIMESTAMP_NTZ(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TIMESTAMP_NTZ, 0);
    }
    public KW_REAL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_REAL, 0);
    }
    public KW_SHORT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SHORT, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_sqlSimpleType;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterSqlSimpleType) {
             listener.enterSqlSimpleType(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitSqlSimpleType) {
             listener.exitSqlSimpleType(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitSqlSimpleType) {
            return visitor.visitSqlSimpleType(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class FunctionNameContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public nonReservedKeywords(): NonReservedKeywordsContext | null {
        return this.getRuleContext(0, NonReservedKeywordsContext);
    }
    public uid(): UidContext | null {
        return this.getRuleContext(0, UidContext);
    }
    public reservedKeywordsUsedAsFuncName(): ReservedKeywordsUsedAsFuncNameContext | null {
        return this.getRuleContext(0, ReservedKeywordsUsedAsFuncNameContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_functionName;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterFunctionName) {
             listener.enterFunctionName(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitFunctionName) {
             listener.exitFunctionName(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitFunctionName) {
            return visitor.visitFunctionName(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class FunctionParamContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public reservedKeywordsUsedAsFuncParam(): ReservedKeywordsUsedAsFuncParamContext | null {
        return this.getRuleContext(0, ReservedKeywordsUsedAsFuncParamContext);
    }
    public timeIntervalUnit(): TimeIntervalUnitContext | null {
        return this.getRuleContext(0, TimeIntervalUnitContext);
    }
    public timePointUnit(): TimePointUnitContext | null {
        return this.getRuleContext(0, TimePointUnitContext);
    }
    public expression(): ExpressionContext | null {
        return this.getRuleContext(0, ExpressionContext);
    }
    public filterClause(): FilterClauseContext | null {
        return this.getRuleContext(0, FilterClauseContext);
    }
    public constant(): ConstantContext | null {
        return this.getRuleContext(0, ConstantContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_functionParam;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterFunctionParam) {
             listener.enterFunctionParam(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitFunctionParam) {
             listener.exitFunctionParam(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitFunctionParam) {
            return visitor.visitFunctionParam(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class FilterClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_FILTER(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_FILTER, 0)!;
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public KW_WHERE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_WHERE, 0)!;
    }
    public booleanExpression(): BooleanExpressionContext {
        return this.getRuleContext(0, BooleanExpressionContext)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_filterClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterFilterClause) {
             listener.enterFilterClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitFilterClause) {
             listener.exitFilterClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitFilterClause) {
            return visitor.visitFilterClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class CorrelationNameContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public identifier(): IdentifierContext {
        return this.getRuleContext(0, IdentifierContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_correlationName;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterCorrelationName) {
             listener.enterCorrelationName(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitCorrelationName) {
             listener.exitCorrelationName(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitCorrelationName) {
            return visitor.visitCorrelationName(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class QualifiedNameContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public identifier(): IdentifierContext | null {
        return this.getRuleContext(0, IdentifierContext);
    }
    public uid(): UidContext | null {
        return this.getRuleContext(0, UidContext);
    }
    public unquotedAnyString(): UnquotedAnyStringContext | null {
        return this.getRuleContext(0, UnquotedAnyStringContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_qualifiedName;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterQualifiedName) {
             listener.enterQualifiedName(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitQualifiedName) {
             listener.exitQualifiedName(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitQualifiedName) {
            return visitor.visitQualifiedName(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class TimeIntervalExpressionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_INTERVAL(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_INTERVAL, 0)!;
    }
    public errorCapturingMultiUnitsInterval(): ErrorCapturingMultiUnitsIntervalContext | null {
        return this.getRuleContext(0, ErrorCapturingMultiUnitsIntervalContext);
    }
    public errorCapturingUnitToUnitInterval(): ErrorCapturingUnitToUnitIntervalContext | null {
        return this.getRuleContext(0, ErrorCapturingUnitToUnitIntervalContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_timeIntervalExpression;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterTimeIntervalExpression) {
             listener.enterTimeIntervalExpression(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitTimeIntervalExpression) {
             listener.exitTimeIntervalExpression(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitTimeIntervalExpression) {
            return visitor.visitTimeIntervalExpression(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ErrorCapturingMultiUnitsIntervalContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public multiUnitsInterval(): MultiUnitsIntervalContext {
        return this.getRuleContext(0, MultiUnitsIntervalContext)!;
    }
    public unitToUnitInterval(): UnitToUnitIntervalContext | null {
        return this.getRuleContext(0, UnitToUnitIntervalContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_errorCapturingMultiUnitsInterval;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterErrorCapturingMultiUnitsInterval) {
             listener.enterErrorCapturingMultiUnitsInterval(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitErrorCapturingMultiUnitsInterval) {
             listener.exitErrorCapturingMultiUnitsInterval(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitErrorCapturingMultiUnitsInterval) {
            return visitor.visitErrorCapturingMultiUnitsInterval(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class MultiUnitsIntervalContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public intervalValue(): IntervalValueContext[];
    public intervalValue(i: number): IntervalValueContext | null;
    public intervalValue(i?: number): IntervalValueContext[] | IntervalValueContext | null {
        if (i === undefined) {
            return this.getRuleContexts(IntervalValueContext);
        }

        return this.getRuleContext(i, IntervalValueContext);
    }
    public timeIntervalUnit(): TimeIntervalUnitContext[];
    public timeIntervalUnit(i: number): TimeIntervalUnitContext | null;
    public timeIntervalUnit(i?: number): TimeIntervalUnitContext[] | TimeIntervalUnitContext | null {
        if (i === undefined) {
            return this.getRuleContexts(TimeIntervalUnitContext);
        }

        return this.getRuleContext(i, TimeIntervalUnitContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_multiUnitsInterval;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterMultiUnitsInterval) {
             listener.enterMultiUnitsInterval(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitMultiUnitsInterval) {
             listener.exitMultiUnitsInterval(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitMultiUnitsInterval) {
            return visitor.visitMultiUnitsInterval(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ErrorCapturingUnitToUnitIntervalContext extends antlr.ParserRuleContext {
    public _body?: UnitToUnitIntervalContext;
    public _error1?: MultiUnitsIntervalContext;
    public _error2?: UnitToUnitIntervalContext;
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public unitToUnitInterval(): UnitToUnitIntervalContext[];
    public unitToUnitInterval(i: number): UnitToUnitIntervalContext | null;
    public unitToUnitInterval(i?: number): UnitToUnitIntervalContext[] | UnitToUnitIntervalContext | null {
        if (i === undefined) {
            return this.getRuleContexts(UnitToUnitIntervalContext);
        }

        return this.getRuleContext(i, UnitToUnitIntervalContext);
    }
    public multiUnitsInterval(): MultiUnitsIntervalContext | null {
        return this.getRuleContext(0, MultiUnitsIntervalContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_errorCapturingUnitToUnitInterval;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterErrorCapturingUnitToUnitInterval) {
             listener.enterErrorCapturingUnitToUnitInterval(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitErrorCapturingUnitToUnitInterval) {
             listener.exitErrorCapturingUnitToUnitInterval(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitErrorCapturingUnitToUnitInterval) {
            return visitor.visitErrorCapturingUnitToUnitInterval(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class UnitToUnitIntervalContext extends antlr.ParserRuleContext {
    public _value?: IntervalValueContext;
    public _from_?: TimeIntervalUnitContext;
    public _to?: TimeIntervalUnitContext;
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_TO(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_TO, 0)!;
    }
    public intervalValue(): IntervalValueContext {
        return this.getRuleContext(0, IntervalValueContext)!;
    }
    public timeIntervalUnit(): TimeIntervalUnitContext[];
    public timeIntervalUnit(i: number): TimeIntervalUnitContext | null;
    public timeIntervalUnit(i?: number): TimeIntervalUnitContext[] | TimeIntervalUnitContext | null {
        if (i === undefined) {
            return this.getRuleContexts(TimeIntervalUnitContext);
        }

        return this.getRuleContext(i, TimeIntervalUnitContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_unitToUnitInterval;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterUnitToUnitInterval) {
             listener.enterUnitToUnitInterval(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitUnitToUnitInterval) {
             listener.exitUnitToUnitInterval(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitUnitToUnitInterval) {
            return visitor.visitUnitToUnitInterval(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class IntervalValueContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public DIG_LITERAL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.DIG_LITERAL, 0);
    }
    public REAL_LITERAL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.REAL_LITERAL, 0);
    }
    public ADD_SIGN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.ADD_SIGN, 0);
    }
    public HYPNEN_SIGN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.HYPNEN_SIGN, 0);
    }
    public STRING_LITERAL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.STRING_LITERAL, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_intervalValue;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterIntervalValue) {
             listener.enterIntervalValue(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitIntervalValue) {
             listener.exitIntervalValue(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitIntervalValue) {
            return visitor.visitIntervalValue(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ColumnAliasContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public anyAlias(): AnyAliasContext {
        return this.getRuleContext(0, AnyAliasContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_columnAlias;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterColumnAlias) {
             listener.enterColumnAlias(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitColumnAlias) {
             listener.exitColumnAlias(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitColumnAlias) {
            return visitor.visitColumnAlias(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class TableAliasContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public anyAlias(): AnyAliasContext {
        return this.getRuleContext(0, AnyAliasContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_tableAlias;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterTableAlias) {
             listener.enterTableAlias(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitTableAlias) {
             listener.exitTableAlias(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitTableAlias) {
            return visitor.visitTableAlias(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class AnyAliasContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public identifier(): IdentifierContext {
        return this.getRuleContext(0, IdentifierContext)!;
    }
    public KW_AS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_AS, 0);
    }
    public identifierList(): IdentifierListContext | null {
        return this.getRuleContext(0, IdentifierListContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_anyAlias;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterAnyAlias) {
             listener.enterAnyAlias(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitAnyAlias) {
             listener.exitAnyAlias(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitAnyAlias) {
            return visitor.visitAnyAlias(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ErrorCapturingIdentifierContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public identifier(): IdentifierContext {
        return this.getRuleContext(0, IdentifierContext)!;
    }
    public errorCapturingIdentifierExtra(): ErrorCapturingIdentifierExtraContext {
        return this.getRuleContext(0, ErrorCapturingIdentifierExtraContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_errorCapturingIdentifier;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterErrorCapturingIdentifier) {
             listener.enterErrorCapturingIdentifier(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitErrorCapturingIdentifier) {
             listener.exitErrorCapturingIdentifier(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitErrorCapturingIdentifier) {
            return visitor.visitErrorCapturingIdentifier(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ErrorCapturingIdentifierExtraContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_errorCapturingIdentifierExtra;
    }
    public override copyFrom(ctx: ErrorCapturingIdentifierExtraContext): void {
        super.copyFrom(ctx);
    }
}
export class ErrorIdentContext extends ErrorCapturingIdentifierExtraContext {
    public constructor(ctx: ErrorCapturingIdentifierExtraContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public KW_MINUS(): antlr.TerminalNode[];
    public KW_MINUS(i: number): antlr.TerminalNode | null;
    public KW_MINUS(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.KW_MINUS);
    	} else {
    		return this.getToken(SparkSQLParser.KW_MINUS, i);
    	}
    }
    public identifier(): IdentifierContext[];
    public identifier(i: number): IdentifierContext | null;
    public identifier(i?: number): IdentifierContext[] | IdentifierContext | null {
        if (i === undefined) {
            return this.getRuleContexts(IdentifierContext);
        }

        return this.getRuleContext(i, IdentifierContext);
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterErrorIdent) {
             listener.enterErrorIdent(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitErrorIdent) {
             listener.exitErrorIdent(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitErrorIdent) {
            return visitor.visitErrorIdent(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class IdentifierListContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public identifierSeq(): IdentifierSeqContext {
        return this.getRuleContext(0, IdentifierSeqContext)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_identifierList;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterIdentifierList) {
             listener.enterIdentifierList(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitIdentifierList) {
             listener.exitIdentifierList(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitIdentifierList) {
            return visitor.visitIdentifierList(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class IdentifierSeqContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public identifier(): IdentifierContext[];
    public identifier(i: number): IdentifierContext | null;
    public identifier(i?: number): IdentifierContext[] | IdentifierContext | null {
        if (i === undefined) {
            return this.getRuleContexts(IdentifierContext);
        }

        return this.getRuleContext(i, IdentifierContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_identifierSeq;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterIdentifierSeq) {
             listener.enterIdentifierSeq(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitIdentifierSeq) {
             listener.exitIdentifierSeq(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitIdentifierSeq) {
            return visitor.visitIdentifierSeq(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class IdentifierContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_identifier;
    }
    public override copyFrom(ctx: IdentifierContext): void {
        super.copyFrom(ctx);
    }
}
export class QuotedIdentifierAlternativeContext extends IdentifierContext {
    public constructor(ctx: IdentifierContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public STRING_LITERAL(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.STRING_LITERAL, 0)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterQuotedIdentifierAlternative) {
             listener.enterQuotedIdentifierAlternative(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitQuotedIdentifierAlternative) {
             listener.exitQuotedIdentifierAlternative(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitQuotedIdentifierAlternative) {
            return visitor.visitQuotedIdentifierAlternative(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class NonReservedKeywordsAlternativeContext extends IdentifierContext {
    public constructor(ctx: IdentifierContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public nonReservedKeywords(): NonReservedKeywordsContext {
        return this.getRuleContext(0, NonReservedKeywordsContext)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterNonReservedKeywordsAlternative) {
             listener.enterNonReservedKeywordsAlternative(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitNonReservedKeywordsAlternative) {
             listener.exitNonReservedKeywordsAlternative(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitNonReservedKeywordsAlternative) {
            return visitor.visitNonReservedKeywordsAlternative(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class UnquotedIdentifierAlternativeContext extends IdentifierContext {
    public constructor(ctx: IdentifierContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public unquotedIdentifier(): UnquotedIdentifierContext {
        return this.getRuleContext(0, UnquotedIdentifierContext)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterUnquotedIdentifierAlternative) {
             listener.enterUnquotedIdentifierAlternative(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitUnquotedIdentifierAlternative) {
             listener.exitUnquotedIdentifierAlternative(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitUnquotedIdentifierAlternative) {
            return visitor.visitUnquotedIdentifierAlternative(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class UrefVarAlternativeContext extends IdentifierContext {
    public constructor(ctx: IdentifierContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public refVar(): RefVarContext {
        return this.getRuleContext(0, RefVarContext)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterUrefVarAlternative) {
             listener.enterUrefVarAlternative(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitUrefVarAlternative) {
             listener.exitUrefVarAlternative(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitUrefVarAlternative) {
            return visitor.visitUrefVarAlternative(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class UnquotedAnyStringContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public unquotedIdentifier(): UnquotedIdentifierContext | null {
        return this.getRuleContext(0, UnquotedIdentifierContext);
    }
    public reservedKeywordsUsedAsFuncParam(): ReservedKeywordsUsedAsFuncParamContext | null {
        return this.getRuleContext(0, ReservedKeywordsUsedAsFuncParamContext);
    }
    public nonReservedKeywords(): NonReservedKeywordsContext | null {
        return this.getRuleContext(0, NonReservedKeywordsContext);
    }
    public reservedKeywordsUsedAsFuncName(): ReservedKeywordsUsedAsFuncNameContext | null {
        return this.getRuleContext(0, ReservedKeywordsUsedAsFuncNameContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_unquotedAnyString;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterUnquotedAnyString) {
             listener.enterUnquotedAnyString(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitUnquotedAnyString) {
             listener.exitUnquotedAnyString(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitUnquotedAnyString) {
            return visitor.visitUnquotedAnyString(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class RefVarContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public DOLLAR(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.DOLLAR, 0)!;
    }
    public LB_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LB_BRACKET, 0)!;
    }
    public unquotedIdentifier(): UnquotedIdentifierContext {
        return this.getRuleContext(0, UnquotedIdentifierContext)!;
    }
    public RB_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RB_BRACKET, 0)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_refVar;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterRefVar) {
             listener.enterRefVar(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitRefVar) {
             listener.exitRefVar(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitRefVar) {
            return visitor.visitRefVar(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class UnquotedIdentifierContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public DIG_LITERAL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.DIG_LITERAL, 0);
    }
    public ID_LITERAL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.ID_LITERAL, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_unquotedIdentifier;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterUnquotedIdentifier) {
             listener.enterUnquotedIdentifier(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitUnquotedIdentifier) {
             listener.exitUnquotedIdentifier(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitUnquotedIdentifier) {
            return visitor.visitUnquotedIdentifier(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class WhenClauseContext extends antlr.ParserRuleContext {
    public _condition?: ExpressionContext;
    public _result?: ExpressionContext;
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_WHEN(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_WHEN, 0)!;
    }
    public KW_THEN(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_THEN, 0)!;
    }
    public expression(): ExpressionContext[];
    public expression(i: number): ExpressionContext | null;
    public expression(i?: number): ExpressionContext[] | ExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ExpressionContext);
        }

        return this.getRuleContext(i, ExpressionContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_whenClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterWhenClause) {
             listener.enterWhenClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitWhenClause) {
             listener.exitWhenClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitWhenClause) {
            return visitor.visitWhenClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class CatalogPathContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public uid(): UidContext {
        return this.getRuleContext(0, UidContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_catalogPath;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterCatalogPath) {
             listener.enterCatalogPath(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitCatalogPath) {
             listener.exitCatalogPath(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitCatalogPath) {
            return visitor.visitCatalogPath(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class DatabasePathContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public uid(): UidContext {
        return this.getRuleContext(0, UidContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_databasePath;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterDatabasePath) {
             listener.enterDatabasePath(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitDatabasePath) {
             listener.exitDatabasePath(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitDatabasePath) {
            return visitor.visitDatabasePath(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class DatabasePathCreateContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public uid(): UidContext {
        return this.getRuleContext(0, UidContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_databasePathCreate;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterDatabasePathCreate) {
             listener.enterDatabasePathCreate(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitDatabasePathCreate) {
             listener.exitDatabasePathCreate(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitDatabasePathCreate) {
            return visitor.visitDatabasePathCreate(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class TablePathCreateContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public uid(): UidContext {
        return this.getRuleContext(0, UidContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_tablePathCreate;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterTablePathCreate) {
             listener.enterTablePathCreate(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitTablePathCreate) {
             listener.exitTablePathCreate(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitTablePathCreate) {
            return visitor.visitTablePathCreate(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class TablePathContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public uid(): UidContext {
        return this.getRuleContext(0, UidContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_tablePath;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterTablePath) {
             listener.enterTablePath(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitTablePath) {
             listener.exitTablePath(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitTablePath) {
            return visitor.visitTablePath(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class AnonymousWindowsNameContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public identifier(): IdentifierContext {
        return this.getRuleContext(0, IdentifierContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_anonymousWindowsName;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterAnonymousWindowsName) {
             listener.enterAnonymousWindowsName(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitAnonymousWindowsName) {
             listener.exitAnonymousWindowsName(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitAnonymousWindowsName) {
            return visitor.visitAnonymousWindowsName(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class UidContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public identifier(): IdentifierContext[];
    public identifier(i: number): IdentifierContext | null;
    public identifier(i?: number): IdentifierContext[] | IdentifierContext | null {
        if (i === undefined) {
            return this.getRuleContexts(IdentifierContext);
        }

        return this.getRuleContext(i, IdentifierContext);
    }
    public DOT(): antlr.TerminalNode[];
    public DOT(i: number): antlr.TerminalNode | null;
    public DOT(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.DOT);
    	} else {
    		return this.getToken(SparkSQLParser.DOT, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_uid;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterUid) {
             listener.enterUid(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitUid) {
             listener.exitUid(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitUid) {
            return visitor.visitUid(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class WithOptionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_WITH(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_WITH, 0)!;
    }
    public tablePropertyList(): TablePropertyListContext {
        return this.getRuleContext(0, TablePropertyListContext)!;
    }
    public KW_DBPROPERTIES(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DBPROPERTIES, 0);
    }
    public KW_TBLPROPERTIES(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TBLPROPERTIES, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_withOption;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterWithOption) {
             listener.enterWithOption(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitWithOption) {
             listener.exitWithOption(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitWithOption) {
            return visitor.visitWithOption(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class IfNotExistsContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_IF(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_IF, 0)!;
    }
    public KW_NOT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_NOT, 0)!;
    }
    public KW_EXISTS(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_EXISTS, 0)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_ifNotExists;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterIfNotExists) {
             listener.enterIfNotExists(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitIfNotExists) {
             listener.exitIfNotExists(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitIfNotExists) {
            return visitor.visitIfNotExists(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class IfExistsContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_IF(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_IF, 0)!;
    }
    public KW_EXISTS(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_EXISTS, 0)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_ifExists;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterIfExists) {
             listener.enterIfExists(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitIfExists) {
             listener.exitIfExists(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitIfExists) {
            return visitor.visitIfExists(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class TablePropertyListContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public tableProperty(): TablePropertyContext[];
    public tableProperty(i: number): TablePropertyContext | null;
    public tableProperty(i?: number): TablePropertyContext[] | TablePropertyContext | null {
        if (i === undefined) {
            return this.getRuleContexts(TablePropertyContext);
        }

        return this.getRuleContext(i, TablePropertyContext);
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_tablePropertyList;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterTablePropertyList) {
             listener.enterTablePropertyList(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitTablePropertyList) {
             listener.exitTablePropertyList(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitTablePropertyList) {
            return visitor.visitTablePropertyList(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class TablePropertyContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public tablePropertyKey(): TablePropertyKeyContext {
        return this.getRuleContext(0, TablePropertyKeyContext)!;
    }
    public EQUAL_SYMBOL(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.EQUAL_SYMBOL, 0)!;
    }
    public tablePropertyValue(): TablePropertyValueContext {
        return this.getRuleContext(0, TablePropertyValueContext)!;
    }
    public KW_DATE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DATE, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_tableProperty;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterTableProperty) {
             listener.enterTableProperty(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitTableProperty) {
             listener.exitTableProperty(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitTableProperty) {
            return visitor.visitTableProperty(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class TablePropertyKeyContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public identifier(): IdentifierContext | null {
        return this.getRuleContext(0, IdentifierContext);
    }
    public uid(): UidContext | null {
        return this.getRuleContext(0, UidContext);
    }
    public stringLiteral(): StringLiteralContext | null {
        return this.getRuleContext(0, StringLiteralContext);
    }
    public functionParam(): FunctionParamContext | null {
        return this.getRuleContext(0, FunctionParamContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_tablePropertyKey;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterTablePropertyKey) {
             listener.enterTablePropertyKey(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitTablePropertyKey) {
             listener.exitTablePropertyKey(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitTablePropertyKey) {
            return visitor.visitTablePropertyKey(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class PropertyNameContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public SINGLE_QUOTE_SYMB(): antlr.TerminalNode[];
    public SINGLE_QUOTE_SYMB(i: number): antlr.TerminalNode | null;
    public SINGLE_QUOTE_SYMB(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.SINGLE_QUOTE_SYMB);
    	} else {
    		return this.getToken(SparkSQLParser.SINGLE_QUOTE_SYMB, i);
    	}
    }
    public constant(): ConstantContext {
        return this.getRuleContext(0, ConstantContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_propertyName;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterPropertyName) {
             listener.enterPropertyName(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitPropertyName) {
             listener.exitPropertyName(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitPropertyName) {
            return visitor.visitPropertyName(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class TablePropertyValueContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public DIG_LITERAL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.DIG_LITERAL, 0);
    }
    public REAL_LITERAL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.REAL_LITERAL, 0);
    }
    public booleanLiteral(): BooleanLiteralContext | null {
        return this.getRuleContext(0, BooleanLiteralContext);
    }
    public uid(): UidContext | null {
        return this.getRuleContext(0, UidContext);
    }
    public constant(): ConstantContext | null {
        return this.getRuleContext(0, ConstantContext);
    }
    public refVar(): RefVarContext | null {
        return this.getRuleContext(0, RefVarContext);
    }
    public SINGLE_QUOTE_SYMB(): antlr.TerminalNode[];
    public SINGLE_QUOTE_SYMB(i: number): antlr.TerminalNode | null;
    public SINGLE_QUOTE_SYMB(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.SINGLE_QUOTE_SYMB);
    	} else {
    		return this.getToken(SparkSQLParser.SINGLE_QUOTE_SYMB, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_tablePropertyValue;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterTablePropertyValue) {
             listener.enterTablePropertyValue(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitTablePropertyValue) {
             listener.exitTablePropertyValue(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitTablePropertyValue) {
            return visitor.visitTablePropertyValue(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ComparisonOperatorContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public EQUAL_SYMBOL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.EQUAL_SYMBOL, 0);
    }
    public GREATER_SYMBOL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.GREATER_SYMBOL, 0);
    }
    public LESS_SYMBOL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.LESS_SYMBOL, 0);
    }
    public EXCLAMATION_SYMBOL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.EXCLAMATION_SYMBOL, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_comparisonOperator;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterComparisonOperator) {
             listener.enterComparisonOperator(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitComparisonOperator) {
             listener.exitComparisonOperator(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitComparisonOperator) {
            return visitor.visitComparisonOperator(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ConstantContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public timeIntervalExpression(): TimeIntervalExpressionContext | null {
        return this.getRuleContext(0, TimeIntervalExpressionContext);
    }
    public timePointLiteral(): TimePointLiteralContext | null {
        return this.getRuleContext(0, TimePointLiteralContext);
    }
    public stringLiteral(): StringLiteralContext | null {
        return this.getRuleContext(0, StringLiteralContext);
    }
    public decimalLiteral(): DecimalLiteralContext | null {
        return this.getRuleContext(0, DecimalLiteralContext);
    }
    public HYPNEN_SIGN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.HYPNEN_SIGN, 0);
    }
    public booleanLiteral(): BooleanLiteralContext | null {
        return this.getRuleContext(0, BooleanLiteralContext);
    }
    public REAL_LITERAL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.REAL_LITERAL, 0);
    }
    public KW_NULL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NULL, 0);
    }
    public KW_NOT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NOT, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_constant;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterConstant) {
             listener.enterConstant(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitConstant) {
             listener.exitConstant(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitConstant) {
            return visitor.visitConstant(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class TimePointLiteralContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public timePointUnit(): TimePointUnitContext {
        return this.getRuleContext(0, TimePointUnitContext)!;
    }
    public stringLiteral(): StringLiteralContext {
        return this.getRuleContext(0, StringLiteralContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_timePointLiteral;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterTimePointLiteral) {
             listener.enterTimePointLiteral(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitTimePointLiteral) {
             listener.exitTimePointLiteral(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitTimePointLiteral) {
            return visitor.visitTimePointLiteral(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class StringLiteralContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public STRING_LITERAL(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.STRING_LITERAL, 0)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_stringLiteral;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterStringLiteral) {
             listener.enterStringLiteral(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitStringLiteral) {
             listener.exitStringLiteral(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitStringLiteral) {
            return visitor.visitStringLiteral(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class DecimalLiteralContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public DIG_LITERAL(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.DIG_LITERAL, 0)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_decimalLiteral;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterDecimalLiteral) {
             listener.enterDecimalLiteral(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitDecimalLiteral) {
             listener.exitDecimalLiteral(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitDecimalLiteral) {
            return visitor.visitDecimalLiteral(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class BooleanLiteralContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_TRUE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TRUE, 0);
    }
    public KW_FALSE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FALSE, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_booleanLiteral;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterBooleanLiteral) {
             listener.enterBooleanLiteral(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitBooleanLiteral) {
             listener.exitBooleanLiteral(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitBooleanLiteral) {
            return visitor.visitBooleanLiteral(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class SetQuantifierContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_DISTINCT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DISTINCT, 0);
    }
    public KW_ALL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ALL, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_setQuantifier;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterSetQuantifier) {
             listener.enterSetQuantifier(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitSetQuantifier) {
             listener.exitSetQuantifier(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitSetQuantifier) {
            return visitor.visitSetQuantifier(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class TimePointUnitContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_YEAR(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_YEAR, 0);
    }
    public KW_QUARTER(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_QUARTER, 0);
    }
    public KW_MONTH(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MONTH, 0);
    }
    public KW_WEEK(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_WEEK, 0);
    }
    public KW_DAY(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DAY, 0);
    }
    public KW_HOUR(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_HOUR, 0);
    }
    public KW_MINUTE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MINUTE, 0);
    }
    public KW_SECOND(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SECOND, 0);
    }
    public KW_MILLISECOND(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MILLISECOND, 0);
    }
    public KW_MICROSECOND(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MICROSECOND, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_timePointUnit;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterTimePointUnit) {
             listener.enterTimePointUnit(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitTimePointUnit) {
             listener.exitTimePointUnit(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitTimePointUnit) {
            return visitor.visitTimePointUnit(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class TimeIntervalUnitContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_MILLENNIUM(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MILLENNIUM, 0);
    }
    public KW_CENTURY(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_CENTURY, 0);
    }
    public KW_DECADE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DECADE, 0);
    }
    public KW_YEAR(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_YEAR, 0);
    }
    public KW_YEARS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_YEARS, 0);
    }
    public KW_QUARTER(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_QUARTER, 0);
    }
    public KW_MONTH(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MONTH, 0);
    }
    public KW_MONTHS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MONTHS, 0);
    }
    public KW_WEEK(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_WEEK, 0);
    }
    public KW_WEEKS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_WEEKS, 0);
    }
    public KW_DAY(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DAY, 0);
    }
    public KW_DAYS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DAYS, 0);
    }
    public KW_HOUR(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_HOUR, 0);
    }
    public KW_HOURS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_HOURS, 0);
    }
    public KW_MINUTE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MINUTE, 0);
    }
    public KW_MINUTES(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MINUTES, 0);
    }
    public KW_SECOND(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SECOND, 0);
    }
    public KW_SECONDS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SECONDS, 0);
    }
    public KW_MILLISECOND(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MILLISECOND, 0);
    }
    public KW_MICROSECOND(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MICROSECOND, 0);
    }
    public KW_NANOSECOND(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NANOSECOND, 0);
    }
    public KW_EPOCH(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_EPOCH, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_timeIntervalUnit;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterTimeIntervalUnit) {
             listener.enterTimeIntervalUnit(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitTimeIntervalUnit) {
             listener.exitTimeIntervalUnit(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitTimeIntervalUnit) {
            return visitor.visitTimeIntervalUnit(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ReservedKeywordsUsedAsFuncParamContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_LEADING(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LEADING, 0);
    }
    public KW_TRAILING(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TRAILING, 0);
    }
    public KW_BOTH(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_BOTH, 0);
    }
    public KW_ALL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ALL, 0);
    }
    public KW_DISTINCT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DISTINCT, 0);
    }
    public ASTERISK_SIGN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.ASTERISK_SIGN, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_reservedKeywordsUsedAsFuncParam;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterReservedKeywordsUsedAsFuncParam) {
             listener.enterReservedKeywordsUsedAsFuncParam(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitReservedKeywordsUsedAsFuncParam) {
             listener.exitReservedKeywordsUsedAsFuncParam(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitReservedKeywordsUsedAsFuncParam) {
            return visitor.visitReservedKeywordsUsedAsFuncParam(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ReservedKeywordsUsedAsFuncNameContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_ABS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ABS, 0);
    }
    public KW_ARRAY(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ARRAY, 0);
    }
    public KW_AVG(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_AVG, 0);
    }
    public KW_CAST(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_CAST, 0);
    }
    public KW_CEIL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_CEIL, 0);
    }
    public KW_COALESCE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_COALESCE, 0);
    }
    public KW_COLLECT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_COLLECT, 0);
    }
    public KW_COUNT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_COUNT, 0);
    }
    public KW_CURRENT_TIMESTAMP(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_CURRENT_TIMESTAMP, 0);
    }
    public KW_DATE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DATE, 0);
    }
    public KW_EXPLODE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_EXPLODE, 0);
    }
    public KW_FIRST_VALUE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FIRST_VALUE, 0);
    }
    public KW_FROM_UNIXTIME(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FROM_UNIXTIME, 0);
    }
    public KW_GROUPING(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_GROUPING, 0);
    }
    public KW_HOUR(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_HOUR, 0);
    }
    public KW_IF(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_IF, 0);
    }
    public KW_LEAD(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LEAD, 0);
    }
    public KW_LAG(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LAG, 0);
    }
    public KW_LAST_VALUE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LAST_VALUE, 0);
    }
    public KW_LEFT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LEFT, 0);
    }
    public KW_NTILE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NTILE, 0);
    }
    public KW_MAP(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MAP, 0);
    }
    public KW_MINUTE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MINUTE, 0);
    }
    public KW_MONTH(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MONTH, 0);
    }
    public KW_OVERLAY(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_OVERLAY, 0);
    }
    public KW_POSITION(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_POSITION, 0);
    }
    public KW_PERCENT_RANK(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PERCENT_RANK, 0);
    }
    public KW_PERCENTILE_CONT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PERCENTILE_CONT, 0);
    }
    public KW_PERCENTILE_DISC(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PERCENTILE_DISC, 0);
    }
    public KW_POWER(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_POWER, 0);
    }
    public KW_QUARTER(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_QUARTER, 0);
    }
    public KW_RANK(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_RANK, 0);
    }
    public KW_ROW_NUMBER(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ROW_NUMBER, 0);
    }
    public KW_RANGE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_RANGE, 0);
    }
    public KW_RIGHT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_RIGHT, 0);
    }
    public KW_SECOND(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SECOND, 0);
    }
    public KW_SUBSTRING(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SUBSTRING, 0);
    }
    public KW_SUM(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SUM, 0);
    }
    public KW_TIME(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TIME, 0);
    }
    public KW_TIMESTAMP(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TIMESTAMP, 0);
    }
    public KW_TIMESTAMP_3(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TIMESTAMP_3, 0);
    }
    public KW_TIMESTAMP_6(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TIMESTAMP_6, 0);
    }
    public KW_TIMESTAMP_9(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TIMESTAMP_9, 0);
    }
    public KW_TRUNCATE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TRUNCATE, 0);
    }
    public KW_UPPER(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_UPPER, 0);
    }
    public KW_WEEK(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_WEEK, 0);
    }
    public KW_YEAR(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_YEAR, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_reservedKeywordsUsedAsFuncName;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterReservedKeywordsUsedAsFuncName) {
             listener.enterReservedKeywordsUsedAsFuncName(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitReservedKeywordsUsedAsFuncName) {
             listener.exitReservedKeywordsUsedAsFuncName(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitReservedKeywordsUsedAsFuncName) {
            return visitor.visitReservedKeywordsUsedAsFuncName(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class NonReservedKeywordsContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_ADD(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ADD, 0);
    }
    public KW_ADMIN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ADMIN, 0);
    }
    public KW_AFTER(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_AFTER, 0);
    }
    public KW_ANALYZE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ANALYZE, 0);
    }
    public KW_ASC(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ASC, 0);
    }
    public KW_BEFORE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_BEFORE, 0);
    }
    public KW_BYTES(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_BYTES, 0);
    }
    public KW_CASCADE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_CASCADE, 0);
    }
    public KW_CATALOG(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_CATALOG, 0);
    }
    public KW_CATALOGS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_CATALOGS, 0);
    }
    public KW_CENTURY(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_CENTURY, 0);
    }
    public KW_CHAIN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_CHAIN, 0);
    }
    public KW_CHANGELOG_MODE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_CHANGELOG_MODE, 0);
    }
    public KW_CHARACTERS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_CHARACTERS, 0);
    }
    public KW_COMMENT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_COMMENT, 0);
    }
    public KW_COMPACT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_COMPACT, 0);
    }
    public KW_COMPUTE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_COMPUTE, 0);
    }
    public KW_COLUMNS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_COLUMNS, 0);
    }
    public KW_CONSTRAINTS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_CONSTRAINTS, 0);
    }
    public KW_CONSTRUCTOR(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_CONSTRUCTOR, 0);
    }
    public KW_CUMULATE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_CUMULATE, 0);
    }
    public KW_DATA(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DATA, 0);
    }
    public KW_DATABASE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DATABASE, 0);
    }
    public KW_DATABASES(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DATABASES, 0);
    }
    public KW_DAYS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DAYS, 0);
    }
    public KW_DECADE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DECADE, 0);
    }
    public KW_DEFINED(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DEFINED, 0);
    }
    public KW_DESC(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DESC, 0);
    }
    public KW_DESCRIPTOR(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DESCRIPTOR, 0);
    }
    public KW_DIV(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DIV, 0);
    }
    public KW_ENCODING(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ENCODING, 0);
    }
    public KW_ENFORCED(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ENFORCED, 0);
    }
    public KW_ENGINE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ENGINE, 0);
    }
    public KW_ERROR(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ERROR, 0);
    }
    public KW_ESTIMATED_COST(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ESTIMATED_COST, 0);
    }
    public KW_EXCEPTION(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_EXCEPTION, 0);
    }
    public KW_EXCLUDE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_EXCLUDE, 0);
    }
    public KW_EXCLUDING(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_EXCLUDING, 0);
    }
    public KW_EXTENDED(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_EXTENDED, 0);
    }
    public KW_FILE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FILE, 0);
    }
    public KW_FINAL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FINAL, 0);
    }
    public KW_FIRST(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FIRST, 0);
    }
    public KW_FOLLOWING(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FOLLOWING, 0);
    }
    public KW_FORMAT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FORMAT, 0);
    }
    public KW_FORTRAN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FORTRAN, 0);
    }
    public KW_FOUND(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FOUND, 0);
    }
    public KW_FRAC_SECOND(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FRAC_SECOND, 0);
    }
    public KW_FUNCTIONS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FUNCTIONS, 0);
    }
    public KW_GENERAL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_GENERAL, 0);
    }
    public KW_GENERATED(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_GENERATED, 0);
    }
    public KW_GO(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_GO, 0);
    }
    public KW_GOTO(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_GOTO, 0);
    }
    public KW_GRANTED(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_GRANTED, 0);
    }
    public KW_HOP(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_HOP, 0);
    }
    public KW_HOURS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_HOURS, 0);
    }
    public KW_IF(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_IF, 0);
    }
    public KW_IGNORE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_IGNORE, 0);
    }
    public KW_INCREMENT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_INCREMENT, 0);
    }
    public KW_INPUT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_INPUT, 0);
    }
    public KW_INVOKER(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_INVOKER, 0);
    }
    public KW_JAR(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_JAR, 0);
    }
    public KW_JARS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_JARS, 0);
    }
    public KW_JAVA(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_JAVA, 0);
    }
    public KW_JSON(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_JSON, 0);
    }
    public KW_JSON_EXECUTION_PLAN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_JSON_EXECUTION_PLAN, 0);
    }
    public KW_KEY(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_KEY, 0);
    }
    public KW_KEY_MEMBER(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_KEY_MEMBER, 0);
    }
    public KW_KEY_TYPE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_KEY_TYPE, 0);
    }
    public KW_LABEL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LABEL, 0);
    }
    public KW_LAST(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LAST, 0);
    }
    public KW_LENGTH(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LENGTH, 0);
    }
    public KW_LEVEL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LEVEL, 0);
    }
    public KW_LOAD(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LOAD, 0);
    }
    public KW_LOCALTIMESTAMP(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LOCALTIMESTAMP, 0);
    }
    public KW_MAP(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MAP, 0);
    }
    public KW_MICROSECOND(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MICROSECOND, 0);
    }
    public KW_MILLENNIUM(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MILLENNIUM, 0);
    }
    public KW_MILLISECOND(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MILLISECOND, 0);
    }
    public KW_MINUTES(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MINUTES, 0);
    }
    public KW_MINVALUE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MINVALUE, 0);
    }
    public KW_MODIFY(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MODIFY, 0);
    }
    public KW_MODULES(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MODULES, 0);
    }
    public KW_MONTHS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MONTHS, 0);
    }
    public KW_NANOSECOND(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NANOSECOND, 0);
    }
    public KW_NULLS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NULLS, 0);
    }
    public KW_NUMBER(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NUMBER, 0);
    }
    public KW_OPTION(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_OPTION, 0);
    }
    public KW_OPTIONS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_OPTIONS, 0);
    }
    public KW_ORDERING(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ORDERING, 0);
    }
    public KW_OUTPUT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_OUTPUT, 0);
    }
    public KW_OVERWRITE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_OVERWRITE, 0);
    }
    public KW_OVERWRITING(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_OVERWRITING, 0);
    }
    public KW_PARTITIONED(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PARTITIONED, 0);
    }
    public KW_PARTITIONS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PARTITIONS, 0);
    }
    public KW_PASSING(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PASSING, 0);
    }
    public KW_PAST(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PAST, 0);
    }
    public KW_PATH(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PATH, 0);
    }
    public KW_PLACING(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PLACING, 0);
    }
    public KW_PLAN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PLAN, 0);
    }
    public KW_PRECEDING(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PRECEDING, 0);
    }
    public KW_PRESERVE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PRESERVE, 0);
    }
    public KW_PRIOR(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PRIOR, 0);
    }
    public KW_PRIVILEGES(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PRIVILEGES, 0);
    }
    public KW_PUBLIC(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PUBLIC, 0);
    }
    public KW_PYTHON(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PYTHON, 0);
    }
    public KW_PYTHON_FILES(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PYTHON_FILES, 0);
    }
    public KW_PYTHON_REQUIREMENTS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PYTHON_REQUIREMENTS, 0);
    }
    public KW_PYTHON_DEPENDENCIES(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PYTHON_DEPENDENCIES, 0);
    }
    public KW_PYTHON_JAR(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PYTHON_JAR, 0);
    }
    public KW_PYTHON_ARCHIVES(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PYTHON_ARCHIVES, 0);
    }
    public KW_PYTHON_PARAMETER(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PYTHON_PARAMETER, 0);
    }
    public KW_QUARTER(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_QUARTER, 0);
    }
    public KW_RAW(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_RAW, 0);
    }
    public KW_READ(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_READ, 0);
    }
    public KW_RELATIVE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_RELATIVE, 0);
    }
    public KW_REMOVE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_REMOVE, 0);
    }
    public KW_RENAME(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_RENAME, 0);
    }
    public KW_REPLACE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_REPLACE, 0);
    }
    public KW_RESPECT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_RESPECT, 0);
    }
    public KW_RESTART(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_RESTART, 0);
    }
    public KW_RESTRICT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_RESTRICT, 0);
    }
    public KW_ROLE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ROLE, 0);
    }
    public KW_ROW_COUNT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ROW_COUNT, 0);
    }
    public KW_SCALA(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SCALA, 0);
    }
    public KW_SCALAR(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SCALAR, 0);
    }
    public KW_SCALE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SCALE, 0);
    }
    public KW_SCHEMA(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SCHEMA, 0);
    }
    public KW_SECONDS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SECONDS, 0);
    }
    public KW_SECTION(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SECTION, 0);
    }
    public KW_SECURITY(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SECURITY, 0);
    }
    public KW_SELF(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SELF, 0);
    }
    public KW_SERVER(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SERVER, 0);
    }
    public KW_SERVER_NAME(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SERVER_NAME, 0);
    }
    public KW_SESSION(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SESSION, 0);
    }
    public KW_SETS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SETS, 0);
    }
    public KW_SIMPLE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SIMPLE, 0);
    }
    public KW_SIZE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SIZE, 0);
    }
    public KW_SLIDE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SLIDE, 0);
    }
    public KW_SOURCE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SOURCE, 0);
    }
    public KW_SPACE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SPACE, 0);
    }
    public KW_STATE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_STATE, 0);
    }
    public KW_STATEMENT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_STATEMENT, 0);
    }
    public KW_STEP(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_STEP, 0);
    }
    public KW_STRING(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_STRING, 0);
    }
    public KW_STRUCTURE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_STRUCTURE, 0);
    }
    public KW_STYLE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_STYLE, 0);
    }
    public KW_TABLES(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TABLES, 0);
    }
    public KW_TEMPORARY(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TEMPORARY, 0);
    }
    public KW_TIMECOL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TIMECOL, 0);
    }
    public KW_FLOOR(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FLOOR, 0);
    }
    public KW_TIMESTAMP_LTZ(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TIMESTAMP_LTZ, 0);
    }
    public KW_TIMESTAMPADD(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TIMESTAMPADD, 0);
    }
    public KW_TIMESTAMPDIFF(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TIMESTAMPDIFF, 0);
    }
    public KW_TOTIMESTAMP(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TOTIMESTAMP, 0);
    }
    public KW_TRANSFORM(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TRANSFORM, 0);
    }
    public KW_TUMBLE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TUMBLE, 0);
    }
    public KW_TYPE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TYPE, 0);
    }
    public KW_UNDER(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_UNDER, 0);
    }
    public KW_UNLOAD(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_UNLOAD, 0);
    }
    public KW_USAGE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_USAGE, 0);
    }
    public KW_USE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_USE, 0);
    }
    public KW_UTF16(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_UTF16, 0);
    }
    public KW_UTF32(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_UTF32, 0);
    }
    public KW_UTF8(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_UTF8, 0);
    }
    public KW_VERSION(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_VERSION, 0);
    }
    public KW_VIEW(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_VIEW, 0);
    }
    public KW_VIEWS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_VIEWS, 0);
    }
    public KW_VIRTUAL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_VIRTUAL, 0);
    }
    public KW_WATERMARK(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_WATERMARK, 0);
    }
    public KW_WATERMARKS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_WATERMARKS, 0);
    }
    public KW_WEEK(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_WEEK, 0);
    }
    public KW_WORK(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_WORK, 0);
    }
    public KW_WRAPPER(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_WRAPPER, 0);
    }
    public KW_YEARS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_YEARS, 0);
    }
    public KW_ZONE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ZONE, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_nonReservedKeywords;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterNonReservedKeywords) {
             listener.enterNonReservedKeywords(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitNonReservedKeywords) {
             listener.exitNonReservedKeywords(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitNonReservedKeywords) {
            return visitor.visitNonReservedKeywords(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class SqlStatementContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public SEMICOLON(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.SEMICOLON, 0)!;
    }
    public dmlStatement(): DmlStatementContext | null {
        return this.getRuleContext(0, DmlStatementContext);
    }
    public createStatement(): CreateStatementContext | null {
        return this.getRuleContext(0, CreateStatementContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_sqlStatement;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterSqlStatement) {
             listener.enterSqlStatement(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitSqlStatement) {
             listener.exitSqlStatement(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitSqlStatement) {
            return visitor.visitSqlStatement(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class SelectStatementContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_selectStatement;
    }
    public override copyFrom(ctx: SelectStatementContext): void {
        super.copyFrom(ctx);
    }
}
export class TableSampleContext extends SelectStatementContext {
    public constructor(ctx: SelectStatementContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public selectClause(): SelectClauseContext {
        return this.getRuleContext(0, SelectClauseContext)!;
    }
    public fromClause(): FromClauseContext {
        return this.getRuleContext(0, FromClauseContext)!;
    }
    public samplingQueries(): SamplingQueriesContext {
        return this.getRuleContext(0, SamplingQueriesContext)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterTableSample) {
             listener.enterTableSample(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitTableSample) {
             listener.exitTableSample(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitTableSample) {
            return visitor.visitTableSample(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class SparkStyleSelectContext extends SelectStatementContext {
    public constructor(ctx: SelectStatementContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public fromClause(): FromClauseContext {
        return this.getRuleContext(0, FromClauseContext)!;
    }
    public selectClause(): SelectClauseContext {
        return this.getRuleContext(0, SelectClauseContext)!;
    }
    public whereClause(): WhereClauseContext | null {
        return this.getRuleContext(0, WhereClauseContext);
    }
    public someByClause(): SomeByClauseContext | null {
        return this.getRuleContext(0, SomeByClauseContext);
    }
    public havingClause(): HavingClauseContext | null {
        return this.getRuleContext(0, HavingClauseContext);
    }
    public windowClause(): WindowClauseContext | null {
        return this.getRuleContext(0, WindowClauseContext);
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterSparkStyleSelect) {
             listener.enterSparkStyleSelect(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitSparkStyleSelect) {
             listener.exitSparkStyleSelect(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitSparkStyleSelect) {
            return visitor.visitSparkStyleSelect(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class MatchRecognizeSelectContext extends SelectStatementContext {
    public constructor(ctx: SelectStatementContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public selectClause(): SelectClauseContext {
        return this.getRuleContext(0, SelectClauseContext)!;
    }
    public fromClause(): FromClauseContext {
        return this.getRuleContext(0, FromClauseContext)!;
    }
    public matchRecognizeClause(): MatchRecognizeClauseContext {
        return this.getRuleContext(0, MatchRecognizeClauseContext)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterMatchRecognizeSelect) {
             listener.enterMatchRecognizeSelect(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitMatchRecognizeSelect) {
             listener.exitMatchRecognizeSelect(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitMatchRecognizeSelect) {
            return visitor.visitMatchRecognizeSelect(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class CommonSelectContext extends SelectStatementContext {
    public constructor(ctx: SelectStatementContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public selectClause(): SelectClauseContext {
        return this.getRuleContext(0, SelectClauseContext)!;
    }
    public fromClause(): FromClauseContext {
        return this.getRuleContext(0, FromClauseContext)!;
    }
    public whereClause(): WhereClauseContext | null {
        return this.getRuleContext(0, WhereClauseContext);
    }
    public someByClause(): SomeByClauseContext | null {
        return this.getRuleContext(0, SomeByClauseContext);
    }
    public havingClause(): HavingClauseContext | null {
        return this.getRuleContext(0, HavingClauseContext);
    }
    public windowClause(): WindowClauseContext | null {
        return this.getRuleContext(0, WindowClauseContext);
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterCommonSelect) {
             listener.enterCommonSelect(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitCommonSelect) {
             listener.exitCommonSelect(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitCommonSelect) {
            return visitor.visitCommonSelect(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ProjectItemDefinitionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_projectItemDefinition;
    }
    public override copyFrom(ctx: ProjectItemDefinitionContext): void {
        super.copyFrom(ctx);
    }
}
export class WindowsProrjectItemContext extends ProjectItemDefinitionContext {
    public constructor(ctx: ProjectItemDefinitionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public overWindowItem(): OverWindowItemContext {
        return this.getRuleContext(0, OverWindowItemContext)!;
    }
    public identifier(): IdentifierContext | null {
        return this.getRuleContext(0, IdentifierContext);
    }
    public KW_AS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_AS, 0);
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterWindowsProrjectItem) {
             listener.enterWindowsProrjectItem(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitWindowsProrjectItem) {
             listener.exitWindowsProrjectItem(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitWindowsProrjectItem) {
            return visitor.visitWindowsProrjectItem(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class ExpressionProjectItemContext extends ProjectItemDefinitionContext {
    public constructor(ctx: ProjectItemDefinitionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public expression(): ExpressionContext[];
    public expression(i: number): ExpressionContext | null;
    public expression(i?: number): ExpressionContext[] | ExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ExpressionContext);
        }

        return this.getRuleContext(i, ExpressionContext);
    }
    public KW_AS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_AS, 0);
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterExpressionProjectItem) {
             listener.enterExpressionProjectItem(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitExpressionProjectItem) {
             listener.exitExpressionProjectItem(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitExpressionProjectItem) {
            return visitor.visitExpressionProjectItem(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
