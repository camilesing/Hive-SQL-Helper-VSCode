// Generated from gen/SparkSQL.g4 by ANTLR 4.13.1

import * as antlr from "antlr4ng";
import { Token } from "antlr4ng";

import { SparkSQLListener } from "./SparkSQLListener.js";
import { SparkSQLVisitor } from "./SparkSQLVisitor.js";

// for running tests with parameters, TODO: discuss strategy for typed parameters in CI
// eslint-disable-next-line no-unused-vars
type int = number;


export class SparkSQLParser extends antlr.Parser {
    public static readonly SPACE = 1;
    public static readonly COMMENT_INPUT = 2;
    public static readonly LINE_COMMENT = 3;
    public static readonly KW_ADD = 4;
    public static readonly KW_ADMIN = 5;
    public static readonly KW_AFTER = 6;
    public static readonly KW_ANALYZE = 7;
    public static readonly KW_ASC = 8;
    public static readonly KW_BEFORE = 9;
    public static readonly KW_BYTE = 10;
    public static readonly KW_BYTES = 11;
    public static readonly KW_CACHE = 12;
    public static readonly KW_CASCADE = 13;
    public static readonly KW_CATALOG = 14;
    public static readonly KW_CATALOGS = 15;
    public static readonly KW_CLEAR = 16;
    public static readonly KW_CENTURY = 17;
    public static readonly KW_CHAIN = 18;
    public static readonly KW_CHANGELOG_MODE = 19;
    public static readonly KW_CHARACTERS = 20;
    public static readonly KW_COMMENT = 21;
    public static readonly KW_COMPACT = 22;
    public static readonly KW_COLUMNS = 23;
    public static readonly KW_CONSTRAINTS = 24;
    public static readonly KW_CONSTRUCTOR = 25;
    public static readonly KW_COMPUTE = 26;
    public static readonly KW_CUMULATE = 27;
    public static readonly KW_DATA = 28;
    public static readonly KW_DATABASE = 29;
    public static readonly KW_DATABASES = 30;
    public static readonly KW_DAYS = 31;
    public static readonly KW_DBPROPERTIES = 32;
    public static readonly KW_DECADE = 33;
    public static readonly KW_DEFINED = 34;
    public static readonly KW_DESC = 35;
    public static readonly KW_DESCRIPTOR = 36;
    public static readonly KW_DIV = 37;
    public static readonly KW_ENCODING = 38;
    public static readonly KW_ENFORCED = 39;
    public static readonly KW_ENGINE = 40;
    public static readonly KW_EPOCH = 41;
    public static readonly KW_ERROR = 42;
    public static readonly KW_ESTIMATED_COST = 43;
    public static readonly KW_EXCEPTION = 44;
    public static readonly KW_EXCLUDE = 45;
    public static readonly KW_EXCLUDING = 46;
    public static readonly KW_EXTENDED = 47;
    public static readonly KW_FILTER = 48;
    public static readonly KW_FILE = 49;
    public static readonly KW_FILES = 50;
    public static readonly KW_FINAL = 51;
    public static readonly KW_FIRST = 52;
    public static readonly KW_FOLLOWING = 53;
    public static readonly KW_FORMAT = 54;
    public static readonly KW_FORTRAN = 55;
    public static readonly KW_FOUND = 56;
    public static readonly KW_FRAC_SECOND = 57;
    public static readonly KW_FUNCTIONS = 58;
    public static readonly KW_GENERAL = 59;
    public static readonly KW_GENERATED = 60;
    public static readonly KW_GO = 61;
    public static readonly KW_GOTO = 62;
    public static readonly KW_GRANTED = 63;
    public static readonly KW_HOP = 64;
    public static readonly KW_HOURS = 65;
    public static readonly KW_IF = 66;
    public static readonly KW_IGNORE = 67;
    public static readonly KW_INCLUDE = 68;
    public static readonly KW_INCREMENT = 69;
    public static readonly KW_INPUT = 70;
    public static readonly KW_INVOKER = 71;
    public static readonly KW_JAR = 72;
    public static readonly KW_JARS = 73;
    public static readonly KW_JAVA = 74;
    public static readonly KW_JSON = 75;
    public static readonly KW_JSON_EXECUTION_PLAN = 76;
    public static readonly KW_KEY = 77;
    public static readonly KW_KEYS = 78;
    public static readonly KW_KEY_MEMBER = 79;
    public static readonly KW_KEY_TYPE = 80;
    public static readonly KW_LABEL = 81;
    public static readonly KW_LAST = 82;
    public static readonly KW_LENGTH = 83;
    public static readonly KW_LEVEL = 84;
    public static readonly KW_LIST = 85;
    public static readonly KW_LOAD = 86;
    public static readonly KW_LOCATION = 87;
    public static readonly KW_LONG = 88;
    public static readonly KW_MAP = 89;
    public static readonly KW_MICROSECOND = 90;
    public static readonly KW_MILLENNIUM = 91;
    public static readonly KW_MILLISECOND = 92;
    public static readonly KW_MINUTES = 93;
    public static readonly KW_MINVALUE = 94;
    public static readonly KW_MODIFY = 95;
    public static readonly KW_MODULES = 96;
    public static readonly KW_MONTHS = 97;
    public static readonly KW_NANOSECOND = 98;
    public static readonly KW_NOSCAN = 99;
    public static readonly KW_NULLS = 100;
    public static readonly KW_NUMBER = 101;
    public static readonly KW_OPTION = 102;
    public static readonly KW_OPTIONS = 103;
    public static readonly KW_ORDERING = 104;
    public static readonly KW_OUTPUT = 105;
    public static readonly KW_OVERWRITE = 106;
    public static readonly KW_OVERWRITING = 107;
    public static readonly KW_PARTITIONED = 108;
    public static readonly KW_PARTITIONS = 109;
    public static readonly KW_PASSING = 110;
    public static readonly KW_PAST = 111;
    public static readonly KW_PATH = 112;
    public static readonly KW_PLACING = 113;
    public static readonly KW_PLAN = 114;
    public static readonly KW_PRECEDING = 115;
    public static readonly KW_PRESERVE = 116;
    public static readonly KW_PRIOR = 117;
    public static readonly KW_PRIVILEGES = 118;
    public static readonly KW_PUBLIC = 119;
    public static readonly KW_PYTHON = 120;
    public static readonly KW_PYTHON_FILES = 121;
    public static readonly KW_PYTHON_REQUIREMENTS = 122;
    public static readonly KW_PYTHON_DEPENDENCIES = 123;
    public static readonly KW_PYTHON_JAR = 124;
    public static readonly KW_PYTHON_ARCHIVES = 125;
    public static readonly KW_PYTHON_PARAMETER = 126;
    public static readonly KW_QUARTER = 127;
    public static readonly KW_QUERY = 128;
    public static readonly KW_RAW = 129;
    public static readonly KW_READ = 130;
    public static readonly KW_REAL = 131;
    public static readonly KW_RELATIVE = 132;
    public static readonly KW_REMOVE = 133;
    public static readonly KW_RENAME = 134;
    public static readonly KW_REPLACE = 135;
    public static readonly KW_RESPECT = 136;
    public static readonly KW_RESTART = 137;
    public static readonly KW_RESTRICT = 138;
    public static readonly KW_ROLE = 139;
    public static readonly KW_ROW_COUNT = 140;
    public static readonly KW_SCALA = 141;
    public static readonly KW_SCALAR = 142;
    public static readonly KW_SCALE = 143;
    public static readonly KW_SCHEMA = 144;
    public static readonly KW_SCHEMAS = 145;
    public static readonly KW_SECONDS = 146;
    public static readonly KW_SECTION = 147;
    public static readonly KW_SECURITY = 148;
    public static readonly KW_SELF = 149;
    public static readonly KW_SERVER = 150;
    public static readonly KW_SERVER_NAME = 151;
    public static readonly KW_SESSION = 152;
    public static readonly KW_SETS = 153;
    public static readonly KW_SHORT = 154;
    public static readonly KW_SIMPLE = 155;
    public static readonly KW_SIZE = 156;
    public static readonly KW_SLIDE = 157;
    public static readonly KW_SOURCE = 158;
    public static readonly KW_SPACE = 159;
    public static readonly KW_SERDEPROPERTIES = 160;
    public static readonly KW_STATE = 161;
    public static readonly KW_STATISTICS = 162;
    public static readonly KW_STATEMENT = 163;
    public static readonly KW_STEP = 164;
    public static readonly KW_STRING = 165;
    public static readonly KW_STRUCTURE = 166;
    public static readonly KW_STYLE = 167;
    public static readonly KW_TABLES = 168;
    public static readonly KW_TEMPORARY = 169;
    public static readonly KW_TIMECOL = 170;
    public static readonly KW_FLOOR = 171;
    public static readonly KW_TIMESTAMP_LTZ = 172;
    public static readonly KW_TIMESTAMP_NTZ = 173;
    public static readonly KW_TIMESTAMPADD = 174;
    public static readonly KW_TIMESTAMPDIFF = 175;
    public static readonly KW_TOTIMESTAMP = 176;
    public static readonly KW_TRANSFORM = 177;
    public static readonly KW_TUMBLE = 178;
    public static readonly KW_TYPE = 179;
    public static readonly KW_UNCACHE = 180;
    public static readonly KW_UNDER = 181;
    public static readonly KW_UNBOUNDED = 182;
    public static readonly KW_UNLOAD = 183;
    public static readonly KW_USAGE = 184;
    public static readonly KW_USE = 185;
    public static readonly KW_UTF16 = 186;
    public static readonly KW_UTF32 = 187;
    public static readonly KW_UTF8 = 188;
    public static readonly KW_VERSION = 189;
    public static readonly KW_VIEW = 190;
    public static readonly KW_VIEWS = 191;
    public static readonly KW_VIRTUAL = 192;
    public static readonly KW_WATERMARK = 193;
    public static readonly KW_WATERMARKS = 194;
    public static readonly KW_WEEK = 195;
    public static readonly KW_WEEKS = 196;
    public static readonly KW_WORK = 197;
    public static readonly KW_WRAPPER = 198;
    public static readonly KW_YEARS = 199;
    public static readonly KW_ZONE = 200;
    public static readonly KW_ABS = 201;
    public static readonly KW_ALL = 202;
    public static readonly KW_ALLOW = 203;
    public static readonly KW_ALTER = 204;
    public static readonly KW_AND = 205;
    public static readonly KW_ANY = 206;
    public static readonly KW_ARE = 207;
    public static readonly KW_ARRAY = 208;
    public static readonly KW_AS = 209;
    public static readonly KW_ASYMMETRIC = 210;
    public static readonly KW_AT = 211;
    public static readonly KW_AVG = 212;
    public static readonly KW_BEGIN = 213;
    public static readonly KW_BETWEEN = 214;
    public static readonly KW_BIGINT = 215;
    public static readonly KW_BINARY = 216;
    public static readonly KW_BIT = 217;
    public static readonly KW_BLOB = 218;
    public static readonly KW_BOOLEAN = 219;
    public static readonly KW_BOTH = 220;
    public static readonly KW_BUCKET = 221;
    public static readonly KW_BY = 222;
    public static readonly KW_CALL = 223;
    public static readonly KW_CALLED = 224;
    public static readonly KW_CASCADED = 225;
    public static readonly KW_CASE = 226;
    public static readonly KW_CAST = 227;
    public static readonly KW_CEIL = 228;
    public static readonly KW_CHAR = 229;
    public static readonly KW_CHARACTER = 230;
    public static readonly KW_CHECK = 231;
    public static readonly KW_CLOB = 232;
    public static readonly KW_CLOSE = 233;
    public static readonly KW_CLUSTER = 234;
    public static readonly KW_CLUSTERED = 235;
    public static readonly KW_COALESCE = 236;
    public static readonly KW_COLLATE = 237;
    public static readonly KW_COLLECT = 238;
    public static readonly KW_COLUMN = 239;
    public static readonly KW_COMMIT = 240;
    public static readonly KW_CONNECT = 241;
    public static readonly KW_CONSTRAINT = 242;
    public static readonly KW_CONTAINS = 243;
    public static readonly KW_CONVERT = 244;
    public static readonly KW_COUNT = 245;
    public static readonly KW_CREATE = 246;
    public static readonly KW_CROSS = 247;
    public static readonly KW_CUBE = 248;
    public static readonly KW_CUME_DIST = 249;
    public static readonly KW_CURRENT = 250;
    public static readonly KW_CURSOR = 251;
    public static readonly KW_CYCLE = 252;
    public static readonly KW_COLLECTION = 253;
    public static readonly KW_DATE = 254;
    public static readonly KW_DATETIME = 255;
    public static readonly KW_DAY = 256;
    public static readonly KW_DEC = 257;
    public static readonly KW_DECIMAL = 258;
    public static readonly KW_DECLARE = 259;
    public static readonly KW_DEFAULT = 260;
    public static readonly KW_DEFINE = 261;
    public static readonly KW_DELETE = 262;
    public static readonly KW_DELIMITED = 263;
    public static readonly KW_DESCRIBE = 264;
    public static readonly KW_DENSE_RANK = 265;
    public static readonly KW_DISTINCT = 266;
    public static readonly KW_DIRECTORY = 267;
    public static readonly KW_DISTRIBUTED = 268;
    public static readonly KW_DISTRIBUTE = 269;
    public static readonly KW_DOUBLE = 270;
    public static readonly KW_DROP = 271;
    public static readonly KW_EACH = 272;
    public static readonly KW_ELSE = 273;
    public static readonly KW_END = 274;
    public static readonly KW_EQUALS = 275;
    public static readonly KW_ESCAPE = 276;
    public static readonly KW_ESCAPED = 277;
    public static readonly KW_EXCEPT = 278;
    public static readonly KW_EXECUTE = 279;
    public static readonly KW_EXISTS = 280;
    public static readonly KW_EXPLAIN = 281;
    public static readonly KW_EXPLODE = 282;
    public static readonly KW_EXPLODE_OUTER = 283;
    public static readonly KW_EXTERNAL = 284;
    public static readonly KW_EXTRACT = 285;
    public static readonly KW_FIRST_VALUE = 286;
    public static readonly KW_FALSE = 287;
    public static readonly KW_FLOAT = 288;
    public static readonly KW_FIELDS = 289;
    public static readonly KW_FOR = 290;
    public static readonly KW_FROM = 291;
    public static readonly KW_FROM_UNIXTIME = 292;
    public static readonly KW_FULL = 293;
    public static readonly KW_FUNCTION = 294;
    public static readonly KW_GLOBAL = 295;
    public static readonly KW_GRANT = 296;
    public static readonly KW_GROUP = 297;
    public static readonly KW_GROUPING = 298;
    public static readonly KW_GROUPS = 299;
    public static readonly KW_HAVING = 300;
    public static readonly KW_HOUR = 301;
    public static readonly KW_IMPORT = 302;
    public static readonly KW_IN = 303;
    public static readonly KW_INCLUDING = 304;
    public static readonly KW_INPUTFORMAT = 305;
    public static readonly KW_INNER = 306;
    public static readonly KW_INOUT = 307;
    public static readonly KW_INSERT = 308;
    public static readonly KW_INT = 309;
    public static readonly KW_INTEGER = 310;
    public static readonly KW_INTERSECT = 311;
    public static readonly KW_INTERVAL = 312;
    public static readonly KW_INTO = 313;
    public static readonly KW_INPATH = 314;
    public static readonly KW_INLINE = 315;
    public static readonly KW_INLINE_OUTER = 316;
    public static readonly KW_ITEMS = 317;
    public static readonly KW_IS = 318;
    public static readonly KW_JOIN = 319;
    public static readonly KW_JSON_TUPLE = 320;
    public static readonly KW_LAG = 321;
    public static readonly KW_LANGUAGE = 322;
    public static readonly KW_LATERAL = 323;
    public static readonly KW_LAST_VALUE = 324;
    public static readonly KW_LEAD = 325;
    public static readonly KW_LEADING = 326;
    public static readonly KW_LEFT = 327;
    public static readonly KW_LIKE = 328;
    public static readonly KW_LINES = 329;
    public static readonly KW_LIMIT = 330;
    public static readonly KW_LOCAL = 331;
    public static readonly KW_LOCALTIMESTAMP = 332;
    public static readonly KW_MATCH = 333;
    public static readonly KW_MATCH_RECOGNIZE = 334;
    public static readonly KW_MEASURES = 335;
    public static readonly KW_MERGE = 336;
    public static readonly KW_METADATA = 337;
    public static readonly KW_MINUS = 338;
    public static readonly KW_MINUTE = 339;
    public static readonly KW_MODIFIES = 340;
    public static readonly KW_MODULE = 341;
    public static readonly KW_MONTH = 342;
    public static readonly KW_MULTISET = 343;
    public static readonly KW_NATURAL = 344;
    public static readonly KW_NEXT = 345;
    public static readonly KW_NO = 346;
    public static readonly KW_NONE = 347;
    public static readonly KW_NOT = 348;
    public static readonly KW_NTILE = 349;
    public static readonly KW_NTH_VALUE = 350;
    public static readonly KW_NULL = 351;
    public static readonly KW_NUMERIC = 352;
    public static readonly KW_OF = 353;
    public static readonly KW_OFFSET = 354;
    public static readonly KW_ON = 355;
    public static readonly KW_ONE = 356;
    public static readonly KW_OR = 357;
    public static readonly KW_ORDER = 358;
    public static readonly KW_OUT = 359;
    public static readonly KW_OUTER = 360;
    public static readonly KW_OUTPUTFORMAT = 361;
    public static readonly KW_OVER = 362;
    public static readonly KW_OVERLAY = 363;
    public static readonly KW_PARSE_URL = 364;
    public static readonly KW_PARTITION = 365;
    public static readonly KW_PATTERN = 366;
    public static readonly KW_PER = 367;
    public static readonly KW_PERCENT = 368;
    public static readonly KW_PERCENT_RANK = 369;
    public static readonly KW_PERCENTILE_CONT = 370;
    public static readonly KW_PERCENTILE_DISC = 371;
    public static readonly KW_PERIOD = 372;
    public static readonly KW_PIVOT = 373;
    public static readonly KW_POSITION = 374;
    public static readonly KW_POWER = 375;
    public static readonly KW_POSEXPLODE = 376;
    public static readonly KW_POSEXPLODE_OUTER = 377;
    public static readonly KW_PRIMARY = 378;
    public static readonly KW_PURGE = 379;
    public static readonly KW_RANGE = 380;
    public static readonly KW_RECORDWRITER = 381;
    public static readonly KW_ROW_NUMBER = 382;
    public static readonly KW_RANK = 383;
    public static readonly KW_REGEXP = 384;
    public static readonly KW_RESET = 385;
    public static readonly KW_REVOKE = 386;
    public static readonly KW_REPAIR = 387;
    public static readonly KW_RIGHT = 388;
    public static readonly KW_RLIKE = 389;
    public static readonly KW_ROLLBACK = 390;
    public static readonly KW_ROLLUP = 391;
    public static readonly KW_ROW = 392;
    public static readonly KW_ROWS = 393;
    public static readonly KW_SECOND = 394;
    public static readonly KW_SELECT = 395;
    public static readonly KW_SET = 396;
    public static readonly KW_SERDE = 397;
    public static readonly KW_SHOW = 398;
    public static readonly KW_SIMILAR = 399;
    public static readonly KW_SKIP = 400;
    public static readonly KW_STORED = 401;
    public static readonly KW_SORTED = 402;
    public static readonly KW_SMALLINT = 403;
    public static readonly KW_STACK = 404;
    public static readonly KW_START = 405;
    public static readonly KW_STATIC = 406;
    public static readonly KW_STRUCT = 407;
    public static readonly KW_SORT = 408;
    public static readonly KW_SUBSTRING = 409;
    public static readonly KW_SUM = 410;
    public static readonly KW_SYMMETRIC = 411;
    public static readonly KW_SYSTEM = 412;
    public static readonly KW_SYSTEM_TIME = 413;
    public static readonly KW_SYSTEM_USER = 414;
    public static readonly KW_TABLE = 415;
    public static readonly KW_TBLPROPERTIES = 416;
    public static readonly KW_TABLESAMPLE = 417;
    public static readonly KW_TERMINATED = 418;
    public static readonly KW_THEN = 419;
    public static readonly KW_TIME = 420;
    public static readonly KW_TIMESTAMP = 421;
    public static readonly KW_TIMESTAMP_3 = 422;
    public static readonly KW_TIMESTAMP_6 = 423;
    public static readonly KW_TIMESTAMP_9 = 424;
    public static readonly KW_TINYINT = 425;
    public static readonly KW_TO = 426;
    public static readonly KW_TRAILING = 427;
    public static readonly KW_TRUE = 428;
    public static readonly KW_TRUNCATE = 429;
    public static readonly KW_UNION = 430;
    public static readonly KW_UNIQUE = 431;
    public static readonly KW_UNKNOWN = 432;
    public static readonly KW_UNSET = 433;
    public static readonly KW_UNPIVOT = 434;
    public static readonly KW_UPPER = 435;
    public static readonly KW_UPSERT = 436;
    public static readonly KW_USER = 437;
    public static readonly KW_USING = 438;
    public static readonly KW_VALUE = 439;
    public static readonly KW_VALUES = 440;
    public static readonly KW_VARBINARY = 441;
    public static readonly KW_VARCHAR = 442;
    public static readonly KW_WHEN = 443;
    public static readonly KW_WHERE = 444;
    public static readonly KW_WINDOW = 445;
    public static readonly KW_WITH = 446;
    public static readonly KW_WITHIN = 447;
    public static readonly KW_WITHOUT = 448;
    public static readonly KW_YEAR = 449;
    public static readonly KW_MATERIALIZED = 450;
    public static readonly KW_FRESHNESS = 451;
    public static readonly KW_REFRESH_MODE = 452;
    public static readonly KW_RECOVER = 453;
    public static readonly KW_CONTINUOUS = 454;
    public static readonly KW_SUSPEND = 455;
    public static readonly KW_RESUME = 456;
    public static readonly KW_REFRESH = 457;
    public static readonly KW_HASH = 458;
    public static readonly KW_BUCKETS = 459;
    public static readonly BIT_NOT_OP = 460;
    public static readonly BIT_OR_OP = 461;
    public static readonly BIT_AND_OP = 462;
    public static readonly BIT_XOR_OP = 463;
    public static readonly EQUAL_SYMBOL = 464;
    public static readonly GREATER_SYMBOL = 465;
    public static readonly LESS_SYMBOL = 466;
    public static readonly EXCLAMATION_SYMBOL = 467;
    public static readonly DOT = 468;
    public static readonly LS_BRACKET = 469;
    public static readonly RS_BRACKET = 470;
    public static readonly LR_BRACKET = 471;
    public static readonly RR_BRACKET = 472;
    public static readonly LB_BRACKET = 473;
    public static readonly RB_BRACKET = 474;
    public static readonly COMMA = 475;
    public static readonly SEMICOLON = 476;
    public static readonly AT_SIGN = 477;
    public static readonly DOLLAR = 478;
    public static readonly SINGLE_QUOTE_SYMB = 479;
    public static readonly DOUBLE_QUOTE_SYMB = 480;
    public static readonly REVERSE_QUOTE_SYMB = 481;
    public static readonly COLON_SYMB = 482;
    public static readonly ASTERISK_SIGN = 483;
    public static readonly UNDERLINE_SIGN = 484;
    public static readonly HYPNEN_SIGN = 485;
    public static readonly ADD_SIGN = 486;
    public static readonly PENCENT_SIGN = 487;
    public static readonly DOUBLE_VERTICAL_SIGN = 488;
    public static readonly DOUBLE_HYPNEN_SIGN = 489;
    public static readonly SLASH_SIGN = 490;
    public static readonly QUESTION_MARK_SIGN = 491;
    public static readonly DOUBLE_RIGHT_ARROW = 492;
    public static readonly STRING_LITERAL = 493;
    public static readonly DIG_LITERAL = 494;
    public static readonly REAL_LITERAL = 495;
    public static readonly ID_LITERAL = 496;
    public static readonly RULE_statement = 0;
    public static readonly RULE_sqlStatements = 1;
    public static readonly RULE_sqlStatement = 2;
    public static readonly RULE_emptyStatement = 3;
    public static readonly RULE_createStatement = 4;
    public static readonly RULE_dmlStatement = 5;
    public static readonly RULE_showTableStatementBody = 6;
    public static readonly RULE_showFunctionStatementBody = 7;
    public static readonly RULE_tableCanHasKeyPropertyList = 8;
    public static readonly RULE_createTable = 9;
    public static readonly RULE_simpleCreateTable = 10;
    public static readonly RULE_simpleCreateTableNoSortElement = 11;
    public static readonly RULE_sortedBy = 12;
    public static readonly RULE_usingCreate = 13;
    public static readonly RULE_tblProperties = 14;
    public static readonly RULE_defaultColumnUsing = 15;
    public static readonly RULE_defaultColumnUsingNoSortElement = 16;
    public static readonly RULE_columnUsing = 17;
    public static readonly RULE_columnUsingNoSortElement = 18;
    public static readonly RULE_usingByQuery = 19;
    public static readonly RULE_usingByQueryNoSortElement = 20;
    public static readonly RULE_intoBuckets = 21;
    public static readonly RULE_hiveFormatCreate = 22;
    public static readonly RULE_hiveFormatpartitionDefinition = 23;
    public static readonly RULE_hiveFormatCreateNoSortElement = 24;
    public static readonly RULE_rowFormatSerde = 25;
    public static readonly RULE_fieldsTerminatedBy = 26;
    public static readonly RULE_storedAs = 27;
    public static readonly RULE_storedAsInputformat = 28;
    public static readonly RULE_outputformat = 29;
    public static readonly RULE_createExternalTable = 30;
    public static readonly RULE_createExternalTableNoSortElement = 31;
    public static readonly RULE_location = 32;
    public static readonly RULE_rowFormatDelimted = 33;
    public static readonly RULE_columnsBody = 34;
    public static readonly RULE_createCustomSerde = 35;
    public static readonly RULE_createCustomSerdeNoSortElement = 36;
    public static readonly RULE_createCustomSerdeExternal = 37;
    public static readonly RULE_createCustomSerdeExternalNoSortElement = 38;
    public static readonly RULE_createTableAsSelect = 39;
    public static readonly RULE_createMaterializedTableAsSelect = 40;
    public static readonly RULE_createMaterializedTableAsSelectNoSortElement = 41;
    public static readonly RULE_createCatalog = 42;
    public static readonly RULE_createDatabase = 43;
    public static readonly RULE_createView = 44;
    public static readonly RULE_createFunction = 45;
    public static readonly RULE_usingClause = 46;
    public static readonly RULE_jarFileName = 47;
    public static readonly RULE_filePath = 48;
    public static readonly RULE_columnPosition = 49;
    public static readonly RULE_renameDefinition = 50;
    public static readonly RULE_setKeyValueDefinition = 51;
    public static readonly RULE_addConstraint = 52;
    public static readonly RULE_dropConstraint = 53;
    public static readonly RULE_addUnique = 54;
    public static readonly RULE_notForced = 55;
    public static readonly RULE_insertStatement = 56;
    public static readonly RULE_insertSimpleStatement = 57;
    public static readonly RULE_insertFromTable = 58;
    public static readonly RULE_insertSparkDirectoryStatement = 59;
    public static readonly RULE_insertSparkDirectoryBody = 60;
    public static readonly RULE_insertHiveDirectoryStatement = 61;
    public static readonly RULE_hiveRowFormatPart = 62;
    public static readonly RULE_insertPartitionDefinition = 63;
    public static readonly RULE_insertMulStatementCompatibility = 64;
    public static readonly RULE_insertMulStatement = 65;
    public static readonly RULE_queryStatement = 66;
    public static readonly RULE_valuesCaluse = 67;
    public static readonly RULE_inlineBody = 68;
    public static readonly RULE_withClause = 69;
    public static readonly RULE_withItem = 70;
    public static readonly RULE_withItemName = 71;
    public static readonly RULE_selectStatement = 72;
    public static readonly RULE_selectClause = 73;
    public static readonly RULE_projectItemDefinition = 74;
    public static readonly RULE_filterPart = 75;
    public static readonly RULE_overWindowItem = 76;
    public static readonly RULE_overClause = 77;
    public static readonly RULE_byClause = 78;
    public static readonly RULE_windowFunctioPart = 79;
    public static readonly RULE_windowFunctionName = 80;
    public static readonly RULE_analyticFunction = 81;
    public static readonly RULE_rangkingFunction = 82;
    public static readonly RULE_fromClause = 83;
    public static readonly RULE_windowFrameForWindowsQuery = 84;
    public static readonly RULE_frameExpession = 85;
    public static readonly RULE_tableExpression = 86;
    public static readonly RULE_tableReference = 87;
    public static readonly RULE_tablePrimary = 88;
    public static readonly RULE_funtionBody = 89;
    public static readonly RULE_unpivotBody = 90;
    public static readonly RULE_pivotBody = 91;
    public static readonly RULE_expressionAsAlias = 92;
    public static readonly RULE_expressionAsAliasList = 93;
    public static readonly RULE_systemTimePeriod = 94;
    public static readonly RULE_dateTimeExpression = 95;
    public static readonly RULE_inlineDataValueClause = 96;
    public static readonly RULE_windowTVFClause = 97;
    public static readonly RULE_tvfClause = 98;
    public static readonly RULE_inlineTableClause = 99;
    public static readonly RULE_rangeClause = 100;
    public static readonly RULE_windowTVFExpression = 101;
    public static readonly RULE_windowTVFName = 102;
    public static readonly RULE_transformClause = 103;
    public static readonly RULE_rowFormatDelimited = 104;
    public static readonly RULE_hiveSerde = 105;
    public static readonly RULE_usingAsColumnPart = 106;
    public static readonly RULE_hiveSerdePart = 107;
    public static readonly RULE_sparkRecordWriterPart = 108;
    public static readonly RULE_windowTVFParam = 109;
    public static readonly RULE_timeIntervalParamName = 110;
    public static readonly RULE_columnDescriptor = 111;
    public static readonly RULE_joinCondition = 112;
    public static readonly RULE_whereClause = 113;
    public static readonly RULE_samplingQueries = 114;
    public static readonly RULE_someByClause = 115;
    public static readonly RULE_clusterByClause = 116;
    public static readonly RULE_clusteredByClause = 117;
    public static readonly RULE_distributeByClause = 118;
    public static readonly RULE_groupByClause = 119;
    public static readonly RULE_groupItemDefinition = 120;
    public static readonly RULE_groupingSets = 121;
    public static readonly RULE_groupingSetsNotionName = 122;
    public static readonly RULE_groupWindowFunction = 123;
    public static readonly RULE_groupWindowFunctionName = 124;
    public static readonly RULE_timeAttrColumn = 125;
    public static readonly RULE_havingClause = 126;
    public static readonly RULE_windowClause = 127;
    public static readonly RULE_namedWindow = 128;
    public static readonly RULE_windowSpec = 129;
    public static readonly RULE_matchRecognizeClause = 130;
    public static readonly RULE_orderByCaluse = 131;
    public static readonly RULE_sortByCaluse = 132;
    public static readonly RULE_orderItemDefinition = 133;
    public static readonly RULE_limitClause = 134;
    public static readonly RULE_offsetClause = 135;
    public static readonly RULE_partitionByClause = 136;
    public static readonly RULE_quantifiers = 137;
    public static readonly RULE_measuresClause = 138;
    public static readonly RULE_patternDefinition = 139;
    public static readonly RULE_patternVariable = 140;
    public static readonly RULE_outputMode = 141;
    public static readonly RULE_afterMatchStrategy = 142;
    public static readonly RULE_patternVariablesDefinition = 143;
    public static readonly RULE_windowFrame = 144;
    public static readonly RULE_frameBound = 145;
    public static readonly RULE_withinClause = 146;
    public static readonly RULE_selfDefinitionClause = 147;
    public static readonly RULE_partitionDefinition = 148;
    public static readonly RULE_transformList = 149;
    public static readonly RULE_transform = 150;
    public static readonly RULE_transformArgument = 151;
    public static readonly RULE_likeDefinition = 152;
    public static readonly RULE_distribution = 153;
    public static readonly RULE_using = 154;
    public static readonly RULE_likeOption = 155;
    public static readonly RULE_columnOptionDefinition = 156;
    public static readonly RULE_physicalColumnDefinitionList = 157;
    public static readonly RULE_physicalColumnDefinition = 158;
    public static readonly RULE_computedColumnExpression = 159;
    public static readonly RULE_watermarkDefinition = 160;
    public static readonly RULE_tableConstraint = 161;
    public static readonly RULE_constraintName = 162;
    public static readonly RULE_valuesDefinition = 163;
    public static readonly RULE_valuesRowDefinition = 164;
    public static readonly RULE_lengthOneDimension = 165;
    public static readonly RULE_lengthTwoOptionalDimension = 166;
    public static readonly RULE_lengthTwoStringDimension = 167;
    public static readonly RULE_lengthOneTypeDimension = 168;
    public static readonly RULE_mapTypeDimension = 169;
    public static readonly RULE_rowTypeDimension = 170;
    public static readonly RULE_structTypeDimension = 171;
    public static readonly RULE_columnConstraint = 172;
    public static readonly RULE_commentSpec = 173;
    public static readonly RULE_metadataColumnDefinition = 174;
    public static readonly RULE_metadataKey = 175;
    public static readonly RULE_computedColumnDefinition = 176;
    public static readonly RULE_columnName = 177;
    public static readonly RULE_columnNameList = 178;
    public static readonly RULE_columnType = 179;
    public static readonly RULE_expression = 180;
    public static readonly RULE_booleanExpression = 181;
    public static readonly RULE_predicate = 182;
    public static readonly RULE_likePredicate = 183;
    public static readonly RULE_valueExpression = 184;
    public static readonly RULE_primaryExpression = 185;
    public static readonly RULE_complexDataTypeExpression = 186;
    public static readonly RULE_arrayExpression = 187;
    public static readonly RULE_structExpression = 188;
    public static readonly RULE_rowExpression = 189;
    public static readonly RULE_mapExpression = 190;
    public static readonly RULE_dataTypeExpression = 191;
    public static readonly RULE_sqlSimpleType = 192;
    public static readonly RULE_functionName = 193;
    public static readonly RULE_functionParam = 194;
    public static readonly RULE_filterClause = 195;
    public static readonly RULE_dereferenceDefinition = 196;
    public static readonly RULE_correlationName = 197;
    public static readonly RULE_qualifiedName = 198;
    public static readonly RULE_timeIntervalExpression = 199;
    public static readonly RULE_errorCapturingMultiUnitsInterval = 200;
    public static readonly RULE_multiUnitsInterval = 201;
    public static readonly RULE_errorCapturingUnitToUnitInterval = 202;
    public static readonly RULE_unitToUnitInterval = 203;
    public static readonly RULE_intervalValue = 204;
    public static readonly RULE_columnAlias = 205;
    public static readonly RULE_tableAlias = 206;
    public static readonly RULE_errorCapturingIdentifier = 207;
    public static readonly RULE_errorCapturingIdentifierExtra = 208;
    public static readonly RULE_identifierList = 209;
    public static readonly RULE_identifierSeq = 210;
    public static readonly RULE_identifier = 211;
    public static readonly RULE_unquotedAnyString = 212;
    public static readonly RULE_refVar = 213;
    public static readonly RULE_unquotedIdentifier = 214;
    public static readonly RULE_quotedIdentifier = 215;
    public static readonly RULE_whenClause = 216;
    public static readonly RULE_catalogPath = 217;
    public static readonly RULE_databasePath = 218;
    public static readonly RULE_databasePathCreate = 219;
    public static readonly RULE_tablePathCreate = 220;
    public static readonly RULE_tablePath = 221;
    public static readonly RULE_anonymousWindowsName = 222;
    public static readonly RULE_uid = 223;
    public static readonly RULE_withOption = 224;
    public static readonly RULE_ifNotExists = 225;
    public static readonly RULE_ifExists = 226;
    public static readonly RULE_tablePropertyList = 227;
    public static readonly RULE_tableProperty = 228;
    public static readonly RULE_tablePropertyKey = 229;
    public static readonly RULE_propertyName = 230;
    public static readonly RULE_tablePropertyValue = 231;
    public static readonly RULE_comparisonOperator = 232;
    public static readonly RULE_constant = 233;
    public static readonly RULE_timePointLiteral = 234;
    public static readonly RULE_anyStringLiteral = 235;
    public static readonly RULE_stringLiteral = 236;
    public static readonly RULE_decimalLiteral = 237;
    public static readonly RULE_booleanLiteral = 238;
    public static readonly RULE_setQuantifier = 239;
    public static readonly RULE_timePointUnit = 240;
    public static readonly RULE_timeIntervalUnit = 241;
    public static readonly RULE_reservedKeywordsUsedAsFuncParam = 242;
    public static readonly RULE_reservedKeywordsUsedAsFuncName = 243;
    public static readonly RULE_nonReservedKeywords = 244;

    public static readonly literalNames = [
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, null, null, 
        null, null, null, null, null, null, null, null, null, "'~'", "'|'", 
        "'&'", "'^'", "'='", "'>'", "'<'", "'!'", "'.'", "'['", "']'", "'('", 
        "')'", "'{'", "'}'", "','", "';'", "'@'", "'$'", "'''", "'\"'", 
        "'`'", "':'", "'*'", "'_'", "'-'", "'+'", "'%'", null, null, "'/'", 
        "'?'"
    ];

    public static readonly symbolicNames = [
        null, "SPACE", "COMMENT_INPUT", "LINE_COMMENT", "KW_ADD", "KW_ADMIN", 
        "KW_AFTER", "KW_ANALYZE", "KW_ASC", "KW_BEFORE", "KW_BYTE", "KW_BYTES", 
        "KW_CACHE", "KW_CASCADE", "KW_CATALOG", "KW_CATALOGS", "KW_CLEAR", 
        "KW_CENTURY", "KW_CHAIN", "KW_CHANGELOG_MODE", "KW_CHARACTERS", 
        "KW_COMMENT", "KW_COMPACT", "KW_COLUMNS", "KW_CONSTRAINTS", "KW_CONSTRUCTOR", 
        "KW_COMPUTE", "KW_CUMULATE", "KW_DATA", "KW_DATABASE", "KW_DATABASES", 
        "KW_DAYS", "KW_DBPROPERTIES", "KW_DECADE", "KW_DEFINED", "KW_DESC", 
        "KW_DESCRIPTOR", "KW_DIV", "KW_ENCODING", "KW_ENFORCED", "KW_ENGINE", 
        "KW_EPOCH", "KW_ERROR", "KW_ESTIMATED_COST", "KW_EXCEPTION", "KW_EXCLUDE", 
        "KW_EXCLUDING", "KW_EXTENDED", "KW_FILTER", "KW_FILE", "KW_FILES", 
        "KW_FINAL", "KW_FIRST", "KW_FOLLOWING", "KW_FORMAT", "KW_FORTRAN", 
        "KW_FOUND", "KW_FRAC_SECOND", "KW_FUNCTIONS", "KW_GENERAL", "KW_GENERATED", 
        "KW_GO", "KW_GOTO", "KW_GRANTED", "KW_HOP", "KW_HOURS", "KW_IF", 
        "KW_IGNORE", "KW_INCLUDE", "KW_INCREMENT", "KW_INPUT", "KW_INVOKER", 
        "KW_JAR", "KW_JARS", "KW_JAVA", "KW_JSON", "KW_JSON_EXECUTION_PLAN", 
        "KW_KEY", "KW_KEYS", "KW_KEY_MEMBER", "KW_KEY_TYPE", "KW_LABEL", 
        "KW_LAST", "KW_LENGTH", "KW_LEVEL", "KW_LIST", "KW_LOAD", "KW_LOCATION", 
        "KW_LONG", "KW_MAP", "KW_MICROSECOND", "KW_MILLENNIUM", "KW_MILLISECOND", 
        "KW_MINUTES", "KW_MINVALUE", "KW_MODIFY", "KW_MODULES", "KW_MONTHS", 
        "KW_NANOSECOND", "KW_NOSCAN", "KW_NULLS", "KW_NUMBER", "KW_OPTION", 
        "KW_OPTIONS", "KW_ORDERING", "KW_OUTPUT", "KW_OVERWRITE", "KW_OVERWRITING", 
        "KW_PARTITIONED", "KW_PARTITIONS", "KW_PASSING", "KW_PAST", "KW_PATH", 
        "KW_PLACING", "KW_PLAN", "KW_PRECEDING", "KW_PRESERVE", "KW_PRIOR", 
        "KW_PRIVILEGES", "KW_PUBLIC", "KW_PYTHON", "KW_PYTHON_FILES", "KW_PYTHON_REQUIREMENTS", 
        "KW_PYTHON_DEPENDENCIES", "KW_PYTHON_JAR", "KW_PYTHON_ARCHIVES", 
        "KW_PYTHON_PARAMETER", "KW_QUARTER", "KW_QUERY", "KW_RAW", "KW_READ", 
        "KW_REAL", "KW_RELATIVE", "KW_REMOVE", "KW_RENAME", "KW_REPLACE", 
        "KW_RESPECT", "KW_RESTART", "KW_RESTRICT", "KW_ROLE", "KW_ROW_COUNT", 
        "KW_SCALA", "KW_SCALAR", "KW_SCALE", "KW_SCHEMA", "KW_SCHEMAS", 
        "KW_SECONDS", "KW_SECTION", "KW_SECURITY", "KW_SELF", "KW_SERVER", 
        "KW_SERVER_NAME", "KW_SESSION", "KW_SETS", "KW_SHORT", "KW_SIMPLE", 
        "KW_SIZE", "KW_SLIDE", "KW_SOURCE", "KW_SPACE", "KW_SERDEPROPERTIES", 
        "KW_STATE", "KW_STATISTICS", "KW_STATEMENT", "KW_STEP", "KW_STRING", 
        "KW_STRUCTURE", "KW_STYLE", "KW_TABLES", "KW_TEMPORARY", "KW_TIMECOL", 
        "KW_FLOOR", "KW_TIMESTAMP_LTZ", "KW_TIMESTAMP_NTZ", "KW_TIMESTAMPADD", 
        "KW_TIMESTAMPDIFF", "KW_TOTIMESTAMP", "KW_TRANSFORM", "KW_TUMBLE", 
        "KW_TYPE", "KW_UNCACHE", "KW_UNDER", "KW_UNBOUNDED", "KW_UNLOAD", 
        "KW_USAGE", "KW_USE", "KW_UTF16", "KW_UTF32", "KW_UTF8", "KW_VERSION", 
        "KW_VIEW", "KW_VIEWS", "KW_VIRTUAL", "KW_WATERMARK", "KW_WATERMARKS", 
        "KW_WEEK", "KW_WEEKS", "KW_WORK", "KW_WRAPPER", "KW_YEARS", "KW_ZONE", 
        "KW_ABS", "KW_ALL", "KW_ALLOW", "KW_ALTER", "KW_AND", "KW_ANY", 
        "KW_ARE", "KW_ARRAY", "KW_AS", "KW_ASYMMETRIC", "KW_AT", "KW_AVG", 
        "KW_BEGIN", "KW_BETWEEN", "KW_BIGINT", "KW_BINARY", "KW_BIT", "KW_BLOB", 
        "KW_BOOLEAN", "KW_BOTH", "KW_BUCKET", "KW_BY", "KW_CALL", "KW_CALLED", 
        "KW_CASCADED", "KW_CASE", "KW_CAST", "KW_CEIL", "KW_CHAR", "KW_CHARACTER", 
        "KW_CHECK", "KW_CLOB", "KW_CLOSE", "KW_CLUSTER", "KW_CLUSTERED", 
        "KW_COALESCE", "KW_COLLATE", "KW_COLLECT", "KW_COLUMN", "KW_COMMIT", 
        "KW_CONNECT", "KW_CONSTRAINT", "KW_CONTAINS", "KW_CONVERT", "KW_COUNT", 
        "KW_CREATE", "KW_CROSS", "KW_CUBE", "KW_CUME_DIST", "KW_CURRENT", 
        "KW_CURSOR", "KW_CYCLE", "KW_COLLECTION", "KW_DATE", "KW_DATETIME", 
        "KW_DAY", "KW_DEC", "KW_DECIMAL", "KW_DECLARE", "KW_DEFAULT", "KW_DEFINE", 
        "KW_DELETE", "KW_DELIMITED", "KW_DESCRIBE", "KW_DENSE_RANK", "KW_DISTINCT", 
        "KW_DIRECTORY", "KW_DISTRIBUTED", "KW_DISTRIBUTE", "KW_DOUBLE", 
        "KW_DROP", "KW_EACH", "KW_ELSE", "KW_END", "KW_EQUALS", "KW_ESCAPE", 
        "KW_ESCAPED", "KW_EXCEPT", "KW_EXECUTE", "KW_EXISTS", "KW_EXPLAIN", 
        "KW_EXPLODE", "KW_EXPLODE_OUTER", "KW_EXTERNAL", "KW_EXTRACT", "KW_FIRST_VALUE", 
        "KW_FALSE", "KW_FLOAT", "KW_FIELDS", "KW_FOR", "KW_FROM", "KW_FROM_UNIXTIME", 
        "KW_FULL", "KW_FUNCTION", "KW_GLOBAL", "KW_GRANT", "KW_GROUP", "KW_GROUPING", 
        "KW_GROUPS", "KW_HAVING", "KW_HOUR", "KW_IMPORT", "KW_IN", "KW_INCLUDING", 
        "KW_INPUTFORMAT", "KW_INNER", "KW_INOUT", "KW_INSERT", "KW_INT", 
        "KW_INTEGER", "KW_INTERSECT", "KW_INTERVAL", "KW_INTO", "KW_INPATH", 
        "KW_INLINE", "KW_INLINE_OUTER", "KW_ITEMS", "KW_IS", "KW_JOIN", 
        "KW_JSON_TUPLE", "KW_LAG", "KW_LANGUAGE", "KW_LATERAL", "KW_LAST_VALUE", 
        "KW_LEAD", "KW_LEADING", "KW_LEFT", "KW_LIKE", "KW_LINES", "KW_LIMIT", 
        "KW_LOCAL", "KW_LOCALTIMESTAMP", "KW_MATCH", "KW_MATCH_RECOGNIZE", 
        "KW_MEASURES", "KW_MERGE", "KW_METADATA", "KW_MINUS", "KW_MINUTE", 
        "KW_MODIFIES", "KW_MODULE", "KW_MONTH", "KW_MULTISET", "KW_NATURAL", 
        "KW_NEXT", "KW_NO", "KW_NONE", "KW_NOT", "KW_NTILE", "KW_NTH_VALUE", 
        "KW_NULL", "KW_NUMERIC", "KW_OF", "KW_OFFSET", "KW_ON", "KW_ONE", 
        "KW_OR", "KW_ORDER", "KW_OUT", "KW_OUTER", "KW_OUTPUTFORMAT", "KW_OVER", 
        "KW_OVERLAY", "KW_PARSE_URL", "KW_PARTITION", "KW_PATTERN", "KW_PER", 
        "KW_PERCENT", "KW_PERCENT_RANK", "KW_PERCENTILE_CONT", "KW_PERCENTILE_DISC", 
        "KW_PERIOD", "KW_PIVOT", "KW_POSITION", "KW_POWER", "KW_POSEXPLODE", 
        "KW_POSEXPLODE_OUTER", "KW_PRIMARY", "KW_PURGE", "KW_RANGE", "KW_RECORDWRITER", 
        "KW_ROW_NUMBER", "KW_RANK", "KW_REGEXP", "KW_RESET", "KW_REVOKE", 
        "KW_REPAIR", "KW_RIGHT", "KW_RLIKE", "KW_ROLLBACK", "KW_ROLLUP", 
        "KW_ROW", "KW_ROWS", "KW_SECOND", "KW_SELECT", "KW_SET", "KW_SERDE", 
        "KW_SHOW", "KW_SIMILAR", "KW_SKIP", "KW_STORED", "KW_SORTED", "KW_SMALLINT", 
        "KW_STACK", "KW_START", "KW_STATIC", "KW_STRUCT", "KW_SORT", "KW_SUBSTRING", 
        "KW_SUM", "KW_SYMMETRIC", "KW_SYSTEM", "KW_SYSTEM_TIME", "KW_SYSTEM_USER", 
        "KW_TABLE", "KW_TBLPROPERTIES", "KW_TABLESAMPLE", "KW_TERMINATED", 
        "KW_THEN", "KW_TIME", "KW_TIMESTAMP", "KW_TIMESTAMP_3", "KW_TIMESTAMP_6", 
        "KW_TIMESTAMP_9", "KW_TINYINT", "KW_TO", "KW_TRAILING", "KW_TRUE", 
        "KW_TRUNCATE", "KW_UNION", "KW_UNIQUE", "KW_UNKNOWN", "KW_UNSET", 
        "KW_UNPIVOT", "KW_UPPER", "KW_UPSERT", "KW_USER", "KW_USING", "KW_VALUE", 
        "KW_VALUES", "KW_VARBINARY", "KW_VARCHAR", "KW_WHEN", "KW_WHERE", 
        "KW_WINDOW", "KW_WITH", "KW_WITHIN", "KW_WITHOUT", "KW_YEAR", "KW_MATERIALIZED", 
        "KW_FRESHNESS", "KW_REFRESH_MODE", "KW_RECOVER", "KW_CONTINUOUS", 
        "KW_SUSPEND", "KW_RESUME", "KW_REFRESH", "KW_HASH", "KW_BUCKETS", 
        "BIT_NOT_OP", "BIT_OR_OP", "BIT_AND_OP", "BIT_XOR_OP", "EQUAL_SYMBOL", 
        "GREATER_SYMBOL", "LESS_SYMBOL", "EXCLAMATION_SYMBOL", "DOT", "LS_BRACKET", 
        "RS_BRACKET", "LR_BRACKET", "RR_BRACKET", "LB_BRACKET", "RB_BRACKET", 
        "COMMA", "SEMICOLON", "AT_SIGN", "DOLLAR", "SINGLE_QUOTE_SYMB", 
        "DOUBLE_QUOTE_SYMB", "REVERSE_QUOTE_SYMB", "COLON_SYMB", "ASTERISK_SIGN", 
        "UNDERLINE_SIGN", "HYPNEN_SIGN", "ADD_SIGN", "PENCENT_SIGN", "DOUBLE_VERTICAL_SIGN", 
        "DOUBLE_HYPNEN_SIGN", "SLASH_SIGN", "QUESTION_MARK_SIGN", "DOUBLE_RIGHT_ARROW", 
        "STRING_LITERAL", "DIG_LITERAL", "REAL_LITERAL", "ID_LITERAL"
    ];
    public static readonly ruleNames = [
        "statement", "sqlStatements", "sqlStatement", "emptyStatement", 
        "createStatement", "dmlStatement", "showTableStatementBody", "showFunctionStatementBody", 
        "tableCanHasKeyPropertyList", "createTable", "simpleCreateTable", 
        "simpleCreateTableNoSortElement", "sortedBy", "usingCreate", "tblProperties", 
        "defaultColumnUsing", "defaultColumnUsingNoSortElement", "columnUsing", 
        "columnUsingNoSortElement", "usingByQuery", "usingByQueryNoSortElement", 
        "intoBuckets", "hiveFormatCreate", "hiveFormatpartitionDefinition", 
        "hiveFormatCreateNoSortElement", "rowFormatSerde", "fieldsTerminatedBy", 
        "storedAs", "storedAsInputformat", "outputformat", "createExternalTable", 
        "createExternalTableNoSortElement", "location", "rowFormatDelimted", 
        "columnsBody", "createCustomSerde", "createCustomSerdeNoSortElement", 
        "createCustomSerdeExternal", "createCustomSerdeExternalNoSortElement", 
        "createTableAsSelect", "createMaterializedTableAsSelect", "createMaterializedTableAsSelectNoSortElement", 
        "createCatalog", "createDatabase", "createView", "createFunction", 
        "usingClause", "jarFileName", "filePath", "columnPosition", "renameDefinition", 
        "setKeyValueDefinition", "addConstraint", "dropConstraint", "addUnique", 
        "notForced", "insertStatement", "insertSimpleStatement", "insertFromTable", 
        "insertSparkDirectoryStatement", "insertSparkDirectoryBody", "insertHiveDirectoryStatement", 
        "hiveRowFormatPart", "insertPartitionDefinition", "insertMulStatementCompatibility", 
        "insertMulStatement", "queryStatement", "valuesCaluse", "inlineBody", 
        "withClause", "withItem", "withItemName", "selectStatement", "selectClause", 
        "projectItemDefinition", "filterPart", "overWindowItem", "overClause", 
        "byClause", "windowFunctioPart", "windowFunctionName", "analyticFunction", 
        "rangkingFunction", "fromClause", "windowFrameForWindowsQuery", 
        "frameExpession", "tableExpression", "tableReference", "tablePrimary", 
        "funtionBody", "unpivotBody", "pivotBody", "expressionAsAlias", 
        "expressionAsAliasList", "systemTimePeriod", "dateTimeExpression", 
        "inlineDataValueClause", "windowTVFClause", "tvfClause", "inlineTableClause", 
        "rangeClause", "windowTVFExpression", "windowTVFName", "transformClause", 
        "rowFormatDelimited", "hiveSerde", "usingAsColumnPart", "hiveSerdePart", 
        "sparkRecordWriterPart", "windowTVFParam", "timeIntervalParamName", 
        "columnDescriptor", "joinCondition", "whereClause", "samplingQueries", 
        "someByClause", "clusterByClause", "clusteredByClause", "distributeByClause", 
        "groupByClause", "groupItemDefinition", "groupingSets", "groupingSetsNotionName", 
        "groupWindowFunction", "groupWindowFunctionName", "timeAttrColumn", 
        "havingClause", "windowClause", "namedWindow", "windowSpec", "matchRecognizeClause", 
        "orderByCaluse", "sortByCaluse", "orderItemDefinition", "limitClause", 
        "offsetClause", "partitionByClause", "quantifiers", "measuresClause", 
        "patternDefinition", "patternVariable", "outputMode", "afterMatchStrategy", 
        "patternVariablesDefinition", "windowFrame", "frameBound", "withinClause", 
        "selfDefinitionClause", "partitionDefinition", "transformList", 
        "transform", "transformArgument", "likeDefinition", "distribution", 
        "using", "likeOption", "columnOptionDefinition", "physicalColumnDefinitionList", 
        "physicalColumnDefinition", "computedColumnExpression", "watermarkDefinition", 
        "tableConstraint", "constraintName", "valuesDefinition", "valuesRowDefinition", 
        "lengthOneDimension", "lengthTwoOptionalDimension", "lengthTwoStringDimension", 
        "lengthOneTypeDimension", "mapTypeDimension", "rowTypeDimension", 
        "structTypeDimension", "columnConstraint", "commentSpec", "metadataColumnDefinition", 
        "metadataKey", "computedColumnDefinition", "columnName", "columnNameList", 
        "columnType", "expression", "booleanExpression", "predicate", "likePredicate", 
        "valueExpression", "primaryExpression", "complexDataTypeExpression", 
        "arrayExpression", "structExpression", "rowExpression", "mapExpression", 
        "dataTypeExpression", "sqlSimpleType", "functionName", "functionParam", 
        "filterClause", "dereferenceDefinition", "correlationName", "qualifiedName", 
        "timeIntervalExpression", "errorCapturingMultiUnitsInterval", "multiUnitsInterval", 
        "errorCapturingUnitToUnitInterval", "unitToUnitInterval", "intervalValue", 
        "columnAlias", "tableAlias", "errorCapturingIdentifier", "errorCapturingIdentifierExtra", 
        "identifierList", "identifierSeq", "identifier", "unquotedAnyString", 
        "refVar", "unquotedIdentifier", "quotedIdentifier", "whenClause", 
        "catalogPath", "databasePath", "databasePathCreate", "tablePathCreate", 
        "tablePath", "anonymousWindowsName", "uid", "withOption", "ifNotExists", 
        "ifExists", "tablePropertyList", "tableProperty", "tablePropertyKey", 
        "propertyName", "tablePropertyValue", "comparisonOperator", "constant", 
        "timePointLiteral", "anyStringLiteral", "stringLiteral", "decimalLiteral", 
        "booleanLiteral", "setQuantifier", "timePointUnit", "timeIntervalUnit", 
        "reservedKeywordsUsedAsFuncParam", "reservedKeywordsUsedAsFuncName", 
        "nonReservedKeywords",
    ];

    public get grammarFileName(): string { return "SparkSQL.g4"; }
    public get literalNames(): (string | null)[] { return SparkSQLParser.literalNames; }
    public get symbolicNames(): (string | null)[] { return SparkSQLParser.symbolicNames; }
    public get ruleNames(): string[] { return SparkSQLParser.ruleNames; }
    public get serializedATN(): number[] { return SparkSQLParser._serializedATN; }

    protected createFailedPredicateException(predicate?: string, message?: string): antlr.FailedPredicateException {
        return new antlr.FailedPredicateException(this, predicate, message);
    }

    public constructor(input: antlr.TokenStream) {
        super(input);
        this.interpreter = new antlr.ParserATNSimulator(this, SparkSQLParser._ATN, SparkSQLParser.decisionsToDFA, new antlr.PredictionContextCache());
    }
    public statement(): StatementContext {
        let localContext = new StatementContext(this.context, this.state);
        this.enterRule(localContext, 0, SparkSQLParser.RULE_statement);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 490;
            this.sqlStatements();
            this.state = 491;
            this.match(SparkSQLParser.EOF);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public sqlStatements(): SqlStatementsContext {
        let localContext = new SqlStatementsContext(this.context, this.state);
        this.enterRule(localContext, 2, SparkSQLParser.RULE_sqlStatements);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 497;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 213 || _la === 246 || ((((_la - 279)) & ~0x1F) === 0 && ((1 << (_la - 279)) & 536875009) !== 0) || _la === 395 || ((((_la - 446)) & ~0x1F) === 0 && ((1 << (_la - 446)) & 1107296257) !== 0)) {
                {
                this.state = 495;
                this.errorHandler.sync(this);
                switch (this.tokenStream.LA(1)) {
                case SparkSQLParser.KW_BEGIN:
                case SparkSQLParser.KW_CREATE:
                case SparkSQLParser.KW_EXECUTE:
                case SparkSQLParser.KW_FROM:
                case SparkSQLParser.KW_INSERT:
                case SparkSQLParser.KW_SELECT:
                case SparkSQLParser.KW_WITH:
                case SparkSQLParser.LR_BRACKET:
                    {
                    this.state = 493;
                    this.sqlStatement();
                    }
                    break;
                case SparkSQLParser.SEMICOLON:
                    {
                    this.state = 494;
                    this.emptyStatement();
                    }
                    break;
                default:
                    throw new antlr.NoViableAltException(this);
                }
                }
                this.state = 499;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public sqlStatement(): SqlStatementContext {
        let localContext = new SqlStatementContext(this.context, this.state);
        this.enterRule(localContext, 4, SparkSQLParser.RULE_sqlStatement);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 502;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.KW_BEGIN:
            case SparkSQLParser.KW_EXECUTE:
            case SparkSQLParser.KW_FROM:
            case SparkSQLParser.KW_INSERT:
            case SparkSQLParser.KW_SELECT:
            case SparkSQLParser.KW_WITH:
            case SparkSQLParser.LR_BRACKET:
                {
                this.state = 500;
                this.dmlStatement();
                }
                break;
            case SparkSQLParser.KW_CREATE:
                {
                this.state = 501;
                this.createStatement();
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
            this.state = 504;
            this.match(SparkSQLParser.SEMICOLON);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public emptyStatement(): EmptyStatementContext {
        let localContext = new EmptyStatementContext(this.context, this.state);
        this.enterRule(localContext, 6, SparkSQLParser.RULE_emptyStatement);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 506;
            this.match(SparkSQLParser.SEMICOLON);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public createStatement(): CreateStatementContext {
        let localContext = new CreateStatementContext(this.context, this.state);
        this.enterRule(localContext, 8, SparkSQLParser.RULE_createStatement);
        try {
            this.state = 513;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 3, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 508;
                this.createTable();
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 509;
                this.createDatabase();
                }
                break;
            case 3:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 510;
                this.createView();
                }
                break;
            case 4:
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 511;
                this.createFunction();
                }
                break;
            case 5:
                this.enterOuterAlt(localContext, 5);
                {
                this.state = 512;
                this.createCatalog();
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public dmlStatement(): DmlStatementContext {
        let localContext = new DmlStatementContext(this.context, this.state);
        this.enterRule(localContext, 10, SparkSQLParser.RULE_dmlStatement);
        try {
            this.state = 517;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.KW_FROM:
            case SparkSQLParser.KW_SELECT:
            case SparkSQLParser.KW_WITH:
            case SparkSQLParser.LR_BRACKET:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 515;
                this.queryStatement(0);
                }
                break;
            case SparkSQLParser.KW_BEGIN:
            case SparkSQLParser.KW_EXECUTE:
            case SparkSQLParser.KW_INSERT:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 516;
                this.insertStatement();
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public showTableStatementBody(): ShowTableStatementBodyContext {
        let localContext = new ShowTableStatementBodyContext(this.context, this.state);
        this.enterRule(localContext, 12, SparkSQLParser.RULE_showTableStatementBody);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 520;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 47) {
                {
                this.state = 519;
                this.match(SparkSQLParser.KW_EXTENDED);
                }
            }

            this.state = 524;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 303) {
                {
                this.state = 522;
                this.match(SparkSQLParser.KW_IN);
                this.state = 523;
                this.match(SparkSQLParser.KW_DEFAULT);
                }
            }

            this.state = 527;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 328) {
                {
                this.state = 526;
                this.likeDefinition();
                }
            }

            this.state = 534;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 365) {
                {
                this.state = 529;
                this.match(SparkSQLParser.KW_PARTITION);
                this.state = 530;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 531;
                this.tableProperty();
                this.state = 532;
                this.match(SparkSQLParser.RR_BRACKET);
                }
            }

            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public showFunctionStatementBody(): ShowFunctionStatementBodyContext {
        let localContext = new ShowFunctionStatementBodyContext(this.context, this.state);
        this.enterRule(localContext, 14, SparkSQLParser.RULE_showFunctionStatementBody);
        let _la: number;
        try {
            this.state = 543;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.KW_ADD:
            case SparkSQLParser.KW_ADMIN:
            case SparkSQLParser.KW_AFTER:
            case SparkSQLParser.KW_ANALYZE:
            case SparkSQLParser.KW_ASC:
            case SparkSQLParser.KW_BEFORE:
            case SparkSQLParser.KW_BYTES:
            case SparkSQLParser.KW_CASCADE:
            case SparkSQLParser.KW_CATALOG:
            case SparkSQLParser.KW_CATALOGS:
            case SparkSQLParser.KW_CENTURY:
            case SparkSQLParser.KW_CHAIN:
            case SparkSQLParser.KW_CHANGELOG_MODE:
            case SparkSQLParser.KW_CHARACTERS:
            case SparkSQLParser.KW_COMMENT:
            case SparkSQLParser.KW_COMPACT:
            case SparkSQLParser.KW_COLUMNS:
            case SparkSQLParser.KW_CONSTRAINTS:
            case SparkSQLParser.KW_CONSTRUCTOR:
            case SparkSQLParser.KW_COMPUTE:
            case SparkSQLParser.KW_CUMULATE:
            case SparkSQLParser.KW_DATA:
            case SparkSQLParser.KW_DATABASE:
            case SparkSQLParser.KW_DATABASES:
            case SparkSQLParser.KW_DAYS:
            case SparkSQLParser.KW_DECADE:
            case SparkSQLParser.KW_DEFINED:
            case SparkSQLParser.KW_DESC:
            case SparkSQLParser.KW_DESCRIPTOR:
            case SparkSQLParser.KW_DIV:
            case SparkSQLParser.KW_ENCODING:
            case SparkSQLParser.KW_ENFORCED:
            case SparkSQLParser.KW_ENGINE:
            case SparkSQLParser.KW_ERROR:
            case SparkSQLParser.KW_ESTIMATED_COST:
            case SparkSQLParser.KW_EXCEPTION:
            case SparkSQLParser.KW_EXCLUDE:
            case SparkSQLParser.KW_EXCLUDING:
            case SparkSQLParser.KW_EXTENDED:
            case SparkSQLParser.KW_FILE:
            case SparkSQLParser.KW_FINAL:
            case SparkSQLParser.KW_FIRST:
            case SparkSQLParser.KW_FOLLOWING:
            case SparkSQLParser.KW_FORMAT:
            case SparkSQLParser.KW_FORTRAN:
            case SparkSQLParser.KW_FOUND:
            case SparkSQLParser.KW_FRAC_SECOND:
            case SparkSQLParser.KW_FUNCTIONS:
            case SparkSQLParser.KW_GENERAL:
            case SparkSQLParser.KW_GENERATED:
            case SparkSQLParser.KW_GO:
            case SparkSQLParser.KW_GOTO:
            case SparkSQLParser.KW_GRANTED:
            case SparkSQLParser.KW_HOP:
            case SparkSQLParser.KW_HOURS:
            case SparkSQLParser.KW_IF:
            case SparkSQLParser.KW_IGNORE:
            case SparkSQLParser.KW_INCREMENT:
            case SparkSQLParser.KW_INPUT:
            case SparkSQLParser.KW_INVOKER:
            case SparkSQLParser.KW_JAR:
            case SparkSQLParser.KW_JARS:
            case SparkSQLParser.KW_JAVA:
            case SparkSQLParser.KW_JSON:
            case SparkSQLParser.KW_JSON_EXECUTION_PLAN:
            case SparkSQLParser.KW_KEY:
            case SparkSQLParser.KW_KEY_MEMBER:
            case SparkSQLParser.KW_KEY_TYPE:
            case SparkSQLParser.KW_LABEL:
            case SparkSQLParser.KW_LAST:
            case SparkSQLParser.KW_LENGTH:
            case SparkSQLParser.KW_LEVEL:
            case SparkSQLParser.KW_LOAD:
            case SparkSQLParser.KW_MAP:
            case SparkSQLParser.KW_MICROSECOND:
            case SparkSQLParser.KW_MILLENNIUM:
            case SparkSQLParser.KW_MILLISECOND:
            case SparkSQLParser.KW_MINUTES:
            case SparkSQLParser.KW_MINVALUE:
            case SparkSQLParser.KW_MODIFY:
            case SparkSQLParser.KW_MODULES:
            case SparkSQLParser.KW_MONTHS:
            case SparkSQLParser.KW_NANOSECOND:
            case SparkSQLParser.KW_NULLS:
            case SparkSQLParser.KW_NUMBER:
            case SparkSQLParser.KW_OPTION:
            case SparkSQLParser.KW_OPTIONS:
            case SparkSQLParser.KW_ORDERING:
            case SparkSQLParser.KW_OUTPUT:
            case SparkSQLParser.KW_OVERWRITE:
            case SparkSQLParser.KW_OVERWRITING:
            case SparkSQLParser.KW_PARTITIONED:
            case SparkSQLParser.KW_PARTITIONS:
            case SparkSQLParser.KW_PASSING:
            case SparkSQLParser.KW_PAST:
            case SparkSQLParser.KW_PATH:
            case SparkSQLParser.KW_PLACING:
            case SparkSQLParser.KW_PLAN:
            case SparkSQLParser.KW_PRECEDING:
            case SparkSQLParser.KW_PRESERVE:
            case SparkSQLParser.KW_PRIOR:
            case SparkSQLParser.KW_PRIVILEGES:
            case SparkSQLParser.KW_PUBLIC:
            case SparkSQLParser.KW_PYTHON:
            case SparkSQLParser.KW_PYTHON_FILES:
            case SparkSQLParser.KW_PYTHON_REQUIREMENTS:
            case SparkSQLParser.KW_PYTHON_DEPENDENCIES:
            case SparkSQLParser.KW_PYTHON_JAR:
            case SparkSQLParser.KW_PYTHON_ARCHIVES:
            case SparkSQLParser.KW_PYTHON_PARAMETER:
            case SparkSQLParser.KW_QUARTER:
            case SparkSQLParser.KW_RAW:
            case SparkSQLParser.KW_READ:
            case SparkSQLParser.KW_RELATIVE:
            case SparkSQLParser.KW_REMOVE:
            case SparkSQLParser.KW_RENAME:
            case SparkSQLParser.KW_REPLACE:
            case SparkSQLParser.KW_RESPECT:
            case SparkSQLParser.KW_RESTART:
            case SparkSQLParser.KW_RESTRICT:
            case SparkSQLParser.KW_ROLE:
            case SparkSQLParser.KW_ROW_COUNT:
            case SparkSQLParser.KW_SCALA:
            case SparkSQLParser.KW_SCALAR:
            case SparkSQLParser.KW_SCALE:
            case SparkSQLParser.KW_SCHEMA:
            case SparkSQLParser.KW_SECONDS:
            case SparkSQLParser.KW_SECTION:
            case SparkSQLParser.KW_SECURITY:
            case SparkSQLParser.KW_SELF:
            case SparkSQLParser.KW_SERVER:
            case SparkSQLParser.KW_SERVER_NAME:
            case SparkSQLParser.KW_SESSION:
            case SparkSQLParser.KW_SETS:
            case SparkSQLParser.KW_SIMPLE:
            case SparkSQLParser.KW_SIZE:
            case SparkSQLParser.KW_SLIDE:
            case SparkSQLParser.KW_SOURCE:
            case SparkSQLParser.KW_SPACE:
            case SparkSQLParser.KW_STATE:
            case SparkSQLParser.KW_STATEMENT:
            case SparkSQLParser.KW_STEP:
            case SparkSQLParser.KW_STRING:
            case SparkSQLParser.KW_STRUCTURE:
            case SparkSQLParser.KW_STYLE:
            case SparkSQLParser.KW_TABLES:
            case SparkSQLParser.KW_TEMPORARY:
            case SparkSQLParser.KW_TIMECOL:
            case SparkSQLParser.KW_FLOOR:
            case SparkSQLParser.KW_TIMESTAMP_LTZ:
            case SparkSQLParser.KW_TIMESTAMPADD:
            case SparkSQLParser.KW_TIMESTAMPDIFF:
            case SparkSQLParser.KW_TOTIMESTAMP:
            case SparkSQLParser.KW_TRANSFORM:
            case SparkSQLParser.KW_TUMBLE:
            case SparkSQLParser.KW_TYPE:
            case SparkSQLParser.KW_UNDER:
            case SparkSQLParser.KW_UNLOAD:
            case SparkSQLParser.KW_USAGE:
            case SparkSQLParser.KW_USE:
            case SparkSQLParser.KW_UTF16:
            case SparkSQLParser.KW_UTF32:
            case SparkSQLParser.KW_UTF8:
            case SparkSQLParser.KW_VERSION:
            case SparkSQLParser.KW_VIEW:
            case SparkSQLParser.KW_VIEWS:
            case SparkSQLParser.KW_VIRTUAL:
            case SparkSQLParser.KW_WATERMARK:
            case SparkSQLParser.KW_WATERMARKS:
            case SparkSQLParser.KW_WEEK:
            case SparkSQLParser.KW_WORK:
            case SparkSQLParser.KW_WRAPPER:
            case SparkSQLParser.KW_YEARS:
            case SparkSQLParser.KW_ZONE:
            case SparkSQLParser.KW_LOCALTIMESTAMP:
            case SparkSQLParser.DOLLAR:
            case SparkSQLParser.STRING_LITERAL:
            case SparkSQLParser.DIG_LITERAL:
            case SparkSQLParser.ID_LITERAL:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 536;
                this.uid();
                }
                break;
            case SparkSQLParser.KW_FROM:
            case SparkSQLParser.KW_LIKE:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 539;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 291) {
                    {
                    this.state = 537;
                    this.match(SparkSQLParser.KW_FROM);
                    this.state = 538;
                    this.uid();
                    }
                }

                this.state = 541;
                this.match(SparkSQLParser.KW_LIKE);
                this.state = 542;
                this.expression();
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public tableCanHasKeyPropertyList(): TableCanHasKeyPropertyListContext {
        let localContext = new TableCanHasKeyPropertyListContext(this.context, this.state);
        this.enterRule(localContext, 16, SparkSQLParser.RULE_tableCanHasKeyPropertyList);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 545;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 548;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 11, this.context) ) {
            case 1:
                {
                this.state = 546;
                this.tableProperty();
                }
                break;
            case 2:
                {
                this.state = 547;
                this.tablePropertyKey();
                }
                break;
            }
            this.state = 557;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 475) {
                {
                {
                this.state = 550;
                this.match(SparkSQLParser.COMMA);
                this.state = 553;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 12, this.context) ) {
                case 1:
                    {
                    this.state = 551;
                    this.tableProperty();
                    }
                    break;
                case 2:
                    {
                    this.state = 552;
                    this.tablePropertyKey();
                    }
                    break;
                }
                }
                }
                this.state = 559;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 560;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public createTable(): CreateTableContext {
        let localContext = new CreateTableContext(this.context, this.state);
        this.enterRule(localContext, 18, SparkSQLParser.RULE_createTable);
        try {
            this.state = 570;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 14, this.context) ) {
            case 1:
                localContext = new SimpleContext(localContext);
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 562;
                this.simpleCreateTable();
                }
                break;
            case 2:
                localContext = new AsSelectContext(localContext);
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 563;
                this.createTableAsSelect();
                }
                break;
            case 3:
                localContext = new MaterializedContext(localContext);
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 564;
                this.createMaterializedTableAsSelect();
                }
                break;
            case 4:
                localContext = new CustomSerdeContext(localContext);
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 565;
                this.createCustomSerde();
                }
                break;
            case 5:
                localContext = new CustomSerdeExternalContext(localContext);
                this.enterOuterAlt(localContext, 5);
                {
                this.state = 566;
                this.createCustomSerdeExternal();
                }
                break;
            case 6:
                localContext = new Using_createContext(localContext);
                this.enterOuterAlt(localContext, 6);
                {
                this.state = 567;
                this.usingCreate();
                }
                break;
            case 7:
                localContext = new HiveCreateContext(localContext);
                this.enterOuterAlt(localContext, 7);
                {
                this.state = 568;
                this.hiveFormatCreate();
                }
                break;
            case 8:
                localContext = new CreateExTableContext(localContext);
                this.enterOuterAlt(localContext, 8);
                {
                this.state = 569;
                this.createExternalTable();
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public simpleCreateTable(): SimpleCreateTableContext {
        let localContext = new SimpleCreateTableContext(this.context, this.state);
        this.enterRule(localContext, 20, SparkSQLParser.RULE_simpleCreateTable);
        let _la: number;
        try {
            let alternative: number;
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 572;
            this.match(SparkSQLParser.KW_CREATE);
            this.state = 574;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 169) {
                {
                this.state = 573;
                this.match(SparkSQLParser.KW_TEMPORARY);
                }
            }

            this.state = 576;
            this.match(SparkSQLParser.KW_TABLE);
            this.state = 578;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 16, this.context) ) {
            case 1:
                {
                this.state = 577;
                this.ifNotExists();
                }
                break;
            }
            this.state = 580;
            this.tablePathCreate();
            this.state = 584;
            this.errorHandler.sync(this);
            alternative = this.interpreter.adaptivePredict(this.tokenStream, 17, this.context);
            while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {
                if (alternative === 1) {
                    {
                    {
                    this.state = 581;
                    this.simpleCreateTableNoSortElement();
                    }
                    }
                }
                this.state = 586;
                this.errorHandler.sync(this);
                alternative = this.interpreter.adaptivePredict(this.tokenStream, 17, this.context);
            }
            this.state = 590;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.LR_BRACKET:
                {
                this.state = 587;
                this.columnsBody();
                }
                break;
            case SparkSQLParser.KW_LIKE:
                {
                {
                this.state = 588;
                this.match(SparkSQLParser.KW_LIKE);
                this.state = 589;
                this.tablePath();
                }
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
            this.state = 595;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 87 || _la === 108 || _la === 234 || _la === 235 || ((((_la - 268)) & ~0x1F) === 0 && ((1 << (_la - 268)) & 538968067) !== 0) || ((((_la - 313)) & ~0x1F) === 0 && ((1 << (_la - 313)) & 98305) !== 0) || _la === 351 || ((((_la - 392)) & ~0x1F) === 0 && ((1 << (_la - 392)) & 1537) !== 0) || _la === 438 || _la === 446) {
                {
                {
                this.state = 592;
                this.simpleCreateTableNoSortElement();
                }
                }
                this.state = 597;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public simpleCreateTableNoSortElement(): SimpleCreateTableNoSortElementContext {
        let localContext = new SimpleCreateTableNoSortElementContext(this.context, this.state);
        this.enterRule(localContext, 22, SparkSQLParser.RULE_simpleCreateTableNoSortElement);
        try {
            this.state = 611;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 20, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 598;
                this.partitionDefinition();
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 599;
                this.withOption();
                }
                break;
            case 3:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 600;
                this.likeDefinition();
                }
                break;
            case 4:
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 601;
                this.distribution();
                }
                break;
            case 5:
                this.enterOuterAlt(localContext, 5);
                {
                this.state = 602;
                this.someByClause();
                }
                break;
            case 6:
                this.enterOuterAlt(localContext, 6);
                {
                this.state = 603;
                this.intoBuckets();
                }
                break;
            case 7:
                this.enterOuterAlt(localContext, 7);
                {
                this.state = 604;
                this.storedAs();
                }
                break;
            case 8:
                this.enterOuterAlt(localContext, 8);
                {
                this.state = 605;
                this.hiveFormatpartitionDefinition();
                }
                break;
            case 9:
                this.enterOuterAlt(localContext, 9);
                {
                this.state = 606;
                this.sortedBy();
                }
                break;
            case 10:
                this.enterOuterAlt(localContext, 10);
                {
                this.state = 607;
                this.rowFormatDelimited();
                }
                break;
            case 11:
                this.enterOuterAlt(localContext, 11);
                {
                this.state = 608;
                this.fieldsTerminatedBy();
                }
                break;
            case 12:
                this.enterOuterAlt(localContext, 12);
                {
                this.state = 609;
                this.using();
                }
                break;
            case 13:
                this.enterOuterAlt(localContext, 13);
                {
                this.state = 610;
                this.location();
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public sortedBy(): SortedByContext {
        let localContext = new SortedByContext(this.context, this.state);
        this.enterRule(localContext, 24, SparkSQLParser.RULE_sortedBy);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 613;
            this.match(SparkSQLParser.KW_SORTED);
            this.state = 614;
            this.match(SparkSQLParser.KW_BY);
            this.state = 615;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 616;
            this.identifier();
            this.state = 618;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 8 || _la === 35) {
                {
                this.state = 617;
                _la = this.tokenStream.LA(1);
                if(!(_la === 8 || _la === 35)) {
                this.errorHandler.recoverInline(this);
                }
                else {
                    this.errorHandler.reportMatch(this);
                    this.consume();
                }
                }
            }

            this.state = 620;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public usingCreate(): UsingCreateContext {
        let localContext = new UsingCreateContext(this.context, this.state);
        this.enterRule(localContext, 26, SparkSQLParser.RULE_usingCreate);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 622;
            this.match(SparkSQLParser.KW_CREATE);
            this.state = 623;
            this.match(SparkSQLParser.KW_TABLE);
            this.state = 625;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 22, this.context) ) {
            case 1:
                {
                this.state = 624;
                this.ifNotExists();
                }
                break;
            }
            this.state = 627;
            this.tablePathCreate();
            this.state = 631;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 23, this.context) ) {
            case 1:
                {
                this.state = 628;
                this.columnUsing();
                }
                break;
            case 2:
                {
                this.state = 629;
                this.usingByQuery();
                }
                break;
            case 3:
                {
                this.state = 630;
                this.defaultColumnUsing();
                }
                break;
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public tblProperties(): TblPropertiesContext {
        let localContext = new TblPropertiesContext(this.context, this.state);
        this.enterRule(localContext, 28, SparkSQLParser.RULE_tblProperties);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 633;
            this.match(SparkSQLParser.KW_TBLPROPERTIES);
            this.state = 634;
            this.tablePropertyList();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public defaultColumnUsing(): DefaultColumnUsingContext {
        let localContext = new DefaultColumnUsingContext(this.context, this.state);
        this.enterRule(localContext, 30, SparkSQLParser.RULE_defaultColumnUsing);
        let _la: number;
        try {
            let alternative: number;
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 636;
            this.using();
            this.state = 640;
            this.errorHandler.sync(this);
            alternative = this.interpreter.adaptivePredict(this.tokenStream, 24, this.context);
            while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {
                if (alternative === 1) {
                    {
                    {
                    this.state = 637;
                    this.defaultColumnUsingNoSortElement();
                    }
                    }
                }
                this.state = 642;
                this.errorHandler.sync(this);
                alternative = this.interpreter.adaptivePredict(this.tokenStream, 24, this.context);
            }
            {
            this.state = 644;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 209) {
                {
                this.state = 643;
                this.match(SparkSQLParser.KW_AS);
                }
            }

            this.state = 646;
            this.queryStatement(0);
            }
            this.state = 651;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 21 || _la === 103 || _la === 108 || _la === 234 || _la === 235 || _la === 269 || _la === 297 || _la === 313 || _la === 416 || _la === 446) {
                {
                {
                this.state = 648;
                this.defaultColumnUsingNoSortElement();
                }
                }
                this.state = 653;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public defaultColumnUsingNoSortElement(): DefaultColumnUsingNoSortElementContext {
        let localContext = new DefaultColumnUsingNoSortElementContext(this.context, this.state);
        this.enterRule(localContext, 32, SparkSQLParser.RULE_defaultColumnUsingNoSortElement);
        try {
            this.state = 667;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.KW_PARTITIONED:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 654;
                this.partitionDefinition();
                }
                break;
            case SparkSQLParser.KW_OPTIONS:
                this.enterOuterAlt(localContext, 2);
                {
                {
                this.state = 655;
                this.match(SparkSQLParser.KW_OPTIONS);
                this.state = 656;
                this.tablePropertyList();
                }
                }
                break;
            case SparkSQLParser.KW_TBLPROPERTIES:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 657;
                this.tblProperties();
                }
                break;
            case SparkSQLParser.KW_CLUSTER:
            case SparkSQLParser.KW_CLUSTERED:
            case SparkSQLParser.KW_DISTRIBUTE:
            case SparkSQLParser.KW_GROUP:
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 658;
                this.someByClause();
                }
                break;
            case SparkSQLParser.KW_INTO:
                this.enterOuterAlt(localContext, 5);
                {
                this.state = 659;
                this.intoBuckets();
                }
                break;
            case SparkSQLParser.KW_WITH:
                this.enterOuterAlt(localContext, 6);
                {
                {
                this.state = 660;
                this.match(SparkSQLParser.KW_WITH);
                this.state = 661;
                this.tableAlias();
                this.state = 662;
                this.match(SparkSQLParser.LB_BRACKET);
                this.state = 663;
                this.queryStatement(0);
                this.state = 664;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                }
                break;
            case SparkSQLParser.KW_COMMENT:
                this.enterOuterAlt(localContext, 7);
                {
                this.state = 666;
                this.commentSpec();
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public columnUsing(): ColumnUsingContext {
        let localContext = new ColumnUsingContext(this.context, this.state);
        this.enterRule(localContext, 34, SparkSQLParser.RULE_columnUsing);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            {
            this.state = 669;
            this.columnsBody();
            this.state = 670;
            this.using();
            }
            this.state = 675;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 21 || _la === 103 || _la === 108 || _la === 234 || _la === 235 || _la === 269 || _la === 297 || _la === 313 || _la === 416) {
                {
                {
                this.state = 672;
                this.columnUsingNoSortElement();
                }
                }
                this.state = 677;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public columnUsingNoSortElement(): ColumnUsingNoSortElementContext {
        let localContext = new ColumnUsingNoSortElementContext(this.context, this.state);
        this.enterRule(localContext, 36, SparkSQLParser.RULE_columnUsingNoSortElement);
        try {
            this.state = 685;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.KW_PARTITIONED:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 678;
                this.partitionDefinition();
                }
                break;
            case SparkSQLParser.KW_OPTIONS:
                this.enterOuterAlt(localContext, 2);
                {
                {
                this.state = 679;
                this.match(SparkSQLParser.KW_OPTIONS);
                this.state = 680;
                this.tablePropertyList();
                }
                }
                break;
            case SparkSQLParser.KW_TBLPROPERTIES:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 681;
                this.tblProperties();
                }
                break;
            case SparkSQLParser.KW_CLUSTER:
            case SparkSQLParser.KW_CLUSTERED:
            case SparkSQLParser.KW_DISTRIBUTE:
            case SparkSQLParser.KW_GROUP:
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 682;
                this.someByClause();
                }
                break;
            case SparkSQLParser.KW_INTO:
                this.enterOuterAlt(localContext, 5);
                {
                this.state = 683;
                this.intoBuckets();
                }
                break;
            case SparkSQLParser.KW_COMMENT:
                this.enterOuterAlt(localContext, 6);
                {
                this.state = 684;
                this.commentSpec();
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public usingByQuery(): UsingByQueryContext {
        let localContext = new UsingByQueryContext(this.context, this.state);
        this.enterRule(localContext, 38, SparkSQLParser.RULE_usingByQuery);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            {
            this.state = 687;
            this.using();
            this.state = 688;
            this.match(SparkSQLParser.KW_AS);
            this.state = 689;
            this.queryStatement(0);
            }
            this.state = 694;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 21 || _la === 103 || _la === 108 || _la === 234 || _la === 235 || _la === 269 || _la === 297 || _la === 313 || _la === 416) {
                {
                {
                this.state = 691;
                this.usingByQueryNoSortElement();
                }
                }
                this.state = 696;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public usingByQueryNoSortElement(): UsingByQueryNoSortElementContext {
        let localContext = new UsingByQueryNoSortElementContext(this.context, this.state);
        this.enterRule(localContext, 40, SparkSQLParser.RULE_usingByQueryNoSortElement);
        try {
            this.state = 704;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.KW_PARTITIONED:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 697;
                this.partitionDefinition();
                }
                break;
            case SparkSQLParser.KW_OPTIONS:
                this.enterOuterAlt(localContext, 2);
                {
                {
                this.state = 698;
                this.match(SparkSQLParser.KW_OPTIONS);
                this.state = 699;
                this.tablePropertyList();
                }
                }
                break;
            case SparkSQLParser.KW_TBLPROPERTIES:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 700;
                this.tblProperties();
                }
                break;
            case SparkSQLParser.KW_CLUSTER:
            case SparkSQLParser.KW_CLUSTERED:
            case SparkSQLParser.KW_DISTRIBUTE:
            case SparkSQLParser.KW_GROUP:
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 701;
                this.someByClause();
                }
                break;
            case SparkSQLParser.KW_INTO:
                this.enterOuterAlt(localContext, 5);
                {
                this.state = 702;
                this.intoBuckets();
                }
                break;
            case SparkSQLParser.KW_COMMENT:
                this.enterOuterAlt(localContext, 6);
                {
                this.state = 703;
                this.commentSpec();
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public intoBuckets(): IntoBucketsContext {
        let localContext = new IntoBucketsContext(this.context, this.state);
        this.enterRule(localContext, 42, SparkSQLParser.RULE_intoBuckets);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 706;
            this.match(SparkSQLParser.KW_INTO);
            this.state = 707;
            this.match(SparkSQLParser.DIG_LITERAL);
            this.state = 708;
            this.match(SparkSQLParser.KW_BUCKETS);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public hiveFormatCreate(): HiveFormatCreateContext {
        let localContext = new HiveFormatCreateContext(this.context, this.state);
        this.enterRule(localContext, 44, SparkSQLParser.RULE_hiveFormatCreate);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 710;
            this.match(SparkSQLParser.KW_CREATE);
            this.state = 712;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 169) {
                {
                this.state = 711;
                this.match(SparkSQLParser.KW_TEMPORARY);
                }
            }

            this.state = 714;
            this.match(SparkSQLParser.KW_TABLE);
            this.state = 716;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 33, this.context) ) {
            case 1:
                {
                this.state = 715;
                this.ifNotExists();
                }
                break;
            }
            this.state = 718;
            this.tablePathCreate();
            this.state = 720;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            do {
                {
                {
                this.state = 719;
                this.hiveFormatCreateNoSortElement();
                }
                }
                this.state = 722;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            } while (_la === 21 || _la === 108 || ((((_la - 209)) & ~0x1F) === 0 && ((1 << (_la - 209)) & 100663297) !== 0) || ((((_la - 269)) & ~0x1F) === 0 && ((1 << (_la - 269)) & 269484033) !== 0) || _la === 328 || _la === 361 || _la === 392 || _la === 401 || _la === 416 || _la === 446 || _la === 471);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public hiveFormatpartitionDefinition(): HiveFormatpartitionDefinitionContext {
        let localContext = new HiveFormatpartitionDefinitionContext(this.context, this.state);
        this.enterRule(localContext, 46, SparkSQLParser.RULE_hiveFormatpartitionDefinition);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 724;
            this.match(SparkSQLParser.KW_PARTITIONED);
            this.state = 725;
            this.match(SparkSQLParser.KW_BY);
            this.state = 726;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 727;
            this.match(SparkSQLParser.ID_LITERAL);
            this.state = 729;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 10 || _la === 88 || _la === 131 || _la === 154 || _la === 172 || _la === 173 || _la === 215 || _la === 219 || ((((_la - 254)) & ~0x1F) === 0 && ((1 << (_la - 254)) & 65553) !== 0) || ((((_la - 288)) & ~0x1F) === 0 && ((1 << (_la - 288)) & 6291457) !== 0) || _la === 352 || ((((_la - 403)) & ~0x1F) === 0 && ((1 << (_la - 403)) & 4587521) !== 0)) {
                {
                this.state = 728;
                this.sqlSimpleType();
                }
            }

            this.state = 738;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 475) {
                {
                {
                this.state = 731;
                this.match(SparkSQLParser.COMMA);
                this.state = 732;
                this.match(SparkSQLParser.ID_LITERAL);
                this.state = 734;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 10 || _la === 88 || _la === 131 || _la === 154 || _la === 172 || _la === 173 || _la === 215 || _la === 219 || ((((_la - 254)) & ~0x1F) === 0 && ((1 << (_la - 254)) & 65553) !== 0) || ((((_la - 288)) & ~0x1F) === 0 && ((1 << (_la - 288)) & 6291457) !== 0) || _la === 352 || ((((_la - 403)) & ~0x1F) === 0 && ((1 << (_la - 403)) & 4587521) !== 0)) {
                    {
                    this.state = 733;
                    this.sqlSimpleType();
                    }
                }

                }
                }
                this.state = 740;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 741;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public hiveFormatCreateNoSortElement(): HiveFormatCreateNoSortElementContext {
        let localContext = new HiveFormatCreateNoSortElementContext(this.context, this.state);
        this.enterRule(localContext, 48, SparkSQLParser.RULE_hiveFormatCreateNoSortElement);
        try {
            this.state = 758;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 38, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 743;
                this.storedAs();
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                {
                this.state = 744;
                this.match(SparkSQLParser.KW_AS);
                this.state = 745;
                this.queryStatement(0);
                }
                }
                break;
            case 3:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 746;
                this.columnsBody();
                }
                break;
            case 4:
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 747;
                this.hiveFormatpartitionDefinition();
                }
                break;
            case 5:
                this.enterOuterAlt(localContext, 5);
                {
                this.state = 748;
                this.withOption();
                }
                break;
            case 6:
                this.enterOuterAlt(localContext, 6);
                {
                this.state = 749;
                this.likeDefinition();
                }
                break;
            case 7:
                this.enterOuterAlt(localContext, 7);
                {
                this.state = 750;
                this.someByClause();
                }
                break;
            case 8:
                this.enterOuterAlt(localContext, 8);
                {
                this.state = 751;
                this.commentSpec();
                }
                break;
            case 9:
                this.enterOuterAlt(localContext, 9);
                {
                this.state = 752;
                this.rowFormatDelimted();
                }
                break;
            case 10:
                this.enterOuterAlt(localContext, 10);
                {
                this.state = 753;
                this.fieldsTerminatedBy();
                }
                break;
            case 11:
                this.enterOuterAlt(localContext, 11);
                {
                this.state = 754;
                this.tblProperties();
                }
                break;
            case 12:
                this.enterOuterAlt(localContext, 12);
                {
                this.state = 755;
                this.storedAsInputformat();
                }
                break;
            case 13:
                this.enterOuterAlt(localContext, 13);
                {
                this.state = 756;
                this.outputformat();
                }
                break;
            case 14:
                this.enterOuterAlt(localContext, 14);
                {
                this.state = 757;
                this.rowFormatSerde();
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public rowFormatSerde(): RowFormatSerdeContext {
        let localContext = new RowFormatSerdeContext(this.context, this.state);
        this.enterRule(localContext, 50, SparkSQLParser.RULE_rowFormatSerde);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 760;
            this.match(SparkSQLParser.KW_ROW);
            this.state = 761;
            this.match(SparkSQLParser.KW_FORMAT);
            this.state = 762;
            this.match(SparkSQLParser.KW_SERDE);
            this.state = 763;
            this.stringLiteral();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public fieldsTerminatedBy(): FieldsTerminatedByContext {
        let localContext = new FieldsTerminatedByContext(this.context, this.state);
        this.enterRule(localContext, 52, SparkSQLParser.RULE_fieldsTerminatedBy);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 765;
            this.match(SparkSQLParser.KW_FIELDS);
            this.state = 766;
            this.match(SparkSQLParser.KW_TERMINATED);
            this.state = 767;
            this.match(SparkSQLParser.KW_BY);
            this.state = 768;
            this.stringLiteral();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public storedAs(): StoredAsContext {
        let localContext = new StoredAsContext(this.context, this.state);
        this.enterRule(localContext, 54, SparkSQLParser.RULE_storedAs);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 770;
            this.match(SparkSQLParser.KW_STORED);
            this.state = 771;
            this.match(SparkSQLParser.KW_AS);
            this.state = 773;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 39, this.context) ) {
            case 1:
                {
                this.state = 772;
                this.identifier();
                }
                break;
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public storedAsInputformat(): StoredAsInputformatContext {
        let localContext = new StoredAsInputformatContext(this.context, this.state);
        this.enterRule(localContext, 56, SparkSQLParser.RULE_storedAsInputformat);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 775;
            this.match(SparkSQLParser.KW_STORED);
            this.state = 776;
            this.match(SparkSQLParser.KW_AS);
            this.state = 777;
            this.match(SparkSQLParser.KW_INPUTFORMAT);
            this.state = 779;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 40, this.context) ) {
            case 1:
                {
                this.state = 778;
                this.identifier();
                }
                break;
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public outputformat(): OutputformatContext {
        let localContext = new OutputformatContext(this.context, this.state);
        this.enterRule(localContext, 58, SparkSQLParser.RULE_outputformat);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 781;
            this.match(SparkSQLParser.KW_OUTPUTFORMAT);
            this.state = 783;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 41, this.context) ) {
            case 1:
                {
                this.state = 782;
                this.identifier();
                }
                break;
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public createExternalTable(): CreateExternalTableContext {
        let localContext = new CreateExternalTableContext(this.context, this.state);
        this.enterRule(localContext, 60, SparkSQLParser.RULE_createExternalTable);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 785;
            this.match(SparkSQLParser.KW_CREATE);
            this.state = 786;
            this.match(SparkSQLParser.KW_EXTERNAL);
            this.state = 787;
            this.match(SparkSQLParser.KW_TABLE);
            this.state = 789;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 42, this.context) ) {
            case 1:
                {
                this.state = 788;
                this.ifNotExists();
                }
                break;
            }
            this.state = 791;
            this.tablePathCreate();
            this.state = 792;
            this.columnsBody();
            this.state = 794;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            do {
                {
                {
                this.state = 793;
                this.createExternalTableNoSortElement();
                }
                }
                this.state = 796;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            } while (_la === 87 || _la === 89 || _la === 253 || _la === 277 || _la === 289 || _la === 329 || _la === 351 || _la === 361 || _la === 392 || _la === 401);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public createExternalTableNoSortElement(): CreateExternalTableNoSortElementContext {
        let localContext = new CreateExternalTableNoSortElementContext(this.context, this.state);
        this.enterRule(localContext, 62, SparkSQLParser.RULE_createExternalTableNoSortElement);
        try {
            this.state = 830;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 44, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 798;
                this.rowFormatDelimted();
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 799;
                this.fieldsTerminatedBy();
                }
                break;
            case 3:
                this.enterOuterAlt(localContext, 3);
                {
                {
                this.state = 800;
                this.match(SparkSQLParser.KW_ROW);
                this.state = 801;
                this.match(SparkSQLParser.KW_FORMAT);
                this.state = 802;
                this.match(SparkSQLParser.KW_SERDE);
                this.state = 803;
                this.stringLiteral();
                }
                }
                break;
            case 4:
                this.enterOuterAlt(localContext, 4);
                {
                {
                this.state = 804;
                this.match(SparkSQLParser.KW_LINES);
                this.state = 805;
                this.match(SparkSQLParser.KW_TERMINATED);
                this.state = 806;
                this.match(SparkSQLParser.KW_BY);
                this.state = 807;
                this.stringLiteral();
                }
                }
                break;
            case 5:
                this.enterOuterAlt(localContext, 5);
                {
                {
                this.state = 808;
                this.match(SparkSQLParser.KW_NULL);
                this.state = 809;
                this.match(SparkSQLParser.KW_DEFINED);
                this.state = 810;
                this.match(SparkSQLParser.KW_AS);
                this.state = 811;
                this.stringLiteral();
                }
                }
                break;
            case 6:
                this.enterOuterAlt(localContext, 6);
                {
                {
                this.state = 812;
                this.match(SparkSQLParser.KW_ESCAPED);
                this.state = 813;
                this.match(SparkSQLParser.KW_BY);
                this.state = 814;
                this.stringLiteral();
                }
                }
                break;
            case 7:
                this.enterOuterAlt(localContext, 7);
                {
                {
                this.state = 815;
                this.match(SparkSQLParser.KW_COLLECTION);
                this.state = 816;
                this.match(SparkSQLParser.KW_ITEMS);
                this.state = 817;
                this.match(SparkSQLParser.KW_TERMINATED);
                this.state = 818;
                this.match(SparkSQLParser.KW_BY);
                this.state = 819;
                this.stringLiteral();
                }
                }
                break;
            case 8:
                this.enterOuterAlt(localContext, 8);
                {
                this.state = 820;
                this.storedAs();
                }
                break;
            case 9:
                this.enterOuterAlt(localContext, 9);
                {
                this.state = 821;
                this.storedAsInputformat();
                }
                break;
            case 10:
                this.enterOuterAlt(localContext, 10);
                {
                this.state = 822;
                this.outputformat();
                }
                break;
            case 11:
                this.enterOuterAlt(localContext, 11);
                {
                this.state = 823;
                this.location();
                }
                break;
            case 12:
                this.enterOuterAlt(localContext, 12);
                {
                {
                this.state = 824;
                this.match(SparkSQLParser.KW_MAP);
                this.state = 825;
                this.match(SparkSQLParser.KW_KEYS);
                this.state = 826;
                this.match(SparkSQLParser.KW_TERMINATED);
                this.state = 827;
                this.match(SparkSQLParser.KW_BY);
                this.state = 828;
                this.stringLiteral();
                }
                }
                break;
            case 13:
                this.enterOuterAlt(localContext, 13);
                {
                this.state = 829;
                this.rowFormatSerde();
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public location(): LocationContext {
        let localContext = new LocationContext(this.context, this.state);
        this.enterRule(localContext, 64, SparkSQLParser.RULE_location);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 832;
            this.match(SparkSQLParser.KW_LOCATION);
            this.state = 833;
            this.filePath();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public rowFormatDelimted(): RowFormatDelimtedContext {
        let localContext = new RowFormatDelimtedContext(this.context, this.state);
        this.enterRule(localContext, 66, SparkSQLParser.RULE_rowFormatDelimted);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 835;
            this.match(SparkSQLParser.KW_ROW);
            this.state = 836;
            this.match(SparkSQLParser.KW_FORMAT);
            this.state = 837;
            this.match(SparkSQLParser.KW_DELIMITED);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public columnsBody(): ColumnsBodyContext {
        let localContext = new ColumnsBodyContext(this.context, this.state);
        this.enterRule(localContext, 68, SparkSQLParser.RULE_columnsBody);
        let _la: number;
        try {
            let alternative: number;
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 839;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 840;
            this.columnOptionDefinition();
            this.state = 842;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 21) {
                {
                this.state = 841;
                this.commentSpec();
                }
            }

            this.state = 851;
            this.errorHandler.sync(this);
            alternative = this.interpreter.adaptivePredict(this.tokenStream, 47, this.context);
            while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {
                if (alternative === 1) {
                    {
                    {
                    this.state = 844;
                    this.match(SparkSQLParser.COMMA);
                    this.state = 845;
                    this.columnOptionDefinition();
                    this.state = 847;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                    if (_la === 21) {
                        {
                        this.state = 846;
                        this.commentSpec();
                        }
                    }

                    }
                    }
                }
                this.state = 853;
                this.errorHandler.sync(this);
                alternative = this.interpreter.adaptivePredict(this.tokenStream, 47, this.context);
            }
            this.state = 859;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 49, this.context) ) {
            case 1:
                {
                this.state = 854;
                this.match(SparkSQLParser.COMMA);
                this.state = 855;
                this.watermarkDefinition();
                this.state = 857;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 21) {
                    {
                    this.state = 856;
                    this.commentSpec();
                    }
                }

                }
                break;
            }
            this.state = 866;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 51, this.context) ) {
            case 1:
                {
                this.state = 861;
                this.match(SparkSQLParser.COMMA);
                this.state = 862;
                this.tableConstraint();
                this.state = 864;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 21) {
                    {
                    this.state = 863;
                    this.commentSpec();
                    }
                }

                }
                break;
            }
            this.state = 873;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 475) {
                {
                this.state = 868;
                this.match(SparkSQLParser.COMMA);
                this.state = 869;
                this.selfDefinitionClause();
                this.state = 871;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 21) {
                    {
                    this.state = 870;
                    this.commentSpec();
                    }
                }

                }
            }

            this.state = 875;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public createCustomSerde(): CreateCustomSerdeContext {
        let localContext = new CreateCustomSerdeContext(this.context, this.state);
        this.enterRule(localContext, 70, SparkSQLParser.RULE_createCustomSerde);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 877;
            this.match(SparkSQLParser.KW_CREATE);
            this.state = 879;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 169) {
                {
                this.state = 878;
                this.match(SparkSQLParser.KW_TEMPORARY);
                }
            }

            this.state = 881;
            this.match(SparkSQLParser.KW_TABLE);
            this.state = 883;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 55, this.context) ) {
            case 1:
                {
                this.state = 882;
                this.ifNotExists();
                }
                break;
            }
            this.state = 885;
            this.tablePathCreate();
            this.state = 889;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 21 || _la === 108 || _la === 268 || _la === 328 || _la === 446 || _la === 471) {
                {
                {
                this.state = 886;
                this.createCustomSerdeNoSortElement();
                }
                }
                this.state = 891;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 892;
            this.match(SparkSQLParser.KW_ROW);
            this.state = 893;
            this.match(SparkSQLParser.KW_FORMAT);
            this.state = 894;
            this.match(SparkSQLParser.KW_SERDE);
            this.state = 895;
            this.tablePropertyKey();
            this.state = 899;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 21 || _la === 108 || _la === 268 || _la === 328 || _la === 446 || _la === 471) {
                {
                {
                this.state = 896;
                this.createCustomSerdeNoSortElement();
                }
                }
                this.state = 901;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 902;
            this.match(SparkSQLParser.KW_SORTED);
            this.state = 903;
            this.match(SparkSQLParser.KW_AS);
            this.state = 904;
            this.match(SparkSQLParser.KW_INPUTFORMAT);
            this.state = 905;
            this.tablePropertyKey();
            this.state = 909;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 21 || _la === 108 || _la === 268 || _la === 328 || _la === 446 || _la === 471) {
                {
                {
                this.state = 906;
                this.createCustomSerdeNoSortElement();
                }
                }
                this.state = 911;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 912;
            this.match(SparkSQLParser.KW_OUTPUTFORMAT);
            this.state = 913;
            this.tablePropertyKey();
            this.state = 917;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 21 || _la === 108 || _la === 268 || _la === 328 || _la === 446 || _la === 471) {
                {
                {
                this.state = 914;
                this.createCustomSerdeNoSortElement();
                }
                }
                this.state = 919;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 920;
            this.tblProperties();
            this.state = 924;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 21 || _la === 108 || _la === 268 || _la === 328 || _la === 446 || _la === 471) {
                {
                {
                this.state = 921;
                this.createCustomSerdeNoSortElement();
                }
                }
                this.state = 926;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public createCustomSerdeNoSortElement(): CreateCustomSerdeNoSortElementContext {
        let localContext = new CreateCustomSerdeNoSortElementContext(this.context, this.state);
        this.enterRule(localContext, 72, SparkSQLParser.RULE_createCustomSerdeNoSortElement);
        try {
            this.state = 933;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.LR_BRACKET:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 927;
                this.columnsBody();
                }
                break;
            case SparkSQLParser.KW_COMMENT:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 928;
                this.commentSpec();
                }
                break;
            case SparkSQLParser.KW_PARTITIONED:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 929;
                this.partitionDefinition();
                }
                break;
            case SparkSQLParser.KW_WITH:
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 930;
                this.withOption();
                }
                break;
            case SparkSQLParser.KW_LIKE:
                this.enterOuterAlt(localContext, 5);
                {
                this.state = 931;
                this.likeDefinition();
                }
                break;
            case SparkSQLParser.KW_DISTRIBUTED:
                this.enterOuterAlt(localContext, 6);
                {
                this.state = 932;
                this.distribution();
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public createCustomSerdeExternal(): CreateCustomSerdeExternalContext {
        let localContext = new CreateCustomSerdeExternalContext(this.context, this.state);
        this.enterRule(localContext, 74, SparkSQLParser.RULE_createCustomSerdeExternal);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 935;
            this.match(SparkSQLParser.KW_CREATE);
            this.state = 936;
            this.match(SparkSQLParser.KW_EXTERNAL);
            this.state = 937;
            this.match(SparkSQLParser.KW_TABLE);
            this.state = 939;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 62, this.context) ) {
            case 1:
                {
                this.state = 938;
                this.ifNotExists();
                }
                break;
            }
            this.state = 941;
            this.tablePathCreate();
            this.state = 945;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 21 || _la === 108 || _la === 268 || _la === 328 || _la === 416 || _la === 446) {
                {
                {
                this.state = 942;
                this.createCustomSerdeExternalNoSortElement();
                }
                }
                this.state = 947;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 948;
            this.columnsBody();
            this.state = 952;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 21 || _la === 108 || _la === 268 || _la === 328 || _la === 416 || _la === 446) {
                {
                {
                this.state = 949;
                this.createCustomSerdeExternalNoSortElement();
                }
                }
                this.state = 954;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 955;
            this.match(SparkSQLParser.KW_ROW);
            this.state = 956;
            this.match(SparkSQLParser.KW_FORMAT);
            this.state = 957;
            this.match(SparkSQLParser.KW_SERDE);
            this.state = 958;
            this.tablePropertyKey();
            this.state = 962;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 21 || _la === 108 || _la === 268 || _la === 328 || _la === 416 || _la === 446) {
                {
                {
                this.state = 959;
                this.createCustomSerdeExternalNoSortElement();
                }
                }
                this.state = 964;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 965;
            this.match(SparkSQLParser.KW_SORTED);
            this.state = 966;
            this.match(SparkSQLParser.KW_AS);
            this.state = 967;
            this.match(SparkSQLParser.KW_INPUTFORMAT);
            this.state = 968;
            this.tablePropertyKey();
            this.state = 972;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 21 || _la === 108 || _la === 268 || _la === 328 || _la === 416 || _la === 446) {
                {
                {
                this.state = 969;
                this.createCustomSerdeExternalNoSortElement();
                }
                }
                this.state = 974;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 975;
            this.match(SparkSQLParser.KW_OUTPUTFORMAT);
            this.state = 976;
            this.tablePropertyKey();
            this.state = 980;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 21 || _la === 108 || _la === 268 || _la === 328 || _la === 416 || _la === 446) {
                {
                {
                this.state = 977;
                this.createCustomSerdeExternalNoSortElement();
                }
                }
                this.state = 982;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 983;
            this.match(SparkSQLParser.KW_LOCATION);
            this.state = 984;
            this.filePath();
            this.state = 988;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 21 || _la === 108 || _la === 268 || _la === 328 || _la === 416 || _la === 446) {
                {
                {
                this.state = 985;
                this.createCustomSerdeExternalNoSortElement();
                }
                }
                this.state = 990;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public createCustomSerdeExternalNoSortElement(): CreateCustomSerdeExternalNoSortElementContext {
        let localContext = new CreateCustomSerdeExternalNoSortElementContext(this.context, this.state);
        this.enterRule(localContext, 76, SparkSQLParser.RULE_createCustomSerdeExternalNoSortElement);
        try {
            this.state = 997;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.KW_COMMENT:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 991;
                this.commentSpec();
                }
                break;
            case SparkSQLParser.KW_PARTITIONED:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 992;
                this.partitionDefinition();
                }
                break;
            case SparkSQLParser.KW_WITH:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 993;
                this.withOption();
                }
                break;
            case SparkSQLParser.KW_LIKE:
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 994;
                this.likeDefinition();
                }
                break;
            case SparkSQLParser.KW_DISTRIBUTED:
                this.enterOuterAlt(localContext, 5);
                {
                this.state = 995;
                this.distribution();
                }
                break;
            case SparkSQLParser.KW_TBLPROPERTIES:
                this.enterOuterAlt(localContext, 6);
                {
                this.state = 996;
                this.tblProperties();
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public createTableAsSelect(): CreateTableAsSelectContext {
        let localContext = new CreateTableAsSelectContext(this.context, this.state);
        this.enterRule(localContext, 78, SparkSQLParser.RULE_createTableAsSelect);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 999;
            this.match(SparkSQLParser.KW_CREATE);
            this.state = 1000;
            this.match(SparkSQLParser.KW_TABLE);
            this.state = 1002;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 70, this.context) ) {
            case 1:
                {
                this.state = 1001;
                this.ifNotExists();
                }
                break;
            }
            this.state = 1004;
            this.tablePathCreate();
            this.state = 1005;
            this.withOption();
            this.state = 1008;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 209) {
                {
                this.state = 1006;
                this.match(SparkSQLParser.KW_AS);
                this.state = 1007;
                this.queryStatement(0);
                }
            }

            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public createMaterializedTableAsSelect(): CreateMaterializedTableAsSelectContext {
        let localContext = new CreateMaterializedTableAsSelectContext(this.context, this.state);
        this.enterRule(localContext, 80, SparkSQLParser.RULE_createMaterializedTableAsSelect);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1010;
            this.match(SparkSQLParser.KW_CREATE);
            this.state = 1011;
            this.match(SparkSQLParser.KW_MATERIALIZED);
            this.state = 1012;
            this.match(SparkSQLParser.KW_TABLE);
            this.state = 1013;
            this.tablePathCreate();
            this.state = 1017;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 108 || _la === 209 || _la === 446 || _la === 452) {
                {
                {
                this.state = 1014;
                this.createMaterializedTableAsSelectNoSortElement();
                }
                }
                this.state = 1019;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 1020;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 1021;
            this.match(SparkSQLParser.KW_PRIMARY);
            this.state = 1022;
            this.match(SparkSQLParser.KW_KEY);
            this.state = 1023;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 1024;
            this.identifier();
            this.state = 1029;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 475) {
                {
                {
                this.state = 1025;
                this.match(SparkSQLParser.COMMA);
                this.state = 1026;
                this.identifier();
                }
                }
                this.state = 1031;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 1032;
            this.match(SparkSQLParser.RR_BRACKET);
            this.state = 1035;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 348) {
                {
                this.state = 1033;
                this.match(SparkSQLParser.KW_NOT);
                this.state = 1034;
                this.match(SparkSQLParser.KW_ENFORCED);
                }
            }

            this.state = 1037;
            this.match(SparkSQLParser.RR_BRACKET);
            this.state = 1041;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 108 || _la === 209 || _la === 446 || _la === 452) {
                {
                {
                this.state = 1038;
                this.createMaterializedTableAsSelectNoSortElement();
                }
                }
                this.state = 1043;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            {
            this.state = 1044;
            this.match(SparkSQLParser.KW_FRESHNESS);
            this.state = 1045;
            this.match(SparkSQLParser.EQUAL_SYMBOL);
            this.state = 1046;
            this.match(SparkSQLParser.KW_INTERVAL);
            this.state = 1047;
            this.identifier();
            this.state = 1048;
            _la = this.tokenStream.LA(1);
            if(!(_la === 256 || _la === 301 || _la === 339 || _la === 394)) {
            this.errorHandler.recoverInline(this);
            }
            else {
                this.errorHandler.reportMatch(this);
                this.consume();
            }
            }
            this.state = 1053;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 108 || _la === 209 || _la === 446 || _la === 452) {
                {
                {
                this.state = 1050;
                this.createMaterializedTableAsSelectNoSortElement();
                }
                }
                this.state = 1055;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public createMaterializedTableAsSelectNoSortElement(): CreateMaterializedTableAsSelectNoSortElementContext {
        let localContext = new CreateMaterializedTableAsSelectNoSortElementContext(this.context, this.state);
        this.enterRule(localContext, 82, SparkSQLParser.RULE_createMaterializedTableAsSelectNoSortElement);
        let _la: number;
        try {
            this.state = 1063;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.KW_PARTITIONED:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 1056;
                this.partitionDefinition();
                }
                break;
            case SparkSQLParser.KW_WITH:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 1057;
                this.withOption();
                }
                break;
            case SparkSQLParser.KW_REFRESH_MODE:
                this.enterOuterAlt(localContext, 3);
                {
                {
                this.state = 1058;
                this.match(SparkSQLParser.KW_REFRESH_MODE);
                this.state = 1059;
                this.match(SparkSQLParser.EQUAL_SYMBOL);
                this.state = 1060;
                _la = this.tokenStream.LA(1);
                if(!(_la === 293 || _la === 454)) {
                this.errorHandler.recoverInline(this);
                }
                else {
                    this.errorHandler.reportMatch(this);
                    this.consume();
                }
                }
                }
                break;
            case SparkSQLParser.KW_AS:
                this.enterOuterAlt(localContext, 4);
                {
                {
                this.state = 1061;
                this.match(SparkSQLParser.KW_AS);
                this.state = 1062;
                this.queryStatement(0);
                }
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public createCatalog(): CreateCatalogContext {
        let localContext = new CreateCatalogContext(this.context, this.state);
        this.enterRule(localContext, 84, SparkSQLParser.RULE_createCatalog);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1065;
            this.match(SparkSQLParser.KW_CREATE);
            this.state = 1066;
            this.match(SparkSQLParser.KW_CATALOG);
            this.state = 1067;
            this.uid();
            this.state = 1068;
            this.withOption();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public createDatabase(): CreateDatabaseContext {
        let localContext = new CreateDatabaseContext(this.context, this.state);
        this.enterRule(localContext, 86, SparkSQLParser.RULE_createDatabase);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1070;
            this.match(SparkSQLParser.KW_CREATE);
            this.state = 1071;
            this.match(SparkSQLParser.KW_DATABASE);
            this.state = 1073;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 78, this.context) ) {
            case 1:
                {
                this.state = 1072;
                this.ifNotExists();
                }
                break;
            }
            this.state = 1075;
            this.databasePathCreate();
            this.state = 1077;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 21) {
                {
                this.state = 1076;
                this.commentSpec();
                }
            }

            this.state = 1081;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 87) {
                {
                this.state = 1079;
                this.match(SparkSQLParser.KW_LOCATION);
                this.state = 1080;
                this.match(SparkSQLParser.STRING_LITERAL);
                }
            }

            this.state = 1084;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 446) {
                {
                this.state = 1083;
                this.withOption();
                }
            }

            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public createView(): CreateViewContext {
        let localContext = new CreateViewContext(this.context, this.state);
        this.enterRule(localContext, 88, SparkSQLParser.RULE_createView);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1086;
            this.match(SparkSQLParser.KW_CREATE);
            this.state = 1089;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 357) {
                {
                this.state = 1087;
                this.match(SparkSQLParser.KW_OR);
                this.state = 1088;
                this.match(SparkSQLParser.KW_REPLACE);
                }
            }

            this.state = 1095;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 169 || _la === 295) {
                {
                this.state = 1092;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 295) {
                    {
                    this.state = 1091;
                    this.match(SparkSQLParser.KW_GLOBAL);
                    }
                }

                this.state = 1094;
                this.match(SparkSQLParser.KW_TEMPORARY);
                }
            }

            this.state = 1097;
            this.match(SparkSQLParser.KW_VIEW);
            this.state = 1099;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 85, this.context) ) {
            case 1:
                {
                this.state = 1098;
                this.ifNotExists();
                }
                break;
            }
            this.state = 1101;
            this.uid();
            this.state = 1103;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 471) {
                {
                this.state = 1102;
                this.columnNameList();
                }
            }

            this.state = 1106;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 21) {
                {
                this.state = 1105;
                this.commentSpec();
                }
            }

            this.state = 1108;
            this.match(SparkSQLParser.KW_AS);
            this.state = 1109;
            this.queryStatement(0);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public createFunction(): CreateFunctionContext {
        let localContext = new CreateFunctionContext(this.context, this.state);
        this.enterRule(localContext, 90, SparkSQLParser.RULE_createFunction);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1111;
            this.match(SparkSQLParser.KW_CREATE);
            this.state = 1114;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 357) {
                {
                this.state = 1112;
                this.match(SparkSQLParser.KW_OR);
                this.state = 1113;
                this.match(SparkSQLParser.KW_REPLACE);
                }
            }

            this.state = 1119;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 89, this.context) ) {
            case 1:
                {
                this.state = 1116;
                this.match(SparkSQLParser.KW_TEMPORARY);
                }
                break;
            case 2:
                {
                this.state = 1117;
                this.match(SparkSQLParser.KW_TEMPORARY);
                this.state = 1118;
                this.match(SparkSQLParser.KW_SYSTEM);
                }
                break;
            }
            this.state = 1121;
            this.match(SparkSQLParser.KW_FUNCTION);
            this.state = 1123;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 90, this.context) ) {
            case 1:
                {
                this.state = 1122;
                this.ifNotExists();
                }
                break;
            }
            this.state = 1125;
            this.functionName();
            this.state = 1126;
            this.match(SparkSQLParser.KW_AS);
            this.state = 1127;
            this.identifier();
            this.state = 1136;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 92, this.context) ) {
            case 1:
                {
                {
                this.state = 1130;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 322) {
                    {
                    this.state = 1128;
                    this.match(SparkSQLParser.KW_LANGUAGE);
                    this.state = 1129;
                    _la = this.tokenStream.LA(1);
                    if(!(_la === 74 || _la === 120 || _la === 141)) {
                    this.errorHandler.recoverInline(this);
                    }
                    else {
                        this.errorHandler.reportMatch(this);
                        this.consume();
                    }
                    }
                }

                this.state = 1132;
                this.usingClause();
                }
                }
                break;
            case 2:
                {
                this.state = 1133;
                this.match(SparkSQLParser.KW_USING);
                this.state = 1134;
                this.match(SparkSQLParser.KW_JAR);
                this.state = 1135;
                this.jarFileName();
                }
                break;
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public usingClause(): UsingClauseContext {
        let localContext = new UsingClauseContext(this.context, this.state);
        this.enterRule(localContext, 92, SparkSQLParser.RULE_usingClause);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1138;
            this.match(SparkSQLParser.KW_USING);
            this.state = 1139;
            this.match(SparkSQLParser.KW_JAR);
            this.state = 1140;
            this.jarFileName();
            this.state = 1146;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 475) {
                {
                {
                this.state = 1141;
                this.match(SparkSQLParser.COMMA);
                this.state = 1142;
                this.match(SparkSQLParser.KW_JAR);
                this.state = 1143;
                this.jarFileName();
                }
                }
                this.state = 1148;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public jarFileName(): JarFileNameContext {
        let localContext = new JarFileNameContext(this.context, this.state);
        this.enterRule(localContext, 94, SparkSQLParser.RULE_jarFileName);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1149;
            this.filePath();
            this.state = 1152;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 468) {
                {
                this.state = 1150;
                this.match(SparkSQLParser.DOT);
                this.state = 1151;
                this.match(SparkSQLParser.KW_JAR);
                }
            }

            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public filePath(): FilePathContext {
        let localContext = new FilePathContext(this.context, this.state);
        this.enterRule(localContext, 96, SparkSQLParser.RULE_filePath);
        let _la: number;
        try {
            this.state = 1163;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.STRING_LITERAL:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 1154;
                this.match(SparkSQLParser.STRING_LITERAL);
                }
                break;
            case SparkSQLParser.SLASH_SIGN:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 1159;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                do {
                    {
                    {
                    this.state = 1155;
                    this.match(SparkSQLParser.SLASH_SIGN);
                    this.state = 1157;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                    if (_la === 496) {
                        {
                        this.state = 1156;
                        this.match(SparkSQLParser.ID_LITERAL);
                        }
                    }

                    }
                    }
                    this.state = 1161;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                } while (_la === 490);
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public columnPosition(): ColumnPositionContext {
        let localContext = new ColumnPositionContext(this.context, this.state);
        this.enterRule(localContext, 98, SparkSQLParser.RULE_columnPosition);
        let _la: number;
        try {
            this.state = 1168;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.KW_FIRST:
            case SparkSQLParser.KW_LAST:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 1165;
                _la = this.tokenStream.LA(1);
                if(!(_la === 52 || _la === 82)) {
                this.errorHandler.recoverInline(this);
                }
                else {
                    this.errorHandler.reportMatch(this);
                    this.consume();
                }
                }
                break;
            case SparkSQLParser.KW_AFTER:
            case SparkSQLParser.KW_BEFORE:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 1166;
                _la = this.tokenStream.LA(1);
                if(!(_la === 6 || _la === 9)) {
                this.errorHandler.recoverInline(this);
                }
                else {
                    this.errorHandler.reportMatch(this);
                    this.consume();
                }
                this.state = 1167;
                this.uid();
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public renameDefinition(): RenameDefinitionContext {
        let localContext = new RenameDefinitionContext(this.context, this.state);
        this.enterRule(localContext, 100, SparkSQLParser.RULE_renameDefinition);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1170;
            this.match(SparkSQLParser.KW_RENAME);
            this.state = 1172;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if ((((_la) & ~0x1F) === 0 && ((1 << _la) & 4294896624) !== 0) || ((((_la - 33)) & ~0x1F) === 0 && ((1 << (_la - 33)) & 4294803199) !== 0) || ((((_la - 65)) & ~0x1F) === 0 && ((1 << (_la - 65)) & 4281327607) !== 0) || ((((_la - 97)) & ~0x1F) === 0 && ((1 << (_la - 97)) & 2147483643) !== 0) || ((((_la - 129)) & ~0x1F) === 0 && ((1 << (_la - 129)) & 2113863675) !== 0) || ((((_la - 161)) & ~0x1F) === 0 && ((1 << (_la - 161)) & 4292341757) !== 0) || ((((_la - 193)) & ~0x1F) === 0 && ((1 << (_la - 193)) & 247) !== 0) || _la === 332 || ((((_la - 478)) & ~0x1F) === 0 && ((1 << (_la - 478)) & 360449) !== 0)) {
                {
                this.state = 1171;
                this.uid();
                }
            }

            this.state = 1174;
            this.match(SparkSQLParser.KW_TO);
            this.state = 1175;
            this.uid();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public setKeyValueDefinition(): SetKeyValueDefinitionContext {
        let localContext = new SetKeyValueDefinitionContext(this.context, this.state);
        this.enterRule(localContext, 102, SparkSQLParser.RULE_setKeyValueDefinition);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1177;
            this.match(SparkSQLParser.KW_SET);
            this.state = 1178;
            this.tablePropertyList();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public addConstraint(): AddConstraintContext {
        let localContext = new AddConstraintContext(this.context, this.state);
        this.enterRule(localContext, 104, SparkSQLParser.RULE_addConstraint);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1180;
            this.match(SparkSQLParser.KW_ADD);
            this.state = 1181;
            this.match(SparkSQLParser.KW_CONSTRAINT);
            this.state = 1182;
            this.constraintName();
            this.state = 1183;
            this.match(SparkSQLParser.KW_PRIMARY);
            this.state = 1184;
            this.match(SparkSQLParser.KW_KEY);
            this.state = 1185;
            this.columnNameList();
            this.state = 1187;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 348) {
                {
                this.state = 1186;
                this.notForced();
                }
            }

            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public dropConstraint(): DropConstraintContext {
        let localContext = new DropConstraintContext(this.context, this.state);
        this.enterRule(localContext, 106, SparkSQLParser.RULE_dropConstraint);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1189;
            this.match(SparkSQLParser.KW_DROP);
            this.state = 1190;
            this.match(SparkSQLParser.KW_CONSTRAINT);
            this.state = 1191;
            this.constraintName();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public addUnique(): AddUniqueContext {
        let localContext = new AddUniqueContext(this.context, this.state);
        this.enterRule(localContext, 108, SparkSQLParser.RULE_addUnique);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1193;
            this.match(SparkSQLParser.KW_ADD);
            this.state = 1194;
            this.match(SparkSQLParser.KW_UNIQUE);
            this.state = 1195;
            this.columnNameList();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public notForced(): NotForcedContext {
        let localContext = new NotForcedContext(this.context, this.state);
        this.enterRule(localContext, 110, SparkSQLParser.RULE_notForced);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1197;
            this.match(SparkSQLParser.KW_NOT);
            this.state = 1198;
            this.match(SparkSQLParser.KW_ENFORCED);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public insertStatement(): InsertStatementContext {
        let localContext = new InsertStatementContext(this.context, this.state);
        this.enterRule(localContext, 112, SparkSQLParser.RULE_insertStatement);
        let _la: number;
        try {
            this.state = 1212;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 103, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 1207;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 102, this.context) ) {
                case 1:
                    {
                    this.state = 1201;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                    if (_la === 279) {
                        {
                        this.state = 1200;
                        this.match(SparkSQLParser.KW_EXECUTE);
                        }
                    }

                    this.state = 1203;
                    this.insertSimpleStatement();
                    }
                    break;
                case 2:
                    {
                    this.state = 1204;
                    this.insertSparkDirectoryStatement();
                    }
                    break;
                case 3:
                    {
                    this.state = 1205;
                    this.insertHiveDirectoryStatement();
                    }
                    break;
                case 4:
                    {
                    this.state = 1206;
                    this.insertFromTable();
                    }
                    break;
                }
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 1209;
                this.insertMulStatementCompatibility();
                }
                break;
            case 3:
                this.enterOuterAlt(localContext, 3);
                {
                {
                this.state = 1210;
                this.match(SparkSQLParser.KW_EXECUTE);
                this.state = 1211;
                this.insertMulStatement();
                }
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public insertSimpleStatement(): InsertSimpleStatementContext {
        let localContext = new InsertSimpleStatementContext(this.context, this.state);
        this.enterRule(localContext, 114, SparkSQLParser.RULE_insertSimpleStatement);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1214;
            this.match(SparkSQLParser.KW_INSERT);
            this.state = 1215;
            _la = this.tokenStream.LA(1);
            if(!(_la === 106 || _la === 313)) {
            this.errorHandler.recoverInline(this);
            }
            else {
                this.errorHandler.reportMatch(this);
                this.consume();
            }
            this.state = 1216;
            this.tablePath();
            this.state = 1218;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 365) {
                {
                this.state = 1217;
                this.insertPartitionDefinition();
                }
            }

            this.state = 1221;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 105, this.context) ) {
            case 1:
                {
                this.state = 1220;
                this.columnNameList();
                }
                break;
            }
            this.state = 1231;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.KW_FROM:
            case SparkSQLParser.KW_SELECT:
            case SparkSQLParser.KW_WITH:
            case SparkSQLParser.LR_BRACKET:
                {
                this.state = 1223;
                this.queryStatement(0);
                }
                break;
            case SparkSQLParser.KW_VALUES:
                {
                this.state = 1224;
                this.valuesDefinition();
                }
                break;
            case SparkSQLParser.KW_REPLACE:
                {
                {
                this.state = 1225;
                this.match(SparkSQLParser.KW_REPLACE);
                this.state = 1226;
                this.whereClause();
                this.state = 1227;
                this.selectStatement();
                }
                }
                break;
            case SparkSQLParser.KW_TABLE:
                {
                {
                this.state = 1229;
                this.match(SparkSQLParser.KW_TABLE);
                this.state = 1230;
                this.tablePath();
                }
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public insertFromTable(): InsertFromTableContext {
        let localContext = new InsertFromTableContext(this.context, this.state);
        this.enterRule(localContext, 116, SparkSQLParser.RULE_insertFromTable);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1233;
            this.match(SparkSQLParser.KW_INSERT);
            this.state = 1234;
            _la = this.tokenStream.LA(1);
            if(!(_la === 106 || _la === 313)) {
            this.errorHandler.recoverInline(this);
            }
            else {
                this.errorHandler.reportMatch(this);
                this.consume();
            }
            this.state = 1235;
            this.tablePath();
            this.state = 1236;
            this.match(SparkSQLParser.KW_TABLE);
            this.state = 1237;
            this.tablePath();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public insertSparkDirectoryStatement(): InsertSparkDirectoryStatementContext {
        let localContext = new InsertSparkDirectoryStatementContext(this.context, this.state);
        this.enterRule(localContext, 118, SparkSQLParser.RULE_insertSparkDirectoryStatement);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1239;
            this.match(SparkSQLParser.KW_INSERT);
            this.state = 1240;
            this.match(SparkSQLParser.KW_OVERWRITE);
            this.state = 1241;
            this.match(SparkSQLParser.KW_DIRECTORY);
            this.state = 1242;
            this.insertSparkDirectoryBody();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public insertSparkDirectoryBody(): InsertSparkDirectoryBodyContext {
        let localContext = new InsertSparkDirectoryBodyContext(this.context, this.state);
        this.enterRule(localContext, 120, SparkSQLParser.RULE_insertSparkDirectoryBody);
        let _la: number;
        try {
            this.state = 1290;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 115, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                {
                this.state = 1245;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 490 || _la === 493) {
                    {
                    this.state = 1244;
                    this.filePath();
                    }
                }

                this.state = 1247;
                this.match(SparkSQLParser.KW_USING);
                this.state = 1248;
                this.match(SparkSQLParser.ID_LITERAL);
                this.state = 1249;
                this.match(SparkSQLParser.KW_OPTIONS);
                this.state = 1250;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 1251;
                this.columnName();
                this.state = 1253;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 90 || _la === 92 || _la === 127 || _la === 195 || _la === 256 || _la === 287 || _la === 301 || _la === 312 || ((((_la - 339)) & ~0x1F) === 0 && ((1 << (_la - 339)) & 4617) !== 0) || _la === 394 || _la === 428 || _la === 449 || ((((_la - 485)) & ~0x1F) === 0 && ((1 << (_la - 485)) & 1793) !== 0)) {
                    {
                    this.state = 1252;
                    this.constant();
                    }
                }

                this.state = 1262;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                while (_la === 475) {
                    {
                    {
                    this.state = 1255;
                    this.match(SparkSQLParser.COMMA);
                    this.state = 1256;
                    this.columnName();
                    this.state = 1258;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                    if (_la === 90 || _la === 92 || _la === 127 || _la === 195 || _la === 256 || _la === 287 || _la === 301 || _la === 312 || ((((_la - 339)) & ~0x1F) === 0 && ((1 << (_la - 339)) & 4617) !== 0) || _la === 394 || _la === 428 || _la === 449 || ((((_la - 485)) & ~0x1F) === 0 && ((1 << (_la - 485)) & 1793) !== 0)) {
                        {
                        this.state = 1257;
                        this.constant();
                        }
                    }

                    }
                    }
                    this.state = 1264;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                }
                this.state = 1265;
                this.match(SparkSQLParser.RR_BRACKET);
                this.state = 1266;
                this.queryStatement(0);
                }
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                {
                this.state = 1268;
                this.match(SparkSQLParser.KW_USING);
                this.state = 1269;
                this.match(SparkSQLParser.ID_LITERAL);
                this.state = 1270;
                this.match(SparkSQLParser.KW_OPTIONS);
                this.state = 1271;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 1276;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 493) {
                    {
                    this.state = 1272;
                    this.match(SparkSQLParser.STRING_LITERAL);
                    this.state = 1274;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                    if (_la === 490 || _la === 493) {
                        {
                        this.state = 1273;
                        this.filePath();
                        }
                    }

                    }
                }

                this.state = 1285;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                while (_la === 475) {
                    {
                    {
                    this.state = 1278;
                    this.match(SparkSQLParser.COMMA);
                    this.state = 1279;
                    this.columnName();
                    this.state = 1281;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                    if (_la === 90 || _la === 92 || _la === 127 || _la === 195 || _la === 256 || _la === 287 || _la === 301 || _la === 312 || ((((_la - 339)) & ~0x1F) === 0 && ((1 << (_la - 339)) & 4617) !== 0) || _la === 394 || _la === 428 || _la === 449 || ((((_la - 485)) & ~0x1F) === 0 && ((1 << (_la - 485)) & 1793) !== 0)) {
                        {
                        this.state = 1280;
                        this.constant();
                        }
                    }

                    }
                    }
                    this.state = 1287;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                }
                this.state = 1288;
                this.match(SparkSQLParser.RR_BRACKET);
                this.state = 1289;
                this.queryStatement(0);
                }
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public insertHiveDirectoryStatement(): InsertHiveDirectoryStatementContext {
        let localContext = new InsertHiveDirectoryStatementContext(this.context, this.state);
        this.enterRule(localContext, 122, SparkSQLParser.RULE_insertHiveDirectoryStatement);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1292;
            this.match(SparkSQLParser.KW_INSERT);
            this.state = 1293;
            this.match(SparkSQLParser.KW_OVERWRITE);
            this.state = 1294;
            this.match(SparkSQLParser.KW_LOCAL);
            this.state = 1295;
            this.match(SparkSQLParser.KW_DIRECTORY);
            this.state = 1296;
            this.filePath();
            this.state = 1299;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.KW_STORED:
                {
                this.state = 1297;
                this.storedAs();
                }
                break;
            case SparkSQLParser.KW_ROW:
                {
                this.state = 1298;
                this.hiveRowFormatPart();
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
            this.state = 1301;
            this.queryStatement(0);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public hiveRowFormatPart(): HiveRowFormatPartContext {
        let localContext = new HiveRowFormatPartContext(this.context, this.state);
        this.enterRule(localContext, 124, SparkSQLParser.RULE_hiveRowFormatPart);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1303;
            this.rowFormatDelimted();
            this.state = 1304;
            this.fieldsTerminatedBy();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public insertPartitionDefinition(): InsertPartitionDefinitionContext {
        let localContext = new InsertPartitionDefinitionContext(this.context, this.state);
        this.enterRule(localContext, 126, SparkSQLParser.RULE_insertPartitionDefinition);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1306;
            this.match(SparkSQLParser.KW_PARTITION);
            this.state = 1307;
            this.tablePropertyList();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public insertMulStatementCompatibility(): InsertMulStatementCompatibilityContext {
        let localContext = new InsertMulStatementCompatibilityContext(this.context, this.state);
        this.enterRule(localContext, 128, SparkSQLParser.RULE_insertMulStatementCompatibility);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1309;
            this.match(SparkSQLParser.KW_BEGIN);
            this.state = 1310;
            this.match(SparkSQLParser.KW_STATEMENT);
            this.state = 1311;
            this.match(SparkSQLParser.KW_SET);
            this.state = 1312;
            this.match(SparkSQLParser.SEMICOLON);
            this.state = 1316;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            do {
                {
                {
                this.state = 1313;
                this.insertSimpleStatement();
                this.state = 1314;
                this.match(SparkSQLParser.SEMICOLON);
                }
                }
                this.state = 1318;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            } while (_la === 308);
            this.state = 1320;
            this.match(SparkSQLParser.KW_END);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public insertMulStatement(): InsertMulStatementContext {
        let localContext = new InsertMulStatementContext(this.context, this.state);
        this.enterRule(localContext, 130, SparkSQLParser.RULE_insertMulStatement);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1322;
            this.match(SparkSQLParser.KW_STATEMENT);
            this.state = 1323;
            this.match(SparkSQLParser.KW_SET);
            this.state = 1324;
            this.match(SparkSQLParser.KW_BEGIN);
            this.state = 1328;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            do {
                {
                {
                this.state = 1325;
                this.insertSimpleStatement();
                this.state = 1326;
                this.match(SparkSQLParser.SEMICOLON);
                }
                }
                this.state = 1330;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            } while (_la === 308);
            this.state = 1332;
            this.match(SparkSQLParser.KW_END);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }

    public queryStatement(): QueryStatementContext;
    public queryStatement(_p: number): QueryStatementContext;
    public queryStatement(_p?: number): QueryStatementContext {
        if (_p === undefined) {
            _p = 0;
        }

        let parentContext = this.context;
        let parentState = this.state;
        let localContext = new QueryStatementContext(this.context, parentState);
        let previousContext = localContext;
        let _startState = 132;
        this.enterRecursionRule(localContext, 132, SparkSQLParser.RULE_queryStatement, _p);
        let _la: number;
        try {
            let alternative: number;
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1358;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.KW_WITH:
                {
                this.state = 1335;
                this.withClause();
                this.state = 1336;
                this.queryStatement(4);
                }
                break;
            case SparkSQLParser.LR_BRACKET:
                {
                this.state = 1338;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 1339;
                this.queryStatement(0);
                this.state = 1340;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case SparkSQLParser.KW_FROM:
            case SparkSQLParser.KW_SELECT:
                {
                this.state = 1344;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 119, this.context) ) {
                case 1:
                    {
                    this.state = 1342;
                    this.selectClause();
                    }
                    break;
                case 2:
                    {
                    this.state = 1343;
                    this.selectStatement();
                    }
                    break;
                }
                this.state = 1347;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 120, this.context) ) {
                case 1:
                    {
                    this.state = 1346;
                    this.sortByCaluse();
                    }
                    break;
                }
                this.state = 1350;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 121, this.context) ) {
                case 1:
                    {
                    this.state = 1349;
                    this.orderByCaluse();
                    }
                    break;
                }
                this.state = 1353;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 122, this.context) ) {
                case 1:
                    {
                    this.state = 1352;
                    this.limitClause();
                    }
                    break;
                }
                this.state = 1356;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 123, this.context) ) {
                case 1:
                    {
                    this.state = 1355;
                    this.offsetClause();
                    }
                    break;
                }
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
            this.context!.stop = this.tokenStream.LT(-1);
            this.state = 1380;
            this.errorHandler.sync(this);
            alternative = this.interpreter.adaptivePredict(this.tokenStream, 130, this.context);
            while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {
                if (alternative === 1) {
                    if (this.parseListeners != null) {
                        this.triggerExitRuleEvent();
                    }
                    previousContext = localContext;
                    {
                    {
                    localContext = new QueryStatementContext(parentContext, parentState);
                    localContext._left = previousContext;
                    this.pushNewRecursionContext(localContext, _startState, SparkSQLParser.RULE_queryStatement);
                    this.state = 1360;
                    if (!(this.precpred(this.context, 2))) {
                        throw this.createFailedPredicateException("this.precpred(this.context, 2)");
                    }
                    this.state = 1361;
                    localContext._operator = this.tokenStream.LT(1);
                    _la = this.tokenStream.LA(1);
                    if(!(_la === 278 || _la === 311 || _la === 338 || _la === 430)) {
                        localContext._operator = this.errorHandler.recoverInline(this);
                    }
                    else {
                        this.errorHandler.reportMatch(this);
                        this.consume();
                    }
                    this.state = 1363;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                    if (_la === 202 || _la === 266) {
                        {
                        this.state = 1362;
                        _la = this.tokenStream.LA(1);
                        if(!(_la === 202 || _la === 266)) {
                        this.errorHandler.recoverInline(this);
                        }
                        else {
                            this.errorHandler.reportMatch(this);
                            this.consume();
                        }
                        }
                    }

                    this.state = 1365;
                    localContext._right = this.queryStatement(0);
                    this.state = 1367;
                    this.errorHandler.sync(this);
                    switch (this.interpreter.adaptivePredict(this.tokenStream, 126, this.context) ) {
                    case 1:
                        {
                        this.state = 1366;
                        this.sortByCaluse();
                        }
                        break;
                    }
                    this.state = 1370;
                    this.errorHandler.sync(this);
                    switch (this.interpreter.adaptivePredict(this.tokenStream, 127, this.context) ) {
                    case 1:
                        {
                        this.state = 1369;
                        this.orderByCaluse();
                        }
                        break;
                    }
                    this.state = 1373;
                    this.errorHandler.sync(this);
                    switch (this.interpreter.adaptivePredict(this.tokenStream, 128, this.context) ) {
                    case 1:
                        {
                        this.state = 1372;
                        this.limitClause();
                        }
                        break;
                    }
                    this.state = 1376;
                    this.errorHandler.sync(this);
                    switch (this.interpreter.adaptivePredict(this.tokenStream, 129, this.context) ) {
                    case 1:
                        {
                        this.state = 1375;
                        this.offsetClause();
                        }
                        break;
                    }
                    }
                    }
                }
                this.state = 1382;
                this.errorHandler.sync(this);
                alternative = this.interpreter.adaptivePredict(this.tokenStream, 130, this.context);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.unrollRecursionContexts(parentContext);
        }
        return localContext;
    }
    public valuesCaluse(): ValuesCaluseContext {
        let localContext = new ValuesCaluseContext(this.context, this.state);
        this.enterRule(localContext, 134, SparkSQLParser.RULE_valuesCaluse);
        try {
            let alternative: number;
            this.enterOuterAlt(localContext, 1);
            {
            {
            this.state = 1383;
            this.match(SparkSQLParser.KW_VALUES);
            this.state = 1384;
            this.inlineBody();
            this.state = 1392;
            this.errorHandler.sync(this);
            alternative = this.interpreter.adaptivePredict(this.tokenStream, 132, this.context);
            while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {
                if (alternative === 1) {
                    {
                    {
                    this.state = 1387;
                    this.errorHandler.sync(this);
                    switch (this.tokenStream.LA(1)) {
                    case SparkSQLParser.COMMA:
                        {
                        this.state = 1385;
                        this.match(SparkSQLParser.COMMA);
                        }
                        break;
                    case SparkSQLParser.KW_ADD:
                    case SparkSQLParser.KW_ADMIN:
                    case SparkSQLParser.KW_AFTER:
                    case SparkSQLParser.KW_ANALYZE:
                    case SparkSQLParser.KW_ASC:
                    case SparkSQLParser.KW_BEFORE:
                    case SparkSQLParser.KW_BYTES:
                    case SparkSQLParser.KW_CASCADE:
                    case SparkSQLParser.KW_CATALOG:
                    case SparkSQLParser.KW_CATALOGS:
                    case SparkSQLParser.KW_CENTURY:
                    case SparkSQLParser.KW_CHAIN:
                    case SparkSQLParser.KW_CHANGELOG_MODE:
                    case SparkSQLParser.KW_CHARACTERS:
                    case SparkSQLParser.KW_COMMENT:
                    case SparkSQLParser.KW_COMPACT:
                    case SparkSQLParser.KW_COLUMNS:
                    case SparkSQLParser.KW_CONSTRAINTS:
                    case SparkSQLParser.KW_CONSTRUCTOR:
                    case SparkSQLParser.KW_COMPUTE:
                    case SparkSQLParser.KW_CUMULATE:
                    case SparkSQLParser.KW_DATA:
                    case SparkSQLParser.KW_DATABASE:
                    case SparkSQLParser.KW_DATABASES:
                    case SparkSQLParser.KW_DAYS:
                    case SparkSQLParser.KW_DECADE:
                    case SparkSQLParser.KW_DEFINED:
                    case SparkSQLParser.KW_DESC:
                    case SparkSQLParser.KW_DESCRIPTOR:
                    case SparkSQLParser.KW_DIV:
                    case SparkSQLParser.KW_ENCODING:
                    case SparkSQLParser.KW_ENFORCED:
                    case SparkSQLParser.KW_ENGINE:
                    case SparkSQLParser.KW_ERROR:
                    case SparkSQLParser.KW_ESTIMATED_COST:
                    case SparkSQLParser.KW_EXCEPTION:
                    case SparkSQLParser.KW_EXCLUDE:
                    case SparkSQLParser.KW_EXCLUDING:
                    case SparkSQLParser.KW_EXTENDED:
                    case SparkSQLParser.KW_FILE:
                    case SparkSQLParser.KW_FINAL:
                    case SparkSQLParser.KW_FIRST:
                    case SparkSQLParser.KW_FOLLOWING:
                    case SparkSQLParser.KW_FORMAT:
                    case SparkSQLParser.KW_FORTRAN:
                    case SparkSQLParser.KW_FOUND:
                    case SparkSQLParser.KW_FRAC_SECOND:
                    case SparkSQLParser.KW_FUNCTIONS:
                    case SparkSQLParser.KW_GENERAL:
                    case SparkSQLParser.KW_GENERATED:
                    case SparkSQLParser.KW_GO:
                    case SparkSQLParser.KW_GOTO:
                    case SparkSQLParser.KW_GRANTED:
                    case SparkSQLParser.KW_HOP:
                    case SparkSQLParser.KW_HOURS:
                    case SparkSQLParser.KW_IF:
                    case SparkSQLParser.KW_IGNORE:
                    case SparkSQLParser.KW_INCREMENT:
                    case SparkSQLParser.KW_INPUT:
                    case SparkSQLParser.KW_INVOKER:
                    case SparkSQLParser.KW_JAR:
                    case SparkSQLParser.KW_JARS:
                    case SparkSQLParser.KW_JAVA:
                    case SparkSQLParser.KW_JSON:
                    case SparkSQLParser.KW_JSON_EXECUTION_PLAN:
                    case SparkSQLParser.KW_KEY:
                    case SparkSQLParser.KW_KEY_MEMBER:
                    case SparkSQLParser.KW_KEY_TYPE:
                    case SparkSQLParser.KW_LABEL:
                    case SparkSQLParser.KW_LAST:
                    case SparkSQLParser.KW_LENGTH:
                    case SparkSQLParser.KW_LEVEL:
                    case SparkSQLParser.KW_LOAD:
                    case SparkSQLParser.KW_MAP:
                    case SparkSQLParser.KW_MICROSECOND:
                    case SparkSQLParser.KW_MILLENNIUM:
                    case SparkSQLParser.KW_MILLISECOND:
                    case SparkSQLParser.KW_MINUTES:
                    case SparkSQLParser.KW_MINVALUE:
                    case SparkSQLParser.KW_MODIFY:
                    case SparkSQLParser.KW_MODULES:
                    case SparkSQLParser.KW_MONTHS:
                    case SparkSQLParser.KW_NANOSECOND:
                    case SparkSQLParser.KW_NULLS:
                    case SparkSQLParser.KW_NUMBER:
                    case SparkSQLParser.KW_OPTION:
                    case SparkSQLParser.KW_OPTIONS:
                    case SparkSQLParser.KW_ORDERING:
                    case SparkSQLParser.KW_OUTPUT:
                    case SparkSQLParser.KW_OVERWRITE:
                    case SparkSQLParser.KW_OVERWRITING:
                    case SparkSQLParser.KW_PARTITIONED:
                    case SparkSQLParser.KW_PARTITIONS:
                    case SparkSQLParser.KW_PASSING:
                    case SparkSQLParser.KW_PAST:
                    case SparkSQLParser.KW_PATH:
                    case SparkSQLParser.KW_PLACING:
                    case SparkSQLParser.KW_PLAN:
                    case SparkSQLParser.KW_PRECEDING:
                    case SparkSQLParser.KW_PRESERVE:
                    case SparkSQLParser.KW_PRIOR:
                    case SparkSQLParser.KW_PRIVILEGES:
                    case SparkSQLParser.KW_PUBLIC:
                    case SparkSQLParser.KW_PYTHON:
                    case SparkSQLParser.KW_PYTHON_FILES:
                    case SparkSQLParser.KW_PYTHON_REQUIREMENTS:
                    case SparkSQLParser.KW_PYTHON_DEPENDENCIES:
                    case SparkSQLParser.KW_PYTHON_JAR:
                    case SparkSQLParser.KW_PYTHON_ARCHIVES:
                    case SparkSQLParser.KW_PYTHON_PARAMETER:
                    case SparkSQLParser.KW_QUARTER:
                    case SparkSQLParser.KW_RAW:
                    case SparkSQLParser.KW_READ:
                    case SparkSQLParser.KW_RELATIVE:
                    case SparkSQLParser.KW_REMOVE:
                    case SparkSQLParser.KW_RENAME:
                    case SparkSQLParser.KW_REPLACE:
                    case SparkSQLParser.KW_RESPECT:
                    case SparkSQLParser.KW_RESTART:
                    case SparkSQLParser.KW_RESTRICT:
                    case SparkSQLParser.KW_ROLE:
                    case SparkSQLParser.KW_ROW_COUNT:
                    case SparkSQLParser.KW_SCALA:
                    case SparkSQLParser.KW_SCALAR:
                    case SparkSQLParser.KW_SCALE:
                    case SparkSQLParser.KW_SCHEMA:
                    case SparkSQLParser.KW_SECONDS:
                    case SparkSQLParser.KW_SECTION:
                    case SparkSQLParser.KW_SECURITY:
                    case SparkSQLParser.KW_SELF:
                    case SparkSQLParser.KW_SERVER:
                    case SparkSQLParser.KW_SERVER_NAME:
                    case SparkSQLParser.KW_SESSION:
                    case SparkSQLParser.KW_SETS:
                    case SparkSQLParser.KW_SIMPLE:
                    case SparkSQLParser.KW_SIZE:
                    case SparkSQLParser.KW_SLIDE:
                    case SparkSQLParser.KW_SOURCE:
                    case SparkSQLParser.KW_SPACE:
                    case SparkSQLParser.KW_STATE:
                    case SparkSQLParser.KW_STATEMENT:
                    case SparkSQLParser.KW_STEP:
                    case SparkSQLParser.KW_STRING:
                    case SparkSQLParser.KW_STRUCTURE:
                    case SparkSQLParser.KW_STYLE:
                    case SparkSQLParser.KW_TABLES:
                    case SparkSQLParser.KW_TEMPORARY:
                    case SparkSQLParser.KW_TIMECOL:
                    case SparkSQLParser.KW_FLOOR:
                    case SparkSQLParser.KW_TIMESTAMP_LTZ:
                    case SparkSQLParser.KW_TIMESTAMPADD:
                    case SparkSQLParser.KW_TIMESTAMPDIFF:
                    case SparkSQLParser.KW_TOTIMESTAMP:
                    case SparkSQLParser.KW_TRANSFORM:
                    case SparkSQLParser.KW_TUMBLE:
                    case SparkSQLParser.KW_TYPE:
                    case SparkSQLParser.KW_UNDER:
                    case SparkSQLParser.KW_UNLOAD:
                    case SparkSQLParser.KW_USAGE:
                    case SparkSQLParser.KW_USE:
                    case SparkSQLParser.KW_UTF16:
                    case SparkSQLParser.KW_UTF32:
                    case SparkSQLParser.KW_UTF8:
                    case SparkSQLParser.KW_VERSION:
                    case SparkSQLParser.KW_VIEW:
                    case SparkSQLParser.KW_VIEWS:
                    case SparkSQLParser.KW_VIRTUAL:
                    case SparkSQLParser.KW_WATERMARK:
                    case SparkSQLParser.KW_WATERMARKS:
                    case SparkSQLParser.KW_WEEK:
                    case SparkSQLParser.KW_WORK:
                    case SparkSQLParser.KW_WRAPPER:
                    case SparkSQLParser.KW_YEARS:
                    case SparkSQLParser.KW_ZONE:
                    case SparkSQLParser.KW_AS:
                    case SparkSQLParser.KW_LOCALTIMESTAMP:
                    case SparkSQLParser.DOLLAR:
                    case SparkSQLParser.STRING_LITERAL:
                    case SparkSQLParser.DIG_LITERAL:
                    case SparkSQLParser.ID_LITERAL:
                        {
                        this.state = 1386;
                        this.tableAlias();
                        }
                        break;
                    case SparkSQLParser.LR_BRACKET:
                        break;
                    default:
                        break;
                    }
                    this.state = 1389;
                    this.inlineBody();
                    }
                    }
                }
                this.state = 1394;
                this.errorHandler.sync(this);
                alternative = this.interpreter.adaptivePredict(this.tokenStream, 132, this.context);
            }
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public inlineBody(): InlineBodyContext {
        let localContext = new InlineBodyContext(this.context, this.state);
        this.enterRule(localContext, 136, SparkSQLParser.RULE_inlineBody);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1395;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 1396;
            this.expression();
            this.state = 1401;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 475) {
                {
                {
                this.state = 1397;
                this.match(SparkSQLParser.COMMA);
                this.state = 1398;
                this.expression();
                }
                }
                this.state = 1403;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 1404;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public withClause(): WithClauseContext {
        let localContext = new WithClauseContext(this.context, this.state);
        this.enterRule(localContext, 138, SparkSQLParser.RULE_withClause);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1406;
            this.match(SparkSQLParser.KW_WITH);
            this.state = 1407;
            this.withItem();
            this.state = 1412;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 475) {
                {
                {
                this.state = 1408;
                this.match(SparkSQLParser.COMMA);
                this.state = 1409;
                this.withItem();
                }
                }
                this.state = 1414;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public withItem(): WithItemContext {
        let localContext = new WithItemContext(this.context, this.state);
        this.enterRule(localContext, 140, SparkSQLParser.RULE_withItem);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1415;
            this.withItemName();
            this.state = 1427;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 471) {
                {
                this.state = 1416;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 1417;
                this.columnName();
                this.state = 1422;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                while (_la === 475) {
                    {
                    {
                    this.state = 1418;
                    this.match(SparkSQLParser.COMMA);
                    this.state = 1419;
                    this.columnName();
                    }
                    }
                    this.state = 1424;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                }
                this.state = 1425;
                this.match(SparkSQLParser.RR_BRACKET);
                }
            }

            this.state = 1429;
            this.match(SparkSQLParser.KW_AS);
            this.state = 1430;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 1431;
            this.queryStatement(0);
            this.state = 1432;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public withItemName(): WithItemNameContext {
        let localContext = new WithItemNameContext(this.context, this.state);
        this.enterRule(localContext, 142, SparkSQLParser.RULE_withItemName);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1434;
            this.identifier();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public selectStatement(): SelectStatementContext {
        let localContext = new SelectStatementContext(this.context, this.state);
        this.enterRule(localContext, 144, SparkSQLParser.RULE_selectStatement);
        try {
            this.state = 1492;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 149, this.context) ) {
            case 1:
                localContext = new CommonSelectContext(localContext);
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 1436;
                this.selectClause();
                this.state = 1437;
                this.fromClause();
                this.state = 1439;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 137, this.context) ) {
                case 1:
                    {
                    this.state = 1438;
                    this.whereClause();
                    }
                    break;
                }
                this.state = 1442;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 138, this.context) ) {
                case 1:
                    {
                    this.state = 1441;
                    this.someByClause();
                    }
                    break;
                }
                this.state = 1445;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 139, this.context) ) {
                case 1:
                    {
                    this.state = 1444;
                    this.havingClause();
                    }
                    break;
                }
                this.state = 1448;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 140, this.context) ) {
                case 1:
                    {
                    this.state = 1447;
                    this.windowClause();
                    }
                    break;
                }
                }
                break;
            case 2:
                localContext = new SparkStyleSelectContext(localContext);
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 1450;
                this.fromClause();
                this.state = 1451;
                this.selectClause();
                this.state = 1453;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 141, this.context) ) {
                case 1:
                    {
                    this.state = 1452;
                    this.whereClause();
                    }
                    break;
                }
                this.state = 1456;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 142, this.context) ) {
                case 1:
                    {
                    this.state = 1455;
                    this.someByClause();
                    }
                    break;
                }
                this.state = 1459;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 143, this.context) ) {
                case 1:
                    {
                    this.state = 1458;
                    this.havingClause();
                    }
                    break;
                }
                this.state = 1462;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 144, this.context) ) {
                case 1:
                    {
                    this.state = 1461;
                    this.windowClause();
                    }
                    break;
                }
                }
                break;
            case 3:
                localContext = new MatchRecognizeSelectContext(localContext);
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 1464;
                this.selectClause();
                this.state = 1465;
                this.fromClause();
                this.state = 1466;
                this.matchRecognizeClause();
                }
                break;
            case 4:
                localContext = new TableSampleContext(localContext);
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 1468;
                this.selectClause();
                this.state = 1469;
                this.fromClause();
                this.state = 1470;
                this.samplingQueries();
                }
                break;
            case 5:
                localContext = new TvfQueryContext(localContext);
                this.enterOuterAlt(localContext, 5);
                {
                this.state = 1472;
                this.selectClause();
                this.state = 1473;
                this.tvfClause();
                }
                break;
            case 6:
                localContext = new InlineTableContext(localContext);
                this.enterOuterAlt(localContext, 6);
                {
                this.state = 1475;
                this.match(SparkSQLParser.KW_SELECT);
                this.state = 1476;
                this.inlineTableClause();
                }
                break;
            case 7:
                localContext = new TransformQueryContext(localContext);
                this.enterOuterAlt(localContext, 7);
                {
                this.state = 1477;
                this.match(SparkSQLParser.KW_SELECT);
                this.state = 1478;
                this.transformClause();
                this.state = 1479;
                this.fromClause();
                this.state = 1481;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 145, this.context) ) {
                case 1:
                    {
                    this.state = 1480;
                    this.whereClause();
                    }
                    break;
                }
                this.state = 1484;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 146, this.context) ) {
                case 1:
                    {
                    this.state = 1483;
                    this.someByClause();
                    }
                    break;
                }
                this.state = 1487;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 147, this.context) ) {
                case 1:
                    {
                    this.state = 1486;
                    this.havingClause();
                    }
                    break;
                }
                this.state = 1490;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 148, this.context) ) {
                case 1:
                    {
                    this.state = 1489;
                    this.windowClause();
                    }
                    break;
                }
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public selectClause(): SelectClauseContext {
        let localContext = new SelectClauseContext(this.context, this.state);
        this.enterRule(localContext, 146, SparkSQLParser.RULE_selectClause);
        let _la: number;
        try {
            let alternative: number;
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1494;
            this.match(SparkSQLParser.KW_SELECT);
            this.state = 1496;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 202 || _la === 266) {
                {
                this.state = 1495;
                this.setQuantifier();
                }
            }

            this.state = 1500;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 151, this.context) ) {
            case 1:
                {
                this.state = 1498;
                this.match(SparkSQLParser.ASTERISK_SIGN);
                }
                break;
            case 2:
                {
                this.state = 1499;
                this.projectItemDefinition();
                }
                break;
            }
            this.state = 1506;
            this.errorHandler.sync(this);
            alternative = this.interpreter.adaptivePredict(this.tokenStream, 152, this.context);
            while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {
                if (alternative === 1) {
                    {
                    {
                    this.state = 1502;
                    this.match(SparkSQLParser.COMMA);
                    this.state = 1503;
                    this.projectItemDefinition();
                    }
                    }
                }
                this.state = 1508;
                this.errorHandler.sync(this);
                alternative = this.interpreter.adaptivePredict(this.tokenStream, 152, this.context);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public projectItemDefinition(): ProjectItemDefinitionContext {
        let localContext = new ProjectItemDefinitionContext(this.context, this.state);
        this.enterRule(localContext, 148, SparkSQLParser.RULE_projectItemDefinition);
        let _la: number;
        try {
            this.state = 1546;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 162, this.context) ) {
            case 1:
                localContext = new WindowsProrjectItemContext(localContext);
                this.enterOuterAlt(localContext, 1);
                {
                {
                this.state = 1509;
                this.overWindowItem();
                }
                this.state = 1514;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 154, this.context) ) {
                case 1:
                    {
                    this.state = 1511;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                    if (_la === 209) {
                        {
                        this.state = 1510;
                        this.match(SparkSQLParser.KW_AS);
                        }
                    }

                    this.state = 1513;
                    this.identifier();
                    }
                    break;
                }
                }
                break;
            case 2:
                localContext = new ExpressionProjectItemContext(localContext);
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 1516;
                this.expression();
                this.state = 1521;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 156, this.context) ) {
                case 1:
                    {
                    this.state = 1518;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                    if (_la === 209) {
                        {
                        this.state = 1517;
                        this.match(SparkSQLParser.KW_AS);
                        }
                    }

                    this.state = 1520;
                    this.expression();
                    }
                    break;
                }
                }
                break;
            case 3:
                localContext = new AggregateFunctionsContext(localContext);
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 1523;
                this.funtionBody();
                this.state = 1524;
                this.filterPart();
                this.state = 1529;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 158, this.context) ) {
                case 1:
                    {
                    this.state = 1526;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                    if (_la === 209) {
                        {
                        this.state = 1525;
                        this.match(SparkSQLParser.KW_AS);
                        }
                    }

                    this.state = 1528;
                    this.identifier();
                    }
                    break;
                }
                }
                break;
            case 4:
                localContext = new OrderSetAggregateFunctionsContext(localContext);
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 1531;
                this.funtionBody();
                this.state = 1532;
                this.match(SparkSQLParser.KW_WITHIN);
                this.state = 1533;
                this.match(SparkSQLParser.KW_GROUP);
                this.state = 1534;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 1535;
                this.orderByCaluse();
                this.state = 1536;
                this.match(SparkSQLParser.RR_BRACKET);
                this.state = 1538;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 159, this.context) ) {
                case 1:
                    {
                    this.state = 1537;
                    this.filterPart();
                    }
                    break;
                }
                this.state = 1544;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 161, this.context) ) {
                case 1:
                    {
                    this.state = 1541;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                    if (_la === 209) {
                        {
                        this.state = 1540;
                        this.match(SparkSQLParser.KW_AS);
                        }
                    }

                    this.state = 1543;
                    this.identifier();
                    }
                    break;
                }
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public filterPart(): FilterPartContext {
        let localContext = new FilterPartContext(this.context, this.state);
        this.enterRule(localContext, 150, SparkSQLParser.RULE_filterPart);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1548;
            this.match(SparkSQLParser.KW_FILTER);
            this.state = 1549;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 1550;
            this.whereClause();
            this.state = 1551;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public overWindowItem(): OverWindowItemContext {
        let localContext = new OverWindowItemContext(this.context, this.state);
        this.enterRule(localContext, 152, SparkSQLParser.RULE_overWindowItem);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1553;
            this.windowFunctioPart();
            this.state = 1556;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 67 || _la === 136) {
                {
                this.state = 1554;
                _la = this.tokenStream.LA(1);
                if(!(_la === 67 || _la === 136)) {
                this.errorHandler.recoverInline(this);
                }
                else {
                    this.errorHandler.reportMatch(this);
                    this.consume();
                }
                this.state = 1555;
                this.match(SparkSQLParser.KW_NULLS);
                }
            }

            this.state = 1558;
            this.match(SparkSQLParser.KW_OVER);
            this.state = 1560;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 164, this.context) ) {
            case 1:
                {
                this.state = 1559;
                this.anonymousWindowsName();
                }
                break;
            }
            this.state = 1579;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 168, this.context) ) {
            case 1:
                {
                this.state = 1562;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 1564;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 269 || _la === 365) {
                    {
                    this.state = 1563;
                    this.overClause();
                    }
                }

                this.state = 1566;
                this.byClause();
                this.state = 1571;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                while (_la === 475) {
                    {
                    {
                    this.state = 1567;
                    this.match(SparkSQLParser.COMMA);
                    this.state = 1568;
                    this.byClause();
                    }
                    }
                    this.state = 1573;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                }
                this.state = 1575;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 380 || _la === 393) {
                    {
                    this.state = 1574;
                    this.windowFrameForWindowsQuery();
                    }
                }

                this.state = 1577;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public overClause(): OverClauseContext {
        let localContext = new OverClauseContext(this.context, this.state);
        this.enterRule(localContext, 154, SparkSQLParser.RULE_overClause);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1581;
            _la = this.tokenStream.LA(1);
            if(!(_la === 269 || _la === 365)) {
            this.errorHandler.recoverInline(this);
            }
            else {
                this.errorHandler.reportMatch(this);
                this.consume();
            }
            this.state = 1582;
            this.match(SparkSQLParser.KW_BY);
            this.state = 1583;
            this.columnName();
            this.state = 1586;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 464) {
                {
                this.state = 1584;
                this.match(SparkSQLParser.EQUAL_SYMBOL);
                this.state = 1585;
                this.expression();
                }
            }

            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public byClause(): ByClauseContext {
        let localContext = new ByClauseContext(this.context, this.state);
        this.enterRule(localContext, 156, SparkSQLParser.RULE_byClause);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1588;
            _la = this.tokenStream.LA(1);
            if(!(_la === 358 || _la === 408)) {
            this.errorHandler.recoverInline(this);
            }
            else {
                this.errorHandler.reportMatch(this);
                this.consume();
            }
            this.state = 1589;
            this.match(SparkSQLParser.KW_BY);
            this.state = 1590;
            this.columnName();
            this.state = 1592;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 8 || _la === 35) {
                {
                this.state = 1591;
                _la = this.tokenStream.LA(1);
                if(!(_la === 8 || _la === 35)) {
                this.errorHandler.recoverInline(this);
                }
                else {
                    this.errorHandler.reportMatch(this);
                    this.consume();
                }
                }
            }

            this.state = 1596;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 100) {
                {
                this.state = 1594;
                this.match(SparkSQLParser.KW_NULLS);
                this.state = 1595;
                _la = this.tokenStream.LA(1);
                if(!(_la === 52 || _la === 82)) {
                this.errorHandler.recoverInline(this);
                }
                else {
                    this.errorHandler.reportMatch(this);
                    this.consume();
                }
                }
            }

            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public windowFunctioPart(): WindowFunctioPartContext {
        let localContext = new WindowFunctioPartContext(this.context, this.state);
        this.enterRule(localContext, 158, SparkSQLParser.RULE_windowFunctioPart);
        let _la: number;
        try {
            this.state = 1613;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 174, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 1598;
                this.windowFunctionName();
                this.state = 1599;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 1608;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if ((((_la) & ~0x1F) === 0 && ((1 << _la) & 4294896624) !== 0) || ((((_la - 33)) & ~0x1F) === 0 && ((1 << (_la - 33)) & 4294836223) !== 0) || ((((_la - 65)) & ~0x1F) === 0 && ((1 << (_la - 65)) & 4281327607) !== 0) || ((((_la - 97)) & ~0x1F) === 0 && ((1 << (_la - 97)) & 2147483643) !== 0) || ((((_la - 129)) & ~0x1F) === 0 && ((1 << (_la - 129)) & 2113863675) !== 0) || ((((_la - 161)) & ~0x1F) === 0 && ((1 << (_la - 161)) & 4292341757) !== 0) || ((((_la - 193)) & ~0x1F) === 0 && ((1 << (_la - 193)) & 134775807) !== 0) || ((((_la - 226)) & ~0x1F) === 0 && ((1 << (_la - 226)) & 1342706695) !== 0) || ((((_la - 266)) & ~0x1F) === 0 && ((1 << (_la - 266)) & 70336513) !== 0) || ((((_la - 298)) & ~0x1F) === 0 && ((1 << (_la - 298)) & 1015037961) !== 0) || ((((_la - 332)) & ~0x1F) === 0 && ((1 << (_la - 332)) & 2148205697) !== 0) || ((((_la - 369)) & ~0x1F) === 0 && ((1 << (_la - 369)) & 42494055) !== 0) || ((((_la - 407)) & ~0x1F) === 0 && ((1 << (_la - 407)) & 276029453) !== 0) || ((((_la - 449)) & ~0x1F) === 0 && ((1 << (_la - 449)) & 541067265) !== 0) || ((((_la - 483)) & ~0x1F) === 0 && ((1 << (_la - 483)) & 15373) !== 0)) {
                    {
                    this.state = 1600;
                    this.functionParam();
                    this.state = 1605;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                    while (_la === 475) {
                        {
                        {
                        this.state = 1601;
                        this.match(SparkSQLParser.COMMA);
                        this.state = 1602;
                        this.functionParam();
                        }
                        }
                        this.state = 1607;
                        this.errorHandler.sync(this);
                        _la = this.tokenStream.LA(1);
                    }
                    }
                }

                this.state = 1610;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 1612;
                this.primaryExpression(0);
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public windowFunctionName(): WindowFunctionNameContext {
        let localContext = new WindowFunctionNameContext(this.context, this.state);
        this.enterRule(localContext, 160, SparkSQLParser.RULE_windowFunctionName);
        try {
            this.state = 1617;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.KW_DENSE_RANK:
            case SparkSQLParser.KW_NTILE:
            case SparkSQLParser.KW_PERCENT_RANK:
            case SparkSQLParser.KW_RANK:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 1615;
                this.rangkingFunction();
                }
                break;
            case SparkSQLParser.KW_CUME_DIST:
            case SparkSQLParser.KW_FIRST_VALUE:
            case SparkSQLParser.KW_LAG:
            case SparkSQLParser.KW_LAST_VALUE:
            case SparkSQLParser.KW_LEAD:
            case SparkSQLParser.KW_NTH_VALUE:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 1616;
                this.analyticFunction();
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public analyticFunction(): AnalyticFunctionContext {
        let localContext = new AnalyticFunctionContext(this.context, this.state);
        this.enterRule(localContext, 162, SparkSQLParser.RULE_analyticFunction);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1619;
            _la = this.tokenStream.LA(1);
            if(!(_la === 249 || _la === 286 || ((((_la - 321)) & ~0x1F) === 0 && ((1 << (_la - 321)) & 536870937) !== 0))) {
            this.errorHandler.recoverInline(this);
            }
            else {
                this.errorHandler.reportMatch(this);
                this.consume();
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public rangkingFunction(): RangkingFunctionContext {
        let localContext = new RangkingFunctionContext(this.context, this.state);
        this.enterRule(localContext, 164, SparkSQLParser.RULE_rangkingFunction);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1621;
            _la = this.tokenStream.LA(1);
            if(!(_la === 265 || _la === 349 || _la === 369 || _la === 383)) {
            this.errorHandler.recoverInline(this);
            }
            else {
                this.errorHandler.reportMatch(this);
                this.consume();
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public fromClause(): FromClauseContext {
        let localContext = new FromClauseContext(this.context, this.state);
        this.enterRule(localContext, 166, SparkSQLParser.RULE_fromClause);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1623;
            this.match(SparkSQLParser.KW_FROM);
            this.state = 1624;
            this.tableExpression(0);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public windowFrameForWindowsQuery(): WindowFrameForWindowsQueryContext {
        let localContext = new WindowFrameForWindowsQueryContext(this.context, this.state);
        this.enterRule(localContext, 168, SparkSQLParser.RULE_windowFrameForWindowsQuery);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1626;
            _la = this.tokenStream.LA(1);
            if(!(_la === 380 || _la === 393)) {
            this.errorHandler.recoverInline(this);
            }
            else {
                this.errorHandler.reportMatch(this);
                this.consume();
            }
            this.state = 1633;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.KW_ADD:
            case SparkSQLParser.KW_ADMIN:
            case SparkSQLParser.KW_AFTER:
            case SparkSQLParser.KW_ANALYZE:
            case SparkSQLParser.KW_ASC:
            case SparkSQLParser.KW_BEFORE:
            case SparkSQLParser.KW_BYTES:
            case SparkSQLParser.KW_CASCADE:
            case SparkSQLParser.KW_CATALOG:
            case SparkSQLParser.KW_CATALOGS:
            case SparkSQLParser.KW_CENTURY:
            case SparkSQLParser.KW_CHAIN:
            case SparkSQLParser.KW_CHANGELOG_MODE:
            case SparkSQLParser.KW_CHARACTERS:
            case SparkSQLParser.KW_COMMENT:
            case SparkSQLParser.KW_COMPACT:
            case SparkSQLParser.KW_COLUMNS:
            case SparkSQLParser.KW_CONSTRAINTS:
            case SparkSQLParser.KW_CONSTRUCTOR:
            case SparkSQLParser.KW_COMPUTE:
            case SparkSQLParser.KW_CUMULATE:
            case SparkSQLParser.KW_DATA:
            case SparkSQLParser.KW_DATABASE:
            case SparkSQLParser.KW_DATABASES:
            case SparkSQLParser.KW_DAYS:
            case SparkSQLParser.KW_DECADE:
            case SparkSQLParser.KW_DEFINED:
            case SparkSQLParser.KW_DESC:
            case SparkSQLParser.KW_DESCRIPTOR:
            case SparkSQLParser.KW_DIV:
            case SparkSQLParser.KW_ENCODING:
            case SparkSQLParser.KW_ENFORCED:
            case SparkSQLParser.KW_ENGINE:
            case SparkSQLParser.KW_ERROR:
            case SparkSQLParser.KW_ESTIMATED_COST:
            case SparkSQLParser.KW_EXCEPTION:
            case SparkSQLParser.KW_EXCLUDE:
            case SparkSQLParser.KW_EXCLUDING:
            case SparkSQLParser.KW_EXTENDED:
            case SparkSQLParser.KW_FILE:
            case SparkSQLParser.KW_FINAL:
            case SparkSQLParser.KW_FIRST:
            case SparkSQLParser.KW_FOLLOWING:
            case SparkSQLParser.KW_FORMAT:
            case SparkSQLParser.KW_FORTRAN:
            case SparkSQLParser.KW_FOUND:
            case SparkSQLParser.KW_FRAC_SECOND:
            case SparkSQLParser.KW_FUNCTIONS:
            case SparkSQLParser.KW_GENERAL:
            case SparkSQLParser.KW_GENERATED:
            case SparkSQLParser.KW_GO:
            case SparkSQLParser.KW_GOTO:
            case SparkSQLParser.KW_GRANTED:
            case SparkSQLParser.KW_HOP:
            case SparkSQLParser.KW_HOURS:
            case SparkSQLParser.KW_IF:
            case SparkSQLParser.KW_IGNORE:
            case SparkSQLParser.KW_INCREMENT:
            case SparkSQLParser.KW_INPUT:
            case SparkSQLParser.KW_INVOKER:
            case SparkSQLParser.KW_JAR:
            case SparkSQLParser.KW_JARS:
            case SparkSQLParser.KW_JAVA:
            case SparkSQLParser.KW_JSON:
            case SparkSQLParser.KW_JSON_EXECUTION_PLAN:
            case SparkSQLParser.KW_KEY:
            case SparkSQLParser.KW_KEY_MEMBER:
            case SparkSQLParser.KW_KEY_TYPE:
            case SparkSQLParser.KW_LABEL:
            case SparkSQLParser.KW_LAST:
            case SparkSQLParser.KW_LENGTH:
            case SparkSQLParser.KW_LEVEL:
            case SparkSQLParser.KW_LOAD:
            case SparkSQLParser.KW_MAP:
            case SparkSQLParser.KW_MICROSECOND:
            case SparkSQLParser.KW_MILLENNIUM:
            case SparkSQLParser.KW_MILLISECOND:
            case SparkSQLParser.KW_MINUTES:
            case SparkSQLParser.KW_MINVALUE:
            case SparkSQLParser.KW_MODIFY:
            case SparkSQLParser.KW_MODULES:
            case SparkSQLParser.KW_MONTHS:
            case SparkSQLParser.KW_NANOSECOND:
            case SparkSQLParser.KW_NULLS:
            case SparkSQLParser.KW_NUMBER:
            case SparkSQLParser.KW_OPTION:
            case SparkSQLParser.KW_OPTIONS:
            case SparkSQLParser.KW_ORDERING:
            case SparkSQLParser.KW_OUTPUT:
            case SparkSQLParser.KW_OVERWRITE:
            case SparkSQLParser.KW_OVERWRITING:
            case SparkSQLParser.KW_PARTITIONED:
            case SparkSQLParser.KW_PARTITIONS:
            case SparkSQLParser.KW_PASSING:
            case SparkSQLParser.KW_PAST:
            case SparkSQLParser.KW_PATH:
            case SparkSQLParser.KW_PLACING:
            case SparkSQLParser.KW_PLAN:
            case SparkSQLParser.KW_PRECEDING:
            case SparkSQLParser.KW_PRESERVE:
            case SparkSQLParser.KW_PRIOR:
            case SparkSQLParser.KW_PRIVILEGES:
            case SparkSQLParser.KW_PUBLIC:
            case SparkSQLParser.KW_PYTHON:
            case SparkSQLParser.KW_PYTHON_FILES:
            case SparkSQLParser.KW_PYTHON_REQUIREMENTS:
            case SparkSQLParser.KW_PYTHON_DEPENDENCIES:
            case SparkSQLParser.KW_PYTHON_JAR:
            case SparkSQLParser.KW_PYTHON_ARCHIVES:
            case SparkSQLParser.KW_PYTHON_PARAMETER:
            case SparkSQLParser.KW_QUARTER:
            case SparkSQLParser.KW_RAW:
            case SparkSQLParser.KW_READ:
            case SparkSQLParser.KW_RELATIVE:
            case SparkSQLParser.KW_REMOVE:
            case SparkSQLParser.KW_RENAME:
            case SparkSQLParser.KW_REPLACE:
            case SparkSQLParser.KW_RESPECT:
            case SparkSQLParser.KW_RESTART:
            case SparkSQLParser.KW_RESTRICT:
            case SparkSQLParser.KW_ROLE:
            case SparkSQLParser.KW_ROW_COUNT:
            case SparkSQLParser.KW_SCALA:
            case SparkSQLParser.KW_SCALAR:
            case SparkSQLParser.KW_SCALE:
            case SparkSQLParser.KW_SCHEMA:
            case SparkSQLParser.KW_SECONDS:
            case SparkSQLParser.KW_SECTION:
            case SparkSQLParser.KW_SECURITY:
            case SparkSQLParser.KW_SELF:
            case SparkSQLParser.KW_SERVER:
            case SparkSQLParser.KW_SERVER_NAME:
            case SparkSQLParser.KW_SESSION:
            case SparkSQLParser.KW_SETS:
            case SparkSQLParser.KW_SIMPLE:
            case SparkSQLParser.KW_SIZE:
            case SparkSQLParser.KW_SLIDE:
            case SparkSQLParser.KW_SOURCE:
            case SparkSQLParser.KW_SPACE:
            case SparkSQLParser.KW_STATE:
            case SparkSQLParser.KW_STATEMENT:
            case SparkSQLParser.KW_STEP:
            case SparkSQLParser.KW_STRING:
            case SparkSQLParser.KW_STRUCTURE:
            case SparkSQLParser.KW_STYLE:
            case SparkSQLParser.KW_TABLES:
            case SparkSQLParser.KW_TEMPORARY:
            case SparkSQLParser.KW_TIMECOL:
            case SparkSQLParser.KW_FLOOR:
            case SparkSQLParser.KW_TIMESTAMP_LTZ:
            case SparkSQLParser.KW_TIMESTAMPADD:
            case SparkSQLParser.KW_TIMESTAMPDIFF:
            case SparkSQLParser.KW_TOTIMESTAMP:
            case SparkSQLParser.KW_TRANSFORM:
            case SparkSQLParser.KW_TUMBLE:
            case SparkSQLParser.KW_TYPE:
            case SparkSQLParser.KW_UNDER:
            case SparkSQLParser.KW_UNBOUNDED:
            case SparkSQLParser.KW_UNLOAD:
            case SparkSQLParser.KW_USAGE:
            case SparkSQLParser.KW_USE:
            case SparkSQLParser.KW_UTF16:
            case SparkSQLParser.KW_UTF32:
            case SparkSQLParser.KW_UTF8:
            case SparkSQLParser.KW_VERSION:
            case SparkSQLParser.KW_VIEW:
            case SparkSQLParser.KW_VIEWS:
            case SparkSQLParser.KW_VIRTUAL:
            case SparkSQLParser.KW_WATERMARK:
            case SparkSQLParser.KW_WATERMARKS:
            case SparkSQLParser.KW_WEEK:
            case SparkSQLParser.KW_WORK:
            case SparkSQLParser.KW_WRAPPER:
            case SparkSQLParser.KW_YEARS:
            case SparkSQLParser.KW_ZONE:
            case SparkSQLParser.KW_ABS:
            case SparkSQLParser.KW_ARRAY:
            case SparkSQLParser.KW_AVG:
            case SparkSQLParser.KW_CASE:
            case SparkSQLParser.KW_CAST:
            case SparkSQLParser.KW_CEIL:
            case SparkSQLParser.KW_COALESCE:
            case SparkSQLParser.KW_COLLECT:
            case SparkSQLParser.KW_COUNT:
            case SparkSQLParser.KW_CURRENT:
            case SparkSQLParser.KW_DATE:
            case SparkSQLParser.KW_DAY:
            case SparkSQLParser.KW_EXISTS:
            case SparkSQLParser.KW_EXPLODE:
            case SparkSQLParser.KW_FIRST_VALUE:
            case SparkSQLParser.KW_FALSE:
            case SparkSQLParser.KW_FROM_UNIXTIME:
            case SparkSQLParser.KW_GROUPING:
            case SparkSQLParser.KW_HOUR:
            case SparkSQLParser.KW_INTERVAL:
            case SparkSQLParser.KW_LAG:
            case SparkSQLParser.KW_LAST_VALUE:
            case SparkSQLParser.KW_LEAD:
            case SparkSQLParser.KW_LEFT:
            case SparkSQLParser.KW_LOCALTIMESTAMP:
            case SparkSQLParser.KW_MINUTE:
            case SparkSQLParser.KW_MONTH:
            case SparkSQLParser.KW_NOT:
            case SparkSQLParser.KW_NTILE:
            case SparkSQLParser.KW_NULL:
            case SparkSQLParser.KW_OVERLAY:
            case SparkSQLParser.KW_PERCENT_RANK:
            case SparkSQLParser.KW_PERCENTILE_CONT:
            case SparkSQLParser.KW_PERCENTILE_DISC:
            case SparkSQLParser.KW_POSITION:
            case SparkSQLParser.KW_POWER:
            case SparkSQLParser.KW_RANGE:
            case SparkSQLParser.KW_ROW_NUMBER:
            case SparkSQLParser.KW_RANK:
            case SparkSQLParser.KW_RIGHT:
            case SparkSQLParser.KW_ROW:
            case SparkSQLParser.KW_SECOND:
            case SparkSQLParser.KW_STRUCT:
            case SparkSQLParser.KW_SUBSTRING:
            case SparkSQLParser.KW_SUM:
            case SparkSQLParser.KW_TIME:
            case SparkSQLParser.KW_TIMESTAMP:
            case SparkSQLParser.KW_TIMESTAMP_3:
            case SparkSQLParser.KW_TIMESTAMP_6:
            case SparkSQLParser.KW_TIMESTAMP_9:
            case SparkSQLParser.KW_TRUE:
            case SparkSQLParser.KW_TRUNCATE:
            case SparkSQLParser.KW_UPPER:
            case SparkSQLParser.KW_YEAR:
            case SparkSQLParser.BIT_NOT_OP:
            case SparkSQLParser.LR_BRACKET:
            case SparkSQLParser.DOLLAR:
            case SparkSQLParser.ASTERISK_SIGN:
            case SparkSQLParser.HYPNEN_SIGN:
            case SparkSQLParser.ADD_SIGN:
            case SparkSQLParser.STRING_LITERAL:
            case SparkSQLParser.DIG_LITERAL:
            case SparkSQLParser.REAL_LITERAL:
            case SparkSQLParser.ID_LITERAL:
                {
                this.state = 1627;
                this.frameExpession();
                }
                break;
            case SparkSQLParser.KW_BETWEEN:
                {
                {
                this.state = 1628;
                this.match(SparkSQLParser.KW_BETWEEN);
                this.state = 1629;
                this.frameExpession();
                this.state = 1630;
                this.match(SparkSQLParser.KW_AND);
                this.state = 1631;
                this.frameExpession();
                }
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public frameExpession(): FrameExpessionContext {
        let localContext = new FrameExpessionContext(this.context, this.state);
        this.enterRule(localContext, 170, SparkSQLParser.RULE_frameExpession);
        try {
            this.state = 1647;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 177, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 1635;
                this.match(SparkSQLParser.KW_UNBOUNDED);
                this.state = 1636;
                this.match(SparkSQLParser.KW_PRECEDING);
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 1637;
                this.expression();
                this.state = 1638;
                this.match(SparkSQLParser.KW_PRECEDING);
                }
                break;
            case 3:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 1640;
                this.match(SparkSQLParser.KW_CURRENT);
                this.state = 1641;
                this.match(SparkSQLParser.KW_ROW);
                }
                break;
            case 4:
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 1642;
                this.expression();
                this.state = 1643;
                this.match(SparkSQLParser.KW_FOLLOWING);
                }
                break;
            case 5:
                this.enterOuterAlt(localContext, 5);
                {
                this.state = 1645;
                this.match(SparkSQLParser.KW_UNBOUNDED);
                this.state = 1646;
                this.match(SparkSQLParser.KW_FOLLOWING);
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }

    public tableExpression(): TableExpressionContext;
    public tableExpression(_p: number): TableExpressionContext;
    public tableExpression(_p?: number): TableExpressionContext {
        if (_p === undefined) {
            _p = 0;
        }

        let parentContext = this.context;
        let parentState = this.state;
        let localContext = new TableExpressionContext(this.context, parentState);
        let previousContext = localContext;
        let _startState = 172;
        this.enterRecursionRule(localContext, 172, SparkSQLParser.RULE_tableExpression, _p);
        let _la: number;
        try {
            let alternative: number;
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1666;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 181, this.context) ) {
            case 1:
                {
                this.state = 1650;
                this.tableReference();
                this.state = 1657;
                this.errorHandler.sync(this);
                alternative = this.interpreter.adaptivePredict(this.tokenStream, 179, this.context);
                while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {
                    if (alternative === 1) {
                        {
                        {
                        this.state = 1652;
                        this.errorHandler.sync(this);
                        _la = this.tokenStream.LA(1);
                        if (_la === 475) {
                            {
                            this.state = 1651;
                            this.match(SparkSQLParser.COMMA);
                            }
                        }

                        this.state = 1654;
                        this.tableReference();
                        }
                        }
                    }
                    this.state = 1659;
                    this.errorHandler.sync(this);
                    alternative = this.interpreter.adaptivePredict(this.tokenStream, 179, this.context);
                }
                }
                break;
            case 2:
                {
                this.state = 1660;
                this.valuesCaluse();
                }
                break;
            case 3:
                {
                this.state = 1661;
                this.tvfClause();
                this.state = 1663;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 180, this.context) ) {
                case 1:
                    {
                    this.state = 1662;
                    this.tableAlias();
                    }
                    break;
                }
                }
                break;
            case 4:
                {
                this.state = 1665;
                this.windowTVFClause();
                }
                break;
            }
            this.context!.stop = this.tokenStream.LT(-1);
            this.state = 1696;
            this.errorHandler.sync(this);
            alternative = this.interpreter.adaptivePredict(this.tokenStream, 188, this.context);
            while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {
                if (alternative === 1) {
                    if (this.parseListeners != null) {
                        this.triggerExitRuleEvent();
                    }
                    previousContext = localContext;
                    {
                    this.state = 1694;
                    this.errorHandler.sync(this);
                    switch (this.interpreter.adaptivePredict(this.tokenStream, 187, this.context) ) {
                    case 1:
                        {
                        localContext = new TableExpressionContext(parentContext, parentState);
                        this.pushNewRecursionContext(localContext, _startState, SparkSQLParser.RULE_tableExpression);
                        this.state = 1668;
                        if (!(this.precpred(this.context, 4))) {
                            throw this.createFailedPredicateException("this.precpred(this.context, 4)");
                        }
                        this.state = 1669;
                        this.match(SparkSQLParser.KW_CROSS);
                        this.state = 1670;
                        this.match(SparkSQLParser.KW_JOIN);
                        this.state = 1671;
                        this.tableExpression(5);
                        }
                        break;
                    case 2:
                        {
                        localContext = new TableExpressionContext(parentContext, parentState);
                        this.pushNewRecursionContext(localContext, _startState, SparkSQLParser.RULE_tableExpression);
                        this.state = 1672;
                        if (!(this.precpred(this.context, 5))) {
                            throw this.createFailedPredicateException("this.precpred(this.context, 5)");
                        }
                        this.state = 1674;
                        this.errorHandler.sync(this);
                        _la = this.tokenStream.LA(1);
                        if (_la === 344) {
                            {
                            this.state = 1673;
                            this.match(SparkSQLParser.KW_NATURAL);
                            }
                        }

                        this.state = 1677;
                        this.errorHandler.sync(this);
                        _la = this.tokenStream.LA(1);
                        if (_la === 293 || _la === 306 || _la === 327 || _la === 388) {
                            {
                            this.state = 1676;
                            _la = this.tokenStream.LA(1);
                            if(!(_la === 293 || _la === 306 || _la === 327 || _la === 388)) {
                            this.errorHandler.recoverInline(this);
                            }
                            else {
                                this.errorHandler.reportMatch(this);
                                this.consume();
                            }
                            }
                        }

                        this.state = 1680;
                        this.errorHandler.sync(this);
                        _la = this.tokenStream.LA(1);
                        if (_la === 360) {
                            {
                            this.state = 1679;
                            this.match(SparkSQLParser.KW_OUTER);
                            }
                        }

                        this.state = 1682;
                        this.match(SparkSQLParser.KW_JOIN);
                        this.state = 1683;
                        this.tableExpression(0);
                        this.state = 1685;
                        this.errorHandler.sync(this);
                        switch (this.interpreter.adaptivePredict(this.tokenStream, 185, this.context) ) {
                        case 1:
                            {
                            this.state = 1684;
                            this.joinCondition();
                            }
                            break;
                        }
                        this.state = 1691;
                        this.errorHandler.sync(this);
                        alternative = this.interpreter.adaptivePredict(this.tokenStream, 186, this.context);
                        while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {
                            if (alternative === 1) {
                                {
                                {
                                this.state = 1687;
                                this.match(SparkSQLParser.COMMA);
                                this.state = 1688;
                                this.tableReference();
                                }
                                }
                            }
                            this.state = 1693;
                            this.errorHandler.sync(this);
                            alternative = this.interpreter.adaptivePredict(this.tokenStream, 186, this.context);
                        }
                        }
                        break;
                    }
                    }
                }
                this.state = 1698;
                this.errorHandler.sync(this);
                alternative = this.interpreter.adaptivePredict(this.tokenStream, 188, this.context);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.unrollRecursionContexts(parentContext);
        }
        return localContext;
    }
    public tableReference(): TableReferenceContext {
        let localContext = new TableReferenceContext(this.context, this.state);
        this.enterRule(localContext, 174, SparkSQLParser.RULE_tableReference);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1699;
            this.tablePrimary();
            this.state = 1701;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 189, this.context) ) {
            case 1:
                {
                this.state = 1700;
                this.tableAlias();
                }
                break;
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public tablePrimary(): TablePrimaryContext {
        let localContext = new TablePrimaryContext(this.context, this.state);
        this.enterRule(localContext, 176, SparkSQLParser.RULE_tablePrimary);
        let _la: number;
        try {
            let alternative: number;
            this.state = 1776;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 201, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 1704;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 415) {
                    {
                    this.state = 1703;
                    this.match(SparkSQLParser.KW_TABLE);
                    }
                }

                this.state = 1706;
                this.tablePath();
                this.state = 1708;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 191, this.context) ) {
                case 1:
                    {
                    this.state = 1707;
                    this.systemTimePeriod();
                    }
                    break;
                }
                this.state = 1714;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 193, this.context) ) {
                case 1:
                    {
                    this.state = 1711;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                    if (_la === 209) {
                        {
                        this.state = 1710;
                        this.match(SparkSQLParser.KW_AS);
                        }
                    }

                    this.state = 1713;
                    this.correlationName();
                    }
                    break;
                }
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 1716;
                this.match(SparkSQLParser.KW_LATERAL);
                this.state = 1717;
                this.match(SparkSQLParser.KW_TABLE);
                this.state = 1720;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 194, this.context) ) {
                case 1:
                    {
                    this.state = 1718;
                    this.funtionBody();
                    }
                    break;
                case 2:
                    {
                    this.state = 1719;
                    this.complexDataTypeExpression();
                    }
                    break;
                }
                }
                break;
            case 3:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 1722;
                this.match(SparkSQLParser.KW_LATERAL);
                this.state = 1723;
                this.match(SparkSQLParser.KW_TABLE);
                this.state = 1724;
                this.match(SparkSQLParser.KW_EXPLODE);
                this.state = 1725;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 1728;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 195, this.context) ) {
                case 1:
                    {
                    this.state = 1726;
                    this.funtionBody();
                    }
                    break;
                case 2:
                    {
                    this.state = 1727;
                    this.complexDataTypeExpression();
                    }
                    break;
                }
                this.state = 1730;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case 4:
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 1733;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 323) {
                    {
                    this.state = 1732;
                    this.match(SparkSQLParser.KW_LATERAL);
                    }
                }

                this.state = 1735;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 1736;
                this.queryStatement(0);
                this.state = 1737;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case 5:
                this.enterOuterAlt(localContext, 5);
                {
                this.state = 1739;
                this.match(SparkSQLParser.KW_LATERAL);
                this.state = 1740;
                this.match(SparkSQLParser.KW_VIEW);
                this.state = 1742;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 360) {
                    {
                    this.state = 1741;
                    this.match(SparkSQLParser.KW_OUTER);
                    }
                }

                this.state = 1744;
                this.funtionBody();
                this.state = 1746;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 198, this.context) ) {
                case 1:
                    {
                    this.state = 1745;
                    this.tableAlias();
                    }
                    break;
                }
                this.state = 1748;
                this.match(SparkSQLParser.KW_AS);
                this.state = 1749;
                this.columnAlias();
                this.state = 1754;
                this.errorHandler.sync(this);
                alternative = this.interpreter.adaptivePredict(this.tokenStream, 199, this.context);
                while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {
                    if (alternative === 1) {
                        {
                        {
                        this.state = 1750;
                        this.match(SparkSQLParser.COMMA);
                        this.state = 1751;
                        this.columnAlias();
                        }
                        }
                    }
                    this.state = 1756;
                    this.errorHandler.sync(this);
                    alternative = this.interpreter.adaptivePredict(this.tokenStream, 199, this.context);
                }
                }
                break;
            case 6:
                this.enterOuterAlt(localContext, 6);
                {
                this.state = 1757;
                this.match(SparkSQLParser.KW_UNSET);
                this.state = 1758;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 1759;
                this.expression();
                this.state = 1760;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case 7:
                this.enterOuterAlt(localContext, 7);
                {
                this.state = 1762;
                this.match(SparkSQLParser.KW_PIVOT);
                this.state = 1763;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 1764;
                this.pivotBody();
                this.state = 1765;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case 8:
                this.enterOuterAlt(localContext, 8);
                {
                this.state = 1767;
                this.match(SparkSQLParser.KW_UNPIVOT);
                this.state = 1770;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 45 || _la === 68) {
                    {
                    this.state = 1768;
                    _la = this.tokenStream.LA(1);
                    if(!(_la === 45 || _la === 68)) {
                    this.errorHandler.recoverInline(this);
                    }
                    else {
                        this.errorHandler.reportMatch(this);
                        this.consume();
                    }
                    this.state = 1769;
                    this.match(SparkSQLParser.KW_NULLS);
                    }
                }

                this.state = 1772;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 1773;
                this.unpivotBody();
                this.state = 1774;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public funtionBody(): FuntionBodyContext {
        let localContext = new FuntionBodyContext(this.context, this.state);
        this.enterRule(localContext, 178, SparkSQLParser.RULE_funtionBody);
        let _la: number;
        try {
            let alternative: number;
            this.state = 1825;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 209, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 1778;
                this.functionName();
                this.state = 1779;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 1782;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 202, this.context) ) {
                case 1:
                    {
                    this.state = 1780;
                    this.funtionBody();
                    }
                    break;
                case 2:
                    {
                    this.state = 1781;
                    this.functionParam();
                    }
                    break;
                }
                this.state = 1791;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                while (_la === 475) {
                    {
                    {
                    this.state = 1784;
                    this.match(SparkSQLParser.COMMA);
                    this.state = 1787;
                    this.errorHandler.sync(this);
                    switch (this.interpreter.adaptivePredict(this.tokenStream, 203, this.context) ) {
                    case 1:
                        {
                        this.state = 1785;
                        this.funtionBody();
                        }
                        break;
                    case 2:
                        {
                        this.state = 1786;
                        this.functionParam();
                        }
                        break;
                    }
                    }
                    }
                    this.state = 1793;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                }
                this.state = 1794;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 1796;
                this.functionName();
                this.state = 1797;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 1800;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 205, this.context) ) {
                case 1:
                    {
                    this.state = 1798;
                    this.funtionBody();
                    }
                    break;
                case 2:
                    {
                    this.state = 1799;
                    this.functionParam();
                    }
                    break;
                }
                this.state = 1809;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                while (_la === 475) {
                    {
                    {
                    this.state = 1802;
                    this.match(SparkSQLParser.COMMA);
                    this.state = 1805;
                    this.errorHandler.sync(this);
                    switch (this.interpreter.adaptivePredict(this.tokenStream, 206, this.context) ) {
                    case 1:
                        {
                        this.state = 1803;
                        this.funtionBody();
                        }
                        break;
                    case 2:
                        {
                        this.state = 1804;
                        this.functionParam();
                        }
                        break;
                    }
                    }
                    }
                    this.state = 1811;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                }
                this.state = 1812;
                this.match(SparkSQLParser.RR_BRACKET);
                this.state = 1813;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 1814;
                this.match(SparkSQLParser.KW_AS);
                this.state = 1815;
                this.tableAlias();
                this.state = 1816;
                this.match(SparkSQLParser.RR_BRACKET);
                this.state = 1817;
                this.projectItemDefinition();
                this.state = 1822;
                this.errorHandler.sync(this);
                alternative = this.interpreter.adaptivePredict(this.tokenStream, 208, this.context);
                while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {
                    if (alternative === 1) {
                        {
                        {
                        this.state = 1818;
                        this.match(SparkSQLParser.COMMA);
                        this.state = 1819;
                        this.projectItemDefinition();
                        }
                        }
                    }
                    this.state = 1824;
                    this.errorHandler.sync(this);
                    alternative = this.interpreter.adaptivePredict(this.tokenStream, 208, this.context);
                }
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public unpivotBody(): UnpivotBodyContext {
        let localContext = new UnpivotBodyContext(this.context, this.state);
        this.enterRule(localContext, 180, SparkSQLParser.RULE_unpivotBody);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1829;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 210, this.context) ) {
            case 1:
                {
                this.state = 1827;
                this.columnName();
                }
                break;
            case 2:
                {
                this.state = 1828;
                this.columnNameList();
                }
                break;
            }
            this.state = 1831;
            this.match(SparkSQLParser.KW_FOR);
            this.state = 1832;
            this.columnName();
            this.state = 1833;
            this.match(SparkSQLParser.KW_IN);
            this.state = 1834;
            this.expressionAsAliasList();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public pivotBody(): PivotBodyContext {
        let localContext = new PivotBodyContext(this.context, this.state);
        this.enterRule(localContext, 182, SparkSQLParser.RULE_pivotBody);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1836;
            this.expressionAsAlias();
            {
            this.state = 1837;
            this.match(SparkSQLParser.COMMA);
            this.state = 1838;
            this.expressionAsAlias();
            }
            this.state = 1840;
            this.match(SparkSQLParser.KW_FOR);
            this.state = 1843;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 211, this.context) ) {
            case 1:
                {
                this.state = 1841;
                this.columnName();
                }
                break;
            case 2:
                {
                this.state = 1842;
                this.columnNameList();
                }
                break;
            }
            this.state = 1845;
            this.match(SparkSQLParser.KW_IN);
            this.state = 1846;
            this.expressionAsAliasList();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public expressionAsAlias(): ExpressionAsAliasContext {
        let localContext = new ExpressionAsAliasContext(this.context, this.state);
        this.enterRule(localContext, 184, SparkSQLParser.RULE_expressionAsAlias);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1848;
            this.expression();
            this.state = 1851;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 209) {
                {
                this.state = 1849;
                this.match(SparkSQLParser.KW_AS);
                this.state = 1850;
                this.columnAlias();
                }
            }

            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public expressionAsAliasList(): ExpressionAsAliasListContext {
        let localContext = new ExpressionAsAliasListContext(this.context, this.state);
        this.enterRule(localContext, 186, SparkSQLParser.RULE_expressionAsAliasList);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1853;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 1854;
            this.expressionAsAlias();
            this.state = 1859;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 475) {
                {
                {
                this.state = 1855;
                this.match(SparkSQLParser.COMMA);
                this.state = 1856;
                this.expressionAsAlias();
                }
                }
                this.state = 1861;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 1862;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public systemTimePeriod(): SystemTimePeriodContext {
        let localContext = new SystemTimePeriodContext(this.context, this.state);
        this.enterRule(localContext, 188, SparkSQLParser.RULE_systemTimePeriod);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1864;
            this.match(SparkSQLParser.KW_FOR);
            this.state = 1865;
            this.match(SparkSQLParser.KW_SYSTEM_TIME);
            this.state = 1866;
            this.match(SparkSQLParser.KW_AS);
            this.state = 1867;
            this.match(SparkSQLParser.KW_OF);
            this.state = 1868;
            this.dateTimeExpression();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public dateTimeExpression(): DateTimeExpressionContext {
        let localContext = new DateTimeExpressionContext(this.context, this.state);
        this.enterRule(localContext, 190, SparkSQLParser.RULE_dateTimeExpression);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1870;
            this.expression();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public inlineDataValueClause(): InlineDataValueClauseContext {
        let localContext = new InlineDataValueClauseContext(this.context, this.state);
        this.enterRule(localContext, 192, SparkSQLParser.RULE_inlineDataValueClause);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1872;
            this.expression();
            this.state = 1877;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 475) {
                {
                {
                this.state = 1873;
                this.match(SparkSQLParser.COMMA);
                this.state = 1874;
                this.expression();
                }
                }
                this.state = 1879;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 1881;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if ((((_la) & ~0x1F) === 0 && ((1 << _la) & 4294896624) !== 0) || ((((_la - 33)) & ~0x1F) === 0 && ((1 << (_la - 33)) & 4294803199) !== 0) || ((((_la - 65)) & ~0x1F) === 0 && ((1 << (_la - 65)) & 4281327607) !== 0) || ((((_la - 97)) & ~0x1F) === 0 && ((1 << (_la - 97)) & 2147483643) !== 0) || ((((_la - 129)) & ~0x1F) === 0 && ((1 << (_la - 129)) & 2113863675) !== 0) || ((((_la - 161)) & ~0x1F) === 0 && ((1 << (_la - 161)) & 4292341757) !== 0) || ((((_la - 193)) & ~0x1F) === 0 && ((1 << (_la - 193)) & 65783) !== 0) || _la === 332 || ((((_la - 478)) & ~0x1F) === 0 && ((1 << (_la - 478)) & 360449) !== 0)) {
                {
                this.state = 1880;
                this.tableAlias();
                }
            }

            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public windowTVFClause(): WindowTVFClauseContext {
        let localContext = new WindowTVFClauseContext(this.context, this.state);
        this.enterRule(localContext, 194, SparkSQLParser.RULE_windowTVFClause);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1883;
            this.match(SparkSQLParser.KW_TABLE);
            this.state = 1884;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 1885;
            this.windowTVFExpression();
            this.state = 1886;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public tvfClause(): TvfClauseContext {
        let localContext = new TvfClauseContext(this.context, this.state);
        this.enterRule(localContext, 196, SparkSQLParser.RULE_tvfClause);
        try {
            localContext = new RangeContext(localContext);
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1888;
            this.rangeClause();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public inlineTableClause(): InlineTableClauseContext {
        let localContext = new InlineTableClauseContext(this.context, this.state);
        this.enterRule(localContext, 198, SparkSQLParser.RULE_inlineTableClause);
        let _la: number;
        try {
            this.state = 1926;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.KW_EXPLODE:
            case SparkSQLParser.KW_EXPLODE_OUTER:
            case SparkSQLParser.KW_INLINE:
            case SparkSQLParser.KW_INLINE_OUTER:
            case SparkSQLParser.KW_POSEXPLODE:
            case SparkSQLParser.KW_POSEXPLODE_OUTER:
                localContext = new OneExpresionContext(localContext);
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 1890;
                _la = this.tokenStream.LA(1);
                if(!(_la === 282 || _la === 283 || _la === 315 || _la === 316 || _la === 376 || _la === 377)) {
                this.errorHandler.recoverInline(this);
                }
                else {
                    this.errorHandler.reportMatch(this);
                    this.consume();
                }
                this.state = 1891;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 1892;
                this.expression();
                this.state = 1893;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case SparkSQLParser.KW_STACK:
                localContext = new StackContext(localContext);
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 1895;
                this.match(SparkSQLParser.KW_STACK);
                this.state = 1896;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 1897;
                this.constant();
                this.state = 1902;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                while (_la === 475) {
                    {
                    {
                    this.state = 1898;
                    this.match(SparkSQLParser.COMMA);
                    this.state = 1899;
                    this.expression();
                    }
                    }
                    this.state = 1904;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                }
                this.state = 1905;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case SparkSQLParser.KW_JSON_TUPLE:
                localContext = new Json_tupleContext(localContext);
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 1907;
                this.match(SparkSQLParser.KW_JSON_TUPLE);
                this.state = 1908;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 1909;
                this.stringLiteral();
                this.state = 1914;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                while (_la === 475) {
                    {
                    {
                    this.state = 1910;
                    this.match(SparkSQLParser.COMMA);
                    this.state = 1911;
                    this.expression();
                    }
                    }
                    this.state = 1916;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                }
                this.state = 1917;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case SparkSQLParser.KW_PARSE_URL:
                localContext = new Parse_urlContext(localContext);
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 1919;
                this.match(SparkSQLParser.KW_PARSE_URL);
                this.state = 1920;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 1921;
                this.stringLiteral();
                this.state = 1922;
                this.match(SparkSQLParser.COMMA);
                this.state = 1923;
                this.stringLiteral();
                this.state = 1924;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public rangeClause(): RangeClauseContext {
        let localContext = new RangeClauseContext(this.context, this.state);
        this.enterRule(localContext, 200, SparkSQLParser.RULE_rangeClause);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1928;
            this.match(SparkSQLParser.KW_RANGE);
            this.state = 1929;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 1930;
            this.expression();
            this.state = 1935;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 475) {
                {
                {
                this.state = 1931;
                this.match(SparkSQLParser.COMMA);
                this.state = 1932;
                this.expression();
                }
                }
                this.state = 1937;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 1938;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public windowTVFExpression(): WindowTVFExpressionContext {
        let localContext = new WindowTVFExpressionContext(this.context, this.state);
        this.enterRule(localContext, 202, SparkSQLParser.RULE_windowTVFExpression);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1940;
            this.windowTVFName();
            this.state = 1941;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 1942;
            this.windowTVFParam();
            this.state = 1947;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 475) {
                {
                {
                this.state = 1943;
                this.match(SparkSQLParser.COMMA);
                this.state = 1944;
                this.windowTVFParam();
                }
                }
                this.state = 1949;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 1950;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public windowTVFName(): WindowTVFNameContext {
        let localContext = new WindowTVFNameContext(this.context, this.state);
        this.enterRule(localContext, 204, SparkSQLParser.RULE_windowTVFName);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1952;
            _la = this.tokenStream.LA(1);
            if(!(_la === 27 || _la === 64 || _la === 178)) {
            this.errorHandler.recoverInline(this);
            }
            else {
                this.errorHandler.reportMatch(this);
                this.consume();
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public transformClause(): TransformClauseContext {
        let localContext = new TransformClauseContext(this.context, this.state);
        this.enterRule(localContext, 206, SparkSQLParser.RULE_transformClause);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1954;
            this.match(SparkSQLParser.KW_TRANSFORM);
            this.state = 1955;
            this.columnNameList();
            this.state = 1967;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 223, this.context) ) {
            case 1:
                {
                {
                this.state = 1956;
                this.match(SparkSQLParser.KW_USING);
                this.state = 1957;
                this.stringLiteral();
                this.state = 1963;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 209) {
                    {
                    this.state = 1958;
                    this.match(SparkSQLParser.KW_AS);
                    this.state = 1961;
                    this.errorHandler.sync(this);
                    switch (this.interpreter.adaptivePredict(this.tokenStream, 221, this.context) ) {
                    case 1:
                        {
                        this.state = 1959;
                        this.columnNameList();
                        }
                        break;
                    case 2:
                        {
                        this.state = 1960;
                        this.physicalColumnDefinitionList();
                        }
                        break;
                    }
                    }
                }

                }
                }
                break;
            case 2:
                {
                this.state = 1965;
                this.rowFormatDelimited();
                }
                break;
            case 3:
                {
                this.state = 1966;
                this.hiveSerde();
                }
                break;
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public rowFormatDelimited(): RowFormatDelimitedContext {
        let localContext = new RowFormatDelimitedContext(this.context, this.state);
        this.enterRule(localContext, 208, SparkSQLParser.RULE_rowFormatDelimited);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1969;
            this.sparkRecordWriterPart();
            this.state = 1970;
            this.usingAsColumnPart();
            this.state = 1971;
            this.sparkRecordWriterPart();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public hiveSerde(): HiveSerdeContext {
        let localContext = new HiveSerdeContext(this.context, this.state);
        this.enterRule(localContext, 210, SparkSQLParser.RULE_hiveSerde);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1973;
            this.hiveSerdePart();
            this.state = 1974;
            this.usingAsColumnPart();
            this.state = 1975;
            this.hiveSerdePart();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public usingAsColumnPart(): UsingAsColumnPartContext {
        let localContext = new UsingAsColumnPartContext(this.context, this.state);
        this.enterRule(localContext, 212, SparkSQLParser.RULE_usingAsColumnPart);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1977;
            this.match(SparkSQLParser.KW_USING);
            this.state = 1978;
            this.stringLiteral();
            this.state = 1979;
            this.match(SparkSQLParser.KW_AS);
            {
            this.state = 1982;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 224, this.context) ) {
            case 1:
                {
                this.state = 1980;
                this.columnNameList();
                }
                break;
            case 2:
                {
                this.state = 1981;
                this.physicalColumnDefinitionList();
                }
                break;
            }
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public hiveSerdePart(): HiveSerdePartContext {
        let localContext = new HiveSerdePartContext(this.context, this.state);
        this.enterRule(localContext, 214, SparkSQLParser.RULE_hiveSerdePart);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1988;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 392) {
                {
                this.state = 1984;
                this.match(SparkSQLParser.KW_ROW);
                this.state = 1985;
                this.match(SparkSQLParser.KW_FORMAT);
                this.state = 1986;
                this.match(SparkSQLParser.KW_SERDE);
                this.state = 1987;
                this.stringLiteral();
                }
            }

            this.state = 1993;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 446) {
                {
                this.state = 1990;
                this.match(SparkSQLParser.KW_WITH);
                this.state = 1991;
                this.match(SparkSQLParser.KW_SERDEPROPERTIES);
                this.state = 1992;
                this.tableCanHasKeyPropertyList();
                }
            }

            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public sparkRecordWriterPart(): SparkRecordWriterPartContext {
        let localContext = new SparkRecordWriterPartContext(this.context, this.state);
        this.enterRule(localContext, 216, SparkSQLParser.RULE_sparkRecordWriterPart);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 1996;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 227, this.context) ) {
            case 1:
                {
                this.state = 1995;
                this.rowFormatDelimted();
                }
                break;
            }
            this.state = 1999;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 228, this.context) ) {
            case 1:
                {
                this.state = 1998;
                this.fieldsTerminatedBy();
                }
                break;
            }
            this.state = 2005;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 229, this.context) ) {
            case 1:
                {
                this.state = 2001;
                this.match(SparkSQLParser.KW_LINES);
                this.state = 2002;
                this.match(SparkSQLParser.KW_TERMINATED);
                this.state = 2003;
                this.match(SparkSQLParser.KW_BY);
                this.state = 2004;
                this.stringLiteral();
                }
                break;
            }
            this.state = 2011;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 230, this.context) ) {
            case 1:
                {
                this.state = 2007;
                this.match(SparkSQLParser.KW_NULL);
                this.state = 2008;
                this.match(SparkSQLParser.KW_DEFINED);
                this.state = 2009;
                this.match(SparkSQLParser.KW_AS);
                this.state = 2010;
                this.stringLiteral();
                }
                break;
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public windowTVFParam(): WindowTVFParamContext {
        let localContext = new WindowTVFParamContext(this.context, this.state);
        this.enterRule(localContext, 218, SparkSQLParser.RULE_windowTVFParam);
        try {
            this.state = 2028;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 231, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 2013;
                this.match(SparkSQLParser.KW_TABLE);
                this.state = 2014;
                this.timeAttrColumn();
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 2015;
                this.columnDescriptor();
                }
                break;
            case 3:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 2016;
                this.timeIntervalExpression();
                }
                break;
            case 4:
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 2017;
                this.match(SparkSQLParser.KW_DATA);
                this.state = 2018;
                this.match(SparkSQLParser.DOUBLE_RIGHT_ARROW);
                this.state = 2019;
                this.match(SparkSQLParser.KW_TABLE);
                this.state = 2020;
                this.timeAttrColumn();
                }
                break;
            case 5:
                this.enterOuterAlt(localContext, 5);
                {
                this.state = 2021;
                this.match(SparkSQLParser.KW_TIMECOL);
                this.state = 2022;
                this.match(SparkSQLParser.DOUBLE_RIGHT_ARROW);
                this.state = 2023;
                this.columnDescriptor();
                }
                break;
            case 6:
                this.enterOuterAlt(localContext, 6);
                {
                this.state = 2024;
                this.timeIntervalParamName();
                this.state = 2025;
                this.match(SparkSQLParser.DOUBLE_RIGHT_ARROW);
                this.state = 2026;
                this.timeIntervalExpression();
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public timeIntervalParamName(): TimeIntervalParamNameContext {
        let localContext = new TimeIntervalParamNameContext(this.context, this.state);
        this.enterRule(localContext, 220, SparkSQLParser.RULE_timeIntervalParamName);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2030;
            _la = this.tokenStream.LA(1);
            if(!(_la === 28 || ((((_la - 156)) & ~0x1F) === 0 && ((1 << (_la - 156)) & 16643) !== 0) || _la === 354)) {
            this.errorHandler.recoverInline(this);
            }
            else {
                this.errorHandler.reportMatch(this);
                this.consume();
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public columnDescriptor(): ColumnDescriptorContext {
        let localContext = new ColumnDescriptorContext(this.context, this.state);
        this.enterRule(localContext, 222, SparkSQLParser.RULE_columnDescriptor);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2032;
            this.match(SparkSQLParser.KW_DESCRIPTOR);
            this.state = 2033;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 2034;
            this.uid();
            this.state = 2035;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public joinCondition(): JoinConditionContext {
        let localContext = new JoinConditionContext(this.context, this.state);
        this.enterRule(localContext, 224, SparkSQLParser.RULE_joinCondition);
        let _la: number;
        try {
            this.state = 2051;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.KW_ON:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 2037;
                this.match(SparkSQLParser.KW_ON);
                this.state = 2038;
                this.booleanExpression(0);
                }
                break;
            case SparkSQLParser.KW_USING:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 2039;
                this.match(SparkSQLParser.KW_USING);
                this.state = 2040;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 2041;
                this.uid();
                this.state = 2046;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                while (_la === 475) {
                    {
                    {
                    this.state = 2042;
                    this.match(SparkSQLParser.COMMA);
                    this.state = 2043;
                    this.uid();
                    }
                    }
                    this.state = 2048;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                }
                this.state = 2049;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public whereClause(): WhereClauseContext {
        let localContext = new WhereClauseContext(this.context, this.state);
        this.enterRule(localContext, 226, SparkSQLParser.RULE_whereClause);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2053;
            this.match(SparkSQLParser.KW_WHERE);
            this.state = 2054;
            this.booleanExpression(0);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public samplingQueries(): SamplingQueriesContext {
        let localContext = new SamplingQueriesContext(this.context, this.state);
        this.enterRule(localContext, 228, SparkSQLParser.RULE_samplingQueries);
        try {
            this.state = 2087;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 238, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 2056;
                this.match(SparkSQLParser.KW_TABLESAMPLE);
                this.state = 2057;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 2061;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 234, this.context) ) {
                case 1:
                    {
                    this.state = 2058;
                    this.decimalLiteral();
                    }
                    break;
                case 2:
                    {
                    this.state = 2059;
                    this.match(SparkSQLParser.DIG_LITERAL);
                    }
                    break;
                case 3:
                    {
                    this.state = 2060;
                    this.expression();
                    }
                    break;
                }
                this.state = 2063;
                this.match(SparkSQLParser.KW_PERCENT);
                this.state = 2064;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 2065;
                this.match(SparkSQLParser.KW_TABLESAMPLE);
                this.state = 2066;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 2069;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 235, this.context) ) {
                case 1:
                    {
                    this.state = 2067;
                    this.match(SparkSQLParser.DIG_LITERAL);
                    }
                    break;
                case 2:
                    {
                    this.state = 2068;
                    this.expression();
                    }
                    break;
                }
                this.state = 2071;
                this.match(SparkSQLParser.KW_ROWS);
                this.state = 2072;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case 3:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 2073;
                this.match(SparkSQLParser.KW_TABLESAMPLE);
                this.state = 2074;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 2075;
                this.match(SparkSQLParser.KW_BUCKET);
                this.state = 2078;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 236, this.context) ) {
                case 1:
                    {
                    this.state = 2076;
                    this.match(SparkSQLParser.DIG_LITERAL);
                    }
                    break;
                case 2:
                    {
                    this.state = 2077;
                    this.expression();
                    }
                    break;
                }
                this.state = 2080;
                this.match(SparkSQLParser.KW_OUT);
                this.state = 2081;
                this.match(SparkSQLParser.KW_OF);
                this.state = 2084;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 237, this.context) ) {
                case 1:
                    {
                    this.state = 2082;
                    this.match(SparkSQLParser.DIG_LITERAL);
                    }
                    break;
                case 2:
                    {
                    this.state = 2083;
                    this.expression();
                    }
                    break;
                }
                this.state = 2086;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public someByClause(): SomeByClauseContext {
        let localContext = new SomeByClauseContext(this.context, this.state);
        this.enterRule(localContext, 230, SparkSQLParser.RULE_someByClause);
        try {
            this.state = 2093;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.KW_CLUSTERED:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 2089;
                this.clusteredByClause();
                }
                break;
            case SparkSQLParser.KW_CLUSTER:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 2090;
                this.clusterByClause();
                }
                break;
            case SparkSQLParser.KW_DISTRIBUTE:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 2091;
                this.distributeByClause();
                }
                break;
            case SparkSQLParser.KW_GROUP:
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 2092;
                this.groupByClause();
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public clusterByClause(): ClusterByClauseContext {
        let localContext = new ClusterByClauseContext(this.context, this.state);
        this.enterRule(localContext, 232, SparkSQLParser.RULE_clusterByClause);
        try {
            let alternative: number;
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2095;
            this.match(SparkSQLParser.KW_CLUSTER);
            this.state = 2096;
            this.match(SparkSQLParser.KW_BY);
            this.state = 2097;
            this.groupItemDefinition();
            this.state = 2102;
            this.errorHandler.sync(this);
            alternative = this.interpreter.adaptivePredict(this.tokenStream, 240, this.context);
            while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {
                if (alternative === 1) {
                    {
                    {
                    this.state = 2098;
                    this.match(SparkSQLParser.COMMA);
                    this.state = 2099;
                    this.groupItemDefinition();
                    }
                    }
                }
                this.state = 2104;
                this.errorHandler.sync(this);
                alternative = this.interpreter.adaptivePredict(this.tokenStream, 240, this.context);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public clusteredByClause(): ClusteredByClauseContext {
        let localContext = new ClusteredByClauseContext(this.context, this.state);
        this.enterRule(localContext, 234, SparkSQLParser.RULE_clusteredByClause);
        try {
            let alternative: number;
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2105;
            this.match(SparkSQLParser.KW_CLUSTERED);
            this.state = 2106;
            this.match(SparkSQLParser.KW_BY);
            this.state = 2107;
            this.groupItemDefinition();
            this.state = 2112;
            this.errorHandler.sync(this);
            alternative = this.interpreter.adaptivePredict(this.tokenStream, 241, this.context);
            while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {
                if (alternative === 1) {
                    {
                    {
                    this.state = 2108;
                    this.match(SparkSQLParser.COMMA);
                    this.state = 2109;
                    this.groupItemDefinition();
                    }
                    }
                }
                this.state = 2114;
                this.errorHandler.sync(this);
                alternative = this.interpreter.adaptivePredict(this.tokenStream, 241, this.context);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public distributeByClause(): DistributeByClauseContext {
        let localContext = new DistributeByClauseContext(this.context, this.state);
        this.enterRule(localContext, 236, SparkSQLParser.RULE_distributeByClause);
        try {
            let alternative: number;
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2115;
            this.match(SparkSQLParser.KW_DISTRIBUTE);
            this.state = 2116;
            this.match(SparkSQLParser.KW_BY);
            this.state = 2117;
            this.groupItemDefinition();
            this.state = 2122;
            this.errorHandler.sync(this);
            alternative = this.interpreter.adaptivePredict(this.tokenStream, 242, this.context);
            while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {
                if (alternative === 1) {
                    {
                    {
                    this.state = 2118;
                    this.match(SparkSQLParser.COMMA);
                    this.state = 2119;
                    this.groupItemDefinition();
                    }
                    }
                }
                this.state = 2124;
                this.errorHandler.sync(this);
                alternative = this.interpreter.adaptivePredict(this.tokenStream, 242, this.context);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public groupByClause(): GroupByClauseContext {
        let localContext = new GroupByClauseContext(this.context, this.state);
        this.enterRule(localContext, 238, SparkSQLParser.RULE_groupByClause);
        try {
            let alternative: number;
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2125;
            this.match(SparkSQLParser.KW_GROUP);
            this.state = 2126;
            this.match(SparkSQLParser.KW_BY);
            this.state = 2127;
            this.groupItemDefinition();
            this.state = 2132;
            this.errorHandler.sync(this);
            alternative = this.interpreter.adaptivePredict(this.tokenStream, 243, this.context);
            while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {
                if (alternative === 1) {
                    {
                    {
                    this.state = 2128;
                    this.match(SparkSQLParser.COMMA);
                    this.state = 2129;
                    this.groupItemDefinition();
                    }
                    }
                }
                this.state = 2134;
                this.errorHandler.sync(this);
                alternative = this.interpreter.adaptivePredict(this.tokenStream, 243, this.context);
            }
            this.state = 2137;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 244, this.context) ) {
            case 1:
                {
                this.state = 2135;
                this.match(SparkSQLParser.KW_WITH);
                this.state = 2136;
                this.groupingSetsNotionName();
                }
                break;
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public groupItemDefinition(): GroupItemDefinitionContext {
        let localContext = new GroupItemDefinitionContext(this.context, this.state);
        this.enterRule(localContext, 240, SparkSQLParser.RULE_groupItemDefinition);
        let _la: number;
        try {
            let alternative: number;
            this.state = 2185;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 249, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 2139;
                this.expression();
                this.state = 2144;
                this.errorHandler.sync(this);
                alternative = this.interpreter.adaptivePredict(this.tokenStream, 245, this.context);
                while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {
                    if (alternative === 1) {
                        {
                        {
                        this.state = 2140;
                        this.match(SparkSQLParser.COMMA);
                        this.state = 2141;
                        this.expression();
                        }
                        }
                    }
                    this.state = 2146;
                    this.errorHandler.sync(this);
                    alternative = this.interpreter.adaptivePredict(this.tokenStream, 245, this.context);
                }
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 2147;
                this.groupWindowFunction();
                }
                break;
            case 3:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 2148;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 2149;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case 4:
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 2150;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 2151;
                this.expression();
                this.state = 2156;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                while (_la === 475) {
                    {
                    {
                    this.state = 2152;
                    this.match(SparkSQLParser.COMMA);
                    this.state = 2153;
                    this.expression();
                    }
                    }
                    this.state = 2158;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                }
                this.state = 2159;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case 5:
                this.enterOuterAlt(localContext, 5);
                {
                this.state = 2161;
                this.groupingSetsNotionName();
                this.state = 2162;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 2163;
                this.expression();
                this.state = 2168;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                while (_la === 475) {
                    {
                    {
                    this.state = 2164;
                    this.match(SparkSQLParser.COMMA);
                    this.state = 2165;
                    this.expression();
                    }
                    }
                    this.state = 2170;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                }
                this.state = 2171;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case 6:
                this.enterOuterAlt(localContext, 6);
                {
                this.state = 2173;
                this.groupingSets();
                this.state = 2174;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 2175;
                this.groupItemDefinition();
                this.state = 2180;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                while (_la === 475) {
                    {
                    {
                    this.state = 2176;
                    this.match(SparkSQLParser.COMMA);
                    this.state = 2177;
                    this.groupItemDefinition();
                    }
                    }
                    this.state = 2182;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                }
                this.state = 2183;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public groupingSets(): GroupingSetsContext {
        let localContext = new GroupingSetsContext(this.context, this.state);
        this.enterRule(localContext, 242, SparkSQLParser.RULE_groupingSets);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2187;
            this.match(SparkSQLParser.KW_GROUPING);
            this.state = 2188;
            this.match(SparkSQLParser.KW_SETS);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public groupingSetsNotionName(): GroupingSetsNotionNameContext {
        let localContext = new GroupingSetsNotionNameContext(this.context, this.state);
        this.enterRule(localContext, 244, SparkSQLParser.RULE_groupingSetsNotionName);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2190;
            _la = this.tokenStream.LA(1);
            if(!(_la === 248 || _la === 391)) {
            this.errorHandler.recoverInline(this);
            }
            else {
                this.errorHandler.reportMatch(this);
                this.consume();
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public groupWindowFunction(): GroupWindowFunctionContext {
        let localContext = new GroupWindowFunctionContext(this.context, this.state);
        this.enterRule(localContext, 246, SparkSQLParser.RULE_groupWindowFunction);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2192;
            this.groupWindowFunctionName();
            this.state = 2193;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 2194;
            this.timeAttrColumn();
            this.state = 2195;
            this.match(SparkSQLParser.COMMA);
            this.state = 2196;
            this.timeIntervalExpression();
            this.state = 2197;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public groupWindowFunctionName(): GroupWindowFunctionNameContext {
        let localContext = new GroupWindowFunctionNameContext(this.context, this.state);
        this.enterRule(localContext, 248, SparkSQLParser.RULE_groupWindowFunctionName);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2199;
            _la = this.tokenStream.LA(1);
            if(!(_la === 64 || _la === 152 || _la === 178)) {
            this.errorHandler.recoverInline(this);
            }
            else {
                this.errorHandler.reportMatch(this);
                this.consume();
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public timeAttrColumn(): TimeAttrColumnContext {
        let localContext = new TimeAttrColumnContext(this.context, this.state);
        this.enterRule(localContext, 250, SparkSQLParser.RULE_timeAttrColumn);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2201;
            this.uid();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public havingClause(): HavingClauseContext {
        let localContext = new HavingClauseContext(this.context, this.state);
        this.enterRule(localContext, 252, SparkSQLParser.RULE_havingClause);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2203;
            this.match(SparkSQLParser.KW_HAVING);
            this.state = 2204;
            this.booleanExpression(0);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public windowClause(): WindowClauseContext {
        let localContext = new WindowClauseContext(this.context, this.state);
        this.enterRule(localContext, 254, SparkSQLParser.RULE_windowClause);
        try {
            let alternative: number;
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2206;
            this.match(SparkSQLParser.KW_WINDOW);
            this.state = 2207;
            this.namedWindow();
            this.state = 2212;
            this.errorHandler.sync(this);
            alternative = this.interpreter.adaptivePredict(this.tokenStream, 250, this.context);
            while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {
                if (alternative === 1) {
                    {
                    {
                    this.state = 2208;
                    this.match(SparkSQLParser.COMMA);
                    this.state = 2209;
                    this.namedWindow();
                    }
                    }
                }
                this.state = 2214;
                this.errorHandler.sync(this);
                alternative = this.interpreter.adaptivePredict(this.tokenStream, 250, this.context);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public namedWindow(): NamedWindowContext {
        let localContext = new NamedWindowContext(this.context, this.state);
        this.enterRule(localContext, 256, SparkSQLParser.RULE_namedWindow);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2215;
            localContext._name = this.errorCapturingIdentifier();
            this.state = 2216;
            this.match(SparkSQLParser.KW_AS);
            this.state = 2217;
            this.windowSpec();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public windowSpec(): WindowSpecContext {
        let localContext = new WindowSpecContext(this.context, this.state);
        this.enterRule(localContext, 258, SparkSQLParser.RULE_windowSpec);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2220;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if ((((_la) & ~0x1F) === 0 && ((1 << _la) & 4294896624) !== 0) || ((((_la - 33)) & ~0x1F) === 0 && ((1 << (_la - 33)) & 4294803199) !== 0) || ((((_la - 65)) & ~0x1F) === 0 && ((1 << (_la - 65)) & 4281327607) !== 0) || ((((_la - 97)) & ~0x1F) === 0 && ((1 << (_la - 97)) & 2147483643) !== 0) || ((((_la - 129)) & ~0x1F) === 0 && ((1 << (_la - 129)) & 2113863675) !== 0) || ((((_la - 161)) & ~0x1F) === 0 && ((1 << (_la - 161)) & 4292341757) !== 0) || ((((_la - 193)) & ~0x1F) === 0 && ((1 << (_la - 193)) & 247) !== 0) || _la === 332 || ((((_la - 478)) & ~0x1F) === 0 && ((1 << (_la - 478)) & 360449) !== 0)) {
                {
                this.state = 2219;
                localContext._name = this.errorCapturingIdentifier();
                }
            }

            this.state = 2222;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 2224;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 365) {
                {
                this.state = 2223;
                this.partitionByClause();
                }
            }

            this.state = 2227;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 408) {
                {
                this.state = 2226;
                this.sortByCaluse();
                }
            }

            this.state = 2230;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 358) {
                {
                this.state = 2229;
                this.orderByCaluse();
                }
            }

            this.state = 2233;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 380 || _la === 393) {
                {
                this.state = 2232;
                this.windowFrame();
                }
            }

            this.state = 2235;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public matchRecognizeClause(): MatchRecognizeClauseContext {
        let localContext = new MatchRecognizeClauseContext(this.context, this.state);
        this.enterRule(localContext, 260, SparkSQLParser.RULE_matchRecognizeClause);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2237;
            this.match(SparkSQLParser.KW_MATCH_RECOGNIZE);
            this.state = 2238;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 2240;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 365) {
                {
                this.state = 2239;
                this.partitionByClause();
                }
            }

            this.state = 2243;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 408) {
                {
                this.state = 2242;
                this.sortByCaluse();
                }
            }

            this.state = 2246;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 358) {
                {
                this.state = 2245;
                this.orderByCaluse();
                }
            }

            this.state = 2249;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 335) {
                {
                this.state = 2248;
                this.measuresClause();
                }
            }

            this.state = 2252;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 202 || _la === 356) {
                {
                this.state = 2251;
                this.outputMode();
                }
            }

            this.state = 2255;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 6) {
                {
                this.state = 2254;
                this.afterMatchStrategy();
                }
            }

            this.state = 2258;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 366) {
                {
                this.state = 2257;
                this.patternDefinition();
                }
            }

            this.state = 2260;
            this.patternVariablesDefinition();
            this.state = 2261;
            this.match(SparkSQLParser.RR_BRACKET);
            this.state = 2266;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 264, this.context) ) {
            case 1:
                {
                this.state = 2263;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 209) {
                    {
                    this.state = 2262;
                    this.match(SparkSQLParser.KW_AS);
                    }
                }

                this.state = 2265;
                this.identifier();
                }
                break;
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public orderByCaluse(): OrderByCaluseContext {
        let localContext = new OrderByCaluseContext(this.context, this.state);
        this.enterRule(localContext, 262, SparkSQLParser.RULE_orderByCaluse);
        try {
            let alternative: number;
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2268;
            this.match(SparkSQLParser.KW_ORDER);
            this.state = 2269;
            this.match(SparkSQLParser.KW_BY);
            this.state = 2270;
            this.orderItemDefinition();
            this.state = 2275;
            this.errorHandler.sync(this);
            alternative = this.interpreter.adaptivePredict(this.tokenStream, 265, this.context);
            while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {
                if (alternative === 1) {
                    {
                    {
                    this.state = 2271;
                    this.match(SparkSQLParser.COMMA);
                    this.state = 2272;
                    this.orderItemDefinition();
                    }
                    }
                }
                this.state = 2277;
                this.errorHandler.sync(this);
                alternative = this.interpreter.adaptivePredict(this.tokenStream, 265, this.context);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public sortByCaluse(): SortByCaluseContext {
        let localContext = new SortByCaluseContext(this.context, this.state);
        this.enterRule(localContext, 264, SparkSQLParser.RULE_sortByCaluse);
        try {
            let alternative: number;
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2278;
            this.match(SparkSQLParser.KW_SORT);
            this.state = 2279;
            this.match(SparkSQLParser.KW_BY);
            this.state = 2280;
            this.orderItemDefinition();
            this.state = 2285;
            this.errorHandler.sync(this);
            alternative = this.interpreter.adaptivePredict(this.tokenStream, 266, this.context);
            while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {
                if (alternative === 1) {
                    {
                    {
                    this.state = 2281;
                    this.match(SparkSQLParser.COMMA);
                    this.state = 2282;
                    this.orderItemDefinition();
                    }
                    }
                }
                this.state = 2287;
                this.errorHandler.sync(this);
                alternative = this.interpreter.adaptivePredict(this.tokenStream, 266, this.context);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public orderItemDefinition(): OrderItemDefinitionContext {
        let localContext = new OrderItemDefinitionContext(this.context, this.state);
        this.enterRule(localContext, 266, SparkSQLParser.RULE_orderItemDefinition);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2288;
            this.expression();
            this.state = 2290;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 267, this.context) ) {
            case 1:
                {
                this.state = 2289;
                localContext._ordering = this.tokenStream.LT(1);
                _la = this.tokenStream.LA(1);
                if(!(_la === 8 || _la === 35)) {
                    localContext._ordering = this.errorHandler.recoverInline(this);
                }
                else {
                    this.errorHandler.reportMatch(this);
                    this.consume();
                }
                }
                break;
            }
            this.state = 2294;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 268, this.context) ) {
            case 1:
                {
                this.state = 2292;
                this.match(SparkSQLParser.KW_NULLS);
                this.state = 2293;
                localContext._nullOrder = this.tokenStream.LT(1);
                _la = this.tokenStream.LA(1);
                if(!(_la === 52 || _la === 82)) {
                    localContext._nullOrder = this.errorHandler.recoverInline(this);
                }
                else {
                    this.errorHandler.reportMatch(this);
                    this.consume();
                }
                }
                break;
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public limitClause(): LimitClauseContext {
        let localContext = new LimitClauseContext(this.context, this.state);
        this.enterRule(localContext, 268, SparkSQLParser.RULE_limitClause);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2296;
            this.match(SparkSQLParser.KW_LIMIT);
            this.state = 2299;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.KW_ALL:
                {
                this.state = 2297;
                this.match(SparkSQLParser.KW_ALL);
                }
                break;
            case SparkSQLParser.KW_ADD:
            case SparkSQLParser.KW_ADMIN:
            case SparkSQLParser.KW_AFTER:
            case SparkSQLParser.KW_ANALYZE:
            case SparkSQLParser.KW_ASC:
            case SparkSQLParser.KW_BEFORE:
            case SparkSQLParser.KW_BYTES:
            case SparkSQLParser.KW_CASCADE:
            case SparkSQLParser.KW_CATALOG:
            case SparkSQLParser.KW_CATALOGS:
            case SparkSQLParser.KW_CENTURY:
            case SparkSQLParser.KW_CHAIN:
            case SparkSQLParser.KW_CHANGELOG_MODE:
            case SparkSQLParser.KW_CHARACTERS:
            case SparkSQLParser.KW_COMMENT:
            case SparkSQLParser.KW_COMPACT:
            case SparkSQLParser.KW_COLUMNS:
            case SparkSQLParser.KW_CONSTRAINTS:
            case SparkSQLParser.KW_CONSTRUCTOR:
            case SparkSQLParser.KW_COMPUTE:
            case SparkSQLParser.KW_CUMULATE:
            case SparkSQLParser.KW_DATA:
            case SparkSQLParser.KW_DATABASE:
            case SparkSQLParser.KW_DATABASES:
            case SparkSQLParser.KW_DAYS:
            case SparkSQLParser.KW_DECADE:
            case SparkSQLParser.KW_DEFINED:
            case SparkSQLParser.KW_DESC:
            case SparkSQLParser.KW_DESCRIPTOR:
            case SparkSQLParser.KW_DIV:
            case SparkSQLParser.KW_ENCODING:
            case SparkSQLParser.KW_ENFORCED:
            case SparkSQLParser.KW_ENGINE:
            case SparkSQLParser.KW_ERROR:
            case SparkSQLParser.KW_ESTIMATED_COST:
            case SparkSQLParser.KW_EXCEPTION:
            case SparkSQLParser.KW_EXCLUDE:
            case SparkSQLParser.KW_EXCLUDING:
            case SparkSQLParser.KW_EXTENDED:
            case SparkSQLParser.KW_FILE:
            case SparkSQLParser.KW_FINAL:
            case SparkSQLParser.KW_FIRST:
            case SparkSQLParser.KW_FOLLOWING:
            case SparkSQLParser.KW_FORMAT:
            case SparkSQLParser.KW_FORTRAN:
            case SparkSQLParser.KW_FOUND:
            case SparkSQLParser.KW_FRAC_SECOND:
            case SparkSQLParser.KW_FUNCTIONS:
            case SparkSQLParser.KW_GENERAL:
            case SparkSQLParser.KW_GENERATED:
            case SparkSQLParser.KW_GO:
            case SparkSQLParser.KW_GOTO:
            case SparkSQLParser.KW_GRANTED:
            case SparkSQLParser.KW_HOP:
            case SparkSQLParser.KW_HOURS:
            case SparkSQLParser.KW_IF:
            case SparkSQLParser.KW_IGNORE:
            case SparkSQLParser.KW_INCREMENT:
            case SparkSQLParser.KW_INPUT:
            case SparkSQLParser.KW_INVOKER:
            case SparkSQLParser.KW_JAR:
            case SparkSQLParser.KW_JARS:
            case SparkSQLParser.KW_JAVA:
            case SparkSQLParser.KW_JSON:
            case SparkSQLParser.KW_JSON_EXECUTION_PLAN:
            case SparkSQLParser.KW_KEY:
            case SparkSQLParser.KW_KEY_MEMBER:
            case SparkSQLParser.KW_KEY_TYPE:
            case SparkSQLParser.KW_LABEL:
            case SparkSQLParser.KW_LAST:
            case SparkSQLParser.KW_LENGTH:
            case SparkSQLParser.KW_LEVEL:
            case SparkSQLParser.KW_LOAD:
            case SparkSQLParser.KW_MAP:
            case SparkSQLParser.KW_MICROSECOND:
            case SparkSQLParser.KW_MILLENNIUM:
            case SparkSQLParser.KW_MILLISECOND:
            case SparkSQLParser.KW_MINUTES:
            case SparkSQLParser.KW_MINVALUE:
            case SparkSQLParser.KW_MODIFY:
            case SparkSQLParser.KW_MODULES:
            case SparkSQLParser.KW_MONTHS:
            case SparkSQLParser.KW_NANOSECOND:
            case SparkSQLParser.KW_NULLS:
            case SparkSQLParser.KW_NUMBER:
            case SparkSQLParser.KW_OPTION:
            case SparkSQLParser.KW_OPTIONS:
            case SparkSQLParser.KW_ORDERING:
            case SparkSQLParser.KW_OUTPUT:
            case SparkSQLParser.KW_OVERWRITE:
            case SparkSQLParser.KW_OVERWRITING:
            case SparkSQLParser.KW_PARTITIONED:
            case SparkSQLParser.KW_PARTITIONS:
            case SparkSQLParser.KW_PASSING:
            case SparkSQLParser.KW_PAST:
            case SparkSQLParser.KW_PATH:
            case SparkSQLParser.KW_PLACING:
            case SparkSQLParser.KW_PLAN:
            case SparkSQLParser.KW_PRECEDING:
            case SparkSQLParser.KW_PRESERVE:
            case SparkSQLParser.KW_PRIOR:
            case SparkSQLParser.KW_PRIVILEGES:
            case SparkSQLParser.KW_PUBLIC:
            case SparkSQLParser.KW_PYTHON:
            case SparkSQLParser.KW_PYTHON_FILES:
            case SparkSQLParser.KW_PYTHON_REQUIREMENTS:
            case SparkSQLParser.KW_PYTHON_DEPENDENCIES:
            case SparkSQLParser.KW_PYTHON_JAR:
            case SparkSQLParser.KW_PYTHON_ARCHIVES:
            case SparkSQLParser.KW_PYTHON_PARAMETER:
            case SparkSQLParser.KW_QUARTER:
            case SparkSQLParser.KW_RAW:
            case SparkSQLParser.KW_READ:
            case SparkSQLParser.KW_RELATIVE:
            case SparkSQLParser.KW_REMOVE:
            case SparkSQLParser.KW_RENAME:
            case SparkSQLParser.KW_REPLACE:
            case SparkSQLParser.KW_RESPECT:
            case SparkSQLParser.KW_RESTART:
            case SparkSQLParser.KW_RESTRICT:
            case SparkSQLParser.KW_ROLE:
            case SparkSQLParser.KW_ROW_COUNT:
            case SparkSQLParser.KW_SCALA:
            case SparkSQLParser.KW_SCALAR:
            case SparkSQLParser.KW_SCALE:
            case SparkSQLParser.KW_SCHEMA:
            case SparkSQLParser.KW_SECONDS:
            case SparkSQLParser.KW_SECTION:
            case SparkSQLParser.KW_SECURITY:
            case SparkSQLParser.KW_SELF:
            case SparkSQLParser.KW_SERVER:
            case SparkSQLParser.KW_SERVER_NAME:
            case SparkSQLParser.KW_SESSION:
            case SparkSQLParser.KW_SETS:
            case SparkSQLParser.KW_SIMPLE:
            case SparkSQLParser.KW_SIZE:
            case SparkSQLParser.KW_SLIDE:
            case SparkSQLParser.KW_SOURCE:
            case SparkSQLParser.KW_SPACE:
            case SparkSQLParser.KW_STATE:
            case SparkSQLParser.KW_STATEMENT:
            case SparkSQLParser.KW_STEP:
            case SparkSQLParser.KW_STRING:
            case SparkSQLParser.KW_STRUCTURE:
            case SparkSQLParser.KW_STYLE:
            case SparkSQLParser.KW_TABLES:
            case SparkSQLParser.KW_TEMPORARY:
            case SparkSQLParser.KW_TIMECOL:
            case SparkSQLParser.KW_FLOOR:
            case SparkSQLParser.KW_TIMESTAMP_LTZ:
            case SparkSQLParser.KW_TIMESTAMPADD:
            case SparkSQLParser.KW_TIMESTAMPDIFF:
            case SparkSQLParser.KW_TOTIMESTAMP:
            case SparkSQLParser.KW_TRANSFORM:
            case SparkSQLParser.KW_TUMBLE:
            case SparkSQLParser.KW_TYPE:
            case SparkSQLParser.KW_UNDER:
            case SparkSQLParser.KW_UNLOAD:
            case SparkSQLParser.KW_USAGE:
            case SparkSQLParser.KW_USE:
            case SparkSQLParser.KW_UTF16:
            case SparkSQLParser.KW_UTF32:
            case SparkSQLParser.KW_UTF8:
            case SparkSQLParser.KW_VERSION:
            case SparkSQLParser.KW_VIEW:
            case SparkSQLParser.KW_VIEWS:
            case SparkSQLParser.KW_VIRTUAL:
            case SparkSQLParser.KW_WATERMARK:
            case SparkSQLParser.KW_WATERMARKS:
            case SparkSQLParser.KW_WEEK:
            case SparkSQLParser.KW_WORK:
            case SparkSQLParser.KW_WRAPPER:
            case SparkSQLParser.KW_YEARS:
            case SparkSQLParser.KW_ZONE:
            case SparkSQLParser.KW_ABS:
            case SparkSQLParser.KW_ARRAY:
            case SparkSQLParser.KW_AVG:
            case SparkSQLParser.KW_CASE:
            case SparkSQLParser.KW_CAST:
            case SparkSQLParser.KW_CEIL:
            case SparkSQLParser.KW_COALESCE:
            case SparkSQLParser.KW_COLLECT:
            case SparkSQLParser.KW_COUNT:
            case SparkSQLParser.KW_DATE:
            case SparkSQLParser.KW_DAY:
            case SparkSQLParser.KW_EXISTS:
            case SparkSQLParser.KW_EXPLODE:
            case SparkSQLParser.KW_FIRST_VALUE:
            case SparkSQLParser.KW_FALSE:
            case SparkSQLParser.KW_FROM_UNIXTIME:
            case SparkSQLParser.KW_GROUPING:
            case SparkSQLParser.KW_HOUR:
            case SparkSQLParser.KW_INTERVAL:
            case SparkSQLParser.KW_LAG:
            case SparkSQLParser.KW_LAST_VALUE:
            case SparkSQLParser.KW_LEAD:
            case SparkSQLParser.KW_LEFT:
            case SparkSQLParser.KW_LOCALTIMESTAMP:
            case SparkSQLParser.KW_MINUTE:
            case SparkSQLParser.KW_MONTH:
            case SparkSQLParser.KW_NOT:
            case SparkSQLParser.KW_NTILE:
            case SparkSQLParser.KW_NULL:
            case SparkSQLParser.KW_OVERLAY:
            case SparkSQLParser.KW_PERCENT_RANK:
            case SparkSQLParser.KW_PERCENTILE_CONT:
            case SparkSQLParser.KW_PERCENTILE_DISC:
            case SparkSQLParser.KW_POSITION:
            case SparkSQLParser.KW_POWER:
            case SparkSQLParser.KW_RANGE:
            case SparkSQLParser.KW_ROW_NUMBER:
            case SparkSQLParser.KW_RANK:
            case SparkSQLParser.KW_RIGHT:
            case SparkSQLParser.KW_ROW:
            case SparkSQLParser.KW_SECOND:
            case SparkSQLParser.KW_STRUCT:
            case SparkSQLParser.KW_SUBSTRING:
            case SparkSQLParser.KW_SUM:
            case SparkSQLParser.KW_TIME:
            case SparkSQLParser.KW_TIMESTAMP:
            case SparkSQLParser.KW_TIMESTAMP_3:
            case SparkSQLParser.KW_TIMESTAMP_6:
            case SparkSQLParser.KW_TIMESTAMP_9:
            case SparkSQLParser.KW_TRUE:
            case SparkSQLParser.KW_TRUNCATE:
            case SparkSQLParser.KW_UPPER:
            case SparkSQLParser.KW_YEAR:
            case SparkSQLParser.BIT_NOT_OP:
            case SparkSQLParser.LR_BRACKET:
            case SparkSQLParser.DOLLAR:
            case SparkSQLParser.ASTERISK_SIGN:
            case SparkSQLParser.HYPNEN_SIGN:
            case SparkSQLParser.ADD_SIGN:
            case SparkSQLParser.STRING_LITERAL:
            case SparkSQLParser.DIG_LITERAL:
            case SparkSQLParser.REAL_LITERAL:
            case SparkSQLParser.ID_LITERAL:
                {
                this.state = 2298;
                localContext._limit = this.expression();
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public offsetClause(): OffsetClauseContext {
        let localContext = new OffsetClauseContext(this.context, this.state);
        this.enterRule(localContext, 270, SparkSQLParser.RULE_offsetClause);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2301;
            this.match(SparkSQLParser.KW_OFFSET);
            this.state = 2304;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 270, this.context) ) {
            case 1:
                {
                this.state = 2302;
                this.match(SparkSQLParser.DIG_LITERAL);
                }
                break;
            case 2:
                {
                this.state = 2303;
                this.expression();
                }
                break;
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public partitionByClause(): PartitionByClauseContext {
        let localContext = new PartitionByClauseContext(this.context, this.state);
        this.enterRule(localContext, 272, SparkSQLParser.RULE_partitionByClause);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2306;
            this.match(SparkSQLParser.KW_PARTITION);
            this.state = 2307;
            this.match(SparkSQLParser.KW_BY);
            this.state = 2308;
            this.expression();
            this.state = 2313;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 475) {
                {
                {
                this.state = 2309;
                this.match(SparkSQLParser.COMMA);
                this.state = 2310;
                this.expression();
                }
                }
                this.state = 2315;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public quantifiers(): QuantifiersContext {
        let localContext = new QuantifiersContext(this.context, this.state);
        this.enterRule(localContext, 274, SparkSQLParser.RULE_quantifiers);
        try {
            this.state = 2332;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 272, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                {
                this.state = 2316;
                this.match(SparkSQLParser.ASTERISK_SIGN);
                }
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                {
                this.state = 2317;
                this.match(SparkSQLParser.ADD_SIGN);
                }
                }
                break;
            case 3:
                this.enterOuterAlt(localContext, 3);
                {
                {
                this.state = 2318;
                this.match(SparkSQLParser.QUESTION_MARK_SIGN);
                }
                }
                break;
            case 4:
                this.enterOuterAlt(localContext, 4);
                {
                {
                this.state = 2319;
                this.match(SparkSQLParser.LB_BRACKET);
                this.state = 2320;
                this.match(SparkSQLParser.DIG_LITERAL);
                this.state = 2321;
                this.match(SparkSQLParser.COMMA);
                this.state = 2322;
                this.match(SparkSQLParser.DIG_LITERAL);
                this.state = 2323;
                this.match(SparkSQLParser.RB_BRACKET);
                }
                }
                break;
            case 5:
                this.enterOuterAlt(localContext, 5);
                {
                {
                this.state = 2324;
                this.match(SparkSQLParser.LB_BRACKET);
                this.state = 2325;
                this.match(SparkSQLParser.DIG_LITERAL);
                this.state = 2326;
                this.match(SparkSQLParser.COMMA);
                this.state = 2327;
                this.match(SparkSQLParser.RB_BRACKET);
                }
                }
                break;
            case 6:
                this.enterOuterAlt(localContext, 6);
                {
                {
                this.state = 2328;
                this.match(SparkSQLParser.LB_BRACKET);
                this.state = 2329;
                this.match(SparkSQLParser.COMMA);
                this.state = 2330;
                this.match(SparkSQLParser.DIG_LITERAL);
                this.state = 2331;
                this.match(SparkSQLParser.RB_BRACKET);
                }
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public measuresClause(): MeasuresClauseContext {
        let localContext = new MeasuresClauseContext(this.context, this.state);
        this.enterRule(localContext, 276, SparkSQLParser.RULE_measuresClause);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2334;
            this.match(SparkSQLParser.KW_MEASURES);
            this.state = 2335;
            this.projectItemDefinition();
            this.state = 2340;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 475) {
                {
                {
                this.state = 2336;
                this.match(SparkSQLParser.COMMA);
                this.state = 2337;
                this.projectItemDefinition();
                }
                }
                this.state = 2342;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public patternDefinition(): PatternDefinitionContext {
        let localContext = new PatternDefinitionContext(this.context, this.state);
        this.enterRule(localContext, 278, SparkSQLParser.RULE_patternDefinition);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2343;
            this.match(SparkSQLParser.KW_PATTERN);
            this.state = 2344;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 2346;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            do {
                {
                {
                this.state = 2345;
                this.patternVariable();
                }
                }
                this.state = 2348;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            } while (_la === 494 || _la === 496);
            this.state = 2350;
            this.match(SparkSQLParser.RR_BRACKET);
            this.state = 2352;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 447) {
                {
                this.state = 2351;
                this.withinClause();
                }
            }

            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public patternVariable(): PatternVariableContext {
        let localContext = new PatternVariableContext(this.context, this.state);
        this.enterRule(localContext, 280, SparkSQLParser.RULE_patternVariable);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2354;
            this.unquotedIdentifier();
            this.state = 2356;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (((((_la - 473)) & ~0x1F) === 0 && ((1 << (_la - 473)) & 271361) !== 0)) {
                {
                this.state = 2355;
                this.quantifiers();
                }
            }

            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public outputMode(): OutputModeContext {
        let localContext = new OutputModeContext(this.context, this.state);
        this.enterRule(localContext, 282, SparkSQLParser.RULE_outputMode);
        try {
            this.state = 2366;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.KW_ALL:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 2358;
                this.match(SparkSQLParser.KW_ALL);
                this.state = 2359;
                this.match(SparkSQLParser.KW_ROWS);
                this.state = 2360;
                this.match(SparkSQLParser.KW_PER);
                this.state = 2361;
                this.match(SparkSQLParser.KW_MATCH);
                }
                break;
            case SparkSQLParser.KW_ONE:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 2362;
                this.match(SparkSQLParser.KW_ONE);
                this.state = 2363;
                this.match(SparkSQLParser.KW_ROW);
                this.state = 2364;
                this.match(SparkSQLParser.KW_PER);
                this.state = 2365;
                this.match(SparkSQLParser.KW_MATCH);
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public afterMatchStrategy(): AfterMatchStrategyContext {
        let localContext = new AfterMatchStrategyContext(this.context, this.state);
        this.enterRule(localContext, 284, SparkSQLParser.RULE_afterMatchStrategy);
        try {
            this.state = 2392;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 278, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 2368;
                this.match(SparkSQLParser.KW_AFTER);
                this.state = 2369;
                this.match(SparkSQLParser.KW_MATCH);
                this.state = 2370;
                this.match(SparkSQLParser.KW_SKIP);
                this.state = 2371;
                this.match(SparkSQLParser.KW_PAST);
                this.state = 2372;
                this.match(SparkSQLParser.KW_LAST);
                this.state = 2373;
                this.match(SparkSQLParser.KW_ROW);
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 2374;
                this.match(SparkSQLParser.KW_AFTER);
                this.state = 2375;
                this.match(SparkSQLParser.KW_MATCH);
                this.state = 2376;
                this.match(SparkSQLParser.KW_SKIP);
                this.state = 2377;
                this.match(SparkSQLParser.KW_TO);
                this.state = 2378;
                this.match(SparkSQLParser.KW_NEXT);
                this.state = 2379;
                this.match(SparkSQLParser.KW_ROW);
                }
                break;
            case 3:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 2380;
                this.match(SparkSQLParser.KW_AFTER);
                this.state = 2381;
                this.match(SparkSQLParser.KW_MATCH);
                this.state = 2382;
                this.match(SparkSQLParser.KW_SKIP);
                this.state = 2383;
                this.match(SparkSQLParser.KW_TO);
                this.state = 2384;
                this.match(SparkSQLParser.KW_LAST);
                this.state = 2385;
                this.unquotedIdentifier();
                }
                break;
            case 4:
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 2386;
                this.match(SparkSQLParser.KW_AFTER);
                this.state = 2387;
                this.match(SparkSQLParser.KW_MATCH);
                this.state = 2388;
                this.match(SparkSQLParser.KW_SKIP);
                this.state = 2389;
                this.match(SparkSQLParser.KW_TO);
                this.state = 2390;
                this.match(SparkSQLParser.KW_FIRST);
                this.state = 2391;
                this.unquotedIdentifier();
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public patternVariablesDefinition(): PatternVariablesDefinitionContext {
        let localContext = new PatternVariablesDefinitionContext(this.context, this.state);
        this.enterRule(localContext, 286, SparkSQLParser.RULE_patternVariablesDefinition);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2394;
            this.match(SparkSQLParser.KW_DEFINE);
            this.state = 2395;
            this.projectItemDefinition();
            this.state = 2400;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 475) {
                {
                {
                this.state = 2396;
                this.match(SparkSQLParser.COMMA);
                this.state = 2397;
                this.projectItemDefinition();
                }
                }
                this.state = 2402;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public windowFrame(): WindowFrameContext {
        let localContext = new WindowFrameContext(this.context, this.state);
        this.enterRule(localContext, 288, SparkSQLParser.RULE_windowFrame);
        try {
            this.state = 2412;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.KW_RANGE:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 2403;
                this.match(SparkSQLParser.KW_RANGE);
                this.state = 2404;
                this.match(SparkSQLParser.KW_BETWEEN);
                this.state = 2405;
                this.timeIntervalExpression();
                this.state = 2406;
                this.frameBound();
                }
                break;
            case SparkSQLParser.KW_ROWS:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 2408;
                this.match(SparkSQLParser.KW_ROWS);
                this.state = 2409;
                this.match(SparkSQLParser.KW_BETWEEN);
                this.state = 2410;
                this.match(SparkSQLParser.DIG_LITERAL);
                this.state = 2411;
                this.frameBound();
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public frameBound(): FrameBoundContext {
        let localContext = new FrameBoundContext(this.context, this.state);
        this.enterRule(localContext, 290, SparkSQLParser.RULE_frameBound);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2414;
            this.match(SparkSQLParser.KW_PRECEDING);
            this.state = 2415;
            this.match(SparkSQLParser.KW_AND);
            this.state = 2416;
            this.match(SparkSQLParser.KW_CURRENT);
            this.state = 2417;
            this.match(SparkSQLParser.KW_ROW);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public withinClause(): WithinClauseContext {
        let localContext = new WithinClauseContext(this.context, this.state);
        this.enterRule(localContext, 292, SparkSQLParser.RULE_withinClause);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2419;
            this.match(SparkSQLParser.KW_WITHIN);
            this.state = 2420;
            this.timeIntervalExpression();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public selfDefinitionClause(): SelfDefinitionClauseContext {
        let localContext = new SelfDefinitionClauseContext(this.context, this.state);
        this.enterRule(localContext, 294, SparkSQLParser.RULE_selfDefinitionClause);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2422;
            this.match(SparkSQLParser.KW_PERIOD);
            this.state = 2423;
            this.match(SparkSQLParser.KW_FOR);
            this.state = 2424;
            this.match(SparkSQLParser.KW_SYSTEM_TIME);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public partitionDefinition(): PartitionDefinitionContext {
        let localContext = new PartitionDefinitionContext(this.context, this.state);
        this.enterRule(localContext, 296, SparkSQLParser.RULE_partitionDefinition);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2426;
            this.match(SparkSQLParser.KW_PARTITIONED);
            this.state = 2427;
            this.match(SparkSQLParser.KW_BY);
            this.state = 2428;
            this.transformList();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public transformList(): TransformListContext {
        let localContext = new TransformListContext(this.context, this.state);
        this.enterRule(localContext, 298, SparkSQLParser.RULE_transformList);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2430;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 2431;
            this.transform();
            this.state = 2433;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if ((((_la) & ~0x1F) === 0 && ((1 << _la) & 4294897648) !== 0) || ((((_la - 33)) & ~0x1F) === 0 && ((1 << (_la - 33)) & 4294803199) !== 0) || ((((_la - 65)) & ~0x1F) === 0 && ((1 << (_la - 65)) & 4289716215) !== 0) || ((((_la - 97)) & ~0x1F) === 0 && ((1 << (_la - 97)) & 2147483643) !== 0) || ((((_la - 129)) & ~0x1F) === 0 && ((1 << (_la - 129)) & 2147418111) !== 0) || ((((_la - 161)) & ~0x1F) === 0 && ((1 << (_la - 161)) & 4292345853) !== 0) || ((((_la - 193)) & ~0x1F) === 0 && ((1 << (_la - 193)) & 71401719) !== 0) || ((((_la - 254)) & ~0x1F) === 0 && ((1 << (_la - 254)) & 65557) !== 0) || ((((_la - 287)) & ~0x1F) === 0 && ((1 << (_la - 287)) & 46153731) !== 0) || ((((_la - 332)) & ~0x1F) === 0 && ((1 << (_la - 332)) & 1639553) !== 0) || ((((_la - 392)) & ~0x1F) === 0 && ((1 << (_la - 392)) & 805341189) !== 0) || ((((_la - 425)) & ~0x1F) === 0 && ((1 << (_la - 425)) & 16777225) !== 0) || ((((_la - 478)) & ~0x1F) === 0 && ((1 << (_la - 478)) & 491649) !== 0)) {
                {
                this.state = 2432;
                this.dataTypeExpression();
                }
            }

            this.state = 2442;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 475) {
                {
                {
                this.state = 2435;
                this.match(SparkSQLParser.COMMA);
                this.state = 2436;
                this.transform();
                this.state = 2438;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if ((((_la) & ~0x1F) === 0 && ((1 << _la) & 4294897648) !== 0) || ((((_la - 33)) & ~0x1F) === 0 && ((1 << (_la - 33)) & 4294803199) !== 0) || ((((_la - 65)) & ~0x1F) === 0 && ((1 << (_la - 65)) & 4289716215) !== 0) || ((((_la - 97)) & ~0x1F) === 0 && ((1 << (_la - 97)) & 2147483643) !== 0) || ((((_la - 129)) & ~0x1F) === 0 && ((1 << (_la - 129)) & 2147418111) !== 0) || ((((_la - 161)) & ~0x1F) === 0 && ((1 << (_la - 161)) & 4292345853) !== 0) || ((((_la - 193)) & ~0x1F) === 0 && ((1 << (_la - 193)) & 71401719) !== 0) || ((((_la - 254)) & ~0x1F) === 0 && ((1 << (_la - 254)) & 65557) !== 0) || ((((_la - 287)) & ~0x1F) === 0 && ((1 << (_la - 287)) & 46153731) !== 0) || ((((_la - 332)) & ~0x1F) === 0 && ((1 << (_la - 332)) & 1639553) !== 0) || ((((_la - 392)) & ~0x1F) === 0 && ((1 << (_la - 392)) & 805341189) !== 0) || ((((_la - 425)) & ~0x1F) === 0 && ((1 << (_la - 425)) & 16777225) !== 0) || ((((_la - 478)) & ~0x1F) === 0 && ((1 << (_la - 478)) & 491649) !== 0)) {
                    {
                    this.state = 2437;
                    this.dataTypeExpression();
                    }
                }

                }
                }
                this.state = 2444;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 2445;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public transform(): TransformContext {
        let localContext = new TransformContext(this.context, this.state);
        this.enterRule(localContext, 300, SparkSQLParser.RULE_transform);
        let _la: number;
        try {
            this.state = 2460;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 285, this.context) ) {
            case 1:
                localContext = new IdentityTransformContext(localContext);
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 2447;
                this.qualifiedName();
                }
                break;
            case 2:
                localContext = new ApplyTransformContext(localContext);
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 2448;
                (localContext as ApplyTransformContext)._transformName = this.identifier();
                this.state = 2449;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 2450;
                this.transformArgument();
                this.state = 2455;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                while (_la === 475) {
                    {
                    {
                    this.state = 2451;
                    this.match(SparkSQLParser.COMMA);
                    this.state = 2452;
                    this.transformArgument();
                    }
                    }
                    this.state = 2457;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                }
                this.state = 2458;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public transformArgument(): TransformArgumentContext {
        let localContext = new TransformArgumentContext(this.context, this.state);
        this.enterRule(localContext, 302, SparkSQLParser.RULE_transformArgument);
        try {
            this.state = 2464;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 286, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 2462;
                this.qualifiedName();
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 2463;
                this.constant();
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public likeDefinition(): LikeDefinitionContext {
        let localContext = new LikeDefinitionContext(this.context, this.state);
        this.enterRule(localContext, 304, SparkSQLParser.RULE_likeDefinition);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2466;
            this.match(SparkSQLParser.KW_LIKE);
            this.state = 2467;
            this.tablePath();
            this.state = 2476;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 288, this.context) ) {
            case 1:
                {
                this.state = 2468;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 2472;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                while (_la === 46 || _la === 107 || _la === 304) {
                    {
                    {
                    this.state = 2469;
                    this.likeOption();
                    }
                    }
                    this.state = 2474;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                }
                this.state = 2475;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public distribution(): DistributionContext {
        let localContext = new DistributionContext(this.context, this.state);
        this.enterRule(localContext, 306, SparkSQLParser.RULE_distribution);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2478;
            this.match(SparkSQLParser.KW_DISTRIBUTED);
            this.state = 2487;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 222) {
                {
                this.state = 2479;
                this.match(SparkSQLParser.KW_BY);
                this.state = 2481;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 458) {
                    {
                    this.state = 2480;
                    this.match(SparkSQLParser.KW_HASH);
                    }
                }

                this.state = 2483;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 2484;
                this.identifier();
                this.state = 2485;
                this.match(SparkSQLParser.RR_BRACKET);
                }
            }

            this.state = 2490;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 291, this.context) ) {
            case 1:
                {
                this.state = 2489;
                this.intoBuckets();
                }
                break;
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public using(): UsingContext {
        let localContext = new UsingContext(this.context, this.state);
        this.enterRule(localContext, 308, SparkSQLParser.RULE_using);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2492;
            this.match(SparkSQLParser.KW_USING);
            this.state = 2493;
            this.match(SparkSQLParser.ID_LITERAL);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public likeOption(): LikeOptionContext {
        let localContext = new LikeOptionContext(this.context, this.state);
        this.enterRule(localContext, 310, SparkSQLParser.RULE_likeOption);
        let _la: number;
        try {
            this.state = 2499;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 292, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                {
                this.state = 2495;
                _la = this.tokenStream.LA(1);
                if(!(_la === 46 || _la === 304)) {
                this.errorHandler.recoverInline(this);
                }
                else {
                    this.errorHandler.reportMatch(this);
                    this.consume();
                }
                this.state = 2496;
                _la = this.tokenStream.LA(1);
                if(!(_la === 24 || _la === 109 || _la === 202)) {
                this.errorHandler.recoverInline(this);
                }
                else {
                    this.errorHandler.reportMatch(this);
                    this.consume();
                }
                }
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                {
                this.state = 2497;
                _la = this.tokenStream.LA(1);
                if(!(_la === 46 || _la === 107 || _la === 304)) {
                this.errorHandler.recoverInline(this);
                }
                else {
                    this.errorHandler.reportMatch(this);
                    this.consume();
                }
                this.state = 2498;
                _la = this.tokenStream.LA(1);
                if(!(_la === 60 || _la === 103 || _la === 194)) {
                this.errorHandler.recoverInline(this);
                }
                else {
                    this.errorHandler.reportMatch(this);
                    this.consume();
                }
                }
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public columnOptionDefinition(): ColumnOptionDefinitionContext {
        let localContext = new ColumnOptionDefinitionContext(this.context, this.state);
        this.enterRule(localContext, 312, SparkSQLParser.RULE_columnOptionDefinition);
        try {
            this.state = 2504;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 293, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 2501;
                this.physicalColumnDefinition();
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 2502;
                this.metadataColumnDefinition();
                }
                break;
            case 3:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 2503;
                this.computedColumnDefinition();
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public physicalColumnDefinitionList(): PhysicalColumnDefinitionListContext {
        let localContext = new PhysicalColumnDefinitionListContext(this.context, this.state);
        this.enterRule(localContext, 314, SparkSQLParser.RULE_physicalColumnDefinitionList);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2506;
            this.match(SparkSQLParser.LR_BRACKET);
            {
            this.state = 2507;
            this.physicalColumnDefinition();
            }
            this.state = 2512;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 475) {
                {
                {
                this.state = 2508;
                this.match(SparkSQLParser.COMMA);
                this.state = 2509;
                this.physicalColumnDefinition();
                }
                }
                this.state = 2514;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 2515;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public physicalColumnDefinition(): PhysicalColumnDefinitionContext {
        let localContext = new PhysicalColumnDefinitionContext(this.context, this.state);
        this.enterRule(localContext, 316, SparkSQLParser.RULE_physicalColumnDefinition);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2517;
            this.columnName();
            this.state = 2518;
            this.columnType();
            this.state = 2520;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 242 || ((((_la - 348)) & ~0x1F) === 0 && ((1 << (_la - 348)) & 1073741833) !== 0)) {
                {
                this.state = 2519;
                this.columnConstraint();
                }
            }

            this.state = 2523;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 296, this.context) ) {
            case 1:
                {
                this.state = 2522;
                this.commentSpec();
                }
                break;
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public computedColumnExpression(): ComputedColumnExpressionContext {
        let localContext = new ComputedColumnExpressionContext(this.context, this.state);
        this.enterRule(localContext, 318, SparkSQLParser.RULE_computedColumnExpression);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2525;
            this.expression();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public watermarkDefinition(): WatermarkDefinitionContext {
        let localContext = new WatermarkDefinitionContext(this.context, this.state);
        this.enterRule(localContext, 320, SparkSQLParser.RULE_watermarkDefinition);
        try {
            this.state = 2542;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 298, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 2527;
                this.match(SparkSQLParser.KW_WATERMARK);
                this.state = 2528;
                this.match(SparkSQLParser.KW_FOR);
                this.state = 2529;
                this.expression();
                this.state = 2530;
                this.match(SparkSQLParser.KW_AS);
                this.state = 2531;
                this.expression();
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 2533;
                this.match(SparkSQLParser.KW_WATERMARK);
                this.state = 2534;
                this.match(SparkSQLParser.KW_FOR);
                this.state = 2537;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 297, this.context) ) {
                case 1:
                    {
                    this.state = 2535;
                    this.uid();
                    }
                    break;
                case 2:
                    {
                    this.state = 2536;
                    this.expression();
                    }
                    break;
                }
                this.state = 2539;
                this.match(SparkSQLParser.KW_AS);
                this.state = 2540;
                this.uid();
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public tableConstraint(): TableConstraintContext {
        let localContext = new TableConstraintContext(this.context, this.state);
        this.enterRule(localContext, 322, SparkSQLParser.RULE_tableConstraint);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2546;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 242) {
                {
                this.state = 2544;
                this.match(SparkSQLParser.KW_CONSTRAINT);
                this.state = 2545;
                this.constraintName();
                }
            }

            this.state = 2548;
            this.match(SparkSQLParser.KW_PRIMARY);
            this.state = 2549;
            this.match(SparkSQLParser.KW_KEY);
            this.state = 2550;
            this.columnNameList();
            this.state = 2551;
            this.match(SparkSQLParser.KW_NOT);
            this.state = 2552;
            this.match(SparkSQLParser.KW_ENFORCED);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public constraintName(): ConstraintNameContext {
        let localContext = new ConstraintNameContext(this.context, this.state);
        this.enterRule(localContext, 324, SparkSQLParser.RULE_constraintName);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2554;
            this.identifier();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public valuesDefinition(): ValuesDefinitionContext {
        let localContext = new ValuesDefinitionContext(this.context, this.state);
        this.enterRule(localContext, 326, SparkSQLParser.RULE_valuesDefinition);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2556;
            this.match(SparkSQLParser.KW_VALUES);
            this.state = 2557;
            this.valuesRowDefinition();
            this.state = 2562;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 475) {
                {
                {
                this.state = 2558;
                this.match(SparkSQLParser.COMMA);
                this.state = 2559;
                this.valuesRowDefinition();
                }
                }
                this.state = 2564;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public valuesRowDefinition(): ValuesRowDefinitionContext {
        let localContext = new ValuesRowDefinitionContext(this.context, this.state);
        this.enterRule(localContext, 328, SparkSQLParser.RULE_valuesRowDefinition);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2565;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 2566;
            this.constant();
            this.state = 2571;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 475) {
                {
                {
                this.state = 2567;
                this.match(SparkSQLParser.COMMA);
                this.state = 2568;
                this.constant();
                }
                }
                this.state = 2573;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 2574;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public lengthOneDimension(): LengthOneDimensionContext {
        let localContext = new LengthOneDimensionContext(this.context, this.state);
        this.enterRule(localContext, 330, SparkSQLParser.RULE_lengthOneDimension);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2576;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 2577;
            this.decimalLiteral();
            this.state = 2578;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public lengthTwoOptionalDimension(): LengthTwoOptionalDimensionContext {
        let localContext = new LengthTwoOptionalDimensionContext(this.context, this.state);
        this.enterRule(localContext, 332, SparkSQLParser.RULE_lengthTwoOptionalDimension);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2580;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 2581;
            this.decimalLiteral();
            this.state = 2584;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 475) {
                {
                this.state = 2582;
                this.match(SparkSQLParser.COMMA);
                this.state = 2583;
                this.decimalLiteral();
                }
            }

            this.state = 2586;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public lengthTwoStringDimension(): LengthTwoStringDimensionContext {
        let localContext = new LengthTwoStringDimensionContext(this.context, this.state);
        this.enterRule(localContext, 334, SparkSQLParser.RULE_lengthTwoStringDimension);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2588;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 2589;
            this.stringLiteral();
            this.state = 2592;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 475) {
                {
                this.state = 2590;
                this.match(SparkSQLParser.COMMA);
                this.state = 2591;
                this.stringLiteral();
                }
            }

            this.state = 2594;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public lengthOneTypeDimension(): LengthOneTypeDimensionContext {
        let localContext = new LengthOneTypeDimensionContext(this.context, this.state);
        this.enterRule(localContext, 336, SparkSQLParser.RULE_lengthOneTypeDimension);
        let _la: number;
        try {
            localContext = new LengthSymbolsTypeDimensionContext(localContext);
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2596;
            this.match(SparkSQLParser.LESS_SYMBOL);
            this.state = 2597;
            this.columnType();
            this.state = 2602;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 475) {
                {
                {
                this.state = 2598;
                this.match(SparkSQLParser.COMMA);
                this.state = 2599;
                this.columnType();
                }
                }
                this.state = 2604;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 2605;
            this.match(SparkSQLParser.GREATER_SYMBOL);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public mapTypeDimension(): MapTypeDimensionContext {
        let localContext = new MapTypeDimensionContext(this.context, this.state);
        this.enterRule(localContext, 338, SparkSQLParser.RULE_mapTypeDimension);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2607;
            this.match(SparkSQLParser.LESS_SYMBOL);
            this.state = 2608;
            this.columnType();
            {
            this.state = 2609;
            this.match(SparkSQLParser.COMMA);
            this.state = 2610;
            this.columnType();
            }
            this.state = 2612;
            this.match(SparkSQLParser.GREATER_SYMBOL);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public rowTypeDimension(): RowTypeDimensionContext {
        let localContext = new RowTypeDimensionContext(this.context, this.state);
        this.enterRule(localContext, 340, SparkSQLParser.RULE_rowTypeDimension);
        let _la: number;
        try {
            localContext = new RowSymbolsTypeDimensionContext(localContext);
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2614;
            this.match(SparkSQLParser.LESS_SYMBOL);
            this.state = 2615;
            this.columnName();
            this.state = 2616;
            this.columnType();
            this.state = 2623;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 475) {
                {
                {
                this.state = 2617;
                this.match(SparkSQLParser.COMMA);
                this.state = 2618;
                this.columnName();
                this.state = 2619;
                this.columnType();
                }
                }
                this.state = 2625;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 2626;
            this.match(SparkSQLParser.GREATER_SYMBOL);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public structTypeDimension(): StructTypeDimensionContext {
        let localContext = new StructTypeDimensionContext(this.context, this.state);
        this.enterRule(localContext, 342, SparkSQLParser.RULE_structTypeDimension);
        let _la: number;
        try {
            localContext = new StructSymbolsTypeDimensionContext(localContext);
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2628;
            this.match(SparkSQLParser.LESS_SYMBOL);
            this.state = 2629;
            this.columnName();
            this.state = 2630;
            this.match(SparkSQLParser.COLON_SYMB);
            this.state = 2631;
            this.columnType();
            this.state = 2639;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 475) {
                {
                {
                this.state = 2632;
                this.match(SparkSQLParser.COMMA);
                this.state = 2633;
                this.columnName();
                this.state = 2634;
                this.match(SparkSQLParser.COLON_SYMB);
                this.state = 2635;
                this.columnType();
                }
                }
                this.state = 2641;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 2642;
            this.match(SparkSQLParser.GREATER_SYMBOL);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public columnConstraint(): ColumnConstraintContext {
        let localContext = new ColumnConstraintContext(this.context, this.state);
        this.enterRule(localContext, 344, SparkSQLParser.RULE_columnConstraint);
        let _la: number;
        try {
            this.state = 2658;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.KW_CONSTRAINT:
            case SparkSQLParser.KW_PRIMARY:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 2646;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 242) {
                    {
                    this.state = 2644;
                    this.match(SparkSQLParser.KW_CONSTRAINT);
                    this.state = 2645;
                    this.constraintName();
                    }
                }

                this.state = 2648;
                this.match(SparkSQLParser.KW_PRIMARY);
                this.state = 2649;
                this.match(SparkSQLParser.KW_KEY);
                this.state = 2652;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 348) {
                    {
                    this.state = 2650;
                    this.match(SparkSQLParser.KW_NOT);
                    this.state = 2651;
                    this.match(SparkSQLParser.KW_ENFORCED);
                    }
                }

                }
                break;
            case SparkSQLParser.KW_NOT:
            case SparkSQLParser.KW_NULL:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 2655;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 348) {
                    {
                    this.state = 2654;
                    this.match(SparkSQLParser.KW_NOT);
                    }
                }

                this.state = 2657;
                this.match(SparkSQLParser.KW_NULL);
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public commentSpec(): CommentSpecContext {
        let localContext = new CommentSpecContext(this.context, this.state);
        this.enterRule(localContext, 346, SparkSQLParser.RULE_commentSpec);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2660;
            this.match(SparkSQLParser.KW_COMMENT);
            this.state = 2661;
            this.propertyName();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public metadataColumnDefinition(): MetadataColumnDefinitionContext {
        let localContext = new MetadataColumnDefinitionContext(this.context, this.state);
        this.enterRule(localContext, 348, SparkSQLParser.RULE_metadataColumnDefinition);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2663;
            this.columnName();
            this.state = 2664;
            this.columnType();
            this.state = 2665;
            this.match(SparkSQLParser.KW_METADATA);
            this.state = 2668;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 291) {
                {
                this.state = 2666;
                this.match(SparkSQLParser.KW_FROM);
                this.state = 2667;
                this.metadataKey();
                }
            }

            this.state = 2671;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 192) {
                {
                this.state = 2670;
                this.match(SparkSQLParser.KW_VIRTUAL);
                }
            }

            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public metadataKey(): MetadataKeyContext {
        let localContext = new MetadataKeyContext(this.context, this.state);
        this.enterRule(localContext, 350, SparkSQLParser.RULE_metadataKey);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2673;
            this.match(SparkSQLParser.STRING_LITERAL);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public computedColumnDefinition(): ComputedColumnDefinitionContext {
        let localContext = new ComputedColumnDefinitionContext(this.context, this.state);
        this.enterRule(localContext, 352, SparkSQLParser.RULE_computedColumnDefinition);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2675;
            this.columnName();
            this.state = 2676;
            this.match(SparkSQLParser.KW_AS);
            this.state = 2677;
            this.computedColumnExpression();
            this.state = 2679;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 313, this.context) ) {
            case 1:
                {
                this.state = 2678;
                this.commentSpec();
                }
                break;
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public columnName(): ColumnNameContext {
        let localContext = new ColumnNameContext(this.context, this.state);
        this.enterRule(localContext, 354, SparkSQLParser.RULE_columnName);
        try {
            this.state = 2683;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 314, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 2681;
                this.uid();
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 2682;
                this.expression();
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public columnNameList(): ColumnNameListContext {
        let localContext = new ColumnNameListContext(this.context, this.state);
        this.enterRule(localContext, 356, SparkSQLParser.RULE_columnNameList);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2685;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 2686;
            this.columnName();
            this.state = 2688;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 21) {
                {
                this.state = 2687;
                this.commentSpec();
                }
            }

            this.state = 2697;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 475) {
                {
                {
                this.state = 2690;
                this.match(SparkSQLParser.COMMA);
                this.state = 2691;
                this.columnName();
                this.state = 2693;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 21) {
                    {
                    this.state = 2692;
                    this.commentSpec();
                    }
                }

                }
                }
                this.state = 2699;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 2700;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public columnType(): ColumnTypeContext {
        let localContext = new ColumnTypeContext(this.context, this.state);
        this.enterRule(localContext, 358, SparkSQLParser.RULE_columnType);
        let _la: number;
        try {
            this.state = 2777;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.KW_BOOLEAN:
            case SparkSQLParser.KW_DATE:
            case SparkSQLParser.KW_NULL:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 2702;
                localContext._typeName = this.tokenStream.LT(1);
                _la = this.tokenStream.LA(1);
                if(!(_la === 219 || _la === 254 || _la === 351)) {
                    localContext._typeName = this.errorHandler.recoverInline(this);
                }
                else {
                    this.errorHandler.reportMatch(this);
                    this.consume();
                }
                }
                break;
            case SparkSQLParser.KW_BYTES:
            case SparkSQLParser.KW_STRING:
            case SparkSQLParser.KW_TIMESTAMP_LTZ:
            case SparkSQLParser.KW_BIGINT:
            case SparkSQLParser.KW_BINARY:
            case SparkSQLParser.KW_CHAR:
            case SparkSQLParser.KW_DATETIME:
            case SparkSQLParser.KW_INT:
            case SparkSQLParser.KW_INTEGER:
            case SparkSQLParser.KW_SMALLINT:
            case SparkSQLParser.KW_TIME:
            case SparkSQLParser.KW_TINYINT:
            case SparkSQLParser.KW_VARBINARY:
            case SparkSQLParser.KW_VARCHAR:
                this.enterOuterAlt(localContext, 2);
                {
                {
                this.state = 2703;
                localContext._typeName = this.tokenStream.LT(1);
                _la = this.tokenStream.LA(1);
                if(!(_la === 11 || _la === 165 || _la === 172 || ((((_la - 215)) & ~0x1F) === 0 && ((1 << (_la - 215)) & 16387) !== 0) || _la === 255 || _la === 309 || _la === 310 || ((((_la - 403)) & ~0x1F) === 0 && ((1 << (_la - 403)) & 4325377) !== 0) || _la === 441 || _la === 442)) {
                    localContext._typeName = this.errorHandler.recoverInline(this);
                }
                else {
                    this.errorHandler.reportMatch(this);
                    this.consume();
                }
                this.state = 2705;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 471) {
                    {
                    this.state = 2704;
                    this.lengthOneDimension();
                    }
                }

                }
                }
                break;
            case SparkSQLParser.KW_TIMESTAMP:
                this.enterOuterAlt(localContext, 3);
                {
                {
                this.state = 2707;
                localContext._typeName = this.match(SparkSQLParser.KW_TIMESTAMP);
                this.state = 2709;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 471) {
                    {
                    this.state = 2708;
                    this.lengthOneDimension();
                    }
                }

                this.state = 2717;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 446 || _la === 448) {
                    {
                    this.state = 2711;
                    _la = this.tokenStream.LA(1);
                    if(!(_la === 446 || _la === 448)) {
                    this.errorHandler.recoverInline(this);
                    }
                    else {
                        this.errorHandler.reportMatch(this);
                        this.consume();
                    }
                    this.state = 2713;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                    if (_la === 331) {
                        {
                        this.state = 2712;
                        this.match(SparkSQLParser.KW_LOCAL);
                        }
                    }

                    this.state = 2715;
                    this.match(SparkSQLParser.KW_TIME);
                    this.state = 2716;
                    this.match(SparkSQLParser.KW_ZONE);
                    }
                }

                }
                }
                break;
            case SparkSQLParser.KW_TIMESTAMP_3:
                this.enterOuterAlt(localContext, 4);
                {
                {
                this.state = 2719;
                localContext._typeName = this.match(SparkSQLParser.KW_TIMESTAMP_3);
                this.state = 2721;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 471) {
                    {
                    this.state = 2720;
                    this.lengthOneDimension();
                    }
                }

                this.state = 2729;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 446 || _la === 448) {
                    {
                    this.state = 2723;
                    _la = this.tokenStream.LA(1);
                    if(!(_la === 446 || _la === 448)) {
                    this.errorHandler.recoverInline(this);
                    }
                    else {
                        this.errorHandler.reportMatch(this);
                        this.consume();
                    }
                    this.state = 2725;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                    if (_la === 331) {
                        {
                        this.state = 2724;
                        this.match(SparkSQLParser.KW_LOCAL);
                        }
                    }

                    this.state = 2727;
                    this.match(SparkSQLParser.KW_TIME);
                    this.state = 2728;
                    this.match(SparkSQLParser.KW_ZONE);
                    }
                }

                }
                }
                break;
            case SparkSQLParser.KW_TIMESTAMP_6:
                this.enterOuterAlt(localContext, 5);
                {
                {
                this.state = 2731;
                localContext._typeName = this.match(SparkSQLParser.KW_TIMESTAMP_6);
                this.state = 2733;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 471) {
                    {
                    this.state = 2732;
                    this.lengthOneDimension();
                    }
                }

                this.state = 2741;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 446 || _la === 448) {
                    {
                    this.state = 2735;
                    _la = this.tokenStream.LA(1);
                    if(!(_la === 446 || _la === 448)) {
                    this.errorHandler.recoverInline(this);
                    }
                    else {
                        this.errorHandler.reportMatch(this);
                        this.consume();
                    }
                    this.state = 2737;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                    if (_la === 331) {
                        {
                        this.state = 2736;
                        this.match(SparkSQLParser.KW_LOCAL);
                        }
                    }

                    this.state = 2739;
                    this.match(SparkSQLParser.KW_TIME);
                    this.state = 2740;
                    this.match(SparkSQLParser.KW_ZONE);
                    }
                }

                }
                }
                break;
            case SparkSQLParser.KW_TIMESTAMP_9:
                this.enterOuterAlt(localContext, 6);
                {
                {
                this.state = 2743;
                localContext._typeName = this.match(SparkSQLParser.KW_TIMESTAMP_9);
                this.state = 2745;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 471) {
                    {
                    this.state = 2744;
                    this.lengthOneDimension();
                    }
                }

                this.state = 2753;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 446 || _la === 448) {
                    {
                    this.state = 2747;
                    _la = this.tokenStream.LA(1);
                    if(!(_la === 446 || _la === 448)) {
                    this.errorHandler.recoverInline(this);
                    }
                    else {
                        this.errorHandler.reportMatch(this);
                        this.consume();
                    }
                    this.state = 2749;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                    if (_la === 331) {
                        {
                        this.state = 2748;
                        this.match(SparkSQLParser.KW_LOCAL);
                        }
                    }

                    this.state = 2751;
                    this.match(SparkSQLParser.KW_TIME);
                    this.state = 2752;
                    this.match(SparkSQLParser.KW_ZONE);
                    }
                }

                }
                }
                break;
            case SparkSQLParser.KW_DEC:
            case SparkSQLParser.KW_DECIMAL:
            case SparkSQLParser.KW_DOUBLE:
            case SparkSQLParser.KW_FLOAT:
            case SparkSQLParser.KW_NUMERIC:
                this.enterOuterAlt(localContext, 7);
                {
                {
                this.state = 2755;
                localContext._typeName = this.tokenStream.LT(1);
                _la = this.tokenStream.LA(1);
                if(!(((((_la - 257)) & ~0x1F) === 0 && ((1 << (_la - 257)) & 2147491843) !== 0) || _la === 352)) {
                    localContext._typeName = this.errorHandler.recoverInline(this);
                }
                else {
                    this.errorHandler.reportMatch(this);
                    this.consume();
                }
                this.state = 2757;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 471) {
                    {
                    this.state = 2756;
                    this.lengthTwoOptionalDimension();
                    }
                }

                }
                }
                break;
            case SparkSQLParser.KW_ARRAY:
            case SparkSQLParser.KW_MULTISET:
                this.enterOuterAlt(localContext, 8);
                {
                {
                this.state = 2759;
                localContext._type_ = this.tokenStream.LT(1);
                _la = this.tokenStream.LA(1);
                if(!(_la === 208 || _la === 343)) {
                    localContext._type_ = this.errorHandler.recoverInline(this);
                }
                else {
                    this.errorHandler.reportMatch(this);
                    this.consume();
                }
                this.state = 2761;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 466) {
                    {
                    this.state = 2760;
                    this.lengthOneTypeDimension();
                    }
                }

                }
                }
                break;
            case SparkSQLParser.KW_MAP:
                this.enterOuterAlt(localContext, 9);
                {
                {
                this.state = 2763;
                localContext._type_ = this.match(SparkSQLParser.KW_MAP);
                this.state = 2765;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 466) {
                    {
                    this.state = 2764;
                    this.mapTypeDimension();
                    }
                }

                }
                }
                break;
            case SparkSQLParser.KW_ROW:
                this.enterOuterAlt(localContext, 10);
                {
                {
                this.state = 2767;
                localContext._type_ = this.match(SparkSQLParser.KW_ROW);
                this.state = 2769;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 466) {
                    {
                    this.state = 2768;
                    this.rowTypeDimension();
                    }
                }

                }
                }
                break;
            case SparkSQLParser.KW_STRUCT:
                this.enterOuterAlt(localContext, 11);
                {
                {
                this.state = 2771;
                localContext._type_ = this.match(SparkSQLParser.KW_STRUCT);
                this.state = 2772;
                this.structTypeDimension();
                }
                }
                break;
            case SparkSQLParser.KW_RAW:
                this.enterOuterAlt(localContext, 12);
                {
                {
                this.state = 2773;
                localContext._type_ = this.match(SparkSQLParser.KW_RAW);
                this.state = 2775;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 471) {
                    {
                    this.state = 2774;
                    this.lengthTwoStringDimension();
                    }
                }

                }
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public expression(): ExpressionContext {
        let localContext = new ExpressionContext(this.context, this.state);
        this.enterRule(localContext, 360, SparkSQLParser.RULE_expression);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2779;
            this.booleanExpression(0);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }

    public booleanExpression(): BooleanExpressionContext;
    public booleanExpression(_p: number): BooleanExpressionContext;
    public booleanExpression(_p?: number): BooleanExpressionContext {
        if (_p === undefined) {
            _p = 0;
        }

        let parentContext = this.context;
        let parentState = this.state;
        let localContext = new BooleanExpressionContext(this.context, parentState);
        let previousContext = localContext;
        let _startState = 362;
        this.enterRecursionRule(localContext, 362, SparkSQLParser.RULE_booleanExpression, _p);
        let _la: number;
        try {
            let alternative: number;
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2793;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 338, this.context) ) {
            case 1:
                {
                localContext = new LogicalNotContext(localContext);
                this.context = localContext;
                previousContext = localContext;

                this.state = 2782;
                this.match(SparkSQLParser.KW_NOT);
                this.state = 2783;
                this.booleanExpression(6);
                }
                break;
            case 2:
                {
                localContext = new ExistsContext(localContext);
                this.context = localContext;
                previousContext = localContext;
                this.state = 2784;
                this.match(SparkSQLParser.KW_EXISTS);
                this.state = 2785;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 2786;
                this.queryStatement(0);
                this.state = 2787;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case 3:
                {
                localContext = new PredicatedContext(localContext);
                this.context = localContext;
                previousContext = localContext;
                this.state = 2789;
                this.valueExpression(0);
                this.state = 2791;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 337, this.context) ) {
                case 1:
                    {
                    this.state = 2790;
                    this.predicate();
                    }
                    break;
                }
                }
                break;
            }
            this.context!.stop = this.tokenStream.LT(-1);
            this.state = 2809;
            this.errorHandler.sync(this);
            alternative = this.interpreter.adaptivePredict(this.tokenStream, 341, this.context);
            while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {
                if (alternative === 1) {
                    if (this.parseListeners != null) {
                        this.triggerExitRuleEvent();
                    }
                    previousContext = localContext;
                    {
                    this.state = 2807;
                    this.errorHandler.sync(this);
                    switch (this.interpreter.adaptivePredict(this.tokenStream, 340, this.context) ) {
                    case 1:
                        {
                        localContext = new LogicalBinaryContext(new BooleanExpressionContext(parentContext, parentState));
                        (localContext as LogicalBinaryContext)._left = previousContext;
                        this.pushNewRecursionContext(localContext, _startState, SparkSQLParser.RULE_booleanExpression);
                        this.state = 2795;
                        if (!(this.precpred(this.context, 3))) {
                            throw this.createFailedPredicateException("this.precpred(this.context, 3)");
                        }
                        this.state = 2796;
                        (localContext as LogicalBinaryContext)._operator = this.match(SparkSQLParser.KW_AND);
                        this.state = 2797;
                        (localContext as LogicalBinaryContext)._right = this.booleanExpression(4);
                        }
                        break;
                    case 2:
                        {
                        localContext = new LogicalBinaryContext(new BooleanExpressionContext(parentContext, parentState));
                        (localContext as LogicalBinaryContext)._left = previousContext;
                        this.pushNewRecursionContext(localContext, _startState, SparkSQLParser.RULE_booleanExpression);
                        this.state = 2798;
                        if (!(this.precpred(this.context, 2))) {
                            throw this.createFailedPredicateException("this.precpred(this.context, 2)");
                        }
                        this.state = 2799;
                        (localContext as LogicalBinaryContext)._operator = this.match(SparkSQLParser.KW_OR);
                        this.state = 2800;
                        (localContext as LogicalBinaryContext)._right = this.booleanExpression(3);
                        }
                        break;
                    case 3:
                        {
                        localContext = new LogicalNestedContext(new BooleanExpressionContext(parentContext, parentState));
                        this.pushNewRecursionContext(localContext, _startState, SparkSQLParser.RULE_booleanExpression);
                        this.state = 2801;
                        if (!(this.precpred(this.context, 1))) {
                            throw this.createFailedPredicateException("this.precpred(this.context, 1)");
                        }
                        this.state = 2802;
                        this.match(SparkSQLParser.KW_IS);
                        this.state = 2804;
                        this.errorHandler.sync(this);
                        _la = this.tokenStream.LA(1);
                        if (_la === 348) {
                            {
                            this.state = 2803;
                            this.match(SparkSQLParser.KW_NOT);
                            }
                        }

                        this.state = 2806;
                        (localContext as LogicalNestedContext)._kind = this.tokenStream.LT(1);
                        _la = this.tokenStream.LA(1);
                        if(!(_la === 287 || _la === 351 || _la === 428 || _la === 432)) {
                            (localContext as LogicalNestedContext)._kind = this.errorHandler.recoverInline(this);
                        }
                        else {
                            this.errorHandler.reportMatch(this);
                            this.consume();
                        }
                        }
                        break;
                    }
                    }
                }
                this.state = 2811;
                this.errorHandler.sync(this);
                alternative = this.interpreter.adaptivePredict(this.tokenStream, 341, this.context);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.unrollRecursionContexts(parentContext);
        }
        return localContext;
    }
    public predicate(): PredicateContext {
        let localContext = new PredicateContext(this.context, this.state);
        this.enterRule(localContext, 364, SparkSQLParser.RULE_predicate);
        let _la: number;
        try {
            this.state = 2879;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 352, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 2813;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 348) {
                    {
                    this.state = 2812;
                    this.match(SparkSQLParser.KW_NOT);
                    }
                }

                this.state = 2815;
                localContext._kind = this.match(SparkSQLParser.KW_BETWEEN);
                this.state = 2817;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 210 || _la === 411) {
                    {
                    this.state = 2816;
                    _la = this.tokenStream.LA(1);
                    if(!(_la === 210 || _la === 411)) {
                    this.errorHandler.recoverInline(this);
                    }
                    else {
                        this.errorHandler.reportMatch(this);
                        this.consume();
                    }
                    }
                }

                this.state = 2819;
                localContext._lower = this.valueExpression(0);
                this.state = 2820;
                this.match(SparkSQLParser.KW_AND);
                this.state = 2821;
                localContext._upper = this.valueExpression(0);
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 2824;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 348) {
                    {
                    this.state = 2823;
                    this.match(SparkSQLParser.KW_NOT);
                    }
                }

                this.state = 2826;
                localContext._kind = this.match(SparkSQLParser.KW_IN);
                this.state = 2827;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 2828;
                this.expression();
                this.state = 2833;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                while (_la === 475) {
                    {
                    {
                    this.state = 2829;
                    this.match(SparkSQLParser.COMMA);
                    this.state = 2830;
                    this.expression();
                    }
                    }
                    this.state = 2835;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                }
                this.state = 2836;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case 3:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 2839;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 348) {
                    {
                    this.state = 2838;
                    this.match(SparkSQLParser.KW_NOT);
                    }
                }

                this.state = 2841;
                localContext._kind = this.match(SparkSQLParser.KW_IN);
                this.state = 2842;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 2843;
                this.queryStatement(0);
                this.state = 2844;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case 4:
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 2846;
                localContext._kind = this.match(SparkSQLParser.KW_EXISTS);
                this.state = 2847;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 2848;
                this.queryStatement(0);
                this.state = 2849;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case 5:
                this.enterOuterAlt(localContext, 5);
                {
                this.state = 2852;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 348) {
                    {
                    this.state = 2851;
                    this.match(SparkSQLParser.KW_NOT);
                    }
                }

                this.state = 2854;
                localContext._kind = this.match(SparkSQLParser.KW_RLIKE);
                this.state = 2855;
                localContext._pattern = this.valueExpression(0);
                }
                break;
            case 6:
                this.enterOuterAlt(localContext, 6);
                {
                this.state = 2856;
                this.likePredicate();
                }
                break;
            case 7:
                this.enterOuterAlt(localContext, 7);
                {
                this.state = 2857;
                this.match(SparkSQLParser.KW_IS);
                this.state = 2859;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 348) {
                    {
                    this.state = 2858;
                    this.match(SparkSQLParser.KW_NOT);
                    }
                }

                this.state = 2861;
                localContext._kind = this.tokenStream.LT(1);
                _la = this.tokenStream.LA(1);
                if(!(_la === 287 || _la === 351 || _la === 428 || _la === 432)) {
                    localContext._kind = this.errorHandler.recoverInline(this);
                }
                else {
                    this.errorHandler.reportMatch(this);
                    this.consume();
                }
                }
                break;
            case 8:
                this.enterOuterAlt(localContext, 8);
                {
                this.state = 2862;
                this.match(SparkSQLParser.KW_IS);
                this.state = 2864;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 348) {
                    {
                    this.state = 2863;
                    this.match(SparkSQLParser.KW_NOT);
                    }
                }

                this.state = 2866;
                localContext._kind = this.match(SparkSQLParser.KW_DISTINCT);
                this.state = 2867;
                this.match(SparkSQLParser.KW_FROM);
                this.state = 2868;
                localContext._right = this.valueExpression(0);
                }
                break;
            case 9:
                this.enterOuterAlt(localContext, 9);
                {
                this.state = 2870;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 348) {
                    {
                    this.state = 2869;
                    this.match(SparkSQLParser.KW_NOT);
                    }
                }

                this.state = 2872;
                localContext._kind = this.match(SparkSQLParser.KW_SIMILAR);
                this.state = 2873;
                this.match(SparkSQLParser.KW_TO);
                this.state = 2874;
                localContext._right = this.valueExpression(0);
                this.state = 2877;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 351, this.context) ) {
                case 1:
                    {
                    this.state = 2875;
                    this.match(SparkSQLParser.KW_ESCAPE);
                    this.state = 2876;
                    this.stringLiteral();
                    }
                    break;
                }
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public likePredicate(): LikePredicateContext {
        let localContext = new LikePredicateContext(this.context, this.state);
        this.enterRule(localContext, 366, SparkSQLParser.RULE_likePredicate);
        let _la: number;
        try {
            this.state = 2919;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 360, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 2882;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 348) {
                    {
                    this.state = 2881;
                    this.match(SparkSQLParser.KW_NOT);
                    }
                }

                this.state = 2884;
                localContext._kind = this.match(SparkSQLParser.KW_LIKE);
                this.state = 2885;
                localContext._quantifier = this.tokenStream.LT(1);
                _la = this.tokenStream.LA(1);
                if(!(_la === 202 || _la === 206)) {
                    localContext._quantifier = this.errorHandler.recoverInline(this);
                }
                else {
                    this.errorHandler.reportMatch(this);
                    this.consume();
                }
                this.state = 2899;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 355, this.context) ) {
                case 1:
                    {
                    this.state = 2886;
                    this.match(SparkSQLParser.LR_BRACKET);
                    this.state = 2887;
                    this.match(SparkSQLParser.RR_BRACKET);
                    }
                    break;
                case 2:
                    {
                    this.state = 2888;
                    this.match(SparkSQLParser.LR_BRACKET);
                    this.state = 2889;
                    this.expression();
                    this.state = 2894;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                    while (_la === 475) {
                        {
                        {
                        this.state = 2890;
                        this.match(SparkSQLParser.COMMA);
                        this.state = 2891;
                        this.expression();
                        }
                        }
                        this.state = 2896;
                        this.errorHandler.sync(this);
                        _la = this.tokenStream.LA(1);
                    }
                    this.state = 2897;
                    this.match(SparkSQLParser.RR_BRACKET);
                    }
                    break;
                }
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 2902;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 348) {
                    {
                    this.state = 2901;
                    this.match(SparkSQLParser.KW_NOT);
                    }
                }

                this.state = 2904;
                localContext._kind = this.tokenStream.LT(1);
                _la = this.tokenStream.LA(1);
                if(!(_la === 328 || _la === 389)) {
                    localContext._kind = this.errorHandler.recoverInline(this);
                }
                else {
                    this.errorHandler.reportMatch(this);
                    this.consume();
                }
                this.state = 2905;
                localContext._pattern = this.valueExpression(0);
                this.state = 2908;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 357, this.context) ) {
                case 1:
                    {
                    this.state = 2906;
                    this.match(SparkSQLParser.KW_ESCAPE);
                    this.state = 2907;
                    this.stringLiteral();
                    }
                    break;
                }
                }
                break;
            case 3:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 2911;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 348) {
                    {
                    this.state = 2910;
                    this.match(SparkSQLParser.KW_NOT);
                    }
                }

                this.state = 2913;
                _la = this.tokenStream.LA(1);
                if(!(_la === 384 || _la === 389)) {
                this.errorHandler.recoverInline(this);
                }
                else {
                    this.errorHandler.reportMatch(this);
                    this.consume();
                }
                this.state = 2914;
                this.stringLiteral();
                this.state = 2917;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 359, this.context) ) {
                case 1:
                    {
                    this.state = 2915;
                    this.match(SparkSQLParser.KW_ESCAPE);
                    this.state = 2916;
                    this.stringLiteral();
                    }
                    break;
                }
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }

    public valueExpression(): ValueExpressionContext;
    public valueExpression(_p: number): ValueExpressionContext;
    public valueExpression(_p?: number): ValueExpressionContext {
        if (_p === undefined) {
            _p = 0;
        }

        let parentContext = this.context;
        let parentState = this.state;
        let localContext = new ValueExpressionContext(this.context, parentState);
        let previousContext = localContext;
        let _startState = 368;
        this.enterRecursionRule(localContext, 368, SparkSQLParser.RULE_valueExpression, _p);
        let _la: number;
        try {
            let alternative: number;
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 2925;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 361, this.context) ) {
            case 1:
                {
                localContext = new ValueExpressionDefaultContext(localContext);
                this.context = localContext;
                previousContext = localContext;

                this.state = 2922;
                this.primaryExpression(0);
                }
                break;
            case 2:
                {
                localContext = new ArithmeticUnaryContext(localContext);
                this.context = localContext;
                previousContext = localContext;
                this.state = 2923;
                (localContext as ArithmeticUnaryContext)._operator = this.tokenStream.LT(1);
                _la = this.tokenStream.LA(1);
                if(!(((((_la - 460)) & ~0x1F) === 0 && ((1 << (_la - 460)) & 100663297) !== 0))) {
                    (localContext as ArithmeticUnaryContext)._operator = this.errorHandler.recoverInline(this);
                }
                else {
                    this.errorHandler.reportMatch(this);
                    this.consume();
                }
                this.state = 2924;
                this.valueExpression(7);
                }
                break;
            }
            this.context!.stop = this.tokenStream.LT(-1);
            this.state = 2948;
            this.errorHandler.sync(this);
            alternative = this.interpreter.adaptivePredict(this.tokenStream, 363, this.context);
            while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {
                if (alternative === 1) {
                    if (this.parseListeners != null) {
                        this.triggerExitRuleEvent();
                    }
                    previousContext = localContext;
                    {
                    this.state = 2946;
                    this.errorHandler.sync(this);
                    switch (this.interpreter.adaptivePredict(this.tokenStream, 362, this.context) ) {
                    case 1:
                        {
                        localContext = new ArithmeticBinaryContext(new ValueExpressionContext(parentContext, parentState));
                        (localContext as ArithmeticBinaryContext)._left = previousContext;
                        this.pushNewRecursionContext(localContext, _startState, SparkSQLParser.RULE_valueExpression);
                        this.state = 2927;
                        if (!(this.precpred(this.context, 6))) {
                            throw this.createFailedPredicateException("this.precpred(this.context, 6)");
                        }
                        this.state = 2928;
                        (localContext as ArithmeticBinaryContext)._operator = this.tokenStream.LT(1);
                        _la = this.tokenStream.LA(1);
                        if(!(_la === 37 || ((((_la - 483)) & ~0x1F) === 0 && ((1 << (_la - 483)) & 145) !== 0))) {
                            (localContext as ArithmeticBinaryContext)._operator = this.errorHandler.recoverInline(this);
                        }
                        else {
                            this.errorHandler.reportMatch(this);
                            this.consume();
                        }
                        this.state = 2929;
                        (localContext as ArithmeticBinaryContext)._right = this.valueExpression(7);
                        }
                        break;
                    case 2:
                        {
                        localContext = new ArithmeticBinaryContext(new ValueExpressionContext(parentContext, parentState));
                        (localContext as ArithmeticBinaryContext)._left = previousContext;
                        this.pushNewRecursionContext(localContext, _startState, SparkSQLParser.RULE_valueExpression);
                        this.state = 2930;
                        if (!(this.precpred(this.context, 5))) {
                            throw this.createFailedPredicateException("this.precpred(this.context, 5)");
                        }
                        this.state = 2931;
                        (localContext as ArithmeticBinaryContext)._operator = this.tokenStream.LT(1);
                        _la = this.tokenStream.LA(1);
                        if(!(((((_la - 485)) & ~0x1F) === 0 && ((1 << (_la - 485)) & 11) !== 0))) {
                            (localContext as ArithmeticBinaryContext)._operator = this.errorHandler.recoverInline(this);
                        }
                        else {
                            this.errorHandler.reportMatch(this);
                            this.consume();
                        }
                        this.state = 2932;
                        (localContext as ArithmeticBinaryContext)._right = this.valueExpression(6);
                        }
                        break;
                    case 3:
                        {
                        localContext = new ArithmeticBinaryContext(new ValueExpressionContext(parentContext, parentState));
                        (localContext as ArithmeticBinaryContext)._left = previousContext;
                        this.pushNewRecursionContext(localContext, _startState, SparkSQLParser.RULE_valueExpression);
                        this.state = 2933;
                        if (!(this.precpred(this.context, 4))) {
                            throw this.createFailedPredicateException("this.precpred(this.context, 4)");
                        }
                        this.state = 2934;
                        (localContext as ArithmeticBinaryContext)._operator = this.match(SparkSQLParser.BIT_AND_OP);
                        this.state = 2935;
                        (localContext as ArithmeticBinaryContext)._right = this.valueExpression(5);
                        }
                        break;
                    case 4:
                        {
                        localContext = new ArithmeticBinaryContext(new ValueExpressionContext(parentContext, parentState));
                        (localContext as ArithmeticBinaryContext)._left = previousContext;
                        this.pushNewRecursionContext(localContext, _startState, SparkSQLParser.RULE_valueExpression);
                        this.state = 2936;
                        if (!(this.precpred(this.context, 3))) {
                            throw this.createFailedPredicateException("this.precpred(this.context, 3)");
                        }
                        this.state = 2937;
                        (localContext as ArithmeticBinaryContext)._operator = this.match(SparkSQLParser.BIT_XOR_OP);
                        this.state = 2938;
                        (localContext as ArithmeticBinaryContext)._right = this.valueExpression(4);
                        }
                        break;
                    case 5:
                        {
                        localContext = new OrContext(new ValueExpressionContext(parentContext, parentState));
                        (localContext as OrContext)._left = previousContext;
                        this.pushNewRecursionContext(localContext, _startState, SparkSQLParser.RULE_valueExpression);
                        this.state = 2939;
                        if (!(this.precpred(this.context, 2))) {
                            throw this.createFailedPredicateException("this.precpred(this.context, 2)");
                        }
                        this.state = 2940;
                        (localContext as OrContext)._operator = this.match(SparkSQLParser.BIT_OR_OP);
                        this.state = 2941;
                        (localContext as OrContext)._right = this.valueExpression(3);
                        }
                        break;
                    case 6:
                        {
                        localContext = new ComparisonContext(new ValueExpressionContext(parentContext, parentState));
                        (localContext as ComparisonContext)._left = previousContext;
                        this.pushNewRecursionContext(localContext, _startState, SparkSQLParser.RULE_valueExpression);
                        this.state = 2942;
                        if (!(this.precpred(this.context, 1))) {
                            throw this.createFailedPredicateException("this.precpred(this.context, 1)");
                        }
                        this.state = 2943;
                        (localContext as ComparisonContext)._operator = this.comparisonOperator();
                        this.state = 2944;
                        (localContext as ComparisonContext)._right = this.valueExpression(2);
                        }
                        break;
                    }
                    }
                }
                this.state = 2950;
                this.errorHandler.sync(this);
                alternative = this.interpreter.adaptivePredict(this.tokenStream, 363, this.context);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.unrollRecursionContexts(parentContext);
        }
        return localContext;
    }

    public primaryExpression(): PrimaryExpressionContext;
    public primaryExpression(_p: number): PrimaryExpressionContext;
    public primaryExpression(_p?: number): PrimaryExpressionContext {
        if (_p === undefined) {
            _p = 0;
        }

        let parentContext = this.context;
        let parentState = this.state;
        let localContext = new PrimaryExpressionContext(this.context, parentState);
        let previousContext = localContext;
        let _startState = 370;
        this.enterRecursionRule(localContext, 370, SparkSQLParser.RULE_primaryExpression, _p);
        let _la: number;
        try {
            let alternative: number;
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 3071;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 376, this.context) ) {
            case 1:
                {
                localContext = new SearchedCaseContext(localContext);
                this.context = localContext;
                previousContext = localContext;

                this.state = 2952;
                this.match(SparkSQLParser.KW_CASE);
                this.state = 2954;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                do {
                    {
                    {
                    this.state = 2953;
                    this.whenClause();
                    }
                    }
                    this.state = 2956;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                } while (_la === 443);
                this.state = 2960;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 273) {
                    {
                    this.state = 2958;
                    this.match(SparkSQLParser.KW_ELSE);
                    this.state = 2959;
                    (localContext as SearchedCaseContext)._elseExpression = this.expression();
                    }
                }

                this.state = 2962;
                this.match(SparkSQLParser.KW_END);
                }
                break;
            case 2:
                {
                localContext = new SimpleCaseContext(localContext);
                this.context = localContext;
                previousContext = localContext;
                this.state = 2964;
                this.match(SparkSQLParser.KW_CASE);
                this.state = 2965;
                (localContext as SimpleCaseContext)._value = this.expression();
                this.state = 2967;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                do {
                    {
                    {
                    this.state = 2966;
                    this.whenClause();
                    }
                    }
                    this.state = 2969;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                } while (_la === 443);
                this.state = 2973;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 273) {
                    {
                    this.state = 2971;
                    this.match(SparkSQLParser.KW_ELSE);
                    this.state = 2972;
                    (localContext as SimpleCaseContext)._elseExpression = this.expression();
                    }
                }

                this.state = 2975;
                this.match(SparkSQLParser.KW_END);
                }
                break;
            case 3:
                {
                localContext = new CastContext(localContext);
                this.context = localContext;
                previousContext = localContext;
                this.state = 2977;
                this.match(SparkSQLParser.KW_CAST);
                this.state = 2978;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 2979;
                this.expression();
                this.state = 2980;
                this.match(SparkSQLParser.KW_AS);
                this.state = 2981;
                this.columnType();
                this.state = 2982;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case 4:
                {
                localContext = new FirstContext(localContext);
                this.context = localContext;
                previousContext = localContext;
                this.state = 2984;
                this.match(SparkSQLParser.KW_FIRST);
                this.state = 2985;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 2986;
                this.expression();
                this.state = 2989;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 67) {
                    {
                    this.state = 2987;
                    this.match(SparkSQLParser.KW_IGNORE);
                    this.state = 2988;
                    this.match(SparkSQLParser.KW_NULLS);
                    }
                }

                this.state = 2991;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case 5:
                {
                localContext = new LastContext(localContext);
                this.context = localContext;
                previousContext = localContext;
                this.state = 2993;
                this.match(SparkSQLParser.KW_LAST);
                this.state = 2994;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 2995;
                this.expression();
                this.state = 2998;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 67) {
                    {
                    this.state = 2996;
                    this.match(SparkSQLParser.KW_IGNORE);
                    this.state = 2997;
                    this.match(SparkSQLParser.KW_NULLS);
                    }
                }

                this.state = 3000;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case 6:
                {
                localContext = new PositionContext(localContext);
                this.context = localContext;
                previousContext = localContext;
                this.state = 3002;
                this.match(SparkSQLParser.KW_POSITION);
                this.state = 3003;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 3004;
                (localContext as PositionContext)._substr = this.valueExpression(0);
                this.state = 3005;
                this.match(SparkSQLParser.KW_IN);
                this.state = 3006;
                (localContext as PositionContext)._str = this.valueExpression(0);
                this.state = 3007;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case 7:
                {
                localContext = new ConstantDefaultContext(localContext);
                this.context = localContext;
                previousContext = localContext;
                this.state = 3009;
                this.constant();
                }
                break;
            case 8:
                {
                localContext = new StarContext(localContext);
                this.context = localContext;
                previousContext = localContext;
                this.state = 3010;
                this.match(SparkSQLParser.ASTERISK_SIGN);
                }
                break;
            case 9:
                {
                localContext = new StarContext(localContext);
                this.context = localContext;
                previousContext = localContext;
                this.state = 3011;
                this.uid();
                this.state = 3012;
                this.match(SparkSQLParser.DOT);
                this.state = 3013;
                this.match(SparkSQLParser.ASTERISK_SIGN);
                }
                break;
            case 10:
                {
                localContext = new SubqueryExpressionContext(localContext);
                this.context = localContext;
                previousContext = localContext;
                this.state = 3015;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 3016;
                this.queryStatement(0);
                this.state = 3017;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case 11:
                {
                localContext = new ValuesContext(localContext);
                this.context = localContext;
                previousContext = localContext;
                this.state = 3019;
                this.match(SparkSQLParser.LR_BRACKET);
                {
                this.state = 3020;
                this.functionParam();
                this.state = 3025;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                while (_la === 475) {
                    {
                    {
                    this.state = 3021;
                    this.match(SparkSQLParser.COMMA);
                    this.state = 3022;
                    this.functionParam();
                    }
                    }
                    this.state = 3027;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                }
                }
                this.state = 3028;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case 12:
                {
                localContext = new FunctionCallContext(localContext);
                this.context = localContext;
                previousContext = localContext;
                this.state = 3030;
                this.functionName();
                this.state = 3031;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 3043;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if ((((_la) & ~0x1F) === 0 && ((1 << _la) & 4294896624) !== 0) || ((((_la - 33)) & ~0x1F) === 0 && ((1 << (_la - 33)) & 4294836223) !== 0) || ((((_la - 65)) & ~0x1F) === 0 && ((1 << (_la - 65)) & 4281327607) !== 0) || ((((_la - 97)) & ~0x1F) === 0 && ((1 << (_la - 97)) & 2147483643) !== 0) || ((((_la - 129)) & ~0x1F) === 0 && ((1 << (_la - 129)) & 2113863675) !== 0) || ((((_la - 161)) & ~0x1F) === 0 && ((1 << (_la - 161)) & 4292341757) !== 0) || ((((_la - 193)) & ~0x1F) === 0 && ((1 << (_la - 193)) & 134775807) !== 0) || ((((_la - 226)) & ~0x1F) === 0 && ((1 << (_la - 226)) & 1342706695) !== 0) || ((((_la - 266)) & ~0x1F) === 0 && ((1 << (_la - 266)) & 70336513) !== 0) || ((((_la - 298)) & ~0x1F) === 0 && ((1 << (_la - 298)) & 1015037961) !== 0) || ((((_la - 332)) & ~0x1F) === 0 && ((1 << (_la - 332)) & 2148205697) !== 0) || ((((_la - 369)) & ~0x1F) === 0 && ((1 << (_la - 369)) & 42494055) !== 0) || ((((_la - 407)) & ~0x1F) === 0 && ((1 << (_la - 407)) & 276029453) !== 0) || ((((_la - 449)) & ~0x1F) === 0 && ((1 << (_la - 449)) & 541067265) !== 0) || ((((_la - 483)) & ~0x1F) === 0 && ((1 << (_la - 483)) & 15373) !== 0)) {
                    {
                    this.state = 3033;
                    this.errorHandler.sync(this);
                    switch (this.interpreter.adaptivePredict(this.tokenStream, 371, this.context) ) {
                    case 1:
                        {
                        this.state = 3032;
                        this.setQuantifier();
                        }
                        break;
                    }
                    this.state = 3035;
                    this.functionParam();
                    this.state = 3040;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                    while (_la === 475) {
                        {
                        {
                        this.state = 3036;
                        this.match(SparkSQLParser.COMMA);
                        this.state = 3037;
                        this.functionParam();
                        }
                        }
                        this.state = 3042;
                        this.errorHandler.sync(this);
                        _la = this.tokenStream.LA(1);
                    }
                    }
                }

                this.state = 3045;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case 13:
                {
                localContext = new FunctionCallContext(localContext);
                this.context = localContext;
                previousContext = localContext;
                this.state = 3047;
                this.functionName();
                this.state = 3048;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 3049;
                this.functionParam();
                this.state = 3050;
                this.match(SparkSQLParser.KW_TO);
                this.state = 3051;
                this.functionParam();
                this.state = 3052;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case 14:
                {
                localContext = new FunctionCallFilterContext(localContext);
                this.context = localContext;
                previousContext = localContext;
                this.state = 3054;
                this.functionName();
                this.state = 3055;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 3057;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 374, this.context) ) {
                case 1:
                    {
                    this.state = 3056;
                    this.setQuantifier();
                    }
                    break;
                }
                this.state = 3059;
                this.functionParam();
                this.state = 3060;
                this.match(SparkSQLParser.RR_BRACKET);
                this.state = 3062;
                this.errorHandler.sync(this);
                switch (this.interpreter.adaptivePredict(this.tokenStream, 375, this.context) ) {
                case 1:
                    {
                    this.state = 3061;
                    this.filterClause();
                    }
                    break;
                }
                }
                break;
            case 15:
                {
                localContext = new ColumnReferenceContext(localContext);
                this.context = localContext;
                previousContext = localContext;
                this.state = 3064;
                this.identifier();
                }
                break;
            case 16:
                {
                localContext = new DereferenceContext(localContext);
                this.context = localContext;
                previousContext = localContext;
                this.state = 3065;
                this.dereferenceDefinition();
                }
                break;
            case 17:
                {
                localContext = new ParenthesizedExpressionContext(localContext);
                this.context = localContext;
                previousContext = localContext;
                this.state = 3066;
                this.match(SparkSQLParser.LR_BRACKET);
                this.state = 3067;
                this.expression();
                this.state = 3068;
                this.match(SparkSQLParser.RR_BRACKET);
                }
                break;
            case 18:
                {
                localContext = new ComplexDataTypeFieldExpressionContext(localContext);
                this.context = localContext;
                previousContext = localContext;
                this.state = 3070;
                this.complexDataTypeExpression();
                }
                break;
            }
            this.context!.stop = this.tokenStream.LT(-1);
            this.state = 3080;
            this.errorHandler.sync(this);
            alternative = this.interpreter.adaptivePredict(this.tokenStream, 377, this.context);
            while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {
                if (alternative === 1) {
                    if (this.parseListeners != null) {
                        this.triggerExitRuleEvent();
                    }
                    previousContext = localContext;
                    {
                    {
                    localContext = new SubscriptContext(new PrimaryExpressionContext(parentContext, parentState));
                    (localContext as SubscriptContext)._value = previousContext;
                    this.pushNewRecursionContext(localContext, _startState, SparkSQLParser.RULE_primaryExpression);
                    this.state = 3073;
                    if (!(this.precpred(this.context, 5))) {
                        throw this.createFailedPredicateException("this.precpred(this.context, 5)");
                    }
                    this.state = 3074;
                    this.match(SparkSQLParser.LS_BRACKET);
                    this.state = 3075;
                    (localContext as SubscriptContext)._index = this.valueExpression(0);
                    this.state = 3076;
                    this.match(SparkSQLParser.RS_BRACKET);
                    }
                    }
                }
                this.state = 3082;
                this.errorHandler.sync(this);
                alternative = this.interpreter.adaptivePredict(this.tokenStream, 377, this.context);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.unrollRecursionContexts(parentContext);
        }
        return localContext;
    }
    public complexDataTypeExpression(): ComplexDataTypeExpressionContext {
        let localContext = new ComplexDataTypeExpressionContext(this.context, this.state);
        this.enterRule(localContext, 372, SparkSQLParser.RULE_complexDataTypeExpression);
        try {
            this.state = 3087;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.KW_ARRAY:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 3083;
                this.arrayExpression();
                }
                break;
            case SparkSQLParser.KW_ROW:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 3084;
                this.rowExpression();
                }
                break;
            case SparkSQLParser.KW_MAP:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 3085;
                this.mapExpression();
                }
                break;
            case SparkSQLParser.KW_STRUCT:
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 3086;
                this.structExpression();
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public arrayExpression(): ArrayExpressionContext {
        let localContext = new ArrayExpressionContext(this.context, this.state);
        this.enterRule(localContext, 374, SparkSQLParser.RULE_arrayExpression);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 3089;
            this.match(SparkSQLParser.KW_ARRAY);
            this.state = 3090;
            this.match(SparkSQLParser.LS_BRACKET);
            this.state = 3091;
            this.dataTypeExpression();
            this.state = 3096;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 475) {
                {
                {
                this.state = 3092;
                this.match(SparkSQLParser.COMMA);
                this.state = 3093;
                this.dataTypeExpression();
                }
                }
                this.state = 3098;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 3099;
            this.match(SparkSQLParser.RS_BRACKET);
            this.state = 3100;
            this.match(SparkSQLParser.KW_ARRAY);
            this.state = 3101;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 3102;
            this.dataTypeExpression();
            this.state = 3107;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 475) {
                {
                {
                this.state = 3103;
                this.match(SparkSQLParser.COMMA);
                this.state = 3104;
                this.dataTypeExpression();
                }
                }
                this.state = 3109;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 3110;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public structExpression(): StructExpressionContext {
        let localContext = new StructExpressionContext(this.context, this.state);
        this.enterRule(localContext, 376, SparkSQLParser.RULE_structExpression);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 3112;
            this.match(SparkSQLParser.KW_STRUCT);
            this.state = 3113;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 3114;
            this.dataTypeExpression();
            this.state = 3119;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 475) {
                {
                {
                this.state = 3115;
                this.match(SparkSQLParser.COMMA);
                this.state = 3116;
                this.dataTypeExpression();
                }
                }
                this.state = 3121;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 3122;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public rowExpression(): RowExpressionContext {
        let localContext = new RowExpressionContext(this.context, this.state);
        this.enterRule(localContext, 378, SparkSQLParser.RULE_rowExpression);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 3124;
            this.match(SparkSQLParser.KW_ROW);
            this.state = 3125;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 3126;
            this.dataTypeExpression();
            this.state = 3131;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 475) {
                {
                {
                this.state = 3127;
                this.match(SparkSQLParser.COMMA);
                this.state = 3128;
                this.dataTypeExpression();
                }
                }
                this.state = 3133;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 3134;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public mapExpression(): MapExpressionContext {
        let localContext = new MapExpressionContext(this.context, this.state);
        this.enterRule(localContext, 380, SparkSQLParser.RULE_mapExpression);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 3136;
            this.match(SparkSQLParser.KW_MAP);
            this.state = 3137;
            this.match(SparkSQLParser.LS_BRACKET);
            this.state = 3138;
            this.dataTypeExpression();
            this.state = 3139;
            this.match(SparkSQLParser.COMMA);
            this.state = 3140;
            this.dataTypeExpression();
            this.state = 3141;
            this.match(SparkSQLParser.RS_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public dataTypeExpression(): DataTypeExpressionContext {
        let localContext = new DataTypeExpressionContext(this.context, this.state);
        this.enterRule(localContext, 382, SparkSQLParser.RULE_dataTypeExpression);
        try {
            this.state = 3147;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 383, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 3143;
                this.columnAlias();
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 3144;
                this.constant();
                }
                break;
            case 3:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 3145;
                this.complexDataTypeExpression();
                }
                break;
            case 4:
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 3146;
                this.sqlSimpleType();
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public sqlSimpleType(): SqlSimpleTypeContext {
        let localContext = new SqlSimpleTypeContext(this.context, this.state);
        this.enterRule(localContext, 384, SparkSQLParser.RULE_sqlSimpleType);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 3149;
            _la = this.tokenStream.LA(1);
            if(!(_la === 10 || _la === 88 || _la === 131 || _la === 154 || _la === 172 || _la === 173 || _la === 215 || _la === 219 || ((((_la - 254)) & ~0x1F) === 0 && ((1 << (_la - 254)) & 65553) !== 0) || ((((_la - 288)) & ~0x1F) === 0 && ((1 << (_la - 288)) & 6291457) !== 0) || _la === 352 || ((((_la - 403)) & ~0x1F) === 0 && ((1 << (_la - 403)) & 4587521) !== 0))) {
            this.errorHandler.recoverInline(this);
            }
            else {
                this.errorHandler.reportMatch(this);
                this.consume();
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public functionName(): FunctionNameContext {
        let localContext = new FunctionNameContext(this.context, this.state);
        this.enterRule(localContext, 386, SparkSQLParser.RULE_functionName);
        try {
            this.state = 3154;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 384, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 3151;
                this.nonReservedKeywords();
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 3152;
                this.uid();
                }
                break;
            case 3:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 3153;
                this.reservedKeywordsUsedAsFuncName();
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public functionParam(): FunctionParamContext {
        let localContext = new FunctionParamContext(this.context, this.state);
        this.enterRule(localContext, 388, SparkSQLParser.RULE_functionParam);
        try {
            this.state = 3162;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 385, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 3156;
                this.reservedKeywordsUsedAsFuncParam();
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 3157;
                this.timeIntervalUnit();
                }
                break;
            case 3:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 3158;
                this.timePointUnit();
                }
                break;
            case 4:
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 3159;
                this.expression();
                }
                break;
            case 5:
                this.enterOuterAlt(localContext, 5);
                {
                this.state = 3160;
                this.filterClause();
                }
                break;
            case 6:
                this.enterOuterAlt(localContext, 6);
                {
                this.state = 3161;
                this.constant();
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public filterClause(): FilterClauseContext {
        let localContext = new FilterClauseContext(this.context, this.state);
        this.enterRule(localContext, 390, SparkSQLParser.RULE_filterClause);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 3164;
            this.match(SparkSQLParser.KW_FILTER);
            this.state = 3165;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 3166;
            this.match(SparkSQLParser.KW_WHERE);
            this.state = 3167;
            this.booleanExpression(0);
            this.state = 3168;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public dereferenceDefinition(): DereferenceDefinitionContext {
        let localContext = new DereferenceDefinitionContext(this.context, this.state);
        this.enterRule(localContext, 392, SparkSQLParser.RULE_dereferenceDefinition);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 3170;
            this.uid();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public correlationName(): CorrelationNameContext {
        let localContext = new CorrelationNameContext(this.context, this.state);
        this.enterRule(localContext, 394, SparkSQLParser.RULE_correlationName);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 3172;
            this.identifier();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public qualifiedName(): QualifiedNameContext {
        let localContext = new QualifiedNameContext(this.context, this.state);
        this.enterRule(localContext, 396, SparkSQLParser.RULE_qualifiedName);
        try {
            this.state = 3177;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 386, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 3174;
                this.identifier();
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 3175;
                this.dereferenceDefinition();
                }
                break;
            case 3:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 3176;
                this.unquotedAnyString();
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public timeIntervalExpression(): TimeIntervalExpressionContext {
        let localContext = new TimeIntervalExpressionContext(this.context, this.state);
        this.enterRule(localContext, 398, SparkSQLParser.RULE_timeIntervalExpression);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 3179;
            this.match(SparkSQLParser.KW_INTERVAL);
            this.state = 3182;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 387, this.context) ) {
            case 1:
                {
                this.state = 3180;
                this.errorCapturingMultiUnitsInterval();
                }
                break;
            case 2:
                {
                this.state = 3181;
                this.errorCapturingUnitToUnitInterval();
                }
                break;
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public errorCapturingMultiUnitsInterval(): ErrorCapturingMultiUnitsIntervalContext {
        let localContext = new ErrorCapturingMultiUnitsIntervalContext(this.context, this.state);
        this.enterRule(localContext, 400, SparkSQLParser.RULE_errorCapturingMultiUnitsInterval);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 3184;
            this.multiUnitsInterval();
            this.state = 3186;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 388, this.context) ) {
            case 1:
                {
                this.state = 3185;
                this.unitToUnitInterval();
                }
                break;
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public multiUnitsInterval(): MultiUnitsIntervalContext {
        let localContext = new MultiUnitsIntervalContext(this.context, this.state);
        this.enterRule(localContext, 402, SparkSQLParser.RULE_multiUnitsInterval);
        try {
            let alternative: number;
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 3191;
            this.errorHandler.sync(this);
            alternative = 1;
            do {
                switch (alternative) {
                case 1:
                    {
                    {
                    this.state = 3188;
                    this.intervalValue();
                    this.state = 3189;
                    this.timeIntervalUnit();
                    }
                    }
                    break;
                default:
                    throw new antlr.NoViableAltException(this);
                }
                this.state = 3193;
                this.errorHandler.sync(this);
                alternative = this.interpreter.adaptivePredict(this.tokenStream, 389, this.context);
            } while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public errorCapturingUnitToUnitInterval(): ErrorCapturingUnitToUnitIntervalContext {
        let localContext = new ErrorCapturingUnitToUnitIntervalContext(this.context, this.state);
        this.enterRule(localContext, 404, SparkSQLParser.RULE_errorCapturingUnitToUnitInterval);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 3195;
            localContext._body = this.unitToUnitInterval();
            this.state = 3198;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 390, this.context) ) {
            case 1:
                {
                this.state = 3196;
                localContext._error1 = this.multiUnitsInterval();
                }
                break;
            case 2:
                {
                this.state = 3197;
                localContext._error2 = this.unitToUnitInterval();
                }
                break;
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public unitToUnitInterval(): UnitToUnitIntervalContext {
        let localContext = new UnitToUnitIntervalContext(this.context, this.state);
        this.enterRule(localContext, 406, SparkSQLParser.RULE_unitToUnitInterval);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 3200;
            localContext._value = this.intervalValue();
            this.state = 3201;
            localContext._from_ = this.timeIntervalUnit();
            this.state = 3202;
            this.match(SparkSQLParser.KW_TO);
            this.state = 3203;
            localContext._to = this.timeIntervalUnit();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public intervalValue(): IntervalValueContext {
        let localContext = new IntervalValueContext(this.context, this.state);
        this.enterRule(localContext, 408, SparkSQLParser.RULE_intervalValue);
        let _la: number;
        try {
            this.state = 3210;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.HYPNEN_SIGN:
            case SparkSQLParser.ADD_SIGN:
            case SparkSQLParser.DIG_LITERAL:
            case SparkSQLParser.REAL_LITERAL:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 3206;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 485 || _la === 486) {
                    {
                    this.state = 3205;
                    _la = this.tokenStream.LA(1);
                    if(!(_la === 485 || _la === 486)) {
                    this.errorHandler.recoverInline(this);
                    }
                    else {
                        this.errorHandler.reportMatch(this);
                        this.consume();
                    }
                    }
                }

                this.state = 3208;
                _la = this.tokenStream.LA(1);
                if(!(_la === 494 || _la === 495)) {
                this.errorHandler.recoverInline(this);
                }
                else {
                    this.errorHandler.reportMatch(this);
                    this.consume();
                }
                }
                break;
            case SparkSQLParser.STRING_LITERAL:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 3209;
                this.match(SparkSQLParser.STRING_LITERAL);
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public columnAlias(): ColumnAliasContext {
        let localContext = new ColumnAliasContext(this.context, this.state);
        this.enterRule(localContext, 410, SparkSQLParser.RULE_columnAlias);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 3213;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 209) {
                {
                this.state = 3212;
                this.match(SparkSQLParser.KW_AS);
                }
            }

            this.state = 3215;
            this.identifier();
            this.state = 3217;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 394, this.context) ) {
            case 1:
                {
                this.state = 3216;
                this.identifierList();
                }
                break;
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public tableAlias(): TableAliasContext {
        let localContext = new TableAliasContext(this.context, this.state);
        this.enterRule(localContext, 412, SparkSQLParser.RULE_tableAlias);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 3220;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 209) {
                {
                this.state = 3219;
                this.match(SparkSQLParser.KW_AS);
                }
            }

            this.state = 3222;
            this.identifier();
            this.state = 3224;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 396, this.context) ) {
            case 1:
                {
                this.state = 3223;
                this.identifierList();
                }
                break;
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public errorCapturingIdentifier(): ErrorCapturingIdentifierContext {
        let localContext = new ErrorCapturingIdentifierContext(this.context, this.state);
        this.enterRule(localContext, 414, SparkSQLParser.RULE_errorCapturingIdentifier);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 3226;
            this.identifier();
            this.state = 3227;
            this.errorCapturingIdentifierExtra();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public errorCapturingIdentifierExtra(): ErrorCapturingIdentifierExtraContext {
        let localContext = new ErrorCapturingIdentifierExtraContext(this.context, this.state);
        this.enterRule(localContext, 416, SparkSQLParser.RULE_errorCapturingIdentifierExtra);
        let _la: number;
        try {
            this.state = 3236;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.KW_MINUS:
                localContext = new ErrorIdentContext(localContext);
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 3231;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                do {
                    {
                    {
                    this.state = 3229;
                    this.match(SparkSQLParser.KW_MINUS);
                    this.state = 3230;
                    this.identifier();
                    }
                    }
                    this.state = 3233;
                    this.errorHandler.sync(this);
                    _la = this.tokenStream.LA(1);
                } while (_la === 338);
                }
                break;
            case SparkSQLParser.KW_AS:
            case SparkSQLParser.LR_BRACKET:
                localContext = new RealIdentContext(localContext);
                this.enterOuterAlt(localContext, 2);
                // tslint:disable-next-line:no-empty
                {
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public identifierList(): IdentifierListContext {
        let localContext = new IdentifierListContext(this.context, this.state);
        this.enterRule(localContext, 418, SparkSQLParser.RULE_identifierList);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 3238;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 3239;
            this.identifierSeq();
            this.state = 3240;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public identifierSeq(): IdentifierSeqContext {
        let localContext = new IdentifierSeqContext(this.context, this.state);
        this.enterRule(localContext, 420, SparkSQLParser.RULE_identifierSeq);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 3242;
            this.identifier();
            this.state = 3247;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 475) {
                {
                {
                this.state = 3243;
                this.match(SparkSQLParser.COMMA);
                this.state = 3244;
                this.identifier();
                }
                }
                this.state = 3249;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public identifier(): IdentifierContext {
        let localContext = new IdentifierContext(this.context, this.state);
        this.enterRule(localContext, 422, SparkSQLParser.RULE_identifier);
        try {
            this.state = 3254;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.DIG_LITERAL:
            case SparkSQLParser.ID_LITERAL:
                localContext = new UnquotedIdentifierAlternativeContext(localContext);
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 3250;
                this.unquotedIdentifier();
                }
                break;
            case SparkSQLParser.STRING_LITERAL:
                localContext = new QuotedIdentifierAlternativeContext(localContext);
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 3251;
                this.quotedIdentifier();
                }
                break;
            case SparkSQLParser.KW_ADD:
            case SparkSQLParser.KW_ADMIN:
            case SparkSQLParser.KW_AFTER:
            case SparkSQLParser.KW_ANALYZE:
            case SparkSQLParser.KW_ASC:
            case SparkSQLParser.KW_BEFORE:
            case SparkSQLParser.KW_BYTES:
            case SparkSQLParser.KW_CASCADE:
            case SparkSQLParser.KW_CATALOG:
            case SparkSQLParser.KW_CATALOGS:
            case SparkSQLParser.KW_CENTURY:
            case SparkSQLParser.KW_CHAIN:
            case SparkSQLParser.KW_CHANGELOG_MODE:
            case SparkSQLParser.KW_CHARACTERS:
            case SparkSQLParser.KW_COMMENT:
            case SparkSQLParser.KW_COMPACT:
            case SparkSQLParser.KW_COLUMNS:
            case SparkSQLParser.KW_CONSTRAINTS:
            case SparkSQLParser.KW_CONSTRUCTOR:
            case SparkSQLParser.KW_COMPUTE:
            case SparkSQLParser.KW_CUMULATE:
            case SparkSQLParser.KW_DATA:
            case SparkSQLParser.KW_DATABASE:
            case SparkSQLParser.KW_DATABASES:
            case SparkSQLParser.KW_DAYS:
            case SparkSQLParser.KW_DECADE:
            case SparkSQLParser.KW_DEFINED:
            case SparkSQLParser.KW_DESC:
            case SparkSQLParser.KW_DESCRIPTOR:
            case SparkSQLParser.KW_DIV:
            case SparkSQLParser.KW_ENCODING:
            case SparkSQLParser.KW_ENFORCED:
            case SparkSQLParser.KW_ENGINE:
            case SparkSQLParser.KW_ERROR:
            case SparkSQLParser.KW_ESTIMATED_COST:
            case SparkSQLParser.KW_EXCEPTION:
            case SparkSQLParser.KW_EXCLUDE:
            case SparkSQLParser.KW_EXCLUDING:
            case SparkSQLParser.KW_EXTENDED:
            case SparkSQLParser.KW_FILE:
            case SparkSQLParser.KW_FINAL:
            case SparkSQLParser.KW_FIRST:
            case SparkSQLParser.KW_FOLLOWING:
            case SparkSQLParser.KW_FORMAT:
            case SparkSQLParser.KW_FORTRAN:
            case SparkSQLParser.KW_FOUND:
            case SparkSQLParser.KW_FRAC_SECOND:
            case SparkSQLParser.KW_FUNCTIONS:
            case SparkSQLParser.KW_GENERAL:
            case SparkSQLParser.KW_GENERATED:
            case SparkSQLParser.KW_GO:
            case SparkSQLParser.KW_GOTO:
            case SparkSQLParser.KW_GRANTED:
            case SparkSQLParser.KW_HOP:
            case SparkSQLParser.KW_HOURS:
            case SparkSQLParser.KW_IF:
            case SparkSQLParser.KW_IGNORE:
            case SparkSQLParser.KW_INCREMENT:
            case SparkSQLParser.KW_INPUT:
            case SparkSQLParser.KW_INVOKER:
            case SparkSQLParser.KW_JAR:
            case SparkSQLParser.KW_JARS:
            case SparkSQLParser.KW_JAVA:
            case SparkSQLParser.KW_JSON:
            case SparkSQLParser.KW_JSON_EXECUTION_PLAN:
            case SparkSQLParser.KW_KEY:
            case SparkSQLParser.KW_KEY_MEMBER:
            case SparkSQLParser.KW_KEY_TYPE:
            case SparkSQLParser.KW_LABEL:
            case SparkSQLParser.KW_LAST:
            case SparkSQLParser.KW_LENGTH:
            case SparkSQLParser.KW_LEVEL:
            case SparkSQLParser.KW_LOAD:
            case SparkSQLParser.KW_MAP:
            case SparkSQLParser.KW_MICROSECOND:
            case SparkSQLParser.KW_MILLENNIUM:
            case SparkSQLParser.KW_MILLISECOND:
            case SparkSQLParser.KW_MINUTES:
            case SparkSQLParser.KW_MINVALUE:
            case SparkSQLParser.KW_MODIFY:
            case SparkSQLParser.KW_MODULES:
            case SparkSQLParser.KW_MONTHS:
            case SparkSQLParser.KW_NANOSECOND:
            case SparkSQLParser.KW_NULLS:
            case SparkSQLParser.KW_NUMBER:
            case SparkSQLParser.KW_OPTION:
            case SparkSQLParser.KW_OPTIONS:
            case SparkSQLParser.KW_ORDERING:
            case SparkSQLParser.KW_OUTPUT:
            case SparkSQLParser.KW_OVERWRITE:
            case SparkSQLParser.KW_OVERWRITING:
            case SparkSQLParser.KW_PARTITIONED:
            case SparkSQLParser.KW_PARTITIONS:
            case SparkSQLParser.KW_PASSING:
            case SparkSQLParser.KW_PAST:
            case SparkSQLParser.KW_PATH:
            case SparkSQLParser.KW_PLACING:
            case SparkSQLParser.KW_PLAN:
            case SparkSQLParser.KW_PRECEDING:
            case SparkSQLParser.KW_PRESERVE:
            case SparkSQLParser.KW_PRIOR:
            case SparkSQLParser.KW_PRIVILEGES:
            case SparkSQLParser.KW_PUBLIC:
            case SparkSQLParser.KW_PYTHON:
            case SparkSQLParser.KW_PYTHON_FILES:
            case SparkSQLParser.KW_PYTHON_REQUIREMENTS:
            case SparkSQLParser.KW_PYTHON_DEPENDENCIES:
            case SparkSQLParser.KW_PYTHON_JAR:
            case SparkSQLParser.KW_PYTHON_ARCHIVES:
            case SparkSQLParser.KW_PYTHON_PARAMETER:
            case SparkSQLParser.KW_QUARTER:
            case SparkSQLParser.KW_RAW:
            case SparkSQLParser.KW_READ:
            case SparkSQLParser.KW_RELATIVE:
            case SparkSQLParser.KW_REMOVE:
            case SparkSQLParser.KW_RENAME:
            case SparkSQLParser.KW_REPLACE:
            case SparkSQLParser.KW_RESPECT:
            case SparkSQLParser.KW_RESTART:
            case SparkSQLParser.KW_RESTRICT:
            case SparkSQLParser.KW_ROLE:
            case SparkSQLParser.KW_ROW_COUNT:
            case SparkSQLParser.KW_SCALA:
            case SparkSQLParser.KW_SCALAR:
            case SparkSQLParser.KW_SCALE:
            case SparkSQLParser.KW_SCHEMA:
            case SparkSQLParser.KW_SECONDS:
            case SparkSQLParser.KW_SECTION:
            case SparkSQLParser.KW_SECURITY:
            case SparkSQLParser.KW_SELF:
            case SparkSQLParser.KW_SERVER:
            case SparkSQLParser.KW_SERVER_NAME:
            case SparkSQLParser.KW_SESSION:
            case SparkSQLParser.KW_SETS:
            case SparkSQLParser.KW_SIMPLE:
            case SparkSQLParser.KW_SIZE:
            case SparkSQLParser.KW_SLIDE:
            case SparkSQLParser.KW_SOURCE:
            case SparkSQLParser.KW_SPACE:
            case SparkSQLParser.KW_STATE:
            case SparkSQLParser.KW_STATEMENT:
            case SparkSQLParser.KW_STEP:
            case SparkSQLParser.KW_STRING:
            case SparkSQLParser.KW_STRUCTURE:
            case SparkSQLParser.KW_STYLE:
            case SparkSQLParser.KW_TABLES:
            case SparkSQLParser.KW_TEMPORARY:
            case SparkSQLParser.KW_TIMECOL:
            case SparkSQLParser.KW_FLOOR:
            case SparkSQLParser.KW_TIMESTAMP_LTZ:
            case SparkSQLParser.KW_TIMESTAMPADD:
            case SparkSQLParser.KW_TIMESTAMPDIFF:
            case SparkSQLParser.KW_TOTIMESTAMP:
            case SparkSQLParser.KW_TRANSFORM:
            case SparkSQLParser.KW_TUMBLE:
            case SparkSQLParser.KW_TYPE:
            case SparkSQLParser.KW_UNDER:
            case SparkSQLParser.KW_UNLOAD:
            case SparkSQLParser.KW_USAGE:
            case SparkSQLParser.KW_USE:
            case SparkSQLParser.KW_UTF16:
            case SparkSQLParser.KW_UTF32:
            case SparkSQLParser.KW_UTF8:
            case SparkSQLParser.KW_VERSION:
            case SparkSQLParser.KW_VIEW:
            case SparkSQLParser.KW_VIEWS:
            case SparkSQLParser.KW_VIRTUAL:
            case SparkSQLParser.KW_WATERMARK:
            case SparkSQLParser.KW_WATERMARKS:
            case SparkSQLParser.KW_WEEK:
            case SparkSQLParser.KW_WORK:
            case SparkSQLParser.KW_WRAPPER:
            case SparkSQLParser.KW_YEARS:
            case SparkSQLParser.KW_ZONE:
            case SparkSQLParser.KW_LOCALTIMESTAMP:
                localContext = new NonReservedKeywordsAlternativeContext(localContext);
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 3252;
                this.nonReservedKeywords();
                }
                break;
            case SparkSQLParser.DOLLAR:
                localContext = new UrefVarAlternativeContext(localContext);
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 3253;
                this.refVar();
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public unquotedAnyString(): UnquotedAnyStringContext {
        let localContext = new UnquotedAnyStringContext(this.context, this.state);
        this.enterRule(localContext, 424, SparkSQLParser.RULE_unquotedAnyString);
        try {
            this.state = 3260;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 401, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 3256;
                this.unquotedIdentifier();
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 3257;
                this.reservedKeywordsUsedAsFuncParam();
                }
                break;
            case 3:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 3258;
                this.nonReservedKeywords();
                }
                break;
            case 4:
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 3259;
                this.reservedKeywordsUsedAsFuncName();
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public refVar(): RefVarContext {
        let localContext = new RefVarContext(this.context, this.state);
        this.enterRule(localContext, 426, SparkSQLParser.RULE_refVar);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 3262;
            this.match(SparkSQLParser.DOLLAR);
            this.state = 3263;
            this.match(SparkSQLParser.LB_BRACKET);
            this.state = 3264;
            this.unquotedIdentifier();
            this.state = 3265;
            this.match(SparkSQLParser.RB_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public unquotedIdentifier(): UnquotedIdentifierContext {
        let localContext = new UnquotedIdentifierContext(this.context, this.state);
        this.enterRule(localContext, 428, SparkSQLParser.RULE_unquotedIdentifier);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 3267;
            _la = this.tokenStream.LA(1);
            if(!(_la === 494 || _la === 496)) {
            this.errorHandler.recoverInline(this);
            }
            else {
                this.errorHandler.reportMatch(this);
                this.consume();
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public quotedIdentifier(): QuotedIdentifierContext {
        let localContext = new QuotedIdentifierContext(this.context, this.state);
        this.enterRule(localContext, 430, SparkSQLParser.RULE_quotedIdentifier);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 3269;
            this.match(SparkSQLParser.STRING_LITERAL);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public whenClause(): WhenClauseContext {
        let localContext = new WhenClauseContext(this.context, this.state);
        this.enterRule(localContext, 432, SparkSQLParser.RULE_whenClause);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 3271;
            this.match(SparkSQLParser.KW_WHEN);
            this.state = 3272;
            localContext._condition = this.expression();
            this.state = 3273;
            this.match(SparkSQLParser.KW_THEN);
            this.state = 3274;
            localContext._result = this.expression();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public catalogPath(): CatalogPathContext {
        let localContext = new CatalogPathContext(this.context, this.state);
        this.enterRule(localContext, 434, SparkSQLParser.RULE_catalogPath);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 3276;
            this.uid();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public databasePath(): DatabasePathContext {
        let localContext = new DatabasePathContext(this.context, this.state);
        this.enterRule(localContext, 436, SparkSQLParser.RULE_databasePath);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 3278;
            this.uid();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public databasePathCreate(): DatabasePathCreateContext {
        let localContext = new DatabasePathCreateContext(this.context, this.state);
        this.enterRule(localContext, 438, SparkSQLParser.RULE_databasePathCreate);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 3280;
            this.uid();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public tablePathCreate(): TablePathCreateContext {
        let localContext = new TablePathCreateContext(this.context, this.state);
        this.enterRule(localContext, 440, SparkSQLParser.RULE_tablePathCreate);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 3282;
            this.uid();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public tablePath(): TablePathContext {
        let localContext = new TablePathContext(this.context, this.state);
        this.enterRule(localContext, 442, SparkSQLParser.RULE_tablePath);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 3284;
            this.uid();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public anonymousWindowsName(): AnonymousWindowsNameContext {
        let localContext = new AnonymousWindowsNameContext(this.context, this.state);
        this.enterRule(localContext, 444, SparkSQLParser.RULE_anonymousWindowsName);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 3286;
            this.identifier();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public uid(): UidContext {
        let localContext = new UidContext(this.context, this.state);
        this.enterRule(localContext, 446, SparkSQLParser.RULE_uid);
        try {
            let alternative: number;
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 3288;
            this.identifier();
            this.state = 3293;
            this.errorHandler.sync(this);
            alternative = this.interpreter.adaptivePredict(this.tokenStream, 402, this.context);
            while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {
                if (alternative === 1) {
                    {
                    {
                    this.state = 3289;
                    this.match(SparkSQLParser.DOT);
                    this.state = 3290;
                    this.identifier();
                    }
                    }
                }
                this.state = 3295;
                this.errorHandler.sync(this);
                alternative = this.interpreter.adaptivePredict(this.tokenStream, 402, this.context);
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public withOption(): WithOptionContext {
        let localContext = new WithOptionContext(this.context, this.state);
        this.enterRule(localContext, 448, SparkSQLParser.RULE_withOption);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 3296;
            this.match(SparkSQLParser.KW_WITH);
            this.state = 3298;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 32 || _la === 416) {
                {
                this.state = 3297;
                _la = this.tokenStream.LA(1);
                if(!(_la === 32 || _la === 416)) {
                this.errorHandler.recoverInline(this);
                }
                else {
                    this.errorHandler.reportMatch(this);
                    this.consume();
                }
                }
            }

            this.state = 3300;
            this.tablePropertyList();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public ifNotExists(): IfNotExistsContext {
        let localContext = new IfNotExistsContext(this.context, this.state);
        this.enterRule(localContext, 450, SparkSQLParser.RULE_ifNotExists);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 3302;
            this.match(SparkSQLParser.KW_IF);
            this.state = 3303;
            this.match(SparkSQLParser.KW_NOT);
            this.state = 3304;
            this.match(SparkSQLParser.KW_EXISTS);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public ifExists(): IfExistsContext {
        let localContext = new IfExistsContext(this.context, this.state);
        this.enterRule(localContext, 452, SparkSQLParser.RULE_ifExists);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 3306;
            this.match(SparkSQLParser.KW_IF);
            this.state = 3307;
            this.match(SparkSQLParser.KW_EXISTS);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public tablePropertyList(): TablePropertyListContext {
        let localContext = new TablePropertyListContext(this.context, this.state);
        this.enterRule(localContext, 454, SparkSQLParser.RULE_tablePropertyList);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 3309;
            this.match(SparkSQLParser.LR_BRACKET);
            this.state = 3310;
            this.tableProperty();
            this.state = 3315;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            while (_la === 475) {
                {
                {
                this.state = 3311;
                this.match(SparkSQLParser.COMMA);
                this.state = 3312;
                this.tableProperty();
                }
                }
                this.state = 3317;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
            }
            this.state = 3318;
            this.match(SparkSQLParser.RR_BRACKET);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public tableProperty(): TablePropertyContext {
        let localContext = new TablePropertyContext(this.context, this.state);
        this.enterRule(localContext, 456, SparkSQLParser.RULE_tableProperty);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 3320;
            this.tablePropertyKey();
            this.state = 3321;
            this.match(SparkSQLParser.EQUAL_SYMBOL);
            this.state = 3323;
            this.errorHandler.sync(this);
            _la = this.tokenStream.LA(1);
            if (_la === 254) {
                {
                this.state = 3322;
                this.match(SparkSQLParser.KW_DATE);
                }
            }

            this.state = 3325;
            this.tablePropertyValue();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public tablePropertyKey(): TablePropertyKeyContext {
        let localContext = new TablePropertyKeyContext(this.context, this.state);
        this.enterRule(localContext, 458, SparkSQLParser.RULE_tablePropertyKey);
        try {
            this.state = 3331;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 406, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 3327;
                this.identifier();
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 3328;
                this.dereferenceDefinition();
                }
                break;
            case 3:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 3329;
                this.stringLiteral();
                }
                break;
            case 4:
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 3330;
                this.functionParam();
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public propertyName(): PropertyNameContext {
        let localContext = new PropertyNameContext(this.context, this.state);
        this.enterRule(localContext, 460, SparkSQLParser.RULE_propertyName);
        try {
            this.state = 3338;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.SINGLE_QUOTE_SYMB:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 3333;
                this.match(SparkSQLParser.SINGLE_QUOTE_SYMB);
                this.state = 3334;
                this.constant();
                this.state = 3335;
                this.match(SparkSQLParser.SINGLE_QUOTE_SYMB);
                }
                break;
            case SparkSQLParser.KW_MICROSECOND:
            case SparkSQLParser.KW_MILLISECOND:
            case SparkSQLParser.KW_QUARTER:
            case SparkSQLParser.KW_WEEK:
            case SparkSQLParser.KW_DAY:
            case SparkSQLParser.KW_FALSE:
            case SparkSQLParser.KW_HOUR:
            case SparkSQLParser.KW_INTERVAL:
            case SparkSQLParser.KW_MINUTE:
            case SparkSQLParser.KW_MONTH:
            case SparkSQLParser.KW_NOT:
            case SparkSQLParser.KW_NULL:
            case SparkSQLParser.KW_SECOND:
            case SparkSQLParser.KW_TRUE:
            case SparkSQLParser.KW_YEAR:
            case SparkSQLParser.HYPNEN_SIGN:
            case SparkSQLParser.STRING_LITERAL:
            case SparkSQLParser.DIG_LITERAL:
            case SparkSQLParser.REAL_LITERAL:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 3337;
                this.constant();
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public tablePropertyValue(): TablePropertyValueContext {
        let localContext = new TablePropertyValueContext(this.context, this.state);
        this.enterRule(localContext, 462, SparkSQLParser.RULE_tablePropertyValue);
        try {
            this.state = 3345;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 408, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 3340;
                this.match(SparkSQLParser.DIG_LITERAL);
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 3341;
                this.match(SparkSQLParser.REAL_LITERAL);
                }
                break;
            case 3:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 3342;
                this.booleanLiteral();
                }
                break;
            case 4:
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 3343;
                this.uid();
                }
                break;
            case 5:
                this.enterOuterAlt(localContext, 5);
                {
                this.state = 3344;
                this.constant();
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public comparisonOperator(): ComparisonOperatorContext {
        let localContext = new ComparisonOperatorContext(this.context, this.state);
        this.enterRule(localContext, 464, SparkSQLParser.RULE_comparisonOperator);
        try {
            this.state = 3361;
            this.errorHandler.sync(this);
            switch (this.interpreter.adaptivePredict(this.tokenStream, 409, this.context) ) {
            case 1:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 3347;
                this.match(SparkSQLParser.EQUAL_SYMBOL);
                }
                break;
            case 2:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 3348;
                this.match(SparkSQLParser.GREATER_SYMBOL);
                }
                break;
            case 3:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 3349;
                this.match(SparkSQLParser.LESS_SYMBOL);
                }
                break;
            case 4:
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 3350;
                this.match(SparkSQLParser.LESS_SYMBOL);
                this.state = 3351;
                this.match(SparkSQLParser.EQUAL_SYMBOL);
                }
                break;
            case 5:
                this.enterOuterAlt(localContext, 5);
                {
                this.state = 3352;
                this.match(SparkSQLParser.GREATER_SYMBOL);
                this.state = 3353;
                this.match(SparkSQLParser.EQUAL_SYMBOL);
                }
                break;
            case 6:
                this.enterOuterAlt(localContext, 6);
                {
                this.state = 3354;
                this.match(SparkSQLParser.LESS_SYMBOL);
                this.state = 3355;
                this.match(SparkSQLParser.GREATER_SYMBOL);
                }
                break;
            case 7:
                this.enterOuterAlt(localContext, 7);
                {
                this.state = 3356;
                this.match(SparkSQLParser.EXCLAMATION_SYMBOL);
                this.state = 3357;
                this.match(SparkSQLParser.EQUAL_SYMBOL);
                }
                break;
            case 8:
                this.enterOuterAlt(localContext, 8);
                {
                this.state = 3358;
                this.match(SparkSQLParser.LESS_SYMBOL);
                this.state = 3359;
                this.match(SparkSQLParser.EQUAL_SYMBOL);
                this.state = 3360;
                this.match(SparkSQLParser.GREATER_SYMBOL);
                }
                break;
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public constant(): ConstantContext {
        let localContext = new ConstantContext(this.context, this.state);
        this.enterRule(localContext, 466, SparkSQLParser.RULE_constant);
        let _la: number;
        try {
            this.state = 3376;
            this.errorHandler.sync(this);
            switch (this.tokenStream.LA(1)) {
            case SparkSQLParser.KW_INTERVAL:
                this.enterOuterAlt(localContext, 1);
                {
                this.state = 3363;
                this.timeIntervalExpression();
                }
                break;
            case SparkSQLParser.KW_MICROSECOND:
            case SparkSQLParser.KW_MILLISECOND:
            case SparkSQLParser.KW_QUARTER:
            case SparkSQLParser.KW_WEEK:
            case SparkSQLParser.KW_DAY:
            case SparkSQLParser.KW_HOUR:
            case SparkSQLParser.KW_MINUTE:
            case SparkSQLParser.KW_MONTH:
            case SparkSQLParser.KW_SECOND:
            case SparkSQLParser.KW_YEAR:
                this.enterOuterAlt(localContext, 2);
                {
                this.state = 3364;
                this.timePointLiteral();
                }
                break;
            case SparkSQLParser.STRING_LITERAL:
                this.enterOuterAlt(localContext, 3);
                {
                this.state = 3365;
                this.stringLiteral();
                }
                break;
            case SparkSQLParser.HYPNEN_SIGN:
            case SparkSQLParser.DIG_LITERAL:
                this.enterOuterAlt(localContext, 4);
                {
                this.state = 3367;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 485) {
                    {
                    this.state = 3366;
                    this.match(SparkSQLParser.HYPNEN_SIGN);
                    }
                }

                this.state = 3369;
                this.decimalLiteral();
                }
                break;
            case SparkSQLParser.KW_FALSE:
            case SparkSQLParser.KW_TRUE:
                this.enterOuterAlt(localContext, 5);
                {
                this.state = 3370;
                this.booleanLiteral();
                }
                break;
            case SparkSQLParser.REAL_LITERAL:
                this.enterOuterAlt(localContext, 6);
                {
                this.state = 3371;
                this.match(SparkSQLParser.REAL_LITERAL);
                }
                break;
            case SparkSQLParser.KW_NOT:
            case SparkSQLParser.KW_NULL:
                this.enterOuterAlt(localContext, 7);
                {
                this.state = 3373;
                this.errorHandler.sync(this);
                _la = this.tokenStream.LA(1);
                if (_la === 348) {
                    {
                    this.state = 3372;
                    this.match(SparkSQLParser.KW_NOT);
                    }
                }

                this.state = 3375;
                this.match(SparkSQLParser.KW_NULL);
                }
                break;
            default:
                throw new antlr.NoViableAltException(this);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public timePointLiteral(): TimePointLiteralContext {
        let localContext = new TimePointLiteralContext(this.context, this.state);
        this.enterRule(localContext, 468, SparkSQLParser.RULE_timePointLiteral);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 3378;
            this.timePointUnit();
            this.state = 3379;
            this.stringLiteral();
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public anyStringLiteral(): AnyStringLiteralContext {
        let localContext = new AnyStringLiteralContext(this.context, this.state);
        this.enterRule(localContext, 470, SparkSQLParser.RULE_anyStringLiteral);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 3381;
            _la = this.tokenStream.LA(1);
            if(!(_la === 493 || _la === 496)) {
            this.errorHandler.recoverInline(this);
            }
            else {
                this.errorHandler.reportMatch(this);
                this.consume();
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public stringLiteral(): StringLiteralContext {
        let localContext = new StringLiteralContext(this.context, this.state);
        this.enterRule(localContext, 472, SparkSQLParser.RULE_stringLiteral);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 3383;
            this.match(SparkSQLParser.STRING_LITERAL);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public decimalLiteral(): DecimalLiteralContext {
        let localContext = new DecimalLiteralContext(this.context, this.state);
        this.enterRule(localContext, 474, SparkSQLParser.RULE_decimalLiteral);
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 3385;
            this.match(SparkSQLParser.DIG_LITERAL);
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public booleanLiteral(): BooleanLiteralContext {
        let localContext = new BooleanLiteralContext(this.context, this.state);
        this.enterRule(localContext, 476, SparkSQLParser.RULE_booleanLiteral);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 3387;
            _la = this.tokenStream.LA(1);
            if(!(_la === 287 || _la === 428)) {
            this.errorHandler.recoverInline(this);
            }
            else {
                this.errorHandler.reportMatch(this);
                this.consume();
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public setQuantifier(): SetQuantifierContext {
        let localContext = new SetQuantifierContext(this.context, this.state);
        this.enterRule(localContext, 478, SparkSQLParser.RULE_setQuantifier);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 3389;
            _la = this.tokenStream.LA(1);
            if(!(_la === 202 || _la === 266)) {
            this.errorHandler.recoverInline(this);
            }
            else {
                this.errorHandler.reportMatch(this);
                this.consume();
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public timePointUnit(): TimePointUnitContext {
        let localContext = new TimePointUnitContext(this.context, this.state);
        this.enterRule(localContext, 480, SparkSQLParser.RULE_timePointUnit);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 3391;
            _la = this.tokenStream.LA(1);
            if(!(_la === 90 || _la === 92 || _la === 127 || _la === 195 || _la === 256 || _la === 301 || _la === 339 || _la === 342 || _la === 394 || _la === 449)) {
            this.errorHandler.recoverInline(this);
            }
            else {
                this.errorHandler.reportMatch(this);
                this.consume();
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public timeIntervalUnit(): TimeIntervalUnitContext {
        let localContext = new TimeIntervalUnitContext(this.context, this.state);
        this.enterRule(localContext, 482, SparkSQLParser.RULE_timeIntervalUnit);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 3393;
            _la = this.tokenStream.LA(1);
            if(!(((((_la - 17)) & ~0x1F) === 0 && ((1 << (_la - 17)) & 16859137) !== 0) || ((((_la - 65)) & ~0x1F) === 0 && ((1 << (_la - 65)) & 503316481) !== 0) || ((((_la - 97)) & ~0x1F) === 0 && ((1 << (_la - 97)) & 1073741827) !== 0) || _la === 146 || ((((_la - 195)) & ~0x1F) === 0 && ((1 << (_la - 195)) & 19) !== 0) || _la === 256 || _la === 301 || _la === 339 || _la === 342 || _la === 394 || _la === 449)) {
            this.errorHandler.recoverInline(this);
            }
            else {
                this.errorHandler.reportMatch(this);
                this.consume();
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public reservedKeywordsUsedAsFuncParam(): ReservedKeywordsUsedAsFuncParamContext {
        let localContext = new ReservedKeywordsUsedAsFuncParamContext(this.context, this.state);
        this.enterRule(localContext, 484, SparkSQLParser.RULE_reservedKeywordsUsedAsFuncParam);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 3395;
            _la = this.tokenStream.LA(1);
            if(!(_la === 202 || _la === 220 || _la === 266 || _la === 326 || _la === 427 || _la === 483)) {
            this.errorHandler.recoverInline(this);
            }
            else {
                this.errorHandler.reportMatch(this);
                this.consume();
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public reservedKeywordsUsedAsFuncName(): ReservedKeywordsUsedAsFuncNameContext {
        let localContext = new ReservedKeywordsUsedAsFuncNameContext(this.context, this.state);
        this.enterRule(localContext, 486, SparkSQLParser.RULE_reservedKeywordsUsedAsFuncName);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 3397;
            _la = this.tokenStream.LA(1);
            if(!(_la === 66 || _la === 89 || _la === 127 || ((((_la - 195)) & ~0x1F) === 0 && ((1 << (_la - 195)) & 139329) !== 0) || ((((_la - 227)) & ~0x1F) === 0 && ((1 << (_la - 227)) & 134482435) !== 0) || ((((_la - 282)) & ~0x1F) === 0 && ((1 << (_la - 282)) & 590865) !== 0) || ((((_la - 321)) & ~0x1F) === 0 && ((1 << (_la - 321)) & 270794841) !== 0) || ((((_la - 363)) & ~0x1F) === 0 && ((1 << (_la - 363)) & 2182748609) !== 0) || ((((_la - 409)) & ~0x1F) === 0 && ((1 << (_la - 409)) & 68220931) !== 0) || _la === 449)) {
            this.errorHandler.recoverInline(this);
            }
            else {
                this.errorHandler.reportMatch(this);
                this.consume();
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }
    public nonReservedKeywords(): NonReservedKeywordsContext {
        let localContext = new NonReservedKeywordsContext(this.context, this.state);
        this.enterRule(localContext, 488, SparkSQLParser.RULE_nonReservedKeywords);
        let _la: number;
        try {
            this.enterOuterAlt(localContext, 1);
            {
            this.state = 3399;
            _la = this.tokenStream.LA(1);
            if(!((((_la) & ~0x1F) === 0 && ((1 << _la) & 4294896624) !== 0) || ((((_la - 33)) & ~0x1F) === 0 && ((1 << (_la - 33)) & 4294803199) !== 0) || ((((_la - 65)) & ~0x1F) === 0 && ((1 << (_la - 65)) & 4281327607) !== 0) || ((((_la - 97)) & ~0x1F) === 0 && ((1 << (_la - 97)) & 2147483643) !== 0) || ((((_la - 129)) & ~0x1F) === 0 && ((1 << (_la - 129)) & 2113863675) !== 0) || ((((_la - 161)) & ~0x1F) === 0 && ((1 << (_la - 161)) & 4292341757) !== 0) || ((((_la - 193)) & ~0x1F) === 0 && ((1 << (_la - 193)) & 247) !== 0) || _la === 332)) {
            this.errorHandler.recoverInline(this);
            }
            else {
                this.errorHandler.reportMatch(this);
                this.consume();
            }
            }
        }
        catch (re) {
            if (re instanceof antlr.RecognitionException) {
                this.errorHandler.reportError(this, re);
                this.errorHandler.recover(this, re);
            } else {
                throw re;
            }
        }
        finally {
            this.exitRule();
        }
        return localContext;
    }

    public override sempred(localContext: antlr.ParserRuleContext | null, ruleIndex: number, predIndex: number): boolean {
        switch (ruleIndex) {
        case 66:
            return this.queryStatement_sempred(localContext as QueryStatementContext, predIndex);
        case 86:
            return this.tableExpression_sempred(localContext as TableExpressionContext, predIndex);
        case 181:
            return this.booleanExpression_sempred(localContext as BooleanExpressionContext, predIndex);
        case 184:
            return this.valueExpression_sempred(localContext as ValueExpressionContext, predIndex);
        case 185:
            return this.primaryExpression_sempred(localContext as PrimaryExpressionContext, predIndex);
        }
        return true;
    }
    private queryStatement_sempred(localContext: QueryStatementContext | null, predIndex: number): boolean {
        switch (predIndex) {
        case 0:
            return this.precpred(this.context, 2);
        }
        return true;
    }
    private tableExpression_sempred(localContext: TableExpressionContext | null, predIndex: number): boolean {
        switch (predIndex) {
        case 1:
            return this.precpred(this.context, 4);
        case 2:
            return this.precpred(this.context, 5);
        }
        return true;
    }
    private booleanExpression_sempred(localContext: BooleanExpressionContext | null, predIndex: number): boolean {
        switch (predIndex) {
        case 3:
            return this.precpred(this.context, 3);
        case 4:
            return this.precpred(this.context, 2);
        case 5:
            return this.precpred(this.context, 1);
        }
        return true;
    }
    private valueExpression_sempred(localContext: ValueExpressionContext | null, predIndex: number): boolean {
        switch (predIndex) {
        case 6:
            return this.precpred(this.context, 6);
        case 7:
            return this.precpred(this.context, 5);
        case 8:
            return this.precpred(this.context, 4);
        case 9:
            return this.precpred(this.context, 3);
        case 10:
            return this.precpred(this.context, 2);
        case 11:
            return this.precpred(this.context, 1);
        }
        return true;
    }
    private primaryExpression_sempred(localContext: PrimaryExpressionContext | null, predIndex: number): boolean {
        switch (predIndex) {
        case 12:
            return this.precpred(this.context, 5);
        }
        return true;
    }

    public static readonly _serializedATN: number[] = [
        4,1,496,3402,2,0,7,0,2,1,7,1,2,2,7,2,2,3,7,3,2,4,7,4,2,5,7,5,2,6,
        7,6,2,7,7,7,2,8,7,8,2,9,7,9,2,10,7,10,2,11,7,11,2,12,7,12,2,13,7,
        13,2,14,7,14,2,15,7,15,2,16,7,16,2,17,7,17,2,18,7,18,2,19,7,19,2,
        20,7,20,2,21,7,21,2,22,7,22,2,23,7,23,2,24,7,24,2,25,7,25,2,26,7,
        26,2,27,7,27,2,28,7,28,2,29,7,29,2,30,7,30,2,31,7,31,2,32,7,32,2,
        33,7,33,2,34,7,34,2,35,7,35,2,36,7,36,2,37,7,37,2,38,7,38,2,39,7,
        39,2,40,7,40,2,41,7,41,2,42,7,42,2,43,7,43,2,44,7,44,2,45,7,45,2,
        46,7,46,2,47,7,47,2,48,7,48,2,49,7,49,2,50,7,50,2,51,7,51,2,52,7,
        52,2,53,7,53,2,54,7,54,2,55,7,55,2,56,7,56,2,57,7,57,2,58,7,58,2,
        59,7,59,2,60,7,60,2,61,7,61,2,62,7,62,2,63,7,63,2,64,7,64,2,65,7,
        65,2,66,7,66,2,67,7,67,2,68,7,68,2,69,7,69,2,70,7,70,2,71,7,71,2,
        72,7,72,2,73,7,73,2,74,7,74,2,75,7,75,2,76,7,76,2,77,7,77,2,78,7,
        78,2,79,7,79,2,80,7,80,2,81,7,81,2,82,7,82,2,83,7,83,2,84,7,84,2,
        85,7,85,2,86,7,86,2,87,7,87,2,88,7,88,2,89,7,89,2,90,7,90,2,91,7,
        91,2,92,7,92,2,93,7,93,2,94,7,94,2,95,7,95,2,96,7,96,2,97,7,97,2,
        98,7,98,2,99,7,99,2,100,7,100,2,101,7,101,2,102,7,102,2,103,7,103,
        2,104,7,104,2,105,7,105,2,106,7,106,2,107,7,107,2,108,7,108,2,109,
        7,109,2,110,7,110,2,111,7,111,2,112,7,112,2,113,7,113,2,114,7,114,
        2,115,7,115,2,116,7,116,2,117,7,117,2,118,7,118,2,119,7,119,2,120,
        7,120,2,121,7,121,2,122,7,122,2,123,7,123,2,124,7,124,2,125,7,125,
        2,126,7,126,2,127,7,127,2,128,7,128,2,129,7,129,2,130,7,130,2,131,
        7,131,2,132,7,132,2,133,7,133,2,134,7,134,2,135,7,135,2,136,7,136,
        2,137,7,137,2,138,7,138,2,139,7,139,2,140,7,140,2,141,7,141,2,142,
        7,142,2,143,7,143,2,144,7,144,2,145,7,145,2,146,7,146,2,147,7,147,
        2,148,7,148,2,149,7,149,2,150,7,150,2,151,7,151,2,152,7,152,2,153,
        7,153,2,154,7,154,2,155,7,155,2,156,7,156,2,157,7,157,2,158,7,158,
        2,159,7,159,2,160,7,160,2,161,7,161,2,162,7,162,2,163,7,163,2,164,
        7,164,2,165,7,165,2,166,7,166,2,167,7,167,2,168,7,168,2,169,7,169,
        2,170,7,170,2,171,7,171,2,172,7,172,2,173,7,173,2,174,7,174,2,175,
        7,175,2,176,7,176,2,177,7,177,2,178,7,178,2,179,7,179,2,180,7,180,
        2,181,7,181,2,182,7,182,2,183,7,183,2,184,7,184,2,185,7,185,2,186,
        7,186,2,187,7,187,2,188,7,188,2,189,7,189,2,190,7,190,2,191,7,191,
        2,192,7,192,2,193,7,193,2,194,7,194,2,195,7,195,2,196,7,196,2,197,
        7,197,2,198,7,198,2,199,7,199,2,200,7,200,2,201,7,201,2,202,7,202,
        2,203,7,203,2,204,7,204,2,205,7,205,2,206,7,206,2,207,7,207,2,208,
        7,208,2,209,7,209,2,210,7,210,2,211,7,211,2,212,7,212,2,213,7,213,
        2,214,7,214,2,215,7,215,2,216,7,216,2,217,7,217,2,218,7,218,2,219,
        7,219,2,220,7,220,2,221,7,221,2,222,7,222,2,223,7,223,2,224,7,224,
        2,225,7,225,2,226,7,226,2,227,7,227,2,228,7,228,2,229,7,229,2,230,
        7,230,2,231,7,231,2,232,7,232,2,233,7,233,2,234,7,234,2,235,7,235,
        2,236,7,236,2,237,7,237,2,238,7,238,2,239,7,239,2,240,7,240,2,241,
        7,241,2,242,7,242,2,243,7,243,2,244,7,244,1,0,1,0,1,0,1,1,1,1,5,
        1,496,8,1,10,1,12,1,499,9,1,1,2,1,2,3,2,503,8,2,1,2,1,2,1,3,1,3,
        1,4,1,4,1,4,1,4,1,4,3,4,514,8,4,1,5,1,5,3,5,518,8,5,1,6,3,6,521,
        8,6,1,6,1,6,3,6,525,8,6,1,6,3,6,528,8,6,1,6,1,6,1,6,1,6,1,6,3,6,
        535,8,6,1,7,1,7,1,7,3,7,540,8,7,1,7,1,7,3,7,544,8,7,1,8,1,8,1,8,
        3,8,549,8,8,1,8,1,8,1,8,3,8,554,8,8,5,8,556,8,8,10,8,12,8,559,9,
        8,1,8,1,8,1,9,1,9,1,9,1,9,1,9,1,9,1,9,1,9,3,9,571,8,9,1,10,1,10,
        3,10,575,8,10,1,10,1,10,3,10,579,8,10,1,10,1,10,5,10,583,8,10,10,
        10,12,10,586,9,10,1,10,1,10,1,10,3,10,591,8,10,1,10,5,10,594,8,10,
        10,10,12,10,597,9,10,1,11,1,11,1,11,1,11,1,11,1,11,1,11,1,11,1,11,
        1,11,1,11,1,11,1,11,3,11,612,8,11,1,12,1,12,1,12,1,12,1,12,3,12,
        619,8,12,1,12,1,12,1,13,1,13,1,13,3,13,626,8,13,1,13,1,13,1,13,1,
        13,3,13,632,8,13,1,14,1,14,1,14,1,15,1,15,5,15,639,8,15,10,15,12,
        15,642,9,15,1,15,3,15,645,8,15,1,15,1,15,1,15,5,15,650,8,15,10,15,
        12,15,653,9,15,1,16,1,16,1,16,1,16,1,16,1,16,1,16,1,16,1,16,1,16,
        1,16,1,16,1,16,3,16,668,8,16,1,17,1,17,1,17,1,17,5,17,674,8,17,10,
        17,12,17,677,9,17,1,18,1,18,1,18,1,18,1,18,1,18,1,18,3,18,686,8,
        18,1,19,1,19,1,19,1,19,1,19,5,19,693,8,19,10,19,12,19,696,9,19,1,
        20,1,20,1,20,1,20,1,20,1,20,1,20,3,20,705,8,20,1,21,1,21,1,21,1,
        21,1,22,1,22,3,22,713,8,22,1,22,1,22,3,22,717,8,22,1,22,1,22,4,22,
        721,8,22,11,22,12,22,722,1,23,1,23,1,23,1,23,1,23,3,23,730,8,23,
        1,23,1,23,1,23,3,23,735,8,23,5,23,737,8,23,10,23,12,23,740,9,23,
        1,23,1,23,1,24,1,24,1,24,1,24,1,24,1,24,1,24,1,24,1,24,1,24,1,24,
        1,24,1,24,1,24,1,24,3,24,759,8,24,1,25,1,25,1,25,1,25,1,25,1,26,
        1,26,1,26,1,26,1,26,1,27,1,27,1,27,3,27,774,8,27,1,28,1,28,1,28,
        1,28,3,28,780,8,28,1,29,1,29,3,29,784,8,29,1,30,1,30,1,30,1,30,3,
        30,790,8,30,1,30,1,30,1,30,4,30,795,8,30,11,30,12,30,796,1,31,1,
        31,1,31,1,31,1,31,1,31,1,31,1,31,1,31,1,31,1,31,1,31,1,31,1,31,1,
        31,1,31,1,31,1,31,1,31,1,31,1,31,1,31,1,31,1,31,1,31,1,31,1,31,1,
        31,1,31,1,31,1,31,1,31,3,31,831,8,31,1,32,1,32,1,32,1,33,1,33,1,
        33,1,33,1,34,1,34,1,34,3,34,843,8,34,1,34,1,34,1,34,3,34,848,8,34,
        5,34,850,8,34,10,34,12,34,853,9,34,1,34,1,34,1,34,3,34,858,8,34,
        3,34,860,8,34,1,34,1,34,1,34,3,34,865,8,34,3,34,867,8,34,1,34,1,
        34,1,34,3,34,872,8,34,3,34,874,8,34,1,34,1,34,1,35,1,35,3,35,880,
        8,35,1,35,1,35,3,35,884,8,35,1,35,1,35,5,35,888,8,35,10,35,12,35,
        891,9,35,1,35,1,35,1,35,1,35,1,35,5,35,898,8,35,10,35,12,35,901,
        9,35,1,35,1,35,1,35,1,35,1,35,5,35,908,8,35,10,35,12,35,911,9,35,
        1,35,1,35,1,35,5,35,916,8,35,10,35,12,35,919,9,35,1,35,1,35,5,35,
        923,8,35,10,35,12,35,926,9,35,1,36,1,36,1,36,1,36,1,36,1,36,3,36,
        934,8,36,1,37,1,37,1,37,1,37,3,37,940,8,37,1,37,1,37,5,37,944,8,
        37,10,37,12,37,947,9,37,1,37,1,37,5,37,951,8,37,10,37,12,37,954,
        9,37,1,37,1,37,1,37,1,37,1,37,5,37,961,8,37,10,37,12,37,964,9,37,
        1,37,1,37,1,37,1,37,1,37,5,37,971,8,37,10,37,12,37,974,9,37,1,37,
        1,37,1,37,5,37,979,8,37,10,37,12,37,982,9,37,1,37,1,37,1,37,5,37,
        987,8,37,10,37,12,37,990,9,37,1,38,1,38,1,38,1,38,1,38,1,38,3,38,
        998,8,38,1,39,1,39,1,39,3,39,1003,8,39,1,39,1,39,1,39,1,39,3,39,
        1009,8,39,1,40,1,40,1,40,1,40,1,40,5,40,1016,8,40,10,40,12,40,1019,
        9,40,1,40,1,40,1,40,1,40,1,40,1,40,1,40,5,40,1028,8,40,10,40,12,
        40,1031,9,40,1,40,1,40,1,40,3,40,1036,8,40,1,40,1,40,5,40,1040,8,
        40,10,40,12,40,1043,9,40,1,40,1,40,1,40,1,40,1,40,1,40,1,40,5,40,
        1052,8,40,10,40,12,40,1055,9,40,1,41,1,41,1,41,1,41,1,41,1,41,1,
        41,3,41,1064,8,41,1,42,1,42,1,42,1,42,1,42,1,43,1,43,1,43,3,43,1074,
        8,43,1,43,1,43,3,43,1078,8,43,1,43,1,43,3,43,1082,8,43,1,43,3,43,
        1085,8,43,1,44,1,44,1,44,3,44,1090,8,44,1,44,3,44,1093,8,44,1,44,
        3,44,1096,8,44,1,44,1,44,3,44,1100,8,44,1,44,1,44,3,44,1104,8,44,
        1,44,3,44,1107,8,44,1,44,1,44,1,44,1,45,1,45,1,45,3,45,1115,8,45,
        1,45,1,45,1,45,3,45,1120,8,45,1,45,1,45,3,45,1124,8,45,1,45,1,45,
        1,45,1,45,1,45,3,45,1131,8,45,1,45,1,45,1,45,1,45,3,45,1137,8,45,
        1,46,1,46,1,46,1,46,1,46,1,46,5,46,1145,8,46,10,46,12,46,1148,9,
        46,1,47,1,47,1,47,3,47,1153,8,47,1,48,1,48,1,48,3,48,1158,8,48,4,
        48,1160,8,48,11,48,12,48,1161,3,48,1164,8,48,1,49,1,49,1,49,3,49,
        1169,8,49,1,50,1,50,3,50,1173,8,50,1,50,1,50,1,50,1,51,1,51,1,51,
        1,52,1,52,1,52,1,52,1,52,1,52,1,52,3,52,1188,8,52,1,53,1,53,1,53,
        1,53,1,54,1,54,1,54,1,54,1,55,1,55,1,55,1,56,3,56,1202,8,56,1,56,
        1,56,1,56,1,56,3,56,1208,8,56,1,56,1,56,1,56,3,56,1213,8,56,1,57,
        1,57,1,57,1,57,3,57,1219,8,57,1,57,3,57,1222,8,57,1,57,1,57,1,57,
        1,57,1,57,1,57,1,57,1,57,3,57,1232,8,57,1,58,1,58,1,58,1,58,1,58,
        1,58,1,59,1,59,1,59,1,59,1,59,1,60,3,60,1246,8,60,1,60,1,60,1,60,
        1,60,1,60,1,60,3,60,1254,8,60,1,60,1,60,1,60,3,60,1259,8,60,5,60,
        1261,8,60,10,60,12,60,1264,9,60,1,60,1,60,1,60,1,60,1,60,1,60,1,
        60,1,60,1,60,3,60,1275,8,60,3,60,1277,8,60,1,60,1,60,1,60,3,60,1282,
        8,60,5,60,1284,8,60,10,60,12,60,1287,9,60,1,60,1,60,3,60,1291,8,
        60,1,61,1,61,1,61,1,61,1,61,1,61,1,61,3,61,1300,8,61,1,61,1,61,1,
        62,1,62,1,62,1,63,1,63,1,63,1,64,1,64,1,64,1,64,1,64,1,64,1,64,4,
        64,1317,8,64,11,64,12,64,1318,1,64,1,64,1,65,1,65,1,65,1,65,1,65,
        1,65,4,65,1329,8,65,11,65,12,65,1330,1,65,1,65,1,66,1,66,1,66,1,
        66,1,66,1,66,1,66,1,66,1,66,1,66,3,66,1345,8,66,1,66,3,66,1348,8,
        66,1,66,3,66,1351,8,66,1,66,3,66,1354,8,66,1,66,3,66,1357,8,66,3,
        66,1359,8,66,1,66,1,66,1,66,3,66,1364,8,66,1,66,1,66,3,66,1368,8,
        66,1,66,3,66,1371,8,66,1,66,3,66,1374,8,66,1,66,3,66,1377,8,66,5,
        66,1379,8,66,10,66,12,66,1382,9,66,1,67,1,67,1,67,1,67,3,67,1388,
        8,67,1,67,5,67,1391,8,67,10,67,12,67,1394,9,67,1,68,1,68,1,68,1,
        68,5,68,1400,8,68,10,68,12,68,1403,9,68,1,68,1,68,1,69,1,69,1,69,
        1,69,5,69,1411,8,69,10,69,12,69,1414,9,69,1,70,1,70,1,70,1,70,1,
        70,5,70,1421,8,70,10,70,12,70,1424,9,70,1,70,1,70,3,70,1428,8,70,
        1,70,1,70,1,70,1,70,1,70,1,71,1,71,1,72,1,72,1,72,3,72,1440,8,72,
        1,72,3,72,1443,8,72,1,72,3,72,1446,8,72,1,72,3,72,1449,8,72,1,72,
        1,72,1,72,3,72,1454,8,72,1,72,3,72,1457,8,72,1,72,3,72,1460,8,72,
        1,72,3,72,1463,8,72,1,72,1,72,1,72,1,72,1,72,1,72,1,72,1,72,1,72,
        1,72,1,72,1,72,1,72,1,72,1,72,1,72,1,72,3,72,1482,8,72,1,72,3,72,
        1485,8,72,1,72,3,72,1488,8,72,1,72,3,72,1491,8,72,3,72,1493,8,72,
        1,73,1,73,3,73,1497,8,73,1,73,1,73,3,73,1501,8,73,1,73,1,73,5,73,
        1505,8,73,10,73,12,73,1508,9,73,1,74,1,74,3,74,1512,8,74,1,74,3,
        74,1515,8,74,1,74,1,74,3,74,1519,8,74,1,74,3,74,1522,8,74,1,74,1,
        74,1,74,3,74,1527,8,74,1,74,3,74,1530,8,74,1,74,1,74,1,74,1,74,1,
        74,1,74,1,74,3,74,1539,8,74,1,74,3,74,1542,8,74,1,74,3,74,1545,8,
        74,3,74,1547,8,74,1,75,1,75,1,75,1,75,1,75,1,76,1,76,1,76,3,76,1557,
        8,76,1,76,1,76,3,76,1561,8,76,1,76,1,76,3,76,1565,8,76,1,76,1,76,
        1,76,5,76,1570,8,76,10,76,12,76,1573,9,76,1,76,3,76,1576,8,76,1,
        76,1,76,3,76,1580,8,76,1,77,1,77,1,77,1,77,1,77,3,77,1587,8,77,1,
        78,1,78,1,78,1,78,3,78,1593,8,78,1,78,1,78,3,78,1597,8,78,1,79,1,
        79,1,79,1,79,1,79,5,79,1604,8,79,10,79,12,79,1607,9,79,3,79,1609,
        8,79,1,79,1,79,1,79,3,79,1614,8,79,1,80,1,80,3,80,1618,8,80,1,81,
        1,81,1,82,1,82,1,83,1,83,1,83,1,84,1,84,1,84,1,84,1,84,1,84,1,84,
        3,84,1634,8,84,1,85,1,85,1,85,1,85,1,85,1,85,1,85,1,85,1,85,1,85,
        1,85,1,85,3,85,1648,8,85,1,86,1,86,1,86,3,86,1653,8,86,1,86,5,86,
        1656,8,86,10,86,12,86,1659,9,86,1,86,1,86,1,86,3,86,1664,8,86,1,
        86,3,86,1667,8,86,1,86,1,86,1,86,1,86,1,86,1,86,3,86,1675,8,86,1,
        86,3,86,1678,8,86,1,86,3,86,1681,8,86,1,86,1,86,1,86,3,86,1686,8,
        86,1,86,1,86,5,86,1690,8,86,10,86,12,86,1693,9,86,5,86,1695,8,86,
        10,86,12,86,1698,9,86,1,87,1,87,3,87,1702,8,87,1,88,3,88,1705,8,
        88,1,88,1,88,3,88,1709,8,88,1,88,3,88,1712,8,88,1,88,3,88,1715,8,
        88,1,88,1,88,1,88,1,88,3,88,1721,8,88,1,88,1,88,1,88,1,88,1,88,1,
        88,3,88,1729,8,88,1,88,1,88,1,88,3,88,1734,8,88,1,88,1,88,1,88,1,
        88,1,88,1,88,1,88,3,88,1743,8,88,1,88,1,88,3,88,1747,8,88,1,88,1,
        88,1,88,1,88,5,88,1753,8,88,10,88,12,88,1756,9,88,1,88,1,88,1,88,
        1,88,1,88,1,88,1,88,1,88,1,88,1,88,1,88,1,88,1,88,3,88,1771,8,88,
        1,88,1,88,1,88,1,88,3,88,1777,8,88,1,89,1,89,1,89,1,89,3,89,1783,
        8,89,1,89,1,89,1,89,3,89,1788,8,89,5,89,1790,8,89,10,89,12,89,1793,
        9,89,1,89,1,89,1,89,1,89,1,89,1,89,3,89,1801,8,89,1,89,1,89,1,89,
        3,89,1806,8,89,5,89,1808,8,89,10,89,12,89,1811,9,89,1,89,1,89,1,
        89,1,89,1,89,1,89,1,89,1,89,5,89,1821,8,89,10,89,12,89,1824,9,89,
        3,89,1826,8,89,1,90,1,90,3,90,1830,8,90,1,90,1,90,1,90,1,90,1,90,
        1,91,1,91,1,91,1,91,1,91,1,91,1,91,3,91,1844,8,91,1,91,1,91,1,91,
        1,92,1,92,1,92,3,92,1852,8,92,1,93,1,93,1,93,1,93,5,93,1858,8,93,
        10,93,12,93,1861,9,93,1,93,1,93,1,94,1,94,1,94,1,94,1,94,1,94,1,
        95,1,95,1,96,1,96,1,96,5,96,1876,8,96,10,96,12,96,1879,9,96,1,96,
        3,96,1882,8,96,1,97,1,97,1,97,1,97,1,97,1,98,1,98,1,99,1,99,1,99,
        1,99,1,99,1,99,1,99,1,99,1,99,1,99,5,99,1901,8,99,10,99,12,99,1904,
        9,99,1,99,1,99,1,99,1,99,1,99,1,99,1,99,5,99,1913,8,99,10,99,12,
        99,1916,9,99,1,99,1,99,1,99,1,99,1,99,1,99,1,99,1,99,1,99,3,99,1927,
        8,99,1,100,1,100,1,100,1,100,1,100,5,100,1934,8,100,10,100,12,100,
        1937,9,100,1,100,1,100,1,101,1,101,1,101,1,101,1,101,5,101,1946,
        8,101,10,101,12,101,1949,9,101,1,101,1,101,1,102,1,102,1,103,1,103,
        1,103,1,103,1,103,1,103,1,103,3,103,1962,8,103,3,103,1964,8,103,
        1,103,1,103,3,103,1968,8,103,1,104,1,104,1,104,1,104,1,105,1,105,
        1,105,1,105,1,106,1,106,1,106,1,106,1,106,3,106,1983,8,106,1,107,
        1,107,1,107,1,107,3,107,1989,8,107,1,107,1,107,1,107,3,107,1994,
        8,107,1,108,3,108,1997,8,108,1,108,3,108,2000,8,108,1,108,1,108,
        1,108,1,108,3,108,2006,8,108,1,108,1,108,1,108,1,108,3,108,2012,
        8,108,1,109,1,109,1,109,1,109,1,109,1,109,1,109,1,109,1,109,1,109,
        1,109,1,109,1,109,1,109,1,109,3,109,2029,8,109,1,110,1,110,1,111,
        1,111,1,111,1,111,1,111,1,112,1,112,1,112,1,112,1,112,1,112,1,112,
        5,112,2045,8,112,10,112,12,112,2048,9,112,1,112,1,112,3,112,2052,
        8,112,1,113,1,113,1,113,1,114,1,114,1,114,1,114,1,114,3,114,2062,
        8,114,1,114,1,114,1,114,1,114,1,114,1,114,3,114,2070,8,114,1,114,
        1,114,1,114,1,114,1,114,1,114,1,114,3,114,2079,8,114,1,114,1,114,
        1,114,1,114,3,114,2085,8,114,1,114,3,114,2088,8,114,1,115,1,115,
        1,115,1,115,3,115,2094,8,115,1,116,1,116,1,116,1,116,1,116,5,116,
        2101,8,116,10,116,12,116,2104,9,116,1,117,1,117,1,117,1,117,1,117,
        5,117,2111,8,117,10,117,12,117,2114,9,117,1,118,1,118,1,118,1,118,
        1,118,5,118,2121,8,118,10,118,12,118,2124,9,118,1,119,1,119,1,119,
        1,119,1,119,5,119,2131,8,119,10,119,12,119,2134,9,119,1,119,1,119,
        3,119,2138,8,119,1,120,1,120,1,120,5,120,2143,8,120,10,120,12,120,
        2146,9,120,1,120,1,120,1,120,1,120,1,120,1,120,1,120,5,120,2155,
        8,120,10,120,12,120,2158,9,120,1,120,1,120,1,120,1,120,1,120,1,120,
        1,120,5,120,2167,8,120,10,120,12,120,2170,9,120,1,120,1,120,1,120,
        1,120,1,120,1,120,1,120,5,120,2179,8,120,10,120,12,120,2182,9,120,
        1,120,1,120,3,120,2186,8,120,1,121,1,121,1,121,1,122,1,122,1,123,
        1,123,1,123,1,123,1,123,1,123,1,123,1,124,1,124,1,125,1,125,1,126,
        1,126,1,126,1,127,1,127,1,127,1,127,5,127,2211,8,127,10,127,12,127,
        2214,9,127,1,128,1,128,1,128,1,128,1,129,3,129,2221,8,129,1,129,
        1,129,3,129,2225,8,129,1,129,3,129,2228,8,129,1,129,3,129,2231,8,
        129,1,129,3,129,2234,8,129,1,129,1,129,1,130,1,130,1,130,3,130,2241,
        8,130,1,130,3,130,2244,8,130,1,130,3,130,2247,8,130,1,130,3,130,
        2250,8,130,1,130,3,130,2253,8,130,1,130,3,130,2256,8,130,1,130,3,
        130,2259,8,130,1,130,1,130,1,130,3,130,2264,8,130,1,130,3,130,2267,
        8,130,1,131,1,131,1,131,1,131,1,131,5,131,2274,8,131,10,131,12,131,
        2277,9,131,1,132,1,132,1,132,1,132,1,132,5,132,2284,8,132,10,132,
        12,132,2287,9,132,1,133,1,133,3,133,2291,8,133,1,133,1,133,3,133,
        2295,8,133,1,134,1,134,1,134,3,134,2300,8,134,1,135,1,135,1,135,
        3,135,2305,8,135,1,136,1,136,1,136,1,136,1,136,5,136,2312,8,136,
        10,136,12,136,2315,9,136,1,137,1,137,1,137,1,137,1,137,1,137,1,137,
        1,137,1,137,1,137,1,137,1,137,1,137,1,137,1,137,1,137,3,137,2333,
        8,137,1,138,1,138,1,138,1,138,5,138,2339,8,138,10,138,12,138,2342,
        9,138,1,139,1,139,1,139,4,139,2347,8,139,11,139,12,139,2348,1,139,
        1,139,3,139,2353,8,139,1,140,1,140,3,140,2357,8,140,1,141,1,141,
        1,141,1,141,1,141,1,141,1,141,1,141,3,141,2367,8,141,1,142,1,142,
        1,142,1,142,1,142,1,142,1,142,1,142,1,142,1,142,1,142,1,142,1,142,
        1,142,1,142,1,142,1,142,1,142,1,142,1,142,1,142,1,142,1,142,1,142,
        3,142,2393,8,142,1,143,1,143,1,143,1,143,5,143,2399,8,143,10,143,
        12,143,2402,9,143,1,144,1,144,1,144,1,144,1,144,1,144,1,144,1,144,
        1,144,3,144,2413,8,144,1,145,1,145,1,145,1,145,1,145,1,146,1,146,
        1,146,1,147,1,147,1,147,1,147,1,148,1,148,1,148,1,148,1,149,1,149,
        1,149,3,149,2434,8,149,1,149,1,149,1,149,3,149,2439,8,149,5,149,
        2441,8,149,10,149,12,149,2444,9,149,1,149,1,149,1,150,1,150,1,150,
        1,150,1,150,1,150,5,150,2454,8,150,10,150,12,150,2457,9,150,1,150,
        1,150,3,150,2461,8,150,1,151,1,151,3,151,2465,8,151,1,152,1,152,
        1,152,1,152,5,152,2471,8,152,10,152,12,152,2474,9,152,1,152,3,152,
        2477,8,152,1,153,1,153,1,153,3,153,2482,8,153,1,153,1,153,1,153,
        1,153,3,153,2488,8,153,1,153,3,153,2491,8,153,1,154,1,154,1,154,
        1,155,1,155,1,155,1,155,3,155,2500,8,155,1,156,1,156,1,156,3,156,
        2505,8,156,1,157,1,157,1,157,1,157,5,157,2511,8,157,10,157,12,157,
        2514,9,157,1,157,1,157,1,158,1,158,1,158,3,158,2521,8,158,1,158,
        3,158,2524,8,158,1,159,1,159,1,160,1,160,1,160,1,160,1,160,1,160,
        1,160,1,160,1,160,1,160,3,160,2538,8,160,1,160,1,160,1,160,3,160,
        2543,8,160,1,161,1,161,3,161,2547,8,161,1,161,1,161,1,161,1,161,
        1,161,1,161,1,162,1,162,1,163,1,163,1,163,1,163,5,163,2561,8,163,
        10,163,12,163,2564,9,163,1,164,1,164,1,164,1,164,5,164,2570,8,164,
        10,164,12,164,2573,9,164,1,164,1,164,1,165,1,165,1,165,1,165,1,166,
        1,166,1,166,1,166,3,166,2585,8,166,1,166,1,166,1,167,1,167,1,167,
        1,167,3,167,2593,8,167,1,167,1,167,1,168,1,168,1,168,1,168,5,168,
        2601,8,168,10,168,12,168,2604,9,168,1,168,1,168,1,169,1,169,1,169,
        1,169,1,169,1,169,1,169,1,170,1,170,1,170,1,170,1,170,1,170,1,170,
        5,170,2622,8,170,10,170,12,170,2625,9,170,1,170,1,170,1,171,1,171,
        1,171,1,171,1,171,1,171,1,171,1,171,1,171,5,171,2638,8,171,10,171,
        12,171,2641,9,171,1,171,1,171,1,172,1,172,3,172,2647,8,172,1,172,
        1,172,1,172,1,172,3,172,2653,8,172,1,172,3,172,2656,8,172,1,172,
        3,172,2659,8,172,1,173,1,173,1,173,1,174,1,174,1,174,1,174,1,174,
        3,174,2669,8,174,1,174,3,174,2672,8,174,1,175,1,175,1,176,1,176,
        1,176,1,176,3,176,2680,8,176,1,177,1,177,3,177,2684,8,177,1,178,
        1,178,1,178,3,178,2689,8,178,1,178,1,178,1,178,3,178,2694,8,178,
        5,178,2696,8,178,10,178,12,178,2699,9,178,1,178,1,178,1,179,1,179,
        1,179,3,179,2706,8,179,1,179,1,179,3,179,2710,8,179,1,179,1,179,
        3,179,2714,8,179,1,179,1,179,3,179,2718,8,179,1,179,1,179,3,179,
        2722,8,179,1,179,1,179,3,179,2726,8,179,1,179,1,179,3,179,2730,8,
        179,1,179,1,179,3,179,2734,8,179,1,179,1,179,3,179,2738,8,179,1,
        179,1,179,3,179,2742,8,179,1,179,1,179,3,179,2746,8,179,1,179,1,
        179,3,179,2750,8,179,1,179,1,179,3,179,2754,8,179,1,179,1,179,3,
        179,2758,8,179,1,179,1,179,3,179,2762,8,179,1,179,1,179,3,179,2766,
        8,179,1,179,1,179,3,179,2770,8,179,1,179,1,179,1,179,1,179,3,179,
        2776,8,179,3,179,2778,8,179,1,180,1,180,1,181,1,181,1,181,1,181,
        1,181,1,181,1,181,1,181,1,181,1,181,3,181,2792,8,181,3,181,2794,
        8,181,1,181,1,181,1,181,1,181,1,181,1,181,1,181,1,181,1,181,3,181,
        2805,8,181,1,181,5,181,2808,8,181,10,181,12,181,2811,9,181,1,182,
        3,182,2814,8,182,1,182,1,182,3,182,2818,8,182,1,182,1,182,1,182,
        1,182,1,182,3,182,2825,8,182,1,182,1,182,1,182,1,182,1,182,5,182,
        2832,8,182,10,182,12,182,2835,9,182,1,182,1,182,1,182,3,182,2840,
        8,182,1,182,1,182,1,182,1,182,1,182,1,182,1,182,1,182,1,182,1,182,
        1,182,3,182,2853,8,182,1,182,1,182,1,182,1,182,1,182,3,182,2860,
        8,182,1,182,1,182,1,182,3,182,2865,8,182,1,182,1,182,1,182,1,182,
        3,182,2871,8,182,1,182,1,182,1,182,1,182,1,182,3,182,2878,8,182,
        3,182,2880,8,182,1,183,3,183,2883,8,183,1,183,1,183,1,183,1,183,
        1,183,1,183,1,183,1,183,5,183,2893,8,183,10,183,12,183,2896,9,183,
        1,183,1,183,3,183,2900,8,183,1,183,3,183,2903,8,183,1,183,1,183,
        1,183,1,183,3,183,2909,8,183,1,183,3,183,2912,8,183,1,183,1,183,
        1,183,1,183,3,183,2918,8,183,3,183,2920,8,183,1,184,1,184,1,184,
        1,184,3,184,2926,8,184,1,184,1,184,1,184,1,184,1,184,1,184,1,184,
        1,184,1,184,1,184,1,184,1,184,1,184,1,184,1,184,1,184,1,184,1,184,
        1,184,5,184,2947,8,184,10,184,12,184,2950,9,184,1,185,1,185,1,185,
        4,185,2955,8,185,11,185,12,185,2956,1,185,1,185,3,185,2961,8,185,
        1,185,1,185,1,185,1,185,1,185,4,185,2968,8,185,11,185,12,185,2969,
        1,185,1,185,3,185,2974,8,185,1,185,1,185,1,185,1,185,1,185,1,185,
        1,185,1,185,1,185,1,185,1,185,1,185,1,185,1,185,3,185,2990,8,185,
        1,185,1,185,1,185,1,185,1,185,1,185,1,185,3,185,2999,8,185,1,185,
        1,185,1,185,1,185,1,185,1,185,1,185,1,185,1,185,1,185,1,185,1,185,
        1,185,1,185,1,185,1,185,1,185,1,185,1,185,1,185,1,185,1,185,1,185,
        5,185,3024,8,185,10,185,12,185,3027,9,185,1,185,1,185,1,185,1,185,
        1,185,3,185,3034,8,185,1,185,1,185,1,185,5,185,3039,8,185,10,185,
        12,185,3042,9,185,3,185,3044,8,185,1,185,1,185,1,185,1,185,1,185,
        1,185,1,185,1,185,1,185,1,185,1,185,1,185,3,185,3058,8,185,1,185,
        1,185,1,185,3,185,3063,8,185,1,185,1,185,1,185,1,185,1,185,1,185,
        1,185,3,185,3072,8,185,1,185,1,185,1,185,1,185,1,185,5,185,3079,
        8,185,10,185,12,185,3082,9,185,1,186,1,186,1,186,1,186,3,186,3088,
        8,186,1,187,1,187,1,187,1,187,1,187,5,187,3095,8,187,10,187,12,187,
        3098,9,187,1,187,1,187,1,187,1,187,1,187,1,187,5,187,3106,8,187,
        10,187,12,187,3109,9,187,1,187,1,187,1,188,1,188,1,188,1,188,1,188,
        5,188,3118,8,188,10,188,12,188,3121,9,188,1,188,1,188,1,189,1,189,
        1,189,1,189,1,189,5,189,3130,8,189,10,189,12,189,3133,9,189,1,189,
        1,189,1,190,1,190,1,190,1,190,1,190,1,190,1,190,1,191,1,191,1,191,
        1,191,3,191,3148,8,191,1,192,1,192,1,193,1,193,1,193,3,193,3155,
        8,193,1,194,1,194,1,194,1,194,1,194,1,194,3,194,3163,8,194,1,195,
        1,195,1,195,1,195,1,195,1,195,1,196,1,196,1,197,1,197,1,198,1,198,
        1,198,3,198,3178,8,198,1,199,1,199,1,199,3,199,3183,8,199,1,200,
        1,200,3,200,3187,8,200,1,201,1,201,1,201,4,201,3192,8,201,11,201,
        12,201,3193,1,202,1,202,1,202,3,202,3199,8,202,1,203,1,203,1,203,
        1,203,1,203,1,204,3,204,3207,8,204,1,204,1,204,3,204,3211,8,204,
        1,205,3,205,3214,8,205,1,205,1,205,3,205,3218,8,205,1,206,3,206,
        3221,8,206,1,206,1,206,3,206,3225,8,206,1,207,1,207,1,207,1,208,
        1,208,4,208,3232,8,208,11,208,12,208,3233,1,208,3,208,3237,8,208,
        1,209,1,209,1,209,1,209,1,210,1,210,1,210,5,210,3246,8,210,10,210,
        12,210,3249,9,210,1,211,1,211,1,211,1,211,3,211,3255,8,211,1,212,
        1,212,1,212,1,212,3,212,3261,8,212,1,213,1,213,1,213,1,213,1,213,
        1,214,1,214,1,215,1,215,1,216,1,216,1,216,1,216,1,216,1,217,1,217,
        1,218,1,218,1,219,1,219,1,220,1,220,1,221,1,221,1,222,1,222,1,223,
        1,223,1,223,5,223,3292,8,223,10,223,12,223,3295,9,223,1,224,1,224,
        3,224,3299,8,224,1,224,1,224,1,225,1,225,1,225,1,225,1,226,1,226,
        1,226,1,227,1,227,1,227,1,227,5,227,3314,8,227,10,227,12,227,3317,
        9,227,1,227,1,227,1,228,1,228,1,228,3,228,3324,8,228,1,228,1,228,
        1,229,1,229,1,229,1,229,3,229,3332,8,229,1,230,1,230,1,230,1,230,
        1,230,3,230,3339,8,230,1,231,1,231,1,231,1,231,1,231,3,231,3346,
        8,231,1,232,1,232,1,232,1,232,1,232,1,232,1,232,1,232,1,232,1,232,
        1,232,1,232,1,232,1,232,3,232,3362,8,232,1,233,1,233,1,233,1,233,
        3,233,3368,8,233,1,233,1,233,1,233,1,233,3,233,3374,8,233,1,233,
        3,233,3377,8,233,1,234,1,234,1,234,1,235,1,235,1,236,1,236,1,237,
        1,237,1,238,1,238,1,239,1,239,1,240,1,240,1,241,1,241,1,242,1,242,
        1,243,1,243,1,244,1,244,1,244,0,5,132,172,362,368,370,245,0,2,4,
        6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48,
        50,52,54,56,58,60,62,64,66,68,70,72,74,76,78,80,82,84,86,88,90,92,
        94,96,98,100,102,104,106,108,110,112,114,116,118,120,122,124,126,
        128,130,132,134,136,138,140,142,144,146,148,150,152,154,156,158,
        160,162,164,166,168,170,172,174,176,178,180,182,184,186,188,190,
        192,194,196,198,200,202,204,206,208,210,212,214,216,218,220,222,
        224,226,228,230,232,234,236,238,240,242,244,246,248,250,252,254,
        256,258,260,262,264,266,268,270,272,274,276,278,280,282,284,286,
        288,290,292,294,296,298,300,302,304,306,308,310,312,314,316,318,
        320,322,324,326,328,330,332,334,336,338,340,342,344,346,348,350,
        352,354,356,358,360,362,364,366,368,370,372,374,376,378,380,382,
        384,386,388,390,392,394,396,398,400,402,404,406,408,410,412,414,
        416,418,420,422,424,426,428,430,432,434,436,438,440,442,444,446,
        448,450,452,454,456,458,460,462,464,466,468,470,472,474,476,478,
        480,482,484,486,488,0,51,2,0,8,8,35,35,4,0,256,256,301,301,339,339,
        394,394,2,0,293,293,454,454,3,0,74,74,120,120,141,141,2,0,52,52,
        82,82,2,0,6,6,9,9,2,0,106,106,313,313,4,0,278,278,311,311,338,338,
        430,430,2,0,202,202,266,266,2,0,67,67,136,136,2,0,269,269,365,365,
        2,0,358,358,408,408,5,0,249,249,286,286,321,321,324,325,350,350,
        4,0,265,265,349,349,369,369,383,383,2,0,380,380,393,393,4,0,293,
        293,306,306,327,327,388,388,2,0,45,45,68,68,3,0,282,283,315,316,
        376,377,3,0,27,27,64,64,178,178,5,0,28,28,156,157,164,164,170,170,
        354,354,2,0,248,248,391,391,3,0,64,64,152,152,178,178,2,0,46,46,
        304,304,3,0,24,24,109,109,202,202,3,0,46,46,107,107,304,304,3,0,
        60,60,103,103,194,194,3,0,219,219,254,254,351,351,11,0,11,11,165,
        165,172,172,215,216,229,229,255,255,309,310,403,403,420,420,425,
        425,441,442,2,0,446,446,448,448,4,0,257,258,270,270,288,288,352,
        352,2,0,208,208,343,343,4,0,287,287,351,351,428,428,432,432,2,0,
        210,210,411,411,2,0,202,202,206,206,2,0,328,328,389,389,2,0,384,
        384,389,389,2,0,460,460,485,486,4,0,37,37,483,483,487,487,490,490,
        2,0,485,486,488,488,16,0,10,10,88,88,131,131,154,154,172,173,215,
        215,219,219,254,254,258,258,270,270,288,288,309,310,352,352,403,
        403,420,421,425,425,1,0,485,486,1,0,494,495,2,0,494,494,496,496,
        2,0,32,32,416,416,2,0,493,493,496,496,2,0,287,287,428,428,10,0,90,
        90,92,92,127,127,195,195,256,256,301,301,339,339,342,342,394,394,
        449,449,17,0,17,17,31,31,33,33,41,41,65,65,90,93,97,98,127,127,146,
        146,195,196,199,199,256,256,301,301,339,339,342,342,394,394,449,
        449,6,0,202,202,220,220,266,266,326,326,427,427,483,483,35,0,66,
        66,89,89,127,127,195,195,201,201,208,208,212,212,227,228,236,236,
        238,238,245,245,254,254,282,282,286,286,292,292,298,298,301,301,
        321,321,324,325,327,327,339,339,342,342,349,349,363,363,369,371,
        374,375,380,380,382,383,388,388,394,394,409,410,420,424,429,429,
        435,435,449,449,24,0,4,9,11,11,13,15,17,31,33,40,42,47,49,49,51,
        67,69,77,79,84,86,86,89,98,100,127,129,130,132,144,146,153,155,159,
        161,161,163,172,174,179,181,181,183,195,197,200,332,332,3758,0,490,
        1,0,0,0,2,497,1,0,0,0,4,502,1,0,0,0,6,506,1,0,0,0,8,513,1,0,0,0,
        10,517,1,0,0,0,12,520,1,0,0,0,14,543,1,0,0,0,16,545,1,0,0,0,18,570,
        1,0,0,0,20,572,1,0,0,0,22,611,1,0,0,0,24,613,1,0,0,0,26,622,1,0,
        0,0,28,633,1,0,0,0,30,636,1,0,0,0,32,667,1,0,0,0,34,669,1,0,0,0,
        36,685,1,0,0,0,38,687,1,0,0,0,40,704,1,0,0,0,42,706,1,0,0,0,44,710,
        1,0,0,0,46,724,1,0,0,0,48,758,1,0,0,0,50,760,1,0,0,0,52,765,1,0,
        0,0,54,770,1,0,0,0,56,775,1,0,0,0,58,781,1,0,0,0,60,785,1,0,0,0,
        62,830,1,0,0,0,64,832,1,0,0,0,66,835,1,0,0,0,68,839,1,0,0,0,70,877,
        1,0,0,0,72,933,1,0,0,0,74,935,1,0,0,0,76,997,1,0,0,0,78,999,1,0,
        0,0,80,1010,1,0,0,0,82,1063,1,0,0,0,84,1065,1,0,0,0,86,1070,1,0,
        0,0,88,1086,1,0,0,0,90,1111,1,0,0,0,92,1138,1,0,0,0,94,1149,1,0,
        0,0,96,1163,1,0,0,0,98,1168,1,0,0,0,100,1170,1,0,0,0,102,1177,1,
        0,0,0,104,1180,1,0,0,0,106,1189,1,0,0,0,108,1193,1,0,0,0,110,1197,
        1,0,0,0,112,1212,1,0,0,0,114,1214,1,0,0,0,116,1233,1,0,0,0,118,1239,
        1,0,0,0,120,1290,1,0,0,0,122,1292,1,0,0,0,124,1303,1,0,0,0,126,1306,
        1,0,0,0,128,1309,1,0,0,0,130,1322,1,0,0,0,132,1358,1,0,0,0,134,1383,
        1,0,0,0,136,1395,1,0,0,0,138,1406,1,0,0,0,140,1415,1,0,0,0,142,1434,
        1,0,0,0,144,1492,1,0,0,0,146,1494,1,0,0,0,148,1546,1,0,0,0,150,1548,
        1,0,0,0,152,1553,1,0,0,0,154,1581,1,0,0,0,156,1588,1,0,0,0,158,1613,
        1,0,0,0,160,1617,1,0,0,0,162,1619,1,0,0,0,164,1621,1,0,0,0,166,1623,
        1,0,0,0,168,1626,1,0,0,0,170,1647,1,0,0,0,172,1666,1,0,0,0,174,1699,
        1,0,0,0,176,1776,1,0,0,0,178,1825,1,0,0,0,180,1829,1,0,0,0,182,1836,
        1,0,0,0,184,1848,1,0,0,0,186,1853,1,0,0,0,188,1864,1,0,0,0,190,1870,
        1,0,0,0,192,1872,1,0,0,0,194,1883,1,0,0,0,196,1888,1,0,0,0,198,1926,
        1,0,0,0,200,1928,1,0,0,0,202,1940,1,0,0,0,204,1952,1,0,0,0,206,1954,
        1,0,0,0,208,1969,1,0,0,0,210,1973,1,0,0,0,212,1977,1,0,0,0,214,1988,
        1,0,0,0,216,1996,1,0,0,0,218,2028,1,0,0,0,220,2030,1,0,0,0,222,2032,
        1,0,0,0,224,2051,1,0,0,0,226,2053,1,0,0,0,228,2087,1,0,0,0,230,2093,
        1,0,0,0,232,2095,1,0,0,0,234,2105,1,0,0,0,236,2115,1,0,0,0,238,2125,
        1,0,0,0,240,2185,1,0,0,0,242,2187,1,0,0,0,244,2190,1,0,0,0,246,2192,
        1,0,0,0,248,2199,1,0,0,0,250,2201,1,0,0,0,252,2203,1,0,0,0,254,2206,
        1,0,0,0,256,2215,1,0,0,0,258,2220,1,0,0,0,260,2237,1,0,0,0,262,2268,
        1,0,0,0,264,2278,1,0,0,0,266,2288,1,0,0,0,268,2296,1,0,0,0,270,2301,
        1,0,0,0,272,2306,1,0,0,0,274,2332,1,0,0,0,276,2334,1,0,0,0,278,2343,
        1,0,0,0,280,2354,1,0,0,0,282,2366,1,0,0,0,284,2392,1,0,0,0,286,2394,
        1,0,0,0,288,2412,1,0,0,0,290,2414,1,0,0,0,292,2419,1,0,0,0,294,2422,
        1,0,0,0,296,2426,1,0,0,0,298,2430,1,0,0,0,300,2460,1,0,0,0,302,2464,
        1,0,0,0,304,2466,1,0,0,0,306,2478,1,0,0,0,308,2492,1,0,0,0,310,2499,
        1,0,0,0,312,2504,1,0,0,0,314,2506,1,0,0,0,316,2517,1,0,0,0,318,2525,
        1,0,0,0,320,2542,1,0,0,0,322,2546,1,0,0,0,324,2554,1,0,0,0,326,2556,
        1,0,0,0,328,2565,1,0,0,0,330,2576,1,0,0,0,332,2580,1,0,0,0,334,2588,
        1,0,0,0,336,2596,1,0,0,0,338,2607,1,0,0,0,340,2614,1,0,0,0,342,2628,
        1,0,0,0,344,2658,1,0,0,0,346,2660,1,0,0,0,348,2663,1,0,0,0,350,2673,
        1,0,0,0,352,2675,1,0,0,0,354,2683,1,0,0,0,356,2685,1,0,0,0,358,2777,
        1,0,0,0,360,2779,1,0,0,0,362,2793,1,0,0,0,364,2879,1,0,0,0,366,2919,
        1,0,0,0,368,2925,1,0,0,0,370,3071,1,0,0,0,372,3087,1,0,0,0,374,3089,
        1,0,0,0,376,3112,1,0,0,0,378,3124,1,0,0,0,380,3136,1,0,0,0,382,3147,
        1,0,0,0,384,3149,1,0,0,0,386,3154,1,0,0,0,388,3162,1,0,0,0,390,3164,
        1,0,0,0,392,3170,1,0,0,0,394,3172,1,0,0,0,396,3177,1,0,0,0,398,3179,
        1,0,0,0,400,3184,1,0,0,0,402,3191,1,0,0,0,404,3195,1,0,0,0,406,3200,
        1,0,0,0,408,3210,1,0,0,0,410,3213,1,0,0,0,412,3220,1,0,0,0,414,3226,
        1,0,0,0,416,3236,1,0,0,0,418,3238,1,0,0,0,420,3242,1,0,0,0,422,3254,
        1,0,0,0,424,3260,1,0,0,0,426,3262,1,0,0,0,428,3267,1,0,0,0,430,3269,
        1,0,0,0,432,3271,1,0,0,0,434,3276,1,0,0,0,436,3278,1,0,0,0,438,3280,
        1,0,0,0,440,3282,1,0,0,0,442,3284,1,0,0,0,444,3286,1,0,0,0,446,3288,
        1,0,0,0,448,3296,1,0,0,0,450,3302,1,0,0,0,452,3306,1,0,0,0,454,3309,
        1,0,0,0,456,3320,1,0,0,0,458,3331,1,0,0,0,460,3338,1,0,0,0,462,3345,
        1,0,0,0,464,3361,1,0,0,0,466,3376,1,0,0,0,468,3378,1,0,0,0,470,3381,
        1,0,0,0,472,3383,1,0,0,0,474,3385,1,0,0,0,476,3387,1,0,0,0,478,3389,
        1,0,0,0,480,3391,1,0,0,0,482,3393,1,0,0,0,484,3395,1,0,0,0,486,3397,
        1,0,0,0,488,3399,1,0,0,0,490,491,3,2,1,0,491,492,5,0,0,1,492,1,1,
        0,0,0,493,496,3,4,2,0,494,496,3,6,3,0,495,493,1,0,0,0,495,494,1,
        0,0,0,496,499,1,0,0,0,497,495,1,0,0,0,497,498,1,0,0,0,498,3,1,0,
        0,0,499,497,1,0,0,0,500,503,3,10,5,0,501,503,3,8,4,0,502,500,1,0,
        0,0,502,501,1,0,0,0,503,504,1,0,0,0,504,505,5,476,0,0,505,5,1,0,
        0,0,506,507,5,476,0,0,507,7,1,0,0,0,508,514,3,18,9,0,509,514,3,86,
        43,0,510,514,3,88,44,0,511,514,3,90,45,0,512,514,3,84,42,0,513,508,
        1,0,0,0,513,509,1,0,0,0,513,510,1,0,0,0,513,511,1,0,0,0,513,512,
        1,0,0,0,514,9,1,0,0,0,515,518,3,132,66,0,516,518,3,112,56,0,517,
        515,1,0,0,0,517,516,1,0,0,0,518,11,1,0,0,0,519,521,5,47,0,0,520,
        519,1,0,0,0,520,521,1,0,0,0,521,524,1,0,0,0,522,523,5,303,0,0,523,
        525,5,260,0,0,524,522,1,0,0,0,524,525,1,0,0,0,525,527,1,0,0,0,526,
        528,3,304,152,0,527,526,1,0,0,0,527,528,1,0,0,0,528,534,1,0,0,0,
        529,530,5,365,0,0,530,531,5,471,0,0,531,532,3,456,228,0,532,533,
        5,472,0,0,533,535,1,0,0,0,534,529,1,0,0,0,534,535,1,0,0,0,535,13,
        1,0,0,0,536,544,3,446,223,0,537,538,5,291,0,0,538,540,3,446,223,
        0,539,537,1,0,0,0,539,540,1,0,0,0,540,541,1,0,0,0,541,542,5,328,
        0,0,542,544,3,360,180,0,543,536,1,0,0,0,543,539,1,0,0,0,544,15,1,
        0,0,0,545,548,5,471,0,0,546,549,3,456,228,0,547,549,3,458,229,0,
        548,546,1,0,0,0,548,547,1,0,0,0,549,557,1,0,0,0,550,553,5,475,0,
        0,551,554,3,456,228,0,552,554,3,458,229,0,553,551,1,0,0,0,553,552,
        1,0,0,0,554,556,1,0,0,0,555,550,1,0,0,0,556,559,1,0,0,0,557,555,
        1,0,0,0,557,558,1,0,0,0,558,560,1,0,0,0,559,557,1,0,0,0,560,561,
        5,472,0,0,561,17,1,0,0,0,562,571,3,20,10,0,563,571,3,78,39,0,564,
        571,3,80,40,0,565,571,3,70,35,0,566,571,3,74,37,0,567,571,3,26,13,
        0,568,571,3,44,22,0,569,571,3,60,30,0,570,562,1,0,0,0,570,563,1,
        0,0,0,570,564,1,0,0,0,570,565,1,0,0,0,570,566,1,0,0,0,570,567,1,
        0,0,0,570,568,1,0,0,0,570,569,1,0,0,0,571,19,1,0,0,0,572,574,5,246,
        0,0,573,575,5,169,0,0,574,573,1,0,0,0,574,575,1,0,0,0,575,576,1,
        0,0,0,576,578,5,415,0,0,577,579,3,450,225,0,578,577,1,0,0,0,578,
        579,1,0,0,0,579,580,1,0,0,0,580,584,3,440,220,0,581,583,3,22,11,
        0,582,581,1,0,0,0,583,586,1,0,0,0,584,582,1,0,0,0,584,585,1,0,0,
        0,585,590,1,0,0,0,586,584,1,0,0,0,587,591,3,68,34,0,588,589,5,328,
        0,0,589,591,3,442,221,0,590,587,1,0,0,0,590,588,1,0,0,0,591,595,
        1,0,0,0,592,594,3,22,11,0,593,592,1,0,0,0,594,597,1,0,0,0,595,593,
        1,0,0,0,595,596,1,0,0,0,596,21,1,0,0,0,597,595,1,0,0,0,598,612,3,
        296,148,0,599,612,3,448,224,0,600,612,3,304,152,0,601,612,3,306,
        153,0,602,612,3,230,115,0,603,612,3,42,21,0,604,612,3,54,27,0,605,
        612,3,46,23,0,606,612,3,24,12,0,607,612,3,208,104,0,608,612,3,52,
        26,0,609,612,3,308,154,0,610,612,3,64,32,0,611,598,1,0,0,0,611,599,
        1,0,0,0,611,600,1,0,0,0,611,601,1,0,0,0,611,602,1,0,0,0,611,603,
        1,0,0,0,611,604,1,0,0,0,611,605,1,0,0,0,611,606,1,0,0,0,611,607,
        1,0,0,0,611,608,1,0,0,0,611,609,1,0,0,0,611,610,1,0,0,0,612,23,1,
        0,0,0,613,614,5,402,0,0,614,615,5,222,0,0,615,616,5,471,0,0,616,
        618,3,422,211,0,617,619,7,0,0,0,618,617,1,0,0,0,618,619,1,0,0,0,
        619,620,1,0,0,0,620,621,5,472,0,0,621,25,1,0,0,0,622,623,5,246,0,
        0,623,625,5,415,0,0,624,626,3,450,225,0,625,624,1,0,0,0,625,626,
        1,0,0,0,626,627,1,0,0,0,627,631,3,440,220,0,628,632,3,34,17,0,629,
        632,3,38,19,0,630,632,3,30,15,0,631,628,1,0,0,0,631,629,1,0,0,0,
        631,630,1,0,0,0,632,27,1,0,0,0,633,634,5,416,0,0,634,635,3,454,227,
        0,635,29,1,0,0,0,636,640,3,308,154,0,637,639,3,32,16,0,638,637,1,
        0,0,0,639,642,1,0,0,0,640,638,1,0,0,0,640,641,1,0,0,0,641,644,1,
        0,0,0,642,640,1,0,0,0,643,645,5,209,0,0,644,643,1,0,0,0,644,645,
        1,0,0,0,645,646,1,0,0,0,646,647,3,132,66,0,647,651,1,0,0,0,648,650,
        3,32,16,0,649,648,1,0,0,0,650,653,1,0,0,0,651,649,1,0,0,0,651,652,
        1,0,0,0,652,31,1,0,0,0,653,651,1,0,0,0,654,668,3,296,148,0,655,656,
        5,103,0,0,656,668,3,454,227,0,657,668,3,28,14,0,658,668,3,230,115,
        0,659,668,3,42,21,0,660,661,5,446,0,0,661,662,3,412,206,0,662,663,
        5,473,0,0,663,664,3,132,66,0,664,665,5,472,0,0,665,668,1,0,0,0,666,
        668,3,346,173,0,667,654,1,0,0,0,667,655,1,0,0,0,667,657,1,0,0,0,
        667,658,1,0,0,0,667,659,1,0,0,0,667,660,1,0,0,0,667,666,1,0,0,0,
        668,33,1,0,0,0,669,670,3,68,34,0,670,671,3,308,154,0,671,675,1,0,
        0,0,672,674,3,36,18,0,673,672,1,0,0,0,674,677,1,0,0,0,675,673,1,
        0,0,0,675,676,1,0,0,0,676,35,1,0,0,0,677,675,1,0,0,0,678,686,3,296,
        148,0,679,680,5,103,0,0,680,686,3,454,227,0,681,686,3,28,14,0,682,
        686,3,230,115,0,683,686,3,42,21,0,684,686,3,346,173,0,685,678,1,
        0,0,0,685,679,1,0,0,0,685,681,1,0,0,0,685,682,1,0,0,0,685,683,1,
        0,0,0,685,684,1,0,0,0,686,37,1,0,0,0,687,688,3,308,154,0,688,689,
        5,209,0,0,689,690,3,132,66,0,690,694,1,0,0,0,691,693,3,40,20,0,692,
        691,1,0,0,0,693,696,1,0,0,0,694,692,1,0,0,0,694,695,1,0,0,0,695,
        39,1,0,0,0,696,694,1,0,0,0,697,705,3,296,148,0,698,699,5,103,0,0,
        699,705,3,454,227,0,700,705,3,28,14,0,701,705,3,230,115,0,702,705,
        3,42,21,0,703,705,3,346,173,0,704,697,1,0,0,0,704,698,1,0,0,0,704,
        700,1,0,0,0,704,701,1,0,0,0,704,702,1,0,0,0,704,703,1,0,0,0,705,
        41,1,0,0,0,706,707,5,313,0,0,707,708,5,494,0,0,708,709,5,459,0,0,
        709,43,1,0,0,0,710,712,5,246,0,0,711,713,5,169,0,0,712,711,1,0,0,
        0,712,713,1,0,0,0,713,714,1,0,0,0,714,716,5,415,0,0,715,717,3,450,
        225,0,716,715,1,0,0,0,716,717,1,0,0,0,717,718,1,0,0,0,718,720,3,
        440,220,0,719,721,3,48,24,0,720,719,1,0,0,0,721,722,1,0,0,0,722,
        720,1,0,0,0,722,723,1,0,0,0,723,45,1,0,0,0,724,725,5,108,0,0,725,
        726,5,222,0,0,726,727,5,471,0,0,727,729,5,496,0,0,728,730,3,384,
        192,0,729,728,1,0,0,0,729,730,1,0,0,0,730,738,1,0,0,0,731,732,5,
        475,0,0,732,734,5,496,0,0,733,735,3,384,192,0,734,733,1,0,0,0,734,
        735,1,0,0,0,735,737,1,0,0,0,736,731,1,0,0,0,737,740,1,0,0,0,738,
        736,1,0,0,0,738,739,1,0,0,0,739,741,1,0,0,0,740,738,1,0,0,0,741,
        742,5,472,0,0,742,47,1,0,0,0,743,759,3,54,27,0,744,745,5,209,0,0,
        745,759,3,132,66,0,746,759,3,68,34,0,747,759,3,46,23,0,748,759,3,
        448,224,0,749,759,3,304,152,0,750,759,3,230,115,0,751,759,3,346,
        173,0,752,759,3,66,33,0,753,759,3,52,26,0,754,759,3,28,14,0,755,
        759,3,56,28,0,756,759,3,58,29,0,757,759,3,50,25,0,758,743,1,0,0,
        0,758,744,1,0,0,0,758,746,1,0,0,0,758,747,1,0,0,0,758,748,1,0,0,
        0,758,749,1,0,0,0,758,750,1,0,0,0,758,751,1,0,0,0,758,752,1,0,0,
        0,758,753,1,0,0,0,758,754,1,0,0,0,758,755,1,0,0,0,758,756,1,0,0,
        0,758,757,1,0,0,0,759,49,1,0,0,0,760,761,5,392,0,0,761,762,5,54,
        0,0,762,763,5,397,0,0,763,764,3,472,236,0,764,51,1,0,0,0,765,766,
        5,289,0,0,766,767,5,418,0,0,767,768,5,222,0,0,768,769,3,472,236,
        0,769,53,1,0,0,0,770,771,5,401,0,0,771,773,5,209,0,0,772,774,3,422,
        211,0,773,772,1,0,0,0,773,774,1,0,0,0,774,55,1,0,0,0,775,776,5,401,
        0,0,776,777,5,209,0,0,777,779,5,305,0,0,778,780,3,422,211,0,779,
        778,1,0,0,0,779,780,1,0,0,0,780,57,1,0,0,0,781,783,5,361,0,0,782,
        784,3,422,211,0,783,782,1,0,0,0,783,784,1,0,0,0,784,59,1,0,0,0,785,
        786,5,246,0,0,786,787,5,284,0,0,787,789,5,415,0,0,788,790,3,450,
        225,0,789,788,1,0,0,0,789,790,1,0,0,0,790,791,1,0,0,0,791,792,3,
        440,220,0,792,794,3,68,34,0,793,795,3,62,31,0,794,793,1,0,0,0,795,
        796,1,0,0,0,796,794,1,0,0,0,796,797,1,0,0,0,797,61,1,0,0,0,798,831,
        3,66,33,0,799,831,3,52,26,0,800,801,5,392,0,0,801,802,5,54,0,0,802,
        803,5,397,0,0,803,831,3,472,236,0,804,805,5,329,0,0,805,806,5,418,
        0,0,806,807,5,222,0,0,807,831,3,472,236,0,808,809,5,351,0,0,809,
        810,5,34,0,0,810,811,5,209,0,0,811,831,3,472,236,0,812,813,5,277,
        0,0,813,814,5,222,0,0,814,831,3,472,236,0,815,816,5,253,0,0,816,
        817,5,317,0,0,817,818,5,418,0,0,818,819,5,222,0,0,819,831,3,472,
        236,0,820,831,3,54,27,0,821,831,3,56,28,0,822,831,3,58,29,0,823,
        831,3,64,32,0,824,825,5,89,0,0,825,826,5,78,0,0,826,827,5,418,0,
        0,827,828,5,222,0,0,828,831,3,472,236,0,829,831,3,50,25,0,830,798,
        1,0,0,0,830,799,1,0,0,0,830,800,1,0,0,0,830,804,1,0,0,0,830,808,
        1,0,0,0,830,812,1,0,0,0,830,815,1,0,0,0,830,820,1,0,0,0,830,821,
        1,0,0,0,830,822,1,0,0,0,830,823,1,0,0,0,830,824,1,0,0,0,830,829,
        1,0,0,0,831,63,1,0,0,0,832,833,5,87,0,0,833,834,3,96,48,0,834,65,
        1,0,0,0,835,836,5,392,0,0,836,837,5,54,0,0,837,838,5,263,0,0,838,
        67,1,0,0,0,839,840,5,471,0,0,840,842,3,312,156,0,841,843,3,346,173,
        0,842,841,1,0,0,0,842,843,1,0,0,0,843,851,1,0,0,0,844,845,5,475,
        0,0,845,847,3,312,156,0,846,848,3,346,173,0,847,846,1,0,0,0,847,
        848,1,0,0,0,848,850,1,0,0,0,849,844,1,0,0,0,850,853,1,0,0,0,851,
        849,1,0,0,0,851,852,1,0,0,0,852,859,1,0,0,0,853,851,1,0,0,0,854,
        855,5,475,0,0,855,857,3,320,160,0,856,858,3,346,173,0,857,856,1,
        0,0,0,857,858,1,0,0,0,858,860,1,0,0,0,859,854,1,0,0,0,859,860,1,
        0,0,0,860,866,1,0,0,0,861,862,5,475,0,0,862,864,3,322,161,0,863,
        865,3,346,173,0,864,863,1,0,0,0,864,865,1,0,0,0,865,867,1,0,0,0,
        866,861,1,0,0,0,866,867,1,0,0,0,867,873,1,0,0,0,868,869,5,475,0,
        0,869,871,3,294,147,0,870,872,3,346,173,0,871,870,1,0,0,0,871,872,
        1,0,0,0,872,874,1,0,0,0,873,868,1,0,0,0,873,874,1,0,0,0,874,875,
        1,0,0,0,875,876,5,472,0,0,876,69,1,0,0,0,877,879,5,246,0,0,878,880,
        5,169,0,0,879,878,1,0,0,0,879,880,1,0,0,0,880,881,1,0,0,0,881,883,
        5,415,0,0,882,884,3,450,225,0,883,882,1,0,0,0,883,884,1,0,0,0,884,
        885,1,0,0,0,885,889,3,440,220,0,886,888,3,72,36,0,887,886,1,0,0,
        0,888,891,1,0,0,0,889,887,1,0,0,0,889,890,1,0,0,0,890,892,1,0,0,
        0,891,889,1,0,0,0,892,893,5,392,0,0,893,894,5,54,0,0,894,895,5,397,
        0,0,895,899,3,458,229,0,896,898,3,72,36,0,897,896,1,0,0,0,898,901,
        1,0,0,0,899,897,1,0,0,0,899,900,1,0,0,0,900,902,1,0,0,0,901,899,
        1,0,0,0,902,903,5,402,0,0,903,904,5,209,0,0,904,905,5,305,0,0,905,
        909,3,458,229,0,906,908,3,72,36,0,907,906,1,0,0,0,908,911,1,0,0,
        0,909,907,1,0,0,0,909,910,1,0,0,0,910,912,1,0,0,0,911,909,1,0,0,
        0,912,913,5,361,0,0,913,917,3,458,229,0,914,916,3,72,36,0,915,914,
        1,0,0,0,916,919,1,0,0,0,917,915,1,0,0,0,917,918,1,0,0,0,918,920,
        1,0,0,0,919,917,1,0,0,0,920,924,3,28,14,0,921,923,3,72,36,0,922,
        921,1,0,0,0,923,926,1,0,0,0,924,922,1,0,0,0,924,925,1,0,0,0,925,
        71,1,0,0,0,926,924,1,0,0,0,927,934,3,68,34,0,928,934,3,346,173,0,
        929,934,3,296,148,0,930,934,3,448,224,0,931,934,3,304,152,0,932,
        934,3,306,153,0,933,927,1,0,0,0,933,928,1,0,0,0,933,929,1,0,0,0,
        933,930,1,0,0,0,933,931,1,0,0,0,933,932,1,0,0,0,934,73,1,0,0,0,935,
        936,5,246,0,0,936,937,5,284,0,0,937,939,5,415,0,0,938,940,3,450,
        225,0,939,938,1,0,0,0,939,940,1,0,0,0,940,941,1,0,0,0,941,945,3,
        440,220,0,942,944,3,76,38,0,943,942,1,0,0,0,944,947,1,0,0,0,945,
        943,1,0,0,0,945,946,1,0,0,0,946,948,1,0,0,0,947,945,1,0,0,0,948,
        952,3,68,34,0,949,951,3,76,38,0,950,949,1,0,0,0,951,954,1,0,0,0,
        952,950,1,0,0,0,952,953,1,0,0,0,953,955,1,0,0,0,954,952,1,0,0,0,
        955,956,5,392,0,0,956,957,5,54,0,0,957,958,5,397,0,0,958,962,3,458,
        229,0,959,961,3,76,38,0,960,959,1,0,0,0,961,964,1,0,0,0,962,960,
        1,0,0,0,962,963,1,0,0,0,963,965,1,0,0,0,964,962,1,0,0,0,965,966,
        5,402,0,0,966,967,5,209,0,0,967,968,5,305,0,0,968,972,3,458,229,
        0,969,971,3,76,38,0,970,969,1,0,0,0,971,974,1,0,0,0,972,970,1,0,
        0,0,972,973,1,0,0,0,973,975,1,0,0,0,974,972,1,0,0,0,975,976,5,361,
        0,0,976,980,3,458,229,0,977,979,3,76,38,0,978,977,1,0,0,0,979,982,
        1,0,0,0,980,978,1,0,0,0,980,981,1,0,0,0,981,983,1,0,0,0,982,980,
        1,0,0,0,983,984,5,87,0,0,984,988,3,96,48,0,985,987,3,76,38,0,986,
        985,1,0,0,0,987,990,1,0,0,0,988,986,1,0,0,0,988,989,1,0,0,0,989,
        75,1,0,0,0,990,988,1,0,0,0,991,998,3,346,173,0,992,998,3,296,148,
        0,993,998,3,448,224,0,994,998,3,304,152,0,995,998,3,306,153,0,996,
        998,3,28,14,0,997,991,1,0,0,0,997,992,1,0,0,0,997,993,1,0,0,0,997,
        994,1,0,0,0,997,995,1,0,0,0,997,996,1,0,0,0,998,77,1,0,0,0,999,1000,
        5,246,0,0,1000,1002,5,415,0,0,1001,1003,3,450,225,0,1002,1001,1,
        0,0,0,1002,1003,1,0,0,0,1003,1004,1,0,0,0,1004,1005,3,440,220,0,
        1005,1008,3,448,224,0,1006,1007,5,209,0,0,1007,1009,3,132,66,0,1008,
        1006,1,0,0,0,1008,1009,1,0,0,0,1009,79,1,0,0,0,1010,1011,5,246,0,
        0,1011,1012,5,450,0,0,1012,1013,5,415,0,0,1013,1017,3,440,220,0,
        1014,1016,3,82,41,0,1015,1014,1,0,0,0,1016,1019,1,0,0,0,1017,1015,
        1,0,0,0,1017,1018,1,0,0,0,1018,1020,1,0,0,0,1019,1017,1,0,0,0,1020,
        1021,5,471,0,0,1021,1022,5,378,0,0,1022,1023,5,77,0,0,1023,1024,
        5,471,0,0,1024,1029,3,422,211,0,1025,1026,5,475,0,0,1026,1028,3,
        422,211,0,1027,1025,1,0,0,0,1028,1031,1,0,0,0,1029,1027,1,0,0,0,
        1029,1030,1,0,0,0,1030,1032,1,0,0,0,1031,1029,1,0,0,0,1032,1035,
        5,472,0,0,1033,1034,5,348,0,0,1034,1036,5,39,0,0,1035,1033,1,0,0,
        0,1035,1036,1,0,0,0,1036,1037,1,0,0,0,1037,1041,5,472,0,0,1038,1040,
        3,82,41,0,1039,1038,1,0,0,0,1040,1043,1,0,0,0,1041,1039,1,0,0,0,
        1041,1042,1,0,0,0,1042,1044,1,0,0,0,1043,1041,1,0,0,0,1044,1045,
        5,451,0,0,1045,1046,5,464,0,0,1046,1047,5,312,0,0,1047,1048,3,422,
        211,0,1048,1049,7,1,0,0,1049,1053,1,0,0,0,1050,1052,3,82,41,0,1051,
        1050,1,0,0,0,1052,1055,1,0,0,0,1053,1051,1,0,0,0,1053,1054,1,0,0,
        0,1054,81,1,0,0,0,1055,1053,1,0,0,0,1056,1064,3,296,148,0,1057,1064,
        3,448,224,0,1058,1059,5,452,0,0,1059,1060,5,464,0,0,1060,1064,7,
        2,0,0,1061,1062,5,209,0,0,1062,1064,3,132,66,0,1063,1056,1,0,0,0,
        1063,1057,1,0,0,0,1063,1058,1,0,0,0,1063,1061,1,0,0,0,1064,83,1,
        0,0,0,1065,1066,5,246,0,0,1066,1067,5,14,0,0,1067,1068,3,446,223,
        0,1068,1069,3,448,224,0,1069,85,1,0,0,0,1070,1071,5,246,0,0,1071,
        1073,5,29,0,0,1072,1074,3,450,225,0,1073,1072,1,0,0,0,1073,1074,
        1,0,0,0,1074,1075,1,0,0,0,1075,1077,3,438,219,0,1076,1078,3,346,
        173,0,1077,1076,1,0,0,0,1077,1078,1,0,0,0,1078,1081,1,0,0,0,1079,
        1080,5,87,0,0,1080,1082,5,493,0,0,1081,1079,1,0,0,0,1081,1082,1,
        0,0,0,1082,1084,1,0,0,0,1083,1085,3,448,224,0,1084,1083,1,0,0,0,
        1084,1085,1,0,0,0,1085,87,1,0,0,0,1086,1089,5,246,0,0,1087,1088,
        5,357,0,0,1088,1090,5,135,0,0,1089,1087,1,0,0,0,1089,1090,1,0,0,
        0,1090,1095,1,0,0,0,1091,1093,5,295,0,0,1092,1091,1,0,0,0,1092,1093,
        1,0,0,0,1093,1094,1,0,0,0,1094,1096,5,169,0,0,1095,1092,1,0,0,0,
        1095,1096,1,0,0,0,1096,1097,1,0,0,0,1097,1099,5,190,0,0,1098,1100,
        3,450,225,0,1099,1098,1,0,0,0,1099,1100,1,0,0,0,1100,1101,1,0,0,
        0,1101,1103,3,446,223,0,1102,1104,3,356,178,0,1103,1102,1,0,0,0,
        1103,1104,1,0,0,0,1104,1106,1,0,0,0,1105,1107,3,346,173,0,1106,1105,
        1,0,0,0,1106,1107,1,0,0,0,1107,1108,1,0,0,0,1108,1109,5,209,0,0,
        1109,1110,3,132,66,0,1110,89,1,0,0,0,1111,1114,5,246,0,0,1112,1113,
        5,357,0,0,1113,1115,5,135,0,0,1114,1112,1,0,0,0,1114,1115,1,0,0,
        0,1115,1119,1,0,0,0,1116,1120,5,169,0,0,1117,1118,5,169,0,0,1118,
        1120,5,412,0,0,1119,1116,1,0,0,0,1119,1117,1,0,0,0,1119,1120,1,0,
        0,0,1120,1121,1,0,0,0,1121,1123,5,294,0,0,1122,1124,3,450,225,0,
        1123,1122,1,0,0,0,1123,1124,1,0,0,0,1124,1125,1,0,0,0,1125,1126,
        3,386,193,0,1126,1127,5,209,0,0,1127,1136,3,422,211,0,1128,1129,
        5,322,0,0,1129,1131,7,3,0,0,1130,1128,1,0,0,0,1130,1131,1,0,0,0,
        1131,1132,1,0,0,0,1132,1137,3,92,46,0,1133,1134,5,438,0,0,1134,1135,
        5,72,0,0,1135,1137,3,94,47,0,1136,1130,1,0,0,0,1136,1133,1,0,0,0,
        1136,1137,1,0,0,0,1137,91,1,0,0,0,1138,1139,5,438,0,0,1139,1140,
        5,72,0,0,1140,1146,3,94,47,0,1141,1142,5,475,0,0,1142,1143,5,72,
        0,0,1143,1145,3,94,47,0,1144,1141,1,0,0,0,1145,1148,1,0,0,0,1146,
        1144,1,0,0,0,1146,1147,1,0,0,0,1147,93,1,0,0,0,1148,1146,1,0,0,0,
        1149,1152,3,96,48,0,1150,1151,5,468,0,0,1151,1153,5,72,0,0,1152,
        1150,1,0,0,0,1152,1153,1,0,0,0,1153,95,1,0,0,0,1154,1164,5,493,0,
        0,1155,1157,5,490,0,0,1156,1158,5,496,0,0,1157,1156,1,0,0,0,1157,
        1158,1,0,0,0,1158,1160,1,0,0,0,1159,1155,1,0,0,0,1160,1161,1,0,0,
        0,1161,1159,1,0,0,0,1161,1162,1,0,0,0,1162,1164,1,0,0,0,1163,1154,
        1,0,0,0,1163,1159,1,0,0,0,1164,97,1,0,0,0,1165,1169,7,4,0,0,1166,
        1167,7,5,0,0,1167,1169,3,446,223,0,1168,1165,1,0,0,0,1168,1166,1,
        0,0,0,1169,99,1,0,0,0,1170,1172,5,134,0,0,1171,1173,3,446,223,0,
        1172,1171,1,0,0,0,1172,1173,1,0,0,0,1173,1174,1,0,0,0,1174,1175,
        5,426,0,0,1175,1176,3,446,223,0,1176,101,1,0,0,0,1177,1178,5,396,
        0,0,1178,1179,3,454,227,0,1179,103,1,0,0,0,1180,1181,5,4,0,0,1181,
        1182,5,242,0,0,1182,1183,3,324,162,0,1183,1184,5,378,0,0,1184,1185,
        5,77,0,0,1185,1187,3,356,178,0,1186,1188,3,110,55,0,1187,1186,1,
        0,0,0,1187,1188,1,0,0,0,1188,105,1,0,0,0,1189,1190,5,271,0,0,1190,
        1191,5,242,0,0,1191,1192,3,324,162,0,1192,107,1,0,0,0,1193,1194,
        5,4,0,0,1194,1195,5,431,0,0,1195,1196,3,356,178,0,1196,109,1,0,0,
        0,1197,1198,5,348,0,0,1198,1199,5,39,0,0,1199,111,1,0,0,0,1200,1202,
        5,279,0,0,1201,1200,1,0,0,0,1201,1202,1,0,0,0,1202,1203,1,0,0,0,
        1203,1208,3,114,57,0,1204,1208,3,118,59,0,1205,1208,3,122,61,0,1206,
        1208,3,116,58,0,1207,1201,1,0,0,0,1207,1204,1,0,0,0,1207,1205,1,
        0,0,0,1207,1206,1,0,0,0,1208,1213,1,0,0,0,1209,1213,3,128,64,0,1210,
        1211,5,279,0,0,1211,1213,3,130,65,0,1212,1207,1,0,0,0,1212,1209,
        1,0,0,0,1212,1210,1,0,0,0,1213,113,1,0,0,0,1214,1215,5,308,0,0,1215,
        1216,7,6,0,0,1216,1218,3,442,221,0,1217,1219,3,126,63,0,1218,1217,
        1,0,0,0,1218,1219,1,0,0,0,1219,1221,1,0,0,0,1220,1222,3,356,178,
        0,1221,1220,1,0,0,0,1221,1222,1,0,0,0,1222,1231,1,0,0,0,1223,1232,
        3,132,66,0,1224,1232,3,326,163,0,1225,1226,5,135,0,0,1226,1227,3,
        226,113,0,1227,1228,3,144,72,0,1228,1232,1,0,0,0,1229,1230,5,415,
        0,0,1230,1232,3,442,221,0,1231,1223,1,0,0,0,1231,1224,1,0,0,0,1231,
        1225,1,0,0,0,1231,1229,1,0,0,0,1232,115,1,0,0,0,1233,1234,5,308,
        0,0,1234,1235,7,6,0,0,1235,1236,3,442,221,0,1236,1237,5,415,0,0,
        1237,1238,3,442,221,0,1238,117,1,0,0,0,1239,1240,5,308,0,0,1240,
        1241,5,106,0,0,1241,1242,5,267,0,0,1242,1243,3,120,60,0,1243,119,
        1,0,0,0,1244,1246,3,96,48,0,1245,1244,1,0,0,0,1245,1246,1,0,0,0,
        1246,1247,1,0,0,0,1247,1248,5,438,0,0,1248,1249,5,496,0,0,1249,1250,
        5,103,0,0,1250,1251,5,471,0,0,1251,1253,3,354,177,0,1252,1254,3,
        466,233,0,1253,1252,1,0,0,0,1253,1254,1,0,0,0,1254,1262,1,0,0,0,
        1255,1256,5,475,0,0,1256,1258,3,354,177,0,1257,1259,3,466,233,0,
        1258,1257,1,0,0,0,1258,1259,1,0,0,0,1259,1261,1,0,0,0,1260,1255,
        1,0,0,0,1261,1264,1,0,0,0,1262,1260,1,0,0,0,1262,1263,1,0,0,0,1263,
        1265,1,0,0,0,1264,1262,1,0,0,0,1265,1266,5,472,0,0,1266,1267,3,132,
        66,0,1267,1291,1,0,0,0,1268,1269,5,438,0,0,1269,1270,5,496,0,0,1270,
        1271,5,103,0,0,1271,1276,5,471,0,0,1272,1274,5,493,0,0,1273,1275,
        3,96,48,0,1274,1273,1,0,0,0,1274,1275,1,0,0,0,1275,1277,1,0,0,0,
        1276,1272,1,0,0,0,1276,1277,1,0,0,0,1277,1285,1,0,0,0,1278,1279,
        5,475,0,0,1279,1281,3,354,177,0,1280,1282,3,466,233,0,1281,1280,
        1,0,0,0,1281,1282,1,0,0,0,1282,1284,1,0,0,0,1283,1278,1,0,0,0,1284,
        1287,1,0,0,0,1285,1283,1,0,0,0,1285,1286,1,0,0,0,1286,1288,1,0,0,
        0,1287,1285,1,0,0,0,1288,1289,5,472,0,0,1289,1291,3,132,66,0,1290,
        1245,1,0,0,0,1290,1268,1,0,0,0,1291,121,1,0,0,0,1292,1293,5,308,
        0,0,1293,1294,5,106,0,0,1294,1295,5,331,0,0,1295,1296,5,267,0,0,
        1296,1299,3,96,48,0,1297,1300,3,54,27,0,1298,1300,3,124,62,0,1299,
        1297,1,0,0,0,1299,1298,1,0,0,0,1300,1301,1,0,0,0,1301,1302,3,132,
        66,0,1302,123,1,0,0,0,1303,1304,3,66,33,0,1304,1305,3,52,26,0,1305,
        125,1,0,0,0,1306,1307,5,365,0,0,1307,1308,3,454,227,0,1308,127,1,
        0,0,0,1309,1310,5,213,0,0,1310,1311,5,163,0,0,1311,1312,5,396,0,
        0,1312,1316,5,476,0,0,1313,1314,3,114,57,0,1314,1315,5,476,0,0,1315,
        1317,1,0,0,0,1316,1313,1,0,0,0,1317,1318,1,0,0,0,1318,1316,1,0,0,
        0,1318,1319,1,0,0,0,1319,1320,1,0,0,0,1320,1321,5,274,0,0,1321,129,
        1,0,0,0,1322,1323,5,163,0,0,1323,1324,5,396,0,0,1324,1328,5,213,
        0,0,1325,1326,3,114,57,0,1326,1327,5,476,0,0,1327,1329,1,0,0,0,1328,
        1325,1,0,0,0,1329,1330,1,0,0,0,1330,1328,1,0,0,0,1330,1331,1,0,0,
        0,1331,1332,1,0,0,0,1332,1333,5,274,0,0,1333,131,1,0,0,0,1334,1335,
        6,66,-1,0,1335,1336,3,138,69,0,1336,1337,3,132,66,4,1337,1359,1,
        0,0,0,1338,1339,5,471,0,0,1339,1340,3,132,66,0,1340,1341,5,472,0,
        0,1341,1359,1,0,0,0,1342,1345,3,146,73,0,1343,1345,3,144,72,0,1344,
        1342,1,0,0,0,1344,1343,1,0,0,0,1345,1347,1,0,0,0,1346,1348,3,264,
        132,0,1347,1346,1,0,0,0,1347,1348,1,0,0,0,1348,1350,1,0,0,0,1349,
        1351,3,262,131,0,1350,1349,1,0,0,0,1350,1351,1,0,0,0,1351,1353,1,
        0,0,0,1352,1354,3,268,134,0,1353,1352,1,0,0,0,1353,1354,1,0,0,0,
        1354,1356,1,0,0,0,1355,1357,3,270,135,0,1356,1355,1,0,0,0,1356,1357,
        1,0,0,0,1357,1359,1,0,0,0,1358,1334,1,0,0,0,1358,1338,1,0,0,0,1358,
        1344,1,0,0,0,1359,1380,1,0,0,0,1360,1361,10,2,0,0,1361,1363,7,7,
        0,0,1362,1364,7,8,0,0,1363,1362,1,0,0,0,1363,1364,1,0,0,0,1364,1365,
        1,0,0,0,1365,1367,3,132,66,0,1366,1368,3,264,132,0,1367,1366,1,0,
        0,0,1367,1368,1,0,0,0,1368,1370,1,0,0,0,1369,1371,3,262,131,0,1370,
        1369,1,0,0,0,1370,1371,1,0,0,0,1371,1373,1,0,0,0,1372,1374,3,268,
        134,0,1373,1372,1,0,0,0,1373,1374,1,0,0,0,1374,1376,1,0,0,0,1375,
        1377,3,270,135,0,1376,1375,1,0,0,0,1376,1377,1,0,0,0,1377,1379,1,
        0,0,0,1378,1360,1,0,0,0,1379,1382,1,0,0,0,1380,1378,1,0,0,0,1380,
        1381,1,0,0,0,1381,133,1,0,0,0,1382,1380,1,0,0,0,1383,1384,5,440,
        0,0,1384,1392,3,136,68,0,1385,1388,5,475,0,0,1386,1388,3,412,206,
        0,1387,1385,1,0,0,0,1387,1386,1,0,0,0,1387,1388,1,0,0,0,1388,1389,
        1,0,0,0,1389,1391,3,136,68,0,1390,1387,1,0,0,0,1391,1394,1,0,0,0,
        1392,1390,1,0,0,0,1392,1393,1,0,0,0,1393,135,1,0,0,0,1394,1392,1,
        0,0,0,1395,1396,5,471,0,0,1396,1401,3,360,180,0,1397,1398,5,475,
        0,0,1398,1400,3,360,180,0,1399,1397,1,0,0,0,1400,1403,1,0,0,0,1401,
        1399,1,0,0,0,1401,1402,1,0,0,0,1402,1404,1,0,0,0,1403,1401,1,0,0,
        0,1404,1405,5,472,0,0,1405,137,1,0,0,0,1406,1407,5,446,0,0,1407,
        1412,3,140,70,0,1408,1409,5,475,0,0,1409,1411,3,140,70,0,1410,1408,
        1,0,0,0,1411,1414,1,0,0,0,1412,1410,1,0,0,0,1412,1413,1,0,0,0,1413,
        139,1,0,0,0,1414,1412,1,0,0,0,1415,1427,3,142,71,0,1416,1417,5,471,
        0,0,1417,1422,3,354,177,0,1418,1419,5,475,0,0,1419,1421,3,354,177,
        0,1420,1418,1,0,0,0,1421,1424,1,0,0,0,1422,1420,1,0,0,0,1422,1423,
        1,0,0,0,1423,1425,1,0,0,0,1424,1422,1,0,0,0,1425,1426,5,472,0,0,
        1426,1428,1,0,0,0,1427,1416,1,0,0,0,1427,1428,1,0,0,0,1428,1429,
        1,0,0,0,1429,1430,5,209,0,0,1430,1431,5,471,0,0,1431,1432,3,132,
        66,0,1432,1433,5,472,0,0,1433,141,1,0,0,0,1434,1435,3,422,211,0,
        1435,143,1,0,0,0,1436,1437,3,146,73,0,1437,1439,3,166,83,0,1438,
        1440,3,226,113,0,1439,1438,1,0,0,0,1439,1440,1,0,0,0,1440,1442,1,
        0,0,0,1441,1443,3,230,115,0,1442,1441,1,0,0,0,1442,1443,1,0,0,0,
        1443,1445,1,0,0,0,1444,1446,3,252,126,0,1445,1444,1,0,0,0,1445,1446,
        1,0,0,0,1446,1448,1,0,0,0,1447,1449,3,254,127,0,1448,1447,1,0,0,
        0,1448,1449,1,0,0,0,1449,1493,1,0,0,0,1450,1451,3,166,83,0,1451,
        1453,3,146,73,0,1452,1454,3,226,113,0,1453,1452,1,0,0,0,1453,1454,
        1,0,0,0,1454,1456,1,0,0,0,1455,1457,3,230,115,0,1456,1455,1,0,0,
        0,1456,1457,1,0,0,0,1457,1459,1,0,0,0,1458,1460,3,252,126,0,1459,
        1458,1,0,0,0,1459,1460,1,0,0,0,1460,1462,1,0,0,0,1461,1463,3,254,
        127,0,1462,1461,1,0,0,0,1462,1463,1,0,0,0,1463,1493,1,0,0,0,1464,
        1465,3,146,73,0,1465,1466,3,166,83,0,1466,1467,3,260,130,0,1467,
        1493,1,0,0,0,1468,1469,3,146,73,0,1469,1470,3,166,83,0,1470,1471,
        3,228,114,0,1471,1493,1,0,0,0,1472,1473,3,146,73,0,1473,1474,3,196,
        98,0,1474,1493,1,0,0,0,1475,1476,5,395,0,0,1476,1493,3,198,99,0,
        1477,1478,5,395,0,0,1478,1479,3,206,103,0,1479,1481,3,166,83,0,1480,
        1482,3,226,113,0,1481,1480,1,0,0,0,1481,1482,1,0,0,0,1482,1484,1,
        0,0,0,1483,1485,3,230,115,0,1484,1483,1,0,0,0,1484,1485,1,0,0,0,
        1485,1487,1,0,0,0,1486,1488,3,252,126,0,1487,1486,1,0,0,0,1487,1488,
        1,0,0,0,1488,1490,1,0,0,0,1489,1491,3,254,127,0,1490,1489,1,0,0,
        0,1490,1491,1,0,0,0,1491,1493,1,0,0,0,1492,1436,1,0,0,0,1492,1450,
        1,0,0,0,1492,1464,1,0,0,0,1492,1468,1,0,0,0,1492,1472,1,0,0,0,1492,
        1475,1,0,0,0,1492,1477,1,0,0,0,1493,145,1,0,0,0,1494,1496,5,395,
        0,0,1495,1497,3,478,239,0,1496,1495,1,0,0,0,1496,1497,1,0,0,0,1497,
        1500,1,0,0,0,1498,1501,5,483,0,0,1499,1501,3,148,74,0,1500,1498,
        1,0,0,0,1500,1499,1,0,0,0,1501,1506,1,0,0,0,1502,1503,5,475,0,0,
        1503,1505,3,148,74,0,1504,1502,1,0,0,0,1505,1508,1,0,0,0,1506,1504,
        1,0,0,0,1506,1507,1,0,0,0,1507,147,1,0,0,0,1508,1506,1,0,0,0,1509,
        1514,3,152,76,0,1510,1512,5,209,0,0,1511,1510,1,0,0,0,1511,1512,
        1,0,0,0,1512,1513,1,0,0,0,1513,1515,3,422,211,0,1514,1511,1,0,0,
        0,1514,1515,1,0,0,0,1515,1547,1,0,0,0,1516,1521,3,360,180,0,1517,
        1519,5,209,0,0,1518,1517,1,0,0,0,1518,1519,1,0,0,0,1519,1520,1,0,
        0,0,1520,1522,3,360,180,0,1521,1518,1,0,0,0,1521,1522,1,0,0,0,1522,
        1547,1,0,0,0,1523,1524,3,178,89,0,1524,1529,3,150,75,0,1525,1527,
        5,209,0,0,1526,1525,1,0,0,0,1526,1527,1,0,0,0,1527,1528,1,0,0,0,
        1528,1530,3,422,211,0,1529,1526,1,0,0,0,1529,1530,1,0,0,0,1530,1547,
        1,0,0,0,1531,1532,3,178,89,0,1532,1533,5,447,0,0,1533,1534,5,297,
        0,0,1534,1535,5,471,0,0,1535,1536,3,262,131,0,1536,1538,5,472,0,
        0,1537,1539,3,150,75,0,1538,1537,1,0,0,0,1538,1539,1,0,0,0,1539,
        1544,1,0,0,0,1540,1542,5,209,0,0,1541,1540,1,0,0,0,1541,1542,1,0,
        0,0,1542,1543,1,0,0,0,1543,1545,3,422,211,0,1544,1541,1,0,0,0,1544,
        1545,1,0,0,0,1545,1547,1,0,0,0,1546,1509,1,0,0,0,1546,1516,1,0,0,
        0,1546,1523,1,0,0,0,1546,1531,1,0,0,0,1547,149,1,0,0,0,1548,1549,
        5,48,0,0,1549,1550,5,471,0,0,1550,1551,3,226,113,0,1551,1552,5,472,
        0,0,1552,151,1,0,0,0,1553,1556,3,158,79,0,1554,1555,7,9,0,0,1555,
        1557,5,100,0,0,1556,1554,1,0,0,0,1556,1557,1,0,0,0,1557,1558,1,0,
        0,0,1558,1560,5,362,0,0,1559,1561,3,444,222,0,1560,1559,1,0,0,0,
        1560,1561,1,0,0,0,1561,1579,1,0,0,0,1562,1564,5,471,0,0,1563,1565,
        3,154,77,0,1564,1563,1,0,0,0,1564,1565,1,0,0,0,1565,1566,1,0,0,0,
        1566,1571,3,156,78,0,1567,1568,5,475,0,0,1568,1570,3,156,78,0,1569,
        1567,1,0,0,0,1570,1573,1,0,0,0,1571,1569,1,0,0,0,1571,1572,1,0,0,
        0,1572,1575,1,0,0,0,1573,1571,1,0,0,0,1574,1576,3,168,84,0,1575,
        1574,1,0,0,0,1575,1576,1,0,0,0,1576,1577,1,0,0,0,1577,1578,5,472,
        0,0,1578,1580,1,0,0,0,1579,1562,1,0,0,0,1579,1580,1,0,0,0,1580,153,
        1,0,0,0,1581,1582,7,10,0,0,1582,1583,5,222,0,0,1583,1586,3,354,177,
        0,1584,1585,5,464,0,0,1585,1587,3,360,180,0,1586,1584,1,0,0,0,1586,
        1587,1,0,0,0,1587,155,1,0,0,0,1588,1589,7,11,0,0,1589,1590,5,222,
        0,0,1590,1592,3,354,177,0,1591,1593,7,0,0,0,1592,1591,1,0,0,0,1592,
        1593,1,0,0,0,1593,1596,1,0,0,0,1594,1595,5,100,0,0,1595,1597,7,4,
        0,0,1596,1594,1,0,0,0,1596,1597,1,0,0,0,1597,157,1,0,0,0,1598,1599,
        3,160,80,0,1599,1608,5,471,0,0,1600,1605,3,388,194,0,1601,1602,5,
        475,0,0,1602,1604,3,388,194,0,1603,1601,1,0,0,0,1604,1607,1,0,0,
        0,1605,1603,1,0,0,0,1605,1606,1,0,0,0,1606,1609,1,0,0,0,1607,1605,
        1,0,0,0,1608,1600,1,0,0,0,1608,1609,1,0,0,0,1609,1610,1,0,0,0,1610,
        1611,5,472,0,0,1611,1614,1,0,0,0,1612,1614,3,370,185,0,1613,1598,
        1,0,0,0,1613,1612,1,0,0,0,1614,159,1,0,0,0,1615,1618,3,164,82,0,
        1616,1618,3,162,81,0,1617,1615,1,0,0,0,1617,1616,1,0,0,0,1618,161,
        1,0,0,0,1619,1620,7,12,0,0,1620,163,1,0,0,0,1621,1622,7,13,0,0,1622,
        165,1,0,0,0,1623,1624,5,291,0,0,1624,1625,3,172,86,0,1625,167,1,
        0,0,0,1626,1633,7,14,0,0,1627,1634,3,170,85,0,1628,1629,5,214,0,
        0,1629,1630,3,170,85,0,1630,1631,5,205,0,0,1631,1632,3,170,85,0,
        1632,1634,1,0,0,0,1633,1627,1,0,0,0,1633,1628,1,0,0,0,1634,169,1,
        0,0,0,1635,1636,5,182,0,0,1636,1648,5,115,0,0,1637,1638,3,360,180,
        0,1638,1639,5,115,0,0,1639,1648,1,0,0,0,1640,1641,5,250,0,0,1641,
        1648,5,392,0,0,1642,1643,3,360,180,0,1643,1644,5,53,0,0,1644,1648,
        1,0,0,0,1645,1646,5,182,0,0,1646,1648,5,53,0,0,1647,1635,1,0,0,0,
        1647,1637,1,0,0,0,1647,1640,1,0,0,0,1647,1642,1,0,0,0,1647,1645,
        1,0,0,0,1648,171,1,0,0,0,1649,1650,6,86,-1,0,1650,1657,3,174,87,
        0,1651,1653,5,475,0,0,1652,1651,1,0,0,0,1652,1653,1,0,0,0,1653,1654,
        1,0,0,0,1654,1656,3,174,87,0,1655,1652,1,0,0,0,1656,1659,1,0,0,0,
        1657,1655,1,0,0,0,1657,1658,1,0,0,0,1658,1667,1,0,0,0,1659,1657,
        1,0,0,0,1660,1667,3,134,67,0,1661,1663,3,196,98,0,1662,1664,3,412,
        206,0,1663,1662,1,0,0,0,1663,1664,1,0,0,0,1664,1667,1,0,0,0,1665,
        1667,3,194,97,0,1666,1649,1,0,0,0,1666,1660,1,0,0,0,1666,1661,1,
        0,0,0,1666,1665,1,0,0,0,1667,1696,1,0,0,0,1668,1669,10,4,0,0,1669,
        1670,5,247,0,0,1670,1671,5,319,0,0,1671,1695,3,172,86,5,1672,1674,
        10,5,0,0,1673,1675,5,344,0,0,1674,1673,1,0,0,0,1674,1675,1,0,0,0,
        1675,1677,1,0,0,0,1676,1678,7,15,0,0,1677,1676,1,0,0,0,1677,1678,
        1,0,0,0,1678,1680,1,0,0,0,1679,1681,5,360,0,0,1680,1679,1,0,0,0,
        1680,1681,1,0,0,0,1681,1682,1,0,0,0,1682,1683,5,319,0,0,1683,1685,
        3,172,86,0,1684,1686,3,224,112,0,1685,1684,1,0,0,0,1685,1686,1,0,
        0,0,1686,1691,1,0,0,0,1687,1688,5,475,0,0,1688,1690,3,174,87,0,1689,
        1687,1,0,0,0,1690,1693,1,0,0,0,1691,1689,1,0,0,0,1691,1692,1,0,0,
        0,1692,1695,1,0,0,0,1693,1691,1,0,0,0,1694,1668,1,0,0,0,1694,1672,
        1,0,0,0,1695,1698,1,0,0,0,1696,1694,1,0,0,0,1696,1697,1,0,0,0,1697,
        173,1,0,0,0,1698,1696,1,0,0,0,1699,1701,3,176,88,0,1700,1702,3,412,
        206,0,1701,1700,1,0,0,0,1701,1702,1,0,0,0,1702,175,1,0,0,0,1703,
        1705,5,415,0,0,1704,1703,1,0,0,0,1704,1705,1,0,0,0,1705,1706,1,0,
        0,0,1706,1708,3,442,221,0,1707,1709,3,188,94,0,1708,1707,1,0,0,0,
        1708,1709,1,0,0,0,1709,1714,1,0,0,0,1710,1712,5,209,0,0,1711,1710,
        1,0,0,0,1711,1712,1,0,0,0,1712,1713,1,0,0,0,1713,1715,3,394,197,
        0,1714,1711,1,0,0,0,1714,1715,1,0,0,0,1715,1777,1,0,0,0,1716,1717,
        5,323,0,0,1717,1720,5,415,0,0,1718,1721,3,178,89,0,1719,1721,3,372,
        186,0,1720,1718,1,0,0,0,1720,1719,1,0,0,0,1721,1777,1,0,0,0,1722,
        1723,5,323,0,0,1723,1724,5,415,0,0,1724,1725,5,282,0,0,1725,1728,
        5,471,0,0,1726,1729,3,178,89,0,1727,1729,3,372,186,0,1728,1726,1,
        0,0,0,1728,1727,1,0,0,0,1729,1730,1,0,0,0,1730,1731,5,472,0,0,1731,
        1777,1,0,0,0,1732,1734,5,323,0,0,1733,1732,1,0,0,0,1733,1734,1,0,
        0,0,1734,1735,1,0,0,0,1735,1736,5,471,0,0,1736,1737,3,132,66,0,1737,
        1738,5,472,0,0,1738,1777,1,0,0,0,1739,1740,5,323,0,0,1740,1742,5,
        190,0,0,1741,1743,5,360,0,0,1742,1741,1,0,0,0,1742,1743,1,0,0,0,
        1743,1744,1,0,0,0,1744,1746,3,178,89,0,1745,1747,3,412,206,0,1746,
        1745,1,0,0,0,1746,1747,1,0,0,0,1747,1748,1,0,0,0,1748,1749,5,209,
        0,0,1749,1754,3,410,205,0,1750,1751,5,475,0,0,1751,1753,3,410,205,
        0,1752,1750,1,0,0,0,1753,1756,1,0,0,0,1754,1752,1,0,0,0,1754,1755,
        1,0,0,0,1755,1777,1,0,0,0,1756,1754,1,0,0,0,1757,1758,5,433,0,0,
        1758,1759,5,471,0,0,1759,1760,3,360,180,0,1760,1761,5,472,0,0,1761,
        1777,1,0,0,0,1762,1763,5,373,0,0,1763,1764,5,471,0,0,1764,1765,3,
        182,91,0,1765,1766,5,472,0,0,1766,1777,1,0,0,0,1767,1770,5,434,0,
        0,1768,1769,7,16,0,0,1769,1771,5,100,0,0,1770,1768,1,0,0,0,1770,
        1771,1,0,0,0,1771,1772,1,0,0,0,1772,1773,5,471,0,0,1773,1774,3,180,
        90,0,1774,1775,5,472,0,0,1775,1777,1,0,0,0,1776,1704,1,0,0,0,1776,
        1716,1,0,0,0,1776,1722,1,0,0,0,1776,1733,1,0,0,0,1776,1739,1,0,0,
        0,1776,1757,1,0,0,0,1776,1762,1,0,0,0,1776,1767,1,0,0,0,1777,177,
        1,0,0,0,1778,1779,3,386,193,0,1779,1782,5,471,0,0,1780,1783,3,178,
        89,0,1781,1783,3,388,194,0,1782,1780,1,0,0,0,1782,1781,1,0,0,0,1783,
        1791,1,0,0,0,1784,1787,5,475,0,0,1785,1788,3,178,89,0,1786,1788,
        3,388,194,0,1787,1785,1,0,0,0,1787,1786,1,0,0,0,1788,1790,1,0,0,
        0,1789,1784,1,0,0,0,1790,1793,1,0,0,0,1791,1789,1,0,0,0,1791,1792,
        1,0,0,0,1792,1794,1,0,0,0,1793,1791,1,0,0,0,1794,1795,5,472,0,0,
        1795,1826,1,0,0,0,1796,1797,3,386,193,0,1797,1800,5,471,0,0,1798,
        1801,3,178,89,0,1799,1801,3,388,194,0,1800,1798,1,0,0,0,1800,1799,
        1,0,0,0,1801,1809,1,0,0,0,1802,1805,5,475,0,0,1803,1806,3,178,89,
        0,1804,1806,3,388,194,0,1805,1803,1,0,0,0,1805,1804,1,0,0,0,1806,
        1808,1,0,0,0,1807,1802,1,0,0,0,1808,1811,1,0,0,0,1809,1807,1,0,0,
        0,1809,1810,1,0,0,0,1810,1812,1,0,0,0,1811,1809,1,0,0,0,1812,1813,
        5,472,0,0,1813,1814,5,471,0,0,1814,1815,5,209,0,0,1815,1816,3,412,
        206,0,1816,1817,5,472,0,0,1817,1822,3,148,74,0,1818,1819,5,475,0,
        0,1819,1821,3,148,74,0,1820,1818,1,0,0,0,1821,1824,1,0,0,0,1822,
        1820,1,0,0,0,1822,1823,1,0,0,0,1823,1826,1,0,0,0,1824,1822,1,0,0,
        0,1825,1778,1,0,0,0,1825,1796,1,0,0,0,1826,179,1,0,0,0,1827,1830,
        3,354,177,0,1828,1830,3,356,178,0,1829,1827,1,0,0,0,1829,1828,1,
        0,0,0,1830,1831,1,0,0,0,1831,1832,5,290,0,0,1832,1833,3,354,177,
        0,1833,1834,5,303,0,0,1834,1835,3,186,93,0,1835,181,1,0,0,0,1836,
        1837,3,184,92,0,1837,1838,5,475,0,0,1838,1839,3,184,92,0,1839,1840,
        1,0,0,0,1840,1843,5,290,0,0,1841,1844,3,354,177,0,1842,1844,3,356,
        178,0,1843,1841,1,0,0,0,1843,1842,1,0,0,0,1844,1845,1,0,0,0,1845,
        1846,5,303,0,0,1846,1847,3,186,93,0,1847,183,1,0,0,0,1848,1851,3,
        360,180,0,1849,1850,5,209,0,0,1850,1852,3,410,205,0,1851,1849,1,
        0,0,0,1851,1852,1,0,0,0,1852,185,1,0,0,0,1853,1854,5,471,0,0,1854,
        1859,3,184,92,0,1855,1856,5,475,0,0,1856,1858,3,184,92,0,1857,1855,
        1,0,0,0,1858,1861,1,0,0,0,1859,1857,1,0,0,0,1859,1860,1,0,0,0,1860,
        1862,1,0,0,0,1861,1859,1,0,0,0,1862,1863,5,472,0,0,1863,187,1,0,
        0,0,1864,1865,5,290,0,0,1865,1866,5,413,0,0,1866,1867,5,209,0,0,
        1867,1868,5,353,0,0,1868,1869,3,190,95,0,1869,189,1,0,0,0,1870,1871,
        3,360,180,0,1871,191,1,0,0,0,1872,1877,3,360,180,0,1873,1874,5,475,
        0,0,1874,1876,3,360,180,0,1875,1873,1,0,0,0,1876,1879,1,0,0,0,1877,
        1875,1,0,0,0,1877,1878,1,0,0,0,1878,1881,1,0,0,0,1879,1877,1,0,0,
        0,1880,1882,3,412,206,0,1881,1880,1,0,0,0,1881,1882,1,0,0,0,1882,
        193,1,0,0,0,1883,1884,5,415,0,0,1884,1885,5,471,0,0,1885,1886,3,
        202,101,0,1886,1887,5,472,0,0,1887,195,1,0,0,0,1888,1889,3,200,100,
        0,1889,197,1,0,0,0,1890,1891,7,17,0,0,1891,1892,5,471,0,0,1892,1893,
        3,360,180,0,1893,1894,5,472,0,0,1894,1927,1,0,0,0,1895,1896,5,404,
        0,0,1896,1897,5,471,0,0,1897,1902,3,466,233,0,1898,1899,5,475,0,
        0,1899,1901,3,360,180,0,1900,1898,1,0,0,0,1901,1904,1,0,0,0,1902,
        1900,1,0,0,0,1902,1903,1,0,0,0,1903,1905,1,0,0,0,1904,1902,1,0,0,
        0,1905,1906,5,472,0,0,1906,1927,1,0,0,0,1907,1908,5,320,0,0,1908,
        1909,5,471,0,0,1909,1914,3,472,236,0,1910,1911,5,475,0,0,1911,1913,
        3,360,180,0,1912,1910,1,0,0,0,1913,1916,1,0,0,0,1914,1912,1,0,0,
        0,1914,1915,1,0,0,0,1915,1917,1,0,0,0,1916,1914,1,0,0,0,1917,1918,
        5,472,0,0,1918,1927,1,0,0,0,1919,1920,5,364,0,0,1920,1921,5,471,
        0,0,1921,1922,3,472,236,0,1922,1923,5,475,0,0,1923,1924,3,472,236,
        0,1924,1925,5,472,0,0,1925,1927,1,0,0,0,1926,1890,1,0,0,0,1926,1895,
        1,0,0,0,1926,1907,1,0,0,0,1926,1919,1,0,0,0,1927,199,1,0,0,0,1928,
        1929,5,380,0,0,1929,1930,5,471,0,0,1930,1935,3,360,180,0,1931,1932,
        5,475,0,0,1932,1934,3,360,180,0,1933,1931,1,0,0,0,1934,1937,1,0,
        0,0,1935,1933,1,0,0,0,1935,1936,1,0,0,0,1936,1938,1,0,0,0,1937,1935,
        1,0,0,0,1938,1939,5,472,0,0,1939,201,1,0,0,0,1940,1941,3,204,102,
        0,1941,1942,5,471,0,0,1942,1947,3,218,109,0,1943,1944,5,475,0,0,
        1944,1946,3,218,109,0,1945,1943,1,0,0,0,1946,1949,1,0,0,0,1947,1945,
        1,0,0,0,1947,1948,1,0,0,0,1948,1950,1,0,0,0,1949,1947,1,0,0,0,1950,
        1951,5,472,0,0,1951,203,1,0,0,0,1952,1953,7,18,0,0,1953,205,1,0,
        0,0,1954,1955,5,177,0,0,1955,1967,3,356,178,0,1956,1957,5,438,0,
        0,1957,1963,3,472,236,0,1958,1961,5,209,0,0,1959,1962,3,356,178,
        0,1960,1962,3,314,157,0,1961,1959,1,0,0,0,1961,1960,1,0,0,0,1962,
        1964,1,0,0,0,1963,1958,1,0,0,0,1963,1964,1,0,0,0,1964,1968,1,0,0,
        0,1965,1968,3,208,104,0,1966,1968,3,210,105,0,1967,1956,1,0,0,0,
        1967,1965,1,0,0,0,1967,1966,1,0,0,0,1968,207,1,0,0,0,1969,1970,3,
        216,108,0,1970,1971,3,212,106,0,1971,1972,3,216,108,0,1972,209,1,
        0,0,0,1973,1974,3,214,107,0,1974,1975,3,212,106,0,1975,1976,3,214,
        107,0,1976,211,1,0,0,0,1977,1978,5,438,0,0,1978,1979,3,472,236,0,
        1979,1982,5,209,0,0,1980,1983,3,356,178,0,1981,1983,3,314,157,0,
        1982,1980,1,0,0,0,1982,1981,1,0,0,0,1982,1983,1,0,0,0,1983,213,1,
        0,0,0,1984,1985,5,392,0,0,1985,1986,5,54,0,0,1986,1987,5,397,0,0,
        1987,1989,3,472,236,0,1988,1984,1,0,0,0,1988,1989,1,0,0,0,1989,1993,
        1,0,0,0,1990,1991,5,446,0,0,1991,1992,5,160,0,0,1992,1994,3,16,8,
        0,1993,1990,1,0,0,0,1993,1994,1,0,0,0,1994,215,1,0,0,0,1995,1997,
        3,66,33,0,1996,1995,1,0,0,0,1996,1997,1,0,0,0,1997,1999,1,0,0,0,
        1998,2000,3,52,26,0,1999,1998,1,0,0,0,1999,2000,1,0,0,0,2000,2005,
        1,0,0,0,2001,2002,5,329,0,0,2002,2003,5,418,0,0,2003,2004,5,222,
        0,0,2004,2006,3,472,236,0,2005,2001,1,0,0,0,2005,2006,1,0,0,0,2006,
        2011,1,0,0,0,2007,2008,5,351,0,0,2008,2009,5,34,0,0,2009,2010,5,
        209,0,0,2010,2012,3,472,236,0,2011,2007,1,0,0,0,2011,2012,1,0,0,
        0,2012,217,1,0,0,0,2013,2014,5,415,0,0,2014,2029,3,250,125,0,2015,
        2029,3,222,111,0,2016,2029,3,398,199,0,2017,2018,5,28,0,0,2018,2019,
        5,492,0,0,2019,2020,5,415,0,0,2020,2029,3,250,125,0,2021,2022,5,
        170,0,0,2022,2023,5,492,0,0,2023,2029,3,222,111,0,2024,2025,3,220,
        110,0,2025,2026,5,492,0,0,2026,2027,3,398,199,0,2027,2029,1,0,0,
        0,2028,2013,1,0,0,0,2028,2015,1,0,0,0,2028,2016,1,0,0,0,2028,2017,
        1,0,0,0,2028,2021,1,0,0,0,2028,2024,1,0,0,0,2029,219,1,0,0,0,2030,
        2031,7,19,0,0,2031,221,1,0,0,0,2032,2033,5,36,0,0,2033,2034,5,471,
        0,0,2034,2035,3,446,223,0,2035,2036,5,472,0,0,2036,223,1,0,0,0,2037,
        2038,5,355,0,0,2038,2052,3,362,181,0,2039,2040,5,438,0,0,2040,2041,
        5,471,0,0,2041,2046,3,446,223,0,2042,2043,5,475,0,0,2043,2045,3,
        446,223,0,2044,2042,1,0,0,0,2045,2048,1,0,0,0,2046,2044,1,0,0,0,
        2046,2047,1,0,0,0,2047,2049,1,0,0,0,2048,2046,1,0,0,0,2049,2050,
        5,472,0,0,2050,2052,1,0,0,0,2051,2037,1,0,0,0,2051,2039,1,0,0,0,
        2052,225,1,0,0,0,2053,2054,5,444,0,0,2054,2055,3,362,181,0,2055,
        227,1,0,0,0,2056,2057,5,417,0,0,2057,2061,5,471,0,0,2058,2062,3,
        474,237,0,2059,2062,5,494,0,0,2060,2062,3,360,180,0,2061,2058,1,
        0,0,0,2061,2059,1,0,0,0,2061,2060,1,0,0,0,2062,2063,1,0,0,0,2063,
        2064,5,368,0,0,2064,2088,5,472,0,0,2065,2066,5,417,0,0,2066,2069,
        5,471,0,0,2067,2070,5,494,0,0,2068,2070,3,360,180,0,2069,2067,1,
        0,0,0,2069,2068,1,0,0,0,2070,2071,1,0,0,0,2071,2072,5,393,0,0,2072,
        2088,5,472,0,0,2073,2074,5,417,0,0,2074,2075,5,471,0,0,2075,2078,
        5,221,0,0,2076,2079,5,494,0,0,2077,2079,3,360,180,0,2078,2076,1,
        0,0,0,2078,2077,1,0,0,0,2079,2080,1,0,0,0,2080,2081,5,359,0,0,2081,
        2084,5,353,0,0,2082,2085,5,494,0,0,2083,2085,3,360,180,0,2084,2082,
        1,0,0,0,2084,2083,1,0,0,0,2085,2086,1,0,0,0,2086,2088,5,472,0,0,
        2087,2056,1,0,0,0,2087,2065,1,0,0,0,2087,2073,1,0,0,0,2088,229,1,
        0,0,0,2089,2094,3,234,117,0,2090,2094,3,232,116,0,2091,2094,3,236,
        118,0,2092,2094,3,238,119,0,2093,2089,1,0,0,0,2093,2090,1,0,0,0,
        2093,2091,1,0,0,0,2093,2092,1,0,0,0,2094,231,1,0,0,0,2095,2096,5,
        234,0,0,2096,2097,5,222,0,0,2097,2102,3,240,120,0,2098,2099,5,475,
        0,0,2099,2101,3,240,120,0,2100,2098,1,0,0,0,2101,2104,1,0,0,0,2102,
        2100,1,0,0,0,2102,2103,1,0,0,0,2103,233,1,0,0,0,2104,2102,1,0,0,
        0,2105,2106,5,235,0,0,2106,2107,5,222,0,0,2107,2112,3,240,120,0,
        2108,2109,5,475,0,0,2109,2111,3,240,120,0,2110,2108,1,0,0,0,2111,
        2114,1,0,0,0,2112,2110,1,0,0,0,2112,2113,1,0,0,0,2113,235,1,0,0,
        0,2114,2112,1,0,0,0,2115,2116,5,269,0,0,2116,2117,5,222,0,0,2117,
        2122,3,240,120,0,2118,2119,5,475,0,0,2119,2121,3,240,120,0,2120,
        2118,1,0,0,0,2121,2124,1,0,0,0,2122,2120,1,0,0,0,2122,2123,1,0,0,
        0,2123,237,1,0,0,0,2124,2122,1,0,0,0,2125,2126,5,297,0,0,2126,2127,
        5,222,0,0,2127,2132,3,240,120,0,2128,2129,5,475,0,0,2129,2131,3,
        240,120,0,2130,2128,1,0,0,0,2131,2134,1,0,0,0,2132,2130,1,0,0,0,
        2132,2133,1,0,0,0,2133,2137,1,0,0,0,2134,2132,1,0,0,0,2135,2136,
        5,446,0,0,2136,2138,3,244,122,0,2137,2135,1,0,0,0,2137,2138,1,0,
        0,0,2138,239,1,0,0,0,2139,2144,3,360,180,0,2140,2141,5,475,0,0,2141,
        2143,3,360,180,0,2142,2140,1,0,0,0,2143,2146,1,0,0,0,2144,2142,1,
        0,0,0,2144,2145,1,0,0,0,2145,2186,1,0,0,0,2146,2144,1,0,0,0,2147,
        2186,3,246,123,0,2148,2149,5,471,0,0,2149,2186,5,472,0,0,2150,2151,
        5,471,0,0,2151,2156,3,360,180,0,2152,2153,5,475,0,0,2153,2155,3,
        360,180,0,2154,2152,1,0,0,0,2155,2158,1,0,0,0,2156,2154,1,0,0,0,
        2156,2157,1,0,0,0,2157,2159,1,0,0,0,2158,2156,1,0,0,0,2159,2160,
        5,472,0,0,2160,2186,1,0,0,0,2161,2162,3,244,122,0,2162,2163,5,471,
        0,0,2163,2168,3,360,180,0,2164,2165,5,475,0,0,2165,2167,3,360,180,
        0,2166,2164,1,0,0,0,2167,2170,1,0,0,0,2168,2166,1,0,0,0,2168,2169,
        1,0,0,0,2169,2171,1,0,0,0,2170,2168,1,0,0,0,2171,2172,5,472,0,0,
        2172,2186,1,0,0,0,2173,2174,3,242,121,0,2174,2175,5,471,0,0,2175,
        2180,3,240,120,0,2176,2177,5,475,0,0,2177,2179,3,240,120,0,2178,
        2176,1,0,0,0,2179,2182,1,0,0,0,2180,2178,1,0,0,0,2180,2181,1,0,0,
        0,2181,2183,1,0,0,0,2182,2180,1,0,0,0,2183,2184,5,472,0,0,2184,2186,
        1,0,0,0,2185,2139,1,0,0,0,2185,2147,1,0,0,0,2185,2148,1,0,0,0,2185,
        2150,1,0,0,0,2185,2161,1,0,0,0,2185,2173,1,0,0,0,2186,241,1,0,0,
        0,2187,2188,5,298,0,0,2188,2189,5,153,0,0,2189,243,1,0,0,0,2190,
        2191,7,20,0,0,2191,245,1,0,0,0,2192,2193,3,248,124,0,2193,2194,5,
        471,0,0,2194,2195,3,250,125,0,2195,2196,5,475,0,0,2196,2197,3,398,
        199,0,2197,2198,5,472,0,0,2198,247,1,0,0,0,2199,2200,7,21,0,0,2200,
        249,1,0,0,0,2201,2202,3,446,223,0,2202,251,1,0,0,0,2203,2204,5,300,
        0,0,2204,2205,3,362,181,0,2205,253,1,0,0,0,2206,2207,5,445,0,0,2207,
        2212,3,256,128,0,2208,2209,5,475,0,0,2209,2211,3,256,128,0,2210,
        2208,1,0,0,0,2211,2214,1,0,0,0,2212,2210,1,0,0,0,2212,2213,1,0,0,
        0,2213,255,1,0,0,0,2214,2212,1,0,0,0,2215,2216,3,414,207,0,2216,
        2217,5,209,0,0,2217,2218,3,258,129,0,2218,257,1,0,0,0,2219,2221,
        3,414,207,0,2220,2219,1,0,0,0,2220,2221,1,0,0,0,2221,2222,1,0,0,
        0,2222,2224,5,471,0,0,2223,2225,3,272,136,0,2224,2223,1,0,0,0,2224,
        2225,1,0,0,0,2225,2227,1,0,0,0,2226,2228,3,264,132,0,2227,2226,1,
        0,0,0,2227,2228,1,0,0,0,2228,2230,1,0,0,0,2229,2231,3,262,131,0,
        2230,2229,1,0,0,0,2230,2231,1,0,0,0,2231,2233,1,0,0,0,2232,2234,
        3,288,144,0,2233,2232,1,0,0,0,2233,2234,1,0,0,0,2234,2235,1,0,0,
        0,2235,2236,5,472,0,0,2236,259,1,0,0,0,2237,2238,5,334,0,0,2238,
        2240,5,471,0,0,2239,2241,3,272,136,0,2240,2239,1,0,0,0,2240,2241,
        1,0,0,0,2241,2243,1,0,0,0,2242,2244,3,264,132,0,2243,2242,1,0,0,
        0,2243,2244,1,0,0,0,2244,2246,1,0,0,0,2245,2247,3,262,131,0,2246,
        2245,1,0,0,0,2246,2247,1,0,0,0,2247,2249,1,0,0,0,2248,2250,3,276,
        138,0,2249,2248,1,0,0,0,2249,2250,1,0,0,0,2250,2252,1,0,0,0,2251,
        2253,3,282,141,0,2252,2251,1,0,0,0,2252,2253,1,0,0,0,2253,2255,1,
        0,0,0,2254,2256,3,284,142,0,2255,2254,1,0,0,0,2255,2256,1,0,0,0,
        2256,2258,1,0,0,0,2257,2259,3,278,139,0,2258,2257,1,0,0,0,2258,2259,
        1,0,0,0,2259,2260,1,0,0,0,2260,2261,3,286,143,0,2261,2266,5,472,
        0,0,2262,2264,5,209,0,0,2263,2262,1,0,0,0,2263,2264,1,0,0,0,2264,
        2265,1,0,0,0,2265,2267,3,422,211,0,2266,2263,1,0,0,0,2266,2267,1,
        0,0,0,2267,261,1,0,0,0,2268,2269,5,358,0,0,2269,2270,5,222,0,0,2270,
        2275,3,266,133,0,2271,2272,5,475,0,0,2272,2274,3,266,133,0,2273,
        2271,1,0,0,0,2274,2277,1,0,0,0,2275,2273,1,0,0,0,2275,2276,1,0,0,
        0,2276,263,1,0,0,0,2277,2275,1,0,0,0,2278,2279,5,408,0,0,2279,2280,
        5,222,0,0,2280,2285,3,266,133,0,2281,2282,5,475,0,0,2282,2284,3,
        266,133,0,2283,2281,1,0,0,0,2284,2287,1,0,0,0,2285,2283,1,0,0,0,
        2285,2286,1,0,0,0,2286,265,1,0,0,0,2287,2285,1,0,0,0,2288,2290,3,
        360,180,0,2289,2291,7,0,0,0,2290,2289,1,0,0,0,2290,2291,1,0,0,0,
        2291,2294,1,0,0,0,2292,2293,5,100,0,0,2293,2295,7,4,0,0,2294,2292,
        1,0,0,0,2294,2295,1,0,0,0,2295,267,1,0,0,0,2296,2299,5,330,0,0,2297,
        2300,5,202,0,0,2298,2300,3,360,180,0,2299,2297,1,0,0,0,2299,2298,
        1,0,0,0,2300,269,1,0,0,0,2301,2304,5,354,0,0,2302,2305,5,494,0,0,
        2303,2305,3,360,180,0,2304,2302,1,0,0,0,2304,2303,1,0,0,0,2305,271,
        1,0,0,0,2306,2307,5,365,0,0,2307,2308,5,222,0,0,2308,2313,3,360,
        180,0,2309,2310,5,475,0,0,2310,2312,3,360,180,0,2311,2309,1,0,0,
        0,2312,2315,1,0,0,0,2313,2311,1,0,0,0,2313,2314,1,0,0,0,2314,273,
        1,0,0,0,2315,2313,1,0,0,0,2316,2333,5,483,0,0,2317,2333,5,486,0,
        0,2318,2333,5,491,0,0,2319,2320,5,473,0,0,2320,2321,5,494,0,0,2321,
        2322,5,475,0,0,2322,2323,5,494,0,0,2323,2333,5,474,0,0,2324,2325,
        5,473,0,0,2325,2326,5,494,0,0,2326,2327,5,475,0,0,2327,2333,5,474,
        0,0,2328,2329,5,473,0,0,2329,2330,5,475,0,0,2330,2331,5,494,0,0,
        2331,2333,5,474,0,0,2332,2316,1,0,0,0,2332,2317,1,0,0,0,2332,2318,
        1,0,0,0,2332,2319,1,0,0,0,2332,2324,1,0,0,0,2332,2328,1,0,0,0,2333,
        275,1,0,0,0,2334,2335,5,335,0,0,2335,2340,3,148,74,0,2336,2337,5,
        475,0,0,2337,2339,3,148,74,0,2338,2336,1,0,0,0,2339,2342,1,0,0,0,
        2340,2338,1,0,0,0,2340,2341,1,0,0,0,2341,277,1,0,0,0,2342,2340,1,
        0,0,0,2343,2344,5,366,0,0,2344,2346,5,471,0,0,2345,2347,3,280,140,
        0,2346,2345,1,0,0,0,2347,2348,1,0,0,0,2348,2346,1,0,0,0,2348,2349,
        1,0,0,0,2349,2350,1,0,0,0,2350,2352,5,472,0,0,2351,2353,3,292,146,
        0,2352,2351,1,0,0,0,2352,2353,1,0,0,0,2353,279,1,0,0,0,2354,2356,
        3,428,214,0,2355,2357,3,274,137,0,2356,2355,1,0,0,0,2356,2357,1,
        0,0,0,2357,281,1,0,0,0,2358,2359,5,202,0,0,2359,2360,5,393,0,0,2360,
        2361,5,367,0,0,2361,2367,5,333,0,0,2362,2363,5,356,0,0,2363,2364,
        5,392,0,0,2364,2365,5,367,0,0,2365,2367,5,333,0,0,2366,2358,1,0,
        0,0,2366,2362,1,0,0,0,2367,283,1,0,0,0,2368,2369,5,6,0,0,2369,2370,
        5,333,0,0,2370,2371,5,400,0,0,2371,2372,5,111,0,0,2372,2373,5,82,
        0,0,2373,2393,5,392,0,0,2374,2375,5,6,0,0,2375,2376,5,333,0,0,2376,
        2377,5,400,0,0,2377,2378,5,426,0,0,2378,2379,5,345,0,0,2379,2393,
        5,392,0,0,2380,2381,5,6,0,0,2381,2382,5,333,0,0,2382,2383,5,400,
        0,0,2383,2384,5,426,0,0,2384,2385,5,82,0,0,2385,2393,3,428,214,0,
        2386,2387,5,6,0,0,2387,2388,5,333,0,0,2388,2389,5,400,0,0,2389,2390,
        5,426,0,0,2390,2391,5,52,0,0,2391,2393,3,428,214,0,2392,2368,1,0,
        0,0,2392,2374,1,0,0,0,2392,2380,1,0,0,0,2392,2386,1,0,0,0,2393,285,
        1,0,0,0,2394,2395,5,261,0,0,2395,2400,3,148,74,0,2396,2397,5,475,
        0,0,2397,2399,3,148,74,0,2398,2396,1,0,0,0,2399,2402,1,0,0,0,2400,
        2398,1,0,0,0,2400,2401,1,0,0,0,2401,287,1,0,0,0,2402,2400,1,0,0,
        0,2403,2404,5,380,0,0,2404,2405,5,214,0,0,2405,2406,3,398,199,0,
        2406,2407,3,290,145,0,2407,2413,1,0,0,0,2408,2409,5,393,0,0,2409,
        2410,5,214,0,0,2410,2411,5,494,0,0,2411,2413,3,290,145,0,2412,2403,
        1,0,0,0,2412,2408,1,0,0,0,2413,289,1,0,0,0,2414,2415,5,115,0,0,2415,
        2416,5,205,0,0,2416,2417,5,250,0,0,2417,2418,5,392,0,0,2418,291,
        1,0,0,0,2419,2420,5,447,0,0,2420,2421,3,398,199,0,2421,293,1,0,0,
        0,2422,2423,5,372,0,0,2423,2424,5,290,0,0,2424,2425,5,413,0,0,2425,
        295,1,0,0,0,2426,2427,5,108,0,0,2427,2428,5,222,0,0,2428,2429,3,
        298,149,0,2429,297,1,0,0,0,2430,2431,5,471,0,0,2431,2433,3,300,150,
        0,2432,2434,3,382,191,0,2433,2432,1,0,0,0,2433,2434,1,0,0,0,2434,
        2442,1,0,0,0,2435,2436,5,475,0,0,2436,2438,3,300,150,0,2437,2439,
        3,382,191,0,2438,2437,1,0,0,0,2438,2439,1,0,0,0,2439,2441,1,0,0,
        0,2440,2435,1,0,0,0,2441,2444,1,0,0,0,2442,2440,1,0,0,0,2442,2443,
        1,0,0,0,2443,2445,1,0,0,0,2444,2442,1,0,0,0,2445,2446,5,472,0,0,
        2446,299,1,0,0,0,2447,2461,3,396,198,0,2448,2449,3,422,211,0,2449,
        2450,5,471,0,0,2450,2455,3,302,151,0,2451,2452,5,475,0,0,2452,2454,
        3,302,151,0,2453,2451,1,0,0,0,2454,2457,1,0,0,0,2455,2453,1,0,0,
        0,2455,2456,1,0,0,0,2456,2458,1,0,0,0,2457,2455,1,0,0,0,2458,2459,
        5,472,0,0,2459,2461,1,0,0,0,2460,2447,1,0,0,0,2460,2448,1,0,0,0,
        2461,301,1,0,0,0,2462,2465,3,396,198,0,2463,2465,3,466,233,0,2464,
        2462,1,0,0,0,2464,2463,1,0,0,0,2465,303,1,0,0,0,2466,2467,5,328,
        0,0,2467,2476,3,442,221,0,2468,2472,5,471,0,0,2469,2471,3,310,155,
        0,2470,2469,1,0,0,0,2471,2474,1,0,0,0,2472,2470,1,0,0,0,2472,2473,
        1,0,0,0,2473,2475,1,0,0,0,2474,2472,1,0,0,0,2475,2477,5,472,0,0,
        2476,2468,1,0,0,0,2476,2477,1,0,0,0,2477,305,1,0,0,0,2478,2487,5,
        268,0,0,2479,2481,5,222,0,0,2480,2482,5,458,0,0,2481,2480,1,0,0,
        0,2481,2482,1,0,0,0,2482,2483,1,0,0,0,2483,2484,5,471,0,0,2484,2485,
        3,422,211,0,2485,2486,5,472,0,0,2486,2488,1,0,0,0,2487,2479,1,0,
        0,0,2487,2488,1,0,0,0,2488,2490,1,0,0,0,2489,2491,3,42,21,0,2490,
        2489,1,0,0,0,2490,2491,1,0,0,0,2491,307,1,0,0,0,2492,2493,5,438,
        0,0,2493,2494,5,496,0,0,2494,309,1,0,0,0,2495,2496,7,22,0,0,2496,
        2500,7,23,0,0,2497,2498,7,24,0,0,2498,2500,7,25,0,0,2499,2495,1,
        0,0,0,2499,2497,1,0,0,0,2500,311,1,0,0,0,2501,2505,3,316,158,0,2502,
        2505,3,348,174,0,2503,2505,3,352,176,0,2504,2501,1,0,0,0,2504,2502,
        1,0,0,0,2504,2503,1,0,0,0,2505,313,1,0,0,0,2506,2507,5,471,0,0,2507,
        2512,3,316,158,0,2508,2509,5,475,0,0,2509,2511,3,316,158,0,2510,
        2508,1,0,0,0,2511,2514,1,0,0,0,2512,2510,1,0,0,0,2512,2513,1,0,0,
        0,2513,2515,1,0,0,0,2514,2512,1,0,0,0,2515,2516,5,472,0,0,2516,315,
        1,0,0,0,2517,2518,3,354,177,0,2518,2520,3,358,179,0,2519,2521,3,
        344,172,0,2520,2519,1,0,0,0,2520,2521,1,0,0,0,2521,2523,1,0,0,0,
        2522,2524,3,346,173,0,2523,2522,1,0,0,0,2523,2524,1,0,0,0,2524,317,
        1,0,0,0,2525,2526,3,360,180,0,2526,319,1,0,0,0,2527,2528,5,193,0,
        0,2528,2529,5,290,0,0,2529,2530,3,360,180,0,2530,2531,5,209,0,0,
        2531,2532,3,360,180,0,2532,2543,1,0,0,0,2533,2534,5,193,0,0,2534,
        2537,5,290,0,0,2535,2538,3,446,223,0,2536,2538,3,360,180,0,2537,
        2535,1,0,0,0,2537,2536,1,0,0,0,2538,2539,1,0,0,0,2539,2540,5,209,
        0,0,2540,2541,3,446,223,0,2541,2543,1,0,0,0,2542,2527,1,0,0,0,2542,
        2533,1,0,0,0,2543,321,1,0,0,0,2544,2545,5,242,0,0,2545,2547,3,324,
        162,0,2546,2544,1,0,0,0,2546,2547,1,0,0,0,2547,2548,1,0,0,0,2548,
        2549,5,378,0,0,2549,2550,5,77,0,0,2550,2551,3,356,178,0,2551,2552,
        5,348,0,0,2552,2553,5,39,0,0,2553,323,1,0,0,0,2554,2555,3,422,211,
        0,2555,325,1,0,0,0,2556,2557,5,440,0,0,2557,2562,3,328,164,0,2558,
        2559,5,475,0,0,2559,2561,3,328,164,0,2560,2558,1,0,0,0,2561,2564,
        1,0,0,0,2562,2560,1,0,0,0,2562,2563,1,0,0,0,2563,327,1,0,0,0,2564,
        2562,1,0,0,0,2565,2566,5,471,0,0,2566,2571,3,466,233,0,2567,2568,
        5,475,0,0,2568,2570,3,466,233,0,2569,2567,1,0,0,0,2570,2573,1,0,
        0,0,2571,2569,1,0,0,0,2571,2572,1,0,0,0,2572,2574,1,0,0,0,2573,2571,
        1,0,0,0,2574,2575,5,472,0,0,2575,329,1,0,0,0,2576,2577,5,471,0,0,
        2577,2578,3,474,237,0,2578,2579,5,472,0,0,2579,331,1,0,0,0,2580,
        2581,5,471,0,0,2581,2584,3,474,237,0,2582,2583,5,475,0,0,2583,2585,
        3,474,237,0,2584,2582,1,0,0,0,2584,2585,1,0,0,0,2585,2586,1,0,0,
        0,2586,2587,5,472,0,0,2587,333,1,0,0,0,2588,2589,5,471,0,0,2589,
        2592,3,472,236,0,2590,2591,5,475,0,0,2591,2593,3,472,236,0,2592,
        2590,1,0,0,0,2592,2593,1,0,0,0,2593,2594,1,0,0,0,2594,2595,5,472,
        0,0,2595,335,1,0,0,0,2596,2597,5,466,0,0,2597,2602,3,358,179,0,2598,
        2599,5,475,0,0,2599,2601,3,358,179,0,2600,2598,1,0,0,0,2601,2604,
        1,0,0,0,2602,2600,1,0,0,0,2602,2603,1,0,0,0,2603,2605,1,0,0,0,2604,
        2602,1,0,0,0,2605,2606,5,465,0,0,2606,337,1,0,0,0,2607,2608,5,466,
        0,0,2608,2609,3,358,179,0,2609,2610,5,475,0,0,2610,2611,3,358,179,
        0,2611,2612,1,0,0,0,2612,2613,5,465,0,0,2613,339,1,0,0,0,2614,2615,
        5,466,0,0,2615,2616,3,354,177,0,2616,2623,3,358,179,0,2617,2618,
        5,475,0,0,2618,2619,3,354,177,0,2619,2620,3,358,179,0,2620,2622,
        1,0,0,0,2621,2617,1,0,0,0,2622,2625,1,0,0,0,2623,2621,1,0,0,0,2623,
        2624,1,0,0,0,2624,2626,1,0,0,0,2625,2623,1,0,0,0,2626,2627,5,465,
        0,0,2627,341,1,0,0,0,2628,2629,5,466,0,0,2629,2630,3,354,177,0,2630,
        2631,5,482,0,0,2631,2639,3,358,179,0,2632,2633,5,475,0,0,2633,2634,
        3,354,177,0,2634,2635,5,482,0,0,2635,2636,3,358,179,0,2636,2638,
        1,0,0,0,2637,2632,1,0,0,0,2638,2641,1,0,0,0,2639,2637,1,0,0,0,2639,
        2640,1,0,0,0,2640,2642,1,0,0,0,2641,2639,1,0,0,0,2642,2643,5,465,
        0,0,2643,343,1,0,0,0,2644,2645,5,242,0,0,2645,2647,3,324,162,0,2646,
        2644,1,0,0,0,2646,2647,1,0,0,0,2647,2648,1,0,0,0,2648,2649,5,378,
        0,0,2649,2652,5,77,0,0,2650,2651,5,348,0,0,2651,2653,5,39,0,0,2652,
        2650,1,0,0,0,2652,2653,1,0,0,0,2653,2659,1,0,0,0,2654,2656,5,348,
        0,0,2655,2654,1,0,0,0,2655,2656,1,0,0,0,2656,2657,1,0,0,0,2657,2659,
        5,351,0,0,2658,2646,1,0,0,0,2658,2655,1,0,0,0,2659,345,1,0,0,0,2660,
        2661,5,21,0,0,2661,2662,3,460,230,0,2662,347,1,0,0,0,2663,2664,3,
        354,177,0,2664,2665,3,358,179,0,2665,2668,5,337,0,0,2666,2667,5,
        291,0,0,2667,2669,3,350,175,0,2668,2666,1,0,0,0,2668,2669,1,0,0,
        0,2669,2671,1,0,0,0,2670,2672,5,192,0,0,2671,2670,1,0,0,0,2671,2672,
        1,0,0,0,2672,349,1,0,0,0,2673,2674,5,493,0,0,2674,351,1,0,0,0,2675,
        2676,3,354,177,0,2676,2677,5,209,0,0,2677,2679,3,318,159,0,2678,
        2680,3,346,173,0,2679,2678,1,0,0,0,2679,2680,1,0,0,0,2680,353,1,
        0,0,0,2681,2684,3,446,223,0,2682,2684,3,360,180,0,2683,2681,1,0,
        0,0,2683,2682,1,0,0,0,2684,355,1,0,0,0,2685,2686,5,471,0,0,2686,
        2688,3,354,177,0,2687,2689,3,346,173,0,2688,2687,1,0,0,0,2688,2689,
        1,0,0,0,2689,2697,1,0,0,0,2690,2691,5,475,0,0,2691,2693,3,354,177,
        0,2692,2694,3,346,173,0,2693,2692,1,0,0,0,2693,2694,1,0,0,0,2694,
        2696,1,0,0,0,2695,2690,1,0,0,0,2696,2699,1,0,0,0,2697,2695,1,0,0,
        0,2697,2698,1,0,0,0,2698,2700,1,0,0,0,2699,2697,1,0,0,0,2700,2701,
        5,472,0,0,2701,357,1,0,0,0,2702,2778,7,26,0,0,2703,2705,7,27,0,0,
        2704,2706,3,330,165,0,2705,2704,1,0,0,0,2705,2706,1,0,0,0,2706,2778,
        1,0,0,0,2707,2709,5,421,0,0,2708,2710,3,330,165,0,2709,2708,1,0,
        0,0,2709,2710,1,0,0,0,2710,2717,1,0,0,0,2711,2713,7,28,0,0,2712,
        2714,5,331,0,0,2713,2712,1,0,0,0,2713,2714,1,0,0,0,2714,2715,1,0,
        0,0,2715,2716,5,420,0,0,2716,2718,5,200,0,0,2717,2711,1,0,0,0,2717,
        2718,1,0,0,0,2718,2778,1,0,0,0,2719,2721,5,422,0,0,2720,2722,3,330,
        165,0,2721,2720,1,0,0,0,2721,2722,1,0,0,0,2722,2729,1,0,0,0,2723,
        2725,7,28,0,0,2724,2726,5,331,0,0,2725,2724,1,0,0,0,2725,2726,1,
        0,0,0,2726,2727,1,0,0,0,2727,2728,5,420,0,0,2728,2730,5,200,0,0,
        2729,2723,1,0,0,0,2729,2730,1,0,0,0,2730,2778,1,0,0,0,2731,2733,
        5,423,0,0,2732,2734,3,330,165,0,2733,2732,1,0,0,0,2733,2734,1,0,
        0,0,2734,2741,1,0,0,0,2735,2737,7,28,0,0,2736,2738,5,331,0,0,2737,
        2736,1,0,0,0,2737,2738,1,0,0,0,2738,2739,1,0,0,0,2739,2740,5,420,
        0,0,2740,2742,5,200,0,0,2741,2735,1,0,0,0,2741,2742,1,0,0,0,2742,
        2778,1,0,0,0,2743,2745,5,424,0,0,2744,2746,3,330,165,0,2745,2744,
        1,0,0,0,2745,2746,1,0,0,0,2746,2753,1,0,0,0,2747,2749,7,28,0,0,2748,
        2750,5,331,0,0,2749,2748,1,0,0,0,2749,2750,1,0,0,0,2750,2751,1,0,
        0,0,2751,2752,5,420,0,0,2752,2754,5,200,0,0,2753,2747,1,0,0,0,2753,
        2754,1,0,0,0,2754,2778,1,0,0,0,2755,2757,7,29,0,0,2756,2758,3,332,
        166,0,2757,2756,1,0,0,0,2757,2758,1,0,0,0,2758,2778,1,0,0,0,2759,
        2761,7,30,0,0,2760,2762,3,336,168,0,2761,2760,1,0,0,0,2761,2762,
        1,0,0,0,2762,2778,1,0,0,0,2763,2765,5,89,0,0,2764,2766,3,338,169,
        0,2765,2764,1,0,0,0,2765,2766,1,0,0,0,2766,2778,1,0,0,0,2767,2769,
        5,392,0,0,2768,2770,3,340,170,0,2769,2768,1,0,0,0,2769,2770,1,0,
        0,0,2770,2778,1,0,0,0,2771,2772,5,407,0,0,2772,2778,3,342,171,0,
        2773,2775,5,129,0,0,2774,2776,3,334,167,0,2775,2774,1,0,0,0,2775,
        2776,1,0,0,0,2776,2778,1,0,0,0,2777,2702,1,0,0,0,2777,2703,1,0,0,
        0,2777,2707,1,0,0,0,2777,2719,1,0,0,0,2777,2731,1,0,0,0,2777,2743,
        1,0,0,0,2777,2755,1,0,0,0,2777,2759,1,0,0,0,2777,2763,1,0,0,0,2777,
        2767,1,0,0,0,2777,2771,1,0,0,0,2777,2773,1,0,0,0,2778,359,1,0,0,
        0,2779,2780,3,362,181,0,2780,361,1,0,0,0,2781,2782,6,181,-1,0,2782,
        2783,5,348,0,0,2783,2794,3,362,181,6,2784,2785,5,280,0,0,2785,2786,
        5,471,0,0,2786,2787,3,132,66,0,2787,2788,5,472,0,0,2788,2794,1,0,
        0,0,2789,2791,3,368,184,0,2790,2792,3,364,182,0,2791,2790,1,0,0,
        0,2791,2792,1,0,0,0,2792,2794,1,0,0,0,2793,2781,1,0,0,0,2793,2784,
        1,0,0,0,2793,2789,1,0,0,0,2794,2809,1,0,0,0,2795,2796,10,3,0,0,2796,
        2797,5,205,0,0,2797,2808,3,362,181,4,2798,2799,10,2,0,0,2799,2800,
        5,357,0,0,2800,2808,3,362,181,3,2801,2802,10,1,0,0,2802,2804,5,318,
        0,0,2803,2805,5,348,0,0,2804,2803,1,0,0,0,2804,2805,1,0,0,0,2805,
        2806,1,0,0,0,2806,2808,7,31,0,0,2807,2795,1,0,0,0,2807,2798,1,0,
        0,0,2807,2801,1,0,0,0,2808,2811,1,0,0,0,2809,2807,1,0,0,0,2809,2810,
        1,0,0,0,2810,363,1,0,0,0,2811,2809,1,0,0,0,2812,2814,5,348,0,0,2813,
        2812,1,0,0,0,2813,2814,1,0,0,0,2814,2815,1,0,0,0,2815,2817,5,214,
        0,0,2816,2818,7,32,0,0,2817,2816,1,0,0,0,2817,2818,1,0,0,0,2818,
        2819,1,0,0,0,2819,2820,3,368,184,0,2820,2821,5,205,0,0,2821,2822,
        3,368,184,0,2822,2880,1,0,0,0,2823,2825,5,348,0,0,2824,2823,1,0,
        0,0,2824,2825,1,0,0,0,2825,2826,1,0,0,0,2826,2827,5,303,0,0,2827,
        2828,5,471,0,0,2828,2833,3,360,180,0,2829,2830,5,475,0,0,2830,2832,
        3,360,180,0,2831,2829,1,0,0,0,2832,2835,1,0,0,0,2833,2831,1,0,0,
        0,2833,2834,1,0,0,0,2834,2836,1,0,0,0,2835,2833,1,0,0,0,2836,2837,
        5,472,0,0,2837,2880,1,0,0,0,2838,2840,5,348,0,0,2839,2838,1,0,0,
        0,2839,2840,1,0,0,0,2840,2841,1,0,0,0,2841,2842,5,303,0,0,2842,2843,
        5,471,0,0,2843,2844,3,132,66,0,2844,2845,5,472,0,0,2845,2880,1,0,
        0,0,2846,2847,5,280,0,0,2847,2848,5,471,0,0,2848,2849,3,132,66,0,
        2849,2850,5,472,0,0,2850,2880,1,0,0,0,2851,2853,5,348,0,0,2852,2851,
        1,0,0,0,2852,2853,1,0,0,0,2853,2854,1,0,0,0,2854,2855,5,389,0,0,
        2855,2880,3,368,184,0,2856,2880,3,366,183,0,2857,2859,5,318,0,0,
        2858,2860,5,348,0,0,2859,2858,1,0,0,0,2859,2860,1,0,0,0,2860,2861,
        1,0,0,0,2861,2880,7,31,0,0,2862,2864,5,318,0,0,2863,2865,5,348,0,
        0,2864,2863,1,0,0,0,2864,2865,1,0,0,0,2865,2866,1,0,0,0,2866,2867,
        5,266,0,0,2867,2868,5,291,0,0,2868,2880,3,368,184,0,2869,2871,5,
        348,0,0,2870,2869,1,0,0,0,2870,2871,1,0,0,0,2871,2872,1,0,0,0,2872,
        2873,5,399,0,0,2873,2874,5,426,0,0,2874,2877,3,368,184,0,2875,2876,
        5,276,0,0,2876,2878,3,472,236,0,2877,2875,1,0,0,0,2877,2878,1,0,
        0,0,2878,2880,1,0,0,0,2879,2813,1,0,0,0,2879,2824,1,0,0,0,2879,2839,
        1,0,0,0,2879,2846,1,0,0,0,2879,2852,1,0,0,0,2879,2856,1,0,0,0,2879,
        2857,1,0,0,0,2879,2862,1,0,0,0,2879,2870,1,0,0,0,2880,365,1,0,0,
        0,2881,2883,5,348,0,0,2882,2881,1,0,0,0,2882,2883,1,0,0,0,2883,2884,
        1,0,0,0,2884,2885,5,328,0,0,2885,2899,7,33,0,0,2886,2887,5,471,0,
        0,2887,2900,5,472,0,0,2888,2889,5,471,0,0,2889,2894,3,360,180,0,
        2890,2891,5,475,0,0,2891,2893,3,360,180,0,2892,2890,1,0,0,0,2893,
        2896,1,0,0,0,2894,2892,1,0,0,0,2894,2895,1,0,0,0,2895,2897,1,0,0,
        0,2896,2894,1,0,0,0,2897,2898,5,472,0,0,2898,2900,1,0,0,0,2899,2886,
        1,0,0,0,2899,2888,1,0,0,0,2900,2920,1,0,0,0,2901,2903,5,348,0,0,
        2902,2901,1,0,0,0,2902,2903,1,0,0,0,2903,2904,1,0,0,0,2904,2905,
        7,34,0,0,2905,2908,3,368,184,0,2906,2907,5,276,0,0,2907,2909,3,472,
        236,0,2908,2906,1,0,0,0,2908,2909,1,0,0,0,2909,2920,1,0,0,0,2910,
        2912,5,348,0,0,2911,2910,1,0,0,0,2911,2912,1,0,0,0,2912,2913,1,0,
        0,0,2913,2914,7,35,0,0,2914,2917,3,472,236,0,2915,2916,5,276,0,0,
        2916,2918,3,472,236,0,2917,2915,1,0,0,0,2917,2918,1,0,0,0,2918,2920,
        1,0,0,0,2919,2882,1,0,0,0,2919,2902,1,0,0,0,2919,2911,1,0,0,0,2920,
        367,1,0,0,0,2921,2922,6,184,-1,0,2922,2926,3,370,185,0,2923,2924,
        7,36,0,0,2924,2926,3,368,184,7,2925,2921,1,0,0,0,2925,2923,1,0,0,
        0,2926,2948,1,0,0,0,2927,2928,10,6,0,0,2928,2929,7,37,0,0,2929,2947,
        3,368,184,7,2930,2931,10,5,0,0,2931,2932,7,38,0,0,2932,2947,3,368,
        184,6,2933,2934,10,4,0,0,2934,2935,5,462,0,0,2935,2947,3,368,184,
        5,2936,2937,10,3,0,0,2937,2938,5,463,0,0,2938,2947,3,368,184,4,2939,
        2940,10,2,0,0,2940,2941,5,461,0,0,2941,2947,3,368,184,3,2942,2943,
        10,1,0,0,2943,2944,3,464,232,0,2944,2945,3,368,184,2,2945,2947,1,
        0,0,0,2946,2927,1,0,0,0,2946,2930,1,0,0,0,2946,2933,1,0,0,0,2946,
        2936,1,0,0,0,2946,2939,1,0,0,0,2946,2942,1,0,0,0,2947,2950,1,0,0,
        0,2948,2946,1,0,0,0,2948,2949,1,0,0,0,2949,369,1,0,0,0,2950,2948,
        1,0,0,0,2951,2952,6,185,-1,0,2952,2954,5,226,0,0,2953,2955,3,432,
        216,0,2954,2953,1,0,0,0,2955,2956,1,0,0,0,2956,2954,1,0,0,0,2956,
        2957,1,0,0,0,2957,2960,1,0,0,0,2958,2959,5,273,0,0,2959,2961,3,360,
        180,0,2960,2958,1,0,0,0,2960,2961,1,0,0,0,2961,2962,1,0,0,0,2962,
        2963,5,274,0,0,2963,3072,1,0,0,0,2964,2965,5,226,0,0,2965,2967,3,
        360,180,0,2966,2968,3,432,216,0,2967,2966,1,0,0,0,2968,2969,1,0,
        0,0,2969,2967,1,0,0,0,2969,2970,1,0,0,0,2970,2973,1,0,0,0,2971,2972,
        5,273,0,0,2972,2974,3,360,180,0,2973,2971,1,0,0,0,2973,2974,1,0,
        0,0,2974,2975,1,0,0,0,2975,2976,5,274,0,0,2976,3072,1,0,0,0,2977,
        2978,5,227,0,0,2978,2979,5,471,0,0,2979,2980,3,360,180,0,2980,2981,
        5,209,0,0,2981,2982,3,358,179,0,2982,2983,5,472,0,0,2983,3072,1,
        0,0,0,2984,2985,5,52,0,0,2985,2986,5,471,0,0,2986,2989,3,360,180,
        0,2987,2988,5,67,0,0,2988,2990,5,100,0,0,2989,2987,1,0,0,0,2989,
        2990,1,0,0,0,2990,2991,1,0,0,0,2991,2992,5,472,0,0,2992,3072,1,0,
        0,0,2993,2994,5,82,0,0,2994,2995,5,471,0,0,2995,2998,3,360,180,0,
        2996,2997,5,67,0,0,2997,2999,5,100,0,0,2998,2996,1,0,0,0,2998,2999,
        1,0,0,0,2999,3000,1,0,0,0,3000,3001,5,472,0,0,3001,3072,1,0,0,0,
        3002,3003,5,374,0,0,3003,3004,5,471,0,0,3004,3005,3,368,184,0,3005,
        3006,5,303,0,0,3006,3007,3,368,184,0,3007,3008,5,472,0,0,3008,3072,
        1,0,0,0,3009,3072,3,466,233,0,3010,3072,5,483,0,0,3011,3012,3,446,
        223,0,3012,3013,5,468,0,0,3013,3014,5,483,0,0,3014,3072,1,0,0,0,
        3015,3016,5,471,0,0,3016,3017,3,132,66,0,3017,3018,5,472,0,0,3018,
        3072,1,0,0,0,3019,3020,5,471,0,0,3020,3025,3,388,194,0,3021,3022,
        5,475,0,0,3022,3024,3,388,194,0,3023,3021,1,0,0,0,3024,3027,1,0,
        0,0,3025,3023,1,0,0,0,3025,3026,1,0,0,0,3026,3028,1,0,0,0,3027,3025,
        1,0,0,0,3028,3029,5,472,0,0,3029,3072,1,0,0,0,3030,3031,3,386,193,
        0,3031,3043,5,471,0,0,3032,3034,3,478,239,0,3033,3032,1,0,0,0,3033,
        3034,1,0,0,0,3034,3035,1,0,0,0,3035,3040,3,388,194,0,3036,3037,5,
        475,0,0,3037,3039,3,388,194,0,3038,3036,1,0,0,0,3039,3042,1,0,0,
        0,3040,3038,1,0,0,0,3040,3041,1,0,0,0,3041,3044,1,0,0,0,3042,3040,
        1,0,0,0,3043,3033,1,0,0,0,3043,3044,1,0,0,0,3044,3045,1,0,0,0,3045,
        3046,5,472,0,0,3046,3072,1,0,0,0,3047,3048,3,386,193,0,3048,3049,
        5,471,0,0,3049,3050,3,388,194,0,3050,3051,5,426,0,0,3051,3052,3,
        388,194,0,3052,3053,5,472,0,0,3053,3072,1,0,0,0,3054,3055,3,386,
        193,0,3055,3057,5,471,0,0,3056,3058,3,478,239,0,3057,3056,1,0,0,
        0,3057,3058,1,0,0,0,3058,3059,1,0,0,0,3059,3060,3,388,194,0,3060,
        3062,5,472,0,0,3061,3063,3,390,195,0,3062,3061,1,0,0,0,3062,3063,
        1,0,0,0,3063,3072,1,0,0,0,3064,3072,3,422,211,0,3065,3072,3,392,
        196,0,3066,3067,5,471,0,0,3067,3068,3,360,180,0,3068,3069,5,472,
        0,0,3069,3072,1,0,0,0,3070,3072,3,372,186,0,3071,2951,1,0,0,0,3071,
        2964,1,0,0,0,3071,2977,1,0,0,0,3071,2984,1,0,0,0,3071,2993,1,0,0,
        0,3071,3002,1,0,0,0,3071,3009,1,0,0,0,3071,3010,1,0,0,0,3071,3011,
        1,0,0,0,3071,3015,1,0,0,0,3071,3019,1,0,0,0,3071,3030,1,0,0,0,3071,
        3047,1,0,0,0,3071,3054,1,0,0,0,3071,3064,1,0,0,0,3071,3065,1,0,0,
        0,3071,3066,1,0,0,0,3071,3070,1,0,0,0,3072,3080,1,0,0,0,3073,3074,
        10,5,0,0,3074,3075,5,469,0,0,3075,3076,3,368,184,0,3076,3077,5,470,
        0,0,3077,3079,1,0,0,0,3078,3073,1,0,0,0,3079,3082,1,0,0,0,3080,3078,
        1,0,0,0,3080,3081,1,0,0,0,3081,371,1,0,0,0,3082,3080,1,0,0,0,3083,
        3088,3,374,187,0,3084,3088,3,378,189,0,3085,3088,3,380,190,0,3086,
        3088,3,376,188,0,3087,3083,1,0,0,0,3087,3084,1,0,0,0,3087,3085,1,
        0,0,0,3087,3086,1,0,0,0,3088,373,1,0,0,0,3089,3090,5,208,0,0,3090,
        3091,5,469,0,0,3091,3096,3,382,191,0,3092,3093,5,475,0,0,3093,3095,
        3,382,191,0,3094,3092,1,0,0,0,3095,3098,1,0,0,0,3096,3094,1,0,0,
        0,3096,3097,1,0,0,0,3097,3099,1,0,0,0,3098,3096,1,0,0,0,3099,3100,
        5,470,0,0,3100,3101,5,208,0,0,3101,3102,5,471,0,0,3102,3107,3,382,
        191,0,3103,3104,5,475,0,0,3104,3106,3,382,191,0,3105,3103,1,0,0,
        0,3106,3109,1,0,0,0,3107,3105,1,0,0,0,3107,3108,1,0,0,0,3108,3110,
        1,0,0,0,3109,3107,1,0,0,0,3110,3111,5,472,0,0,3111,375,1,0,0,0,3112,
        3113,5,407,0,0,3113,3114,5,471,0,0,3114,3119,3,382,191,0,3115,3116,
        5,475,0,0,3116,3118,3,382,191,0,3117,3115,1,0,0,0,3118,3121,1,0,
        0,0,3119,3117,1,0,0,0,3119,3120,1,0,0,0,3120,3122,1,0,0,0,3121,3119,
        1,0,0,0,3122,3123,5,472,0,0,3123,377,1,0,0,0,3124,3125,5,392,0,0,
        3125,3126,5,471,0,0,3126,3131,3,382,191,0,3127,3128,5,475,0,0,3128,
        3130,3,382,191,0,3129,3127,1,0,0,0,3130,3133,1,0,0,0,3131,3129,1,
        0,0,0,3131,3132,1,0,0,0,3132,3134,1,0,0,0,3133,3131,1,0,0,0,3134,
        3135,5,472,0,0,3135,379,1,0,0,0,3136,3137,5,89,0,0,3137,3138,5,469,
        0,0,3138,3139,3,382,191,0,3139,3140,5,475,0,0,3140,3141,3,382,191,
        0,3141,3142,5,470,0,0,3142,381,1,0,0,0,3143,3148,3,410,205,0,3144,
        3148,3,466,233,0,3145,3148,3,372,186,0,3146,3148,3,384,192,0,3147,
        3143,1,0,0,0,3147,3144,1,0,0,0,3147,3145,1,0,0,0,3147,3146,1,0,0,
        0,3148,383,1,0,0,0,3149,3150,7,39,0,0,3150,385,1,0,0,0,3151,3155,
        3,488,244,0,3152,3155,3,446,223,0,3153,3155,3,486,243,0,3154,3151,
        1,0,0,0,3154,3152,1,0,0,0,3154,3153,1,0,0,0,3155,387,1,0,0,0,3156,
        3163,3,484,242,0,3157,3163,3,482,241,0,3158,3163,3,480,240,0,3159,
        3163,3,360,180,0,3160,3163,3,390,195,0,3161,3163,3,466,233,0,3162,
        3156,1,0,0,0,3162,3157,1,0,0,0,3162,3158,1,0,0,0,3162,3159,1,0,0,
        0,3162,3160,1,0,0,0,3162,3161,1,0,0,0,3163,389,1,0,0,0,3164,3165,
        5,48,0,0,3165,3166,5,471,0,0,3166,3167,5,444,0,0,3167,3168,3,362,
        181,0,3168,3169,5,472,0,0,3169,391,1,0,0,0,3170,3171,3,446,223,0,
        3171,393,1,0,0,0,3172,3173,3,422,211,0,3173,395,1,0,0,0,3174,3178,
        3,422,211,0,3175,3178,3,392,196,0,3176,3178,3,424,212,0,3177,3174,
        1,0,0,0,3177,3175,1,0,0,0,3177,3176,1,0,0,0,3178,397,1,0,0,0,3179,
        3182,5,312,0,0,3180,3183,3,400,200,0,3181,3183,3,404,202,0,3182,
        3180,1,0,0,0,3182,3181,1,0,0,0,3182,3183,1,0,0,0,3183,399,1,0,0,
        0,3184,3186,3,402,201,0,3185,3187,3,406,203,0,3186,3185,1,0,0,0,
        3186,3187,1,0,0,0,3187,401,1,0,0,0,3188,3189,3,408,204,0,3189,3190,
        3,482,241,0,3190,3192,1,0,0,0,3191,3188,1,0,0,0,3192,3193,1,0,0,
        0,3193,3191,1,0,0,0,3193,3194,1,0,0,0,3194,403,1,0,0,0,3195,3198,
        3,406,203,0,3196,3199,3,402,201,0,3197,3199,3,406,203,0,3198,3196,
        1,0,0,0,3198,3197,1,0,0,0,3198,3199,1,0,0,0,3199,405,1,0,0,0,3200,
        3201,3,408,204,0,3201,3202,3,482,241,0,3202,3203,5,426,0,0,3203,
        3204,3,482,241,0,3204,407,1,0,0,0,3205,3207,7,40,0,0,3206,3205,1,
        0,0,0,3206,3207,1,0,0,0,3207,3208,1,0,0,0,3208,3211,7,41,0,0,3209,
        3211,5,493,0,0,3210,3206,1,0,0,0,3210,3209,1,0,0,0,3211,409,1,0,
        0,0,3212,3214,5,209,0,0,3213,3212,1,0,0,0,3213,3214,1,0,0,0,3214,
        3215,1,0,0,0,3215,3217,3,422,211,0,3216,3218,3,418,209,0,3217,3216,
        1,0,0,0,3217,3218,1,0,0,0,3218,411,1,0,0,0,3219,3221,5,209,0,0,3220,
        3219,1,0,0,0,3220,3221,1,0,0,0,3221,3222,1,0,0,0,3222,3224,3,422,
        211,0,3223,3225,3,418,209,0,3224,3223,1,0,0,0,3224,3225,1,0,0,0,
        3225,413,1,0,0,0,3226,3227,3,422,211,0,3227,3228,3,416,208,0,3228,
        415,1,0,0,0,3229,3230,5,338,0,0,3230,3232,3,422,211,0,3231,3229,
        1,0,0,0,3232,3233,1,0,0,0,3233,3231,1,0,0,0,3233,3234,1,0,0,0,3234,
        3237,1,0,0,0,3235,3237,1,0,0,0,3236,3231,1,0,0,0,3236,3235,1,0,0,
        0,3237,417,1,0,0,0,3238,3239,5,471,0,0,3239,3240,3,420,210,0,3240,
        3241,5,472,0,0,3241,419,1,0,0,0,3242,3247,3,422,211,0,3243,3244,
        5,475,0,0,3244,3246,3,422,211,0,3245,3243,1,0,0,0,3246,3249,1,0,
        0,0,3247,3245,1,0,0,0,3247,3248,1,0,0,0,3248,421,1,0,0,0,3249,3247,
        1,0,0,0,3250,3255,3,428,214,0,3251,3255,3,430,215,0,3252,3255,3,
        488,244,0,3253,3255,3,426,213,0,3254,3250,1,0,0,0,3254,3251,1,0,
        0,0,3254,3252,1,0,0,0,3254,3253,1,0,0,0,3255,423,1,0,0,0,3256,3261,
        3,428,214,0,3257,3261,3,484,242,0,3258,3261,3,488,244,0,3259,3261,
        3,486,243,0,3260,3256,1,0,0,0,3260,3257,1,0,0,0,3260,3258,1,0,0,
        0,3260,3259,1,0,0,0,3261,425,1,0,0,0,3262,3263,5,478,0,0,3263,3264,
        5,473,0,0,3264,3265,3,428,214,0,3265,3266,5,474,0,0,3266,427,1,0,
        0,0,3267,3268,7,42,0,0,3268,429,1,0,0,0,3269,3270,5,493,0,0,3270,
        431,1,0,0,0,3271,3272,5,443,0,0,3272,3273,3,360,180,0,3273,3274,
        5,419,0,0,3274,3275,3,360,180,0,3275,433,1,0,0,0,3276,3277,3,446,
        223,0,3277,435,1,0,0,0,3278,3279,3,446,223,0,3279,437,1,0,0,0,3280,
        3281,3,446,223,0,3281,439,1,0,0,0,3282,3283,3,446,223,0,3283,441,
        1,0,0,0,3284,3285,3,446,223,0,3285,443,1,0,0,0,3286,3287,3,422,211,
        0,3287,445,1,0,0,0,3288,3293,3,422,211,0,3289,3290,5,468,0,0,3290,
        3292,3,422,211,0,3291,3289,1,0,0,0,3292,3295,1,0,0,0,3293,3291,1,
        0,0,0,3293,3294,1,0,0,0,3294,447,1,0,0,0,3295,3293,1,0,0,0,3296,
        3298,5,446,0,0,3297,3299,7,43,0,0,3298,3297,1,0,0,0,3298,3299,1,
        0,0,0,3299,3300,1,0,0,0,3300,3301,3,454,227,0,3301,449,1,0,0,0,3302,
        3303,5,66,0,0,3303,3304,5,348,0,0,3304,3305,5,280,0,0,3305,451,1,
        0,0,0,3306,3307,5,66,0,0,3307,3308,5,280,0,0,3308,453,1,0,0,0,3309,
        3310,5,471,0,0,3310,3315,3,456,228,0,3311,3312,5,475,0,0,3312,3314,
        3,456,228,0,3313,3311,1,0,0,0,3314,3317,1,0,0,0,3315,3313,1,0,0,
        0,3315,3316,1,0,0,0,3316,3318,1,0,0,0,3317,3315,1,0,0,0,3318,3319,
        5,472,0,0,3319,455,1,0,0,0,3320,3321,3,458,229,0,3321,3323,5,464,
        0,0,3322,3324,5,254,0,0,3323,3322,1,0,0,0,3323,3324,1,0,0,0,3324,
        3325,1,0,0,0,3325,3326,3,462,231,0,3326,457,1,0,0,0,3327,3332,3,
        422,211,0,3328,3332,3,392,196,0,3329,3332,3,472,236,0,3330,3332,
        3,388,194,0,3331,3327,1,0,0,0,3331,3328,1,0,0,0,3331,3329,1,0,0,
        0,3331,3330,1,0,0,0,3332,459,1,0,0,0,3333,3334,5,479,0,0,3334,3335,
        3,466,233,0,3335,3336,5,479,0,0,3336,3339,1,0,0,0,3337,3339,3,466,
        233,0,3338,3333,1,0,0,0,3338,3337,1,0,0,0,3339,461,1,0,0,0,3340,
        3346,5,494,0,0,3341,3346,5,495,0,0,3342,3346,3,476,238,0,3343,3346,
        3,446,223,0,3344,3346,3,466,233,0,3345,3340,1,0,0,0,3345,3341,1,
        0,0,0,3345,3342,1,0,0,0,3345,3343,1,0,0,0,3345,3344,1,0,0,0,3346,
        463,1,0,0,0,3347,3362,5,464,0,0,3348,3362,5,465,0,0,3349,3362,5,
        466,0,0,3350,3351,5,466,0,0,3351,3362,5,464,0,0,3352,3353,5,465,
        0,0,3353,3362,5,464,0,0,3354,3355,5,466,0,0,3355,3362,5,465,0,0,
        3356,3357,5,467,0,0,3357,3362,5,464,0,0,3358,3359,5,466,0,0,3359,
        3360,5,464,0,0,3360,3362,5,465,0,0,3361,3347,1,0,0,0,3361,3348,1,
        0,0,0,3361,3349,1,0,0,0,3361,3350,1,0,0,0,3361,3352,1,0,0,0,3361,
        3354,1,0,0,0,3361,3356,1,0,0,0,3361,3358,1,0,0,0,3362,465,1,0,0,
        0,3363,3377,3,398,199,0,3364,3377,3,468,234,0,3365,3377,3,472,236,
        0,3366,3368,5,485,0,0,3367,3366,1,0,0,0,3367,3368,1,0,0,0,3368,3369,
        1,0,0,0,3369,3377,3,474,237,0,3370,3377,3,476,238,0,3371,3377,5,
        495,0,0,3372,3374,5,348,0,0,3373,3372,1,0,0,0,3373,3374,1,0,0,0,
        3374,3375,1,0,0,0,3375,3377,5,351,0,0,3376,3363,1,0,0,0,3376,3364,
        1,0,0,0,3376,3365,1,0,0,0,3376,3367,1,0,0,0,3376,3370,1,0,0,0,3376,
        3371,1,0,0,0,3376,3373,1,0,0,0,3377,467,1,0,0,0,3378,3379,3,480,
        240,0,3379,3380,3,472,236,0,3380,469,1,0,0,0,3381,3382,7,44,0,0,
        3382,471,1,0,0,0,3383,3384,5,493,0,0,3384,473,1,0,0,0,3385,3386,
        5,494,0,0,3386,475,1,0,0,0,3387,3388,7,45,0,0,3388,477,1,0,0,0,3389,
        3390,7,8,0,0,3390,479,1,0,0,0,3391,3392,7,46,0,0,3392,481,1,0,0,
        0,3393,3394,7,47,0,0,3394,483,1,0,0,0,3395,3396,7,48,0,0,3396,485,
        1,0,0,0,3397,3398,7,49,0,0,3398,487,1,0,0,0,3399,3400,7,50,0,0,3400,
        489,1,0,0,0,413,495,497,502,513,517,520,524,527,534,539,543,548,
        553,557,570,574,578,584,590,595,611,618,625,631,640,644,651,667,
        675,685,694,704,712,716,722,729,734,738,758,773,779,783,789,796,
        830,842,847,851,857,859,864,866,871,873,879,883,889,899,909,917,
        924,933,939,945,952,962,972,980,988,997,1002,1008,1017,1029,1035,
        1041,1053,1063,1073,1077,1081,1084,1089,1092,1095,1099,1103,1106,
        1114,1119,1123,1130,1136,1146,1152,1157,1161,1163,1168,1172,1187,
        1201,1207,1212,1218,1221,1231,1245,1253,1258,1262,1274,1276,1281,
        1285,1290,1299,1318,1330,1344,1347,1350,1353,1356,1358,1363,1367,
        1370,1373,1376,1380,1387,1392,1401,1412,1422,1427,1439,1442,1445,
        1448,1453,1456,1459,1462,1481,1484,1487,1490,1492,1496,1500,1506,
        1511,1514,1518,1521,1526,1529,1538,1541,1544,1546,1556,1560,1564,
        1571,1575,1579,1586,1592,1596,1605,1608,1613,1617,1633,1647,1652,
        1657,1663,1666,1674,1677,1680,1685,1691,1694,1696,1701,1704,1708,
        1711,1714,1720,1728,1733,1742,1746,1754,1770,1776,1782,1787,1791,
        1800,1805,1809,1822,1825,1829,1843,1851,1859,1877,1881,1902,1914,
        1926,1935,1947,1961,1963,1967,1982,1988,1993,1996,1999,2005,2011,
        2028,2046,2051,2061,2069,2078,2084,2087,2093,2102,2112,2122,2132,
        2137,2144,2156,2168,2180,2185,2212,2220,2224,2227,2230,2233,2240,
        2243,2246,2249,2252,2255,2258,2263,2266,2275,2285,2290,2294,2299,
        2304,2313,2332,2340,2348,2352,2356,2366,2392,2400,2412,2433,2438,
        2442,2455,2460,2464,2472,2476,2481,2487,2490,2499,2504,2512,2520,
        2523,2537,2542,2546,2562,2571,2584,2592,2602,2623,2639,2646,2652,
        2655,2658,2668,2671,2679,2683,2688,2693,2697,2705,2709,2713,2717,
        2721,2725,2729,2733,2737,2741,2745,2749,2753,2757,2761,2765,2769,
        2775,2777,2791,2793,2804,2807,2809,2813,2817,2824,2833,2839,2852,
        2859,2864,2870,2877,2879,2882,2894,2899,2902,2908,2911,2917,2919,
        2925,2946,2948,2956,2960,2969,2973,2989,2998,3025,3033,3040,3043,
        3057,3062,3071,3080,3087,3096,3107,3119,3131,3147,3154,3162,3177,
        3182,3186,3193,3198,3206,3210,3213,3217,3220,3224,3233,3236,3247,
        3254,3260,3293,3298,3315,3323,3331,3338,3345,3361,3367,3373,3376
    ];

    private static __ATN: antlr.ATN;
    public static get _ATN(): antlr.ATN {
        if (!SparkSQLParser.__ATN) {
            SparkSQLParser.__ATN = new antlr.ATNDeserializer().deserialize(SparkSQLParser._serializedATN);
        }

        return SparkSQLParser.__ATN;
    }


    private static readonly vocabulary = new antlr.Vocabulary(SparkSQLParser.literalNames, SparkSQLParser.symbolicNames, []);

    public override get vocabulary(): antlr.Vocabulary {
        return SparkSQLParser.vocabulary;
    }

    private static readonly decisionsToDFA = SparkSQLParser._ATN.decisionToState.map( (ds: antlr.DecisionState, index: number) => new antlr.DFA(ds, index) );
}

export class StatementContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public sqlStatements(): SqlStatementsContext {
        return this.getRuleContext(0, SqlStatementsContext)!;
    }
    public EOF(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.EOF, 0)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_statement;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterStatement) {
             listener.enterStatement(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitStatement) {
             listener.exitStatement(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitStatement) {
            return visitor.visitStatement(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class SqlStatementsContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public sqlStatement(): SqlStatementContext[];
    public sqlStatement(i: number): SqlStatementContext | null;
    public sqlStatement(i?: number): SqlStatementContext[] | SqlStatementContext | null {
        if (i === undefined) {
            return this.getRuleContexts(SqlStatementContext);
        }

        return this.getRuleContext(i, SqlStatementContext);
    }
    public emptyStatement(): EmptyStatementContext[];
    public emptyStatement(i: number): EmptyStatementContext | null;
    public emptyStatement(i?: number): EmptyStatementContext[] | EmptyStatementContext | null {
        if (i === undefined) {
            return this.getRuleContexts(EmptyStatementContext);
        }

        return this.getRuleContext(i, EmptyStatementContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_sqlStatements;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterSqlStatements) {
             listener.enterSqlStatements(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitSqlStatements) {
             listener.exitSqlStatements(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitSqlStatements) {
            return visitor.visitSqlStatements(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class SqlStatementContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public SEMICOLON(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.SEMICOLON, 0)!;
    }
    public dmlStatement(): DmlStatementContext | null {
        return this.getRuleContext(0, DmlStatementContext);
    }
    public createStatement(): CreateStatementContext | null {
        return this.getRuleContext(0, CreateStatementContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_sqlStatement;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterSqlStatement) {
             listener.enterSqlStatement(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitSqlStatement) {
             listener.exitSqlStatement(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitSqlStatement) {
            return visitor.visitSqlStatement(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class EmptyStatementContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public SEMICOLON(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.SEMICOLON, 0)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_emptyStatement;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterEmptyStatement) {
             listener.enterEmptyStatement(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitEmptyStatement) {
             listener.exitEmptyStatement(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitEmptyStatement) {
            return visitor.visitEmptyStatement(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class CreateStatementContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public createTable(): CreateTableContext | null {
        return this.getRuleContext(0, CreateTableContext);
    }
    public createDatabase(): CreateDatabaseContext | null {
        return this.getRuleContext(0, CreateDatabaseContext);
    }
    public createView(): CreateViewContext | null {
        return this.getRuleContext(0, CreateViewContext);
    }
    public createFunction(): CreateFunctionContext | null {
        return this.getRuleContext(0, CreateFunctionContext);
    }
    public createCatalog(): CreateCatalogContext | null {
        return this.getRuleContext(0, CreateCatalogContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_createStatement;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterCreateStatement) {
             listener.enterCreateStatement(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitCreateStatement) {
             listener.exitCreateStatement(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitCreateStatement) {
            return visitor.visitCreateStatement(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class DmlStatementContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public queryStatement(): QueryStatementContext | null {
        return this.getRuleContext(0, QueryStatementContext);
    }
    public insertStatement(): InsertStatementContext | null {
        return this.getRuleContext(0, InsertStatementContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_dmlStatement;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterDmlStatement) {
             listener.enterDmlStatement(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitDmlStatement) {
             listener.exitDmlStatement(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitDmlStatement) {
            return visitor.visitDmlStatement(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ShowTableStatementBodyContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_EXTENDED(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_EXTENDED, 0);
    }
    public KW_IN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_IN, 0);
    }
    public KW_DEFAULT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DEFAULT, 0);
    }
    public likeDefinition(): LikeDefinitionContext | null {
        return this.getRuleContext(0, LikeDefinitionContext);
    }
    public KW_PARTITION(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PARTITION, 0);
    }
    public LR_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0);
    }
    public tableProperty(): TablePropertyContext | null {
        return this.getRuleContext(0, TablePropertyContext);
    }
    public RR_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_showTableStatementBody;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterShowTableStatementBody) {
             listener.enterShowTableStatementBody(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitShowTableStatementBody) {
             listener.exitShowTableStatementBody(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitShowTableStatementBody) {
            return visitor.visitShowTableStatementBody(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ShowFunctionStatementBodyContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public uid(): UidContext | null {
        return this.getRuleContext(0, UidContext);
    }
    public KW_LIKE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LIKE, 0);
    }
    public expression(): ExpressionContext | null {
        return this.getRuleContext(0, ExpressionContext);
    }
    public KW_FROM(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FROM, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_showFunctionStatementBody;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterShowFunctionStatementBody) {
             listener.enterShowFunctionStatementBody(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitShowFunctionStatementBody) {
             listener.exitShowFunctionStatementBody(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitShowFunctionStatementBody) {
            return visitor.visitShowFunctionStatementBody(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class TableCanHasKeyPropertyListContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public tableProperty(): TablePropertyContext[];
    public tableProperty(i: number): TablePropertyContext | null;
    public tableProperty(i?: number): TablePropertyContext[] | TablePropertyContext | null {
        if (i === undefined) {
            return this.getRuleContexts(TablePropertyContext);
        }

        return this.getRuleContext(i, TablePropertyContext);
    }
    public tablePropertyKey(): TablePropertyKeyContext[];
    public tablePropertyKey(i: number): TablePropertyKeyContext | null;
    public tablePropertyKey(i?: number): TablePropertyKeyContext[] | TablePropertyKeyContext | null {
        if (i === undefined) {
            return this.getRuleContexts(TablePropertyKeyContext);
        }

        return this.getRuleContext(i, TablePropertyKeyContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_tableCanHasKeyPropertyList;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterTableCanHasKeyPropertyList) {
             listener.enterTableCanHasKeyPropertyList(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitTableCanHasKeyPropertyList) {
             listener.exitTableCanHasKeyPropertyList(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitTableCanHasKeyPropertyList) {
            return visitor.visitTableCanHasKeyPropertyList(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class CreateTableContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_createTable;
    }
    public override copyFrom(ctx: CreateTableContext): void {
        super.copyFrom(ctx);
    }
}
export class CreateExTableContext extends CreateTableContext {
    public constructor(ctx: CreateTableContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public createExternalTable(): CreateExternalTableContext {
        return this.getRuleContext(0, CreateExternalTableContext)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterCreateExTable) {
             listener.enterCreateExTable(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitCreateExTable) {
             listener.exitCreateExTable(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitCreateExTable) {
            return visitor.visitCreateExTable(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class Using_createContext extends CreateTableContext {
    public constructor(ctx: CreateTableContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public usingCreate(): UsingCreateContext {
        return this.getRuleContext(0, UsingCreateContext)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterUsing_create) {
             listener.enterUsing_create(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitUsing_create) {
             listener.exitUsing_create(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitUsing_create) {
            return visitor.visitUsing_create(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class MaterializedContext extends CreateTableContext {
    public constructor(ctx: CreateTableContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public createMaterializedTableAsSelect(): CreateMaterializedTableAsSelectContext {
        return this.getRuleContext(0, CreateMaterializedTableAsSelectContext)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterMaterialized) {
             listener.enterMaterialized(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitMaterialized) {
             listener.exitMaterialized(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitMaterialized) {
            return visitor.visitMaterialized(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class SimpleContext extends CreateTableContext {
    public constructor(ctx: CreateTableContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public simpleCreateTable(): SimpleCreateTableContext {
        return this.getRuleContext(0, SimpleCreateTableContext)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterSimple) {
             listener.enterSimple(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitSimple) {
             listener.exitSimple(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitSimple) {
            return visitor.visitSimple(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class AsSelectContext extends CreateTableContext {
    public constructor(ctx: CreateTableContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public createTableAsSelect(): CreateTableAsSelectContext {
        return this.getRuleContext(0, CreateTableAsSelectContext)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterAsSelect) {
             listener.enterAsSelect(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitAsSelect) {
             listener.exitAsSelect(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitAsSelect) {
            return visitor.visitAsSelect(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class CustomSerdeContext extends CreateTableContext {
    public constructor(ctx: CreateTableContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public createCustomSerde(): CreateCustomSerdeContext {
        return this.getRuleContext(0, CreateCustomSerdeContext)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterCustomSerde) {
             listener.enterCustomSerde(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitCustomSerde) {
             listener.exitCustomSerde(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitCustomSerde) {
            return visitor.visitCustomSerde(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class CustomSerdeExternalContext extends CreateTableContext {
    public constructor(ctx: CreateTableContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public createCustomSerdeExternal(): CreateCustomSerdeExternalContext {
        return this.getRuleContext(0, CreateCustomSerdeExternalContext)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterCustomSerdeExternal) {
             listener.enterCustomSerdeExternal(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitCustomSerdeExternal) {
             listener.exitCustomSerdeExternal(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitCustomSerdeExternal) {
            return visitor.visitCustomSerdeExternal(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class HiveCreateContext extends CreateTableContext {
    public constructor(ctx: CreateTableContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public hiveFormatCreate(): HiveFormatCreateContext {
        return this.getRuleContext(0, HiveFormatCreateContext)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterHiveCreate) {
             listener.enterHiveCreate(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitHiveCreate) {
             listener.exitHiveCreate(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitHiveCreate) {
            return visitor.visitHiveCreate(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class SimpleCreateTableContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_CREATE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_CREATE, 0)!;
    }
    public KW_TABLE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_TABLE, 0)!;
    }
    public tablePathCreate(): TablePathCreateContext {
        return this.getRuleContext(0, TablePathCreateContext)!;
    }
    public columnsBody(): ColumnsBodyContext | null {
        return this.getRuleContext(0, ColumnsBodyContext);
    }
    public KW_TEMPORARY(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TEMPORARY, 0);
    }
    public ifNotExists(): IfNotExistsContext | null {
        return this.getRuleContext(0, IfNotExistsContext);
    }
    public simpleCreateTableNoSortElement(): SimpleCreateTableNoSortElementContext[];
    public simpleCreateTableNoSortElement(i: number): SimpleCreateTableNoSortElementContext | null;
    public simpleCreateTableNoSortElement(i?: number): SimpleCreateTableNoSortElementContext[] | SimpleCreateTableNoSortElementContext | null {
        if (i === undefined) {
            return this.getRuleContexts(SimpleCreateTableNoSortElementContext);
        }

        return this.getRuleContext(i, SimpleCreateTableNoSortElementContext);
    }
    public KW_LIKE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LIKE, 0);
    }
    public tablePath(): TablePathContext | null {
        return this.getRuleContext(0, TablePathContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_simpleCreateTable;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterSimpleCreateTable) {
             listener.enterSimpleCreateTable(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitSimpleCreateTable) {
             listener.exitSimpleCreateTable(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitSimpleCreateTable) {
            return visitor.visitSimpleCreateTable(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class SimpleCreateTableNoSortElementContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public partitionDefinition(): PartitionDefinitionContext | null {
        return this.getRuleContext(0, PartitionDefinitionContext);
    }
    public withOption(): WithOptionContext | null {
        return this.getRuleContext(0, WithOptionContext);
    }
    public likeDefinition(): LikeDefinitionContext | null {
        return this.getRuleContext(0, LikeDefinitionContext);
    }
    public distribution(): DistributionContext | null {
        return this.getRuleContext(0, DistributionContext);
    }
    public someByClause(): SomeByClauseContext | null {
        return this.getRuleContext(0, SomeByClauseContext);
    }
    public intoBuckets(): IntoBucketsContext | null {
        return this.getRuleContext(0, IntoBucketsContext);
    }
    public storedAs(): StoredAsContext | null {
        return this.getRuleContext(0, StoredAsContext);
    }
    public hiveFormatpartitionDefinition(): HiveFormatpartitionDefinitionContext | null {
        return this.getRuleContext(0, HiveFormatpartitionDefinitionContext);
    }
    public sortedBy(): SortedByContext | null {
        return this.getRuleContext(0, SortedByContext);
    }
    public rowFormatDelimited(): RowFormatDelimitedContext | null {
        return this.getRuleContext(0, RowFormatDelimitedContext);
    }
    public fieldsTerminatedBy(): FieldsTerminatedByContext | null {
        return this.getRuleContext(0, FieldsTerminatedByContext);
    }
    public using(): UsingContext | null {
        return this.getRuleContext(0, UsingContext);
    }
    public location(): LocationContext | null {
        return this.getRuleContext(0, LocationContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_simpleCreateTableNoSortElement;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterSimpleCreateTableNoSortElement) {
             listener.enterSimpleCreateTableNoSortElement(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitSimpleCreateTableNoSortElement) {
             listener.exitSimpleCreateTableNoSortElement(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitSimpleCreateTableNoSortElement) {
            return visitor.visitSimpleCreateTableNoSortElement(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class SortedByContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_SORTED(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_SORTED, 0)!;
    }
    public KW_BY(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_BY, 0)!;
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public identifier(): IdentifierContext {
        return this.getRuleContext(0, IdentifierContext)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public KW_ASC(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ASC, 0);
    }
    public KW_DESC(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DESC, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_sortedBy;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterSortedBy) {
             listener.enterSortedBy(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitSortedBy) {
             listener.exitSortedBy(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitSortedBy) {
            return visitor.visitSortedBy(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class UsingCreateContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_CREATE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_CREATE, 0)!;
    }
    public KW_TABLE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_TABLE, 0)!;
    }
    public tablePathCreate(): TablePathCreateContext {
        return this.getRuleContext(0, TablePathCreateContext)!;
    }
    public columnUsing(): ColumnUsingContext | null {
        return this.getRuleContext(0, ColumnUsingContext);
    }
    public usingByQuery(): UsingByQueryContext | null {
        return this.getRuleContext(0, UsingByQueryContext);
    }
    public defaultColumnUsing(): DefaultColumnUsingContext | null {
        return this.getRuleContext(0, DefaultColumnUsingContext);
    }
    public ifNotExists(): IfNotExistsContext | null {
        return this.getRuleContext(0, IfNotExistsContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_usingCreate;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterUsingCreate) {
             listener.enterUsingCreate(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitUsingCreate) {
             listener.exitUsingCreate(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitUsingCreate) {
            return visitor.visitUsingCreate(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class TblPropertiesContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_TBLPROPERTIES(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_TBLPROPERTIES, 0)!;
    }
    public tablePropertyList(): TablePropertyListContext {
        return this.getRuleContext(0, TablePropertyListContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_tblProperties;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterTblProperties) {
             listener.enterTblProperties(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitTblProperties) {
             listener.exitTblProperties(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitTblProperties) {
            return visitor.visitTblProperties(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class DefaultColumnUsingContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public using(): UsingContext {
        return this.getRuleContext(0, UsingContext)!;
    }
    public queryStatement(): QueryStatementContext | null {
        return this.getRuleContext(0, QueryStatementContext);
    }
    public defaultColumnUsingNoSortElement(): DefaultColumnUsingNoSortElementContext[];
    public defaultColumnUsingNoSortElement(i: number): DefaultColumnUsingNoSortElementContext | null;
    public defaultColumnUsingNoSortElement(i?: number): DefaultColumnUsingNoSortElementContext[] | DefaultColumnUsingNoSortElementContext | null {
        if (i === undefined) {
            return this.getRuleContexts(DefaultColumnUsingNoSortElementContext);
        }

        return this.getRuleContext(i, DefaultColumnUsingNoSortElementContext);
    }
    public KW_AS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_AS, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_defaultColumnUsing;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterDefaultColumnUsing) {
             listener.enterDefaultColumnUsing(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitDefaultColumnUsing) {
             listener.exitDefaultColumnUsing(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitDefaultColumnUsing) {
            return visitor.visitDefaultColumnUsing(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class DefaultColumnUsingNoSortElementContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public partitionDefinition(): PartitionDefinitionContext | null {
        return this.getRuleContext(0, PartitionDefinitionContext);
    }
    public KW_OPTIONS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_OPTIONS, 0);
    }
    public tablePropertyList(): TablePropertyListContext | null {
        return this.getRuleContext(0, TablePropertyListContext);
    }
    public tblProperties(): TblPropertiesContext | null {
        return this.getRuleContext(0, TblPropertiesContext);
    }
    public someByClause(): SomeByClauseContext | null {
        return this.getRuleContext(0, SomeByClauseContext);
    }
    public intoBuckets(): IntoBucketsContext | null {
        return this.getRuleContext(0, IntoBucketsContext);
    }
    public KW_WITH(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_WITH, 0);
    }
    public tableAlias(): TableAliasContext | null {
        return this.getRuleContext(0, TableAliasContext);
    }
    public LB_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.LB_BRACKET, 0);
    }
    public queryStatement(): QueryStatementContext | null {
        return this.getRuleContext(0, QueryStatementContext);
    }
    public RR_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0);
    }
    public commentSpec(): CommentSpecContext | null {
        return this.getRuleContext(0, CommentSpecContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_defaultColumnUsingNoSortElement;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterDefaultColumnUsingNoSortElement) {
             listener.enterDefaultColumnUsingNoSortElement(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitDefaultColumnUsingNoSortElement) {
             listener.exitDefaultColumnUsingNoSortElement(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitDefaultColumnUsingNoSortElement) {
            return visitor.visitDefaultColumnUsingNoSortElement(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ColumnUsingContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public columnsBody(): ColumnsBodyContext | null {
        return this.getRuleContext(0, ColumnsBodyContext);
    }
    public using(): UsingContext | null {
        return this.getRuleContext(0, UsingContext);
    }
    public columnUsingNoSortElement(): ColumnUsingNoSortElementContext[];
    public columnUsingNoSortElement(i: number): ColumnUsingNoSortElementContext | null;
    public columnUsingNoSortElement(i?: number): ColumnUsingNoSortElementContext[] | ColumnUsingNoSortElementContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ColumnUsingNoSortElementContext);
        }

        return this.getRuleContext(i, ColumnUsingNoSortElementContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_columnUsing;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterColumnUsing) {
             listener.enterColumnUsing(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitColumnUsing) {
             listener.exitColumnUsing(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitColumnUsing) {
            return visitor.visitColumnUsing(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ColumnUsingNoSortElementContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public partitionDefinition(): PartitionDefinitionContext | null {
        return this.getRuleContext(0, PartitionDefinitionContext);
    }
    public KW_OPTIONS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_OPTIONS, 0);
    }
    public tablePropertyList(): TablePropertyListContext | null {
        return this.getRuleContext(0, TablePropertyListContext);
    }
    public tblProperties(): TblPropertiesContext | null {
        return this.getRuleContext(0, TblPropertiesContext);
    }
    public someByClause(): SomeByClauseContext | null {
        return this.getRuleContext(0, SomeByClauseContext);
    }
    public intoBuckets(): IntoBucketsContext | null {
        return this.getRuleContext(0, IntoBucketsContext);
    }
    public commentSpec(): CommentSpecContext | null {
        return this.getRuleContext(0, CommentSpecContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_columnUsingNoSortElement;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterColumnUsingNoSortElement) {
             listener.enterColumnUsingNoSortElement(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitColumnUsingNoSortElement) {
             listener.exitColumnUsingNoSortElement(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitColumnUsingNoSortElement) {
            return visitor.visitColumnUsingNoSortElement(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class UsingByQueryContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public using(): UsingContext | null {
        return this.getRuleContext(0, UsingContext);
    }
    public KW_AS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_AS, 0);
    }
    public queryStatement(): QueryStatementContext | null {
        return this.getRuleContext(0, QueryStatementContext);
    }
    public usingByQueryNoSortElement(): UsingByQueryNoSortElementContext[];
    public usingByQueryNoSortElement(i: number): UsingByQueryNoSortElementContext | null;
    public usingByQueryNoSortElement(i?: number): UsingByQueryNoSortElementContext[] | UsingByQueryNoSortElementContext | null {
        if (i === undefined) {
            return this.getRuleContexts(UsingByQueryNoSortElementContext);
        }

        return this.getRuleContext(i, UsingByQueryNoSortElementContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_usingByQuery;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterUsingByQuery) {
             listener.enterUsingByQuery(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitUsingByQuery) {
             listener.exitUsingByQuery(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitUsingByQuery) {
            return visitor.visitUsingByQuery(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class UsingByQueryNoSortElementContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public partitionDefinition(): PartitionDefinitionContext | null {
        return this.getRuleContext(0, PartitionDefinitionContext);
    }
    public KW_OPTIONS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_OPTIONS, 0);
    }
    public tablePropertyList(): TablePropertyListContext | null {
        return this.getRuleContext(0, TablePropertyListContext);
    }
    public tblProperties(): TblPropertiesContext | null {
        return this.getRuleContext(0, TblPropertiesContext);
    }
    public someByClause(): SomeByClauseContext | null {
        return this.getRuleContext(0, SomeByClauseContext);
    }
    public intoBuckets(): IntoBucketsContext | null {
        return this.getRuleContext(0, IntoBucketsContext);
    }
    public commentSpec(): CommentSpecContext | null {
        return this.getRuleContext(0, CommentSpecContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_usingByQueryNoSortElement;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterUsingByQueryNoSortElement) {
             listener.enterUsingByQueryNoSortElement(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitUsingByQueryNoSortElement) {
             listener.exitUsingByQueryNoSortElement(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitUsingByQueryNoSortElement) {
            return visitor.visitUsingByQueryNoSortElement(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class IntoBucketsContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_INTO(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_INTO, 0)!;
    }
    public DIG_LITERAL(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.DIG_LITERAL, 0)!;
    }
    public KW_BUCKETS(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_BUCKETS, 0)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_intoBuckets;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterIntoBuckets) {
             listener.enterIntoBuckets(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitIntoBuckets) {
             listener.exitIntoBuckets(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitIntoBuckets) {
            return visitor.visitIntoBuckets(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class HiveFormatCreateContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_CREATE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_CREATE, 0)!;
    }
    public KW_TABLE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_TABLE, 0)!;
    }
    public tablePathCreate(): TablePathCreateContext {
        return this.getRuleContext(0, TablePathCreateContext)!;
    }
    public KW_TEMPORARY(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TEMPORARY, 0);
    }
    public ifNotExists(): IfNotExistsContext | null {
        return this.getRuleContext(0, IfNotExistsContext);
    }
    public hiveFormatCreateNoSortElement(): HiveFormatCreateNoSortElementContext[];
    public hiveFormatCreateNoSortElement(i: number): HiveFormatCreateNoSortElementContext | null;
    public hiveFormatCreateNoSortElement(i?: number): HiveFormatCreateNoSortElementContext[] | HiveFormatCreateNoSortElementContext | null {
        if (i === undefined) {
            return this.getRuleContexts(HiveFormatCreateNoSortElementContext);
        }

        return this.getRuleContext(i, HiveFormatCreateNoSortElementContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_hiveFormatCreate;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterHiveFormatCreate) {
             listener.enterHiveFormatCreate(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitHiveFormatCreate) {
             listener.exitHiveFormatCreate(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitHiveFormatCreate) {
            return visitor.visitHiveFormatCreate(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class HiveFormatpartitionDefinitionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_PARTITIONED(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_PARTITIONED, 0)!;
    }
    public KW_BY(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_BY, 0)!;
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public ID_LITERAL(): antlr.TerminalNode[];
    public ID_LITERAL(i: number): antlr.TerminalNode | null;
    public ID_LITERAL(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.ID_LITERAL);
    	} else {
    		return this.getToken(SparkSQLParser.ID_LITERAL, i);
    	}
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public sqlSimpleType(): SqlSimpleTypeContext[];
    public sqlSimpleType(i: number): SqlSimpleTypeContext | null;
    public sqlSimpleType(i?: number): SqlSimpleTypeContext[] | SqlSimpleTypeContext | null {
        if (i === undefined) {
            return this.getRuleContexts(SqlSimpleTypeContext);
        }

        return this.getRuleContext(i, SqlSimpleTypeContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_hiveFormatpartitionDefinition;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterHiveFormatpartitionDefinition) {
             listener.enterHiveFormatpartitionDefinition(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitHiveFormatpartitionDefinition) {
             listener.exitHiveFormatpartitionDefinition(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitHiveFormatpartitionDefinition) {
            return visitor.visitHiveFormatpartitionDefinition(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class HiveFormatCreateNoSortElementContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public storedAs(): StoredAsContext | null {
        return this.getRuleContext(0, StoredAsContext);
    }
    public KW_AS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_AS, 0);
    }
    public queryStatement(): QueryStatementContext | null {
        return this.getRuleContext(0, QueryStatementContext);
    }
    public columnsBody(): ColumnsBodyContext | null {
        return this.getRuleContext(0, ColumnsBodyContext);
    }
    public hiveFormatpartitionDefinition(): HiveFormatpartitionDefinitionContext | null {
        return this.getRuleContext(0, HiveFormatpartitionDefinitionContext);
    }
    public withOption(): WithOptionContext | null {
        return this.getRuleContext(0, WithOptionContext);
    }
    public likeDefinition(): LikeDefinitionContext | null {
        return this.getRuleContext(0, LikeDefinitionContext);
    }
    public someByClause(): SomeByClauseContext | null {
        return this.getRuleContext(0, SomeByClauseContext);
    }
    public commentSpec(): CommentSpecContext | null {
        return this.getRuleContext(0, CommentSpecContext);
    }
    public rowFormatDelimted(): RowFormatDelimtedContext | null {
        return this.getRuleContext(0, RowFormatDelimtedContext);
    }
    public fieldsTerminatedBy(): FieldsTerminatedByContext | null {
        return this.getRuleContext(0, FieldsTerminatedByContext);
    }
    public tblProperties(): TblPropertiesContext | null {
        return this.getRuleContext(0, TblPropertiesContext);
    }
    public storedAsInputformat(): StoredAsInputformatContext | null {
        return this.getRuleContext(0, StoredAsInputformatContext);
    }
    public outputformat(): OutputformatContext | null {
        return this.getRuleContext(0, OutputformatContext);
    }
    public rowFormatSerde(): RowFormatSerdeContext | null {
        return this.getRuleContext(0, RowFormatSerdeContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_hiveFormatCreateNoSortElement;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterHiveFormatCreateNoSortElement) {
             listener.enterHiveFormatCreateNoSortElement(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitHiveFormatCreateNoSortElement) {
             listener.exitHiveFormatCreateNoSortElement(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitHiveFormatCreateNoSortElement) {
            return visitor.visitHiveFormatCreateNoSortElement(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class RowFormatSerdeContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_ROW(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_ROW, 0)!;
    }
    public KW_FORMAT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_FORMAT, 0)!;
    }
    public KW_SERDE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_SERDE, 0)!;
    }
    public stringLiteral(): StringLiteralContext {
        return this.getRuleContext(0, StringLiteralContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_rowFormatSerde;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterRowFormatSerde) {
             listener.enterRowFormatSerde(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitRowFormatSerde) {
             listener.exitRowFormatSerde(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitRowFormatSerde) {
            return visitor.visitRowFormatSerde(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class FieldsTerminatedByContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_FIELDS(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_FIELDS, 0)!;
    }
    public KW_TERMINATED(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_TERMINATED, 0)!;
    }
    public KW_BY(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_BY, 0)!;
    }
    public stringLiteral(): StringLiteralContext {
        return this.getRuleContext(0, StringLiteralContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_fieldsTerminatedBy;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterFieldsTerminatedBy) {
             listener.enterFieldsTerminatedBy(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitFieldsTerminatedBy) {
             listener.exitFieldsTerminatedBy(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitFieldsTerminatedBy) {
            return visitor.visitFieldsTerminatedBy(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class StoredAsContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_STORED(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_STORED, 0)!;
    }
    public KW_AS(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_AS, 0)!;
    }
    public identifier(): IdentifierContext | null {
        return this.getRuleContext(0, IdentifierContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_storedAs;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterStoredAs) {
             listener.enterStoredAs(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitStoredAs) {
             listener.exitStoredAs(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitStoredAs) {
            return visitor.visitStoredAs(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class StoredAsInputformatContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_STORED(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_STORED, 0)!;
    }
    public KW_AS(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_AS, 0)!;
    }
    public KW_INPUTFORMAT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_INPUTFORMAT, 0)!;
    }
    public identifier(): IdentifierContext | null {
        return this.getRuleContext(0, IdentifierContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_storedAsInputformat;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterStoredAsInputformat) {
             listener.enterStoredAsInputformat(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitStoredAsInputformat) {
             listener.exitStoredAsInputformat(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitStoredAsInputformat) {
            return visitor.visitStoredAsInputformat(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class OutputformatContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_OUTPUTFORMAT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_OUTPUTFORMAT, 0)!;
    }
    public identifier(): IdentifierContext | null {
        return this.getRuleContext(0, IdentifierContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_outputformat;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterOutputformat) {
             listener.enterOutputformat(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitOutputformat) {
             listener.exitOutputformat(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitOutputformat) {
            return visitor.visitOutputformat(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class CreateExternalTableContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_CREATE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_CREATE, 0)!;
    }
    public KW_EXTERNAL(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_EXTERNAL, 0)!;
    }
    public KW_TABLE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_TABLE, 0)!;
    }
    public tablePathCreate(): TablePathCreateContext {
        return this.getRuleContext(0, TablePathCreateContext)!;
    }
    public columnsBody(): ColumnsBodyContext {
        return this.getRuleContext(0, ColumnsBodyContext)!;
    }
    public ifNotExists(): IfNotExistsContext | null {
        return this.getRuleContext(0, IfNotExistsContext);
    }
    public createExternalTableNoSortElement(): CreateExternalTableNoSortElementContext[];
    public createExternalTableNoSortElement(i: number): CreateExternalTableNoSortElementContext | null;
    public createExternalTableNoSortElement(i?: number): CreateExternalTableNoSortElementContext[] | CreateExternalTableNoSortElementContext | null {
        if (i === undefined) {
            return this.getRuleContexts(CreateExternalTableNoSortElementContext);
        }

        return this.getRuleContext(i, CreateExternalTableNoSortElementContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_createExternalTable;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterCreateExternalTable) {
             listener.enterCreateExternalTable(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitCreateExternalTable) {
             listener.exitCreateExternalTable(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitCreateExternalTable) {
            return visitor.visitCreateExternalTable(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class CreateExternalTableNoSortElementContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public rowFormatDelimted(): RowFormatDelimtedContext | null {
        return this.getRuleContext(0, RowFormatDelimtedContext);
    }
    public fieldsTerminatedBy(): FieldsTerminatedByContext | null {
        return this.getRuleContext(0, FieldsTerminatedByContext);
    }
    public KW_ROW(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ROW, 0);
    }
    public KW_FORMAT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FORMAT, 0);
    }
    public KW_SERDE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SERDE, 0);
    }
    public stringLiteral(): StringLiteralContext | null {
        return this.getRuleContext(0, StringLiteralContext);
    }
    public KW_LINES(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LINES, 0);
    }
    public KW_TERMINATED(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TERMINATED, 0);
    }
    public KW_BY(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_BY, 0);
    }
    public KW_NULL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NULL, 0);
    }
    public KW_DEFINED(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DEFINED, 0);
    }
    public KW_AS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_AS, 0);
    }
    public KW_ESCAPED(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ESCAPED, 0);
    }
    public KW_COLLECTION(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_COLLECTION, 0);
    }
    public KW_ITEMS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ITEMS, 0);
    }
    public storedAs(): StoredAsContext | null {
        return this.getRuleContext(0, StoredAsContext);
    }
    public storedAsInputformat(): StoredAsInputformatContext | null {
        return this.getRuleContext(0, StoredAsInputformatContext);
    }
    public outputformat(): OutputformatContext | null {
        return this.getRuleContext(0, OutputformatContext);
    }
    public location(): LocationContext | null {
        return this.getRuleContext(0, LocationContext);
    }
    public KW_MAP(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MAP, 0);
    }
    public KW_KEYS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_KEYS, 0);
    }
    public rowFormatSerde(): RowFormatSerdeContext | null {
        return this.getRuleContext(0, RowFormatSerdeContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_createExternalTableNoSortElement;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterCreateExternalTableNoSortElement) {
             listener.enterCreateExternalTableNoSortElement(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitCreateExternalTableNoSortElement) {
             listener.exitCreateExternalTableNoSortElement(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitCreateExternalTableNoSortElement) {
            return visitor.visitCreateExternalTableNoSortElement(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class LocationContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_LOCATION(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_LOCATION, 0)!;
    }
    public filePath(): FilePathContext {
        return this.getRuleContext(0, FilePathContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_location;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterLocation) {
             listener.enterLocation(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitLocation) {
             listener.exitLocation(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitLocation) {
            return visitor.visitLocation(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class RowFormatDelimtedContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_ROW(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_ROW, 0)!;
    }
    public KW_FORMAT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_FORMAT, 0)!;
    }
    public KW_DELIMITED(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_DELIMITED, 0)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_rowFormatDelimted;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterRowFormatDelimted) {
             listener.enterRowFormatDelimted(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitRowFormatDelimted) {
             listener.exitRowFormatDelimted(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitRowFormatDelimted) {
            return visitor.visitRowFormatDelimted(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ColumnsBodyContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public columnOptionDefinition(): ColumnOptionDefinitionContext[];
    public columnOptionDefinition(i: number): ColumnOptionDefinitionContext | null;
    public columnOptionDefinition(i?: number): ColumnOptionDefinitionContext[] | ColumnOptionDefinitionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ColumnOptionDefinitionContext);
        }

        return this.getRuleContext(i, ColumnOptionDefinitionContext);
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public commentSpec(): CommentSpecContext[];
    public commentSpec(i: number): CommentSpecContext | null;
    public commentSpec(i?: number): CommentSpecContext[] | CommentSpecContext | null {
        if (i === undefined) {
            return this.getRuleContexts(CommentSpecContext);
        }

        return this.getRuleContext(i, CommentSpecContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public watermarkDefinition(): WatermarkDefinitionContext | null {
        return this.getRuleContext(0, WatermarkDefinitionContext);
    }
    public tableConstraint(): TableConstraintContext | null {
        return this.getRuleContext(0, TableConstraintContext);
    }
    public selfDefinitionClause(): SelfDefinitionClauseContext | null {
        return this.getRuleContext(0, SelfDefinitionClauseContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_columnsBody;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterColumnsBody) {
             listener.enterColumnsBody(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitColumnsBody) {
             listener.exitColumnsBody(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitColumnsBody) {
            return visitor.visitColumnsBody(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class CreateCustomSerdeContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_CREATE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_CREATE, 0)!;
    }
    public KW_TABLE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_TABLE, 0)!;
    }
    public tablePathCreate(): TablePathCreateContext {
        return this.getRuleContext(0, TablePathCreateContext)!;
    }
    public KW_ROW(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_ROW, 0)!;
    }
    public KW_FORMAT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_FORMAT, 0)!;
    }
    public KW_SERDE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_SERDE, 0)!;
    }
    public tablePropertyKey(): TablePropertyKeyContext[];
    public tablePropertyKey(i: number): TablePropertyKeyContext | null;
    public tablePropertyKey(i?: number): TablePropertyKeyContext[] | TablePropertyKeyContext | null {
        if (i === undefined) {
            return this.getRuleContexts(TablePropertyKeyContext);
        }

        return this.getRuleContext(i, TablePropertyKeyContext);
    }
    public KW_SORTED(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_SORTED, 0)!;
    }
    public KW_AS(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_AS, 0)!;
    }
    public KW_INPUTFORMAT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_INPUTFORMAT, 0)!;
    }
    public KW_OUTPUTFORMAT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_OUTPUTFORMAT, 0)!;
    }
    public tblProperties(): TblPropertiesContext {
        return this.getRuleContext(0, TblPropertiesContext)!;
    }
    public KW_TEMPORARY(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TEMPORARY, 0);
    }
    public ifNotExists(): IfNotExistsContext | null {
        return this.getRuleContext(0, IfNotExistsContext);
    }
    public createCustomSerdeNoSortElement(): CreateCustomSerdeNoSortElementContext[];
    public createCustomSerdeNoSortElement(i: number): CreateCustomSerdeNoSortElementContext | null;
    public createCustomSerdeNoSortElement(i?: number): CreateCustomSerdeNoSortElementContext[] | CreateCustomSerdeNoSortElementContext | null {
        if (i === undefined) {
            return this.getRuleContexts(CreateCustomSerdeNoSortElementContext);
        }

        return this.getRuleContext(i, CreateCustomSerdeNoSortElementContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_createCustomSerde;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterCreateCustomSerde) {
             listener.enterCreateCustomSerde(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitCreateCustomSerde) {
             listener.exitCreateCustomSerde(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitCreateCustomSerde) {
            return visitor.visitCreateCustomSerde(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class CreateCustomSerdeNoSortElementContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public columnsBody(): ColumnsBodyContext | null {
        return this.getRuleContext(0, ColumnsBodyContext);
    }
    public commentSpec(): CommentSpecContext | null {
        return this.getRuleContext(0, CommentSpecContext);
    }
    public partitionDefinition(): PartitionDefinitionContext | null {
        return this.getRuleContext(0, PartitionDefinitionContext);
    }
    public withOption(): WithOptionContext | null {
        return this.getRuleContext(0, WithOptionContext);
    }
    public likeDefinition(): LikeDefinitionContext | null {
        return this.getRuleContext(0, LikeDefinitionContext);
    }
    public distribution(): DistributionContext | null {
        return this.getRuleContext(0, DistributionContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_createCustomSerdeNoSortElement;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterCreateCustomSerdeNoSortElement) {
             listener.enterCreateCustomSerdeNoSortElement(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitCreateCustomSerdeNoSortElement) {
             listener.exitCreateCustomSerdeNoSortElement(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitCreateCustomSerdeNoSortElement) {
            return visitor.visitCreateCustomSerdeNoSortElement(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class CreateCustomSerdeExternalContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_CREATE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_CREATE, 0)!;
    }
    public KW_EXTERNAL(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_EXTERNAL, 0)!;
    }
    public KW_TABLE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_TABLE, 0)!;
    }
    public tablePathCreate(): TablePathCreateContext {
        return this.getRuleContext(0, TablePathCreateContext)!;
    }
    public columnsBody(): ColumnsBodyContext {
        return this.getRuleContext(0, ColumnsBodyContext)!;
    }
    public KW_ROW(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_ROW, 0)!;
    }
    public KW_FORMAT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_FORMAT, 0)!;
    }
    public KW_SERDE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_SERDE, 0)!;
    }
    public tablePropertyKey(): TablePropertyKeyContext[];
    public tablePropertyKey(i: number): TablePropertyKeyContext | null;
    public tablePropertyKey(i?: number): TablePropertyKeyContext[] | TablePropertyKeyContext | null {
        if (i === undefined) {
            return this.getRuleContexts(TablePropertyKeyContext);
        }

        return this.getRuleContext(i, TablePropertyKeyContext);
    }
    public KW_SORTED(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_SORTED, 0)!;
    }
    public KW_AS(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_AS, 0)!;
    }
    public KW_INPUTFORMAT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_INPUTFORMAT, 0)!;
    }
    public KW_OUTPUTFORMAT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_OUTPUTFORMAT, 0)!;
    }
    public KW_LOCATION(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_LOCATION, 0)!;
    }
    public filePath(): FilePathContext {
        return this.getRuleContext(0, FilePathContext)!;
    }
    public ifNotExists(): IfNotExistsContext | null {
        return this.getRuleContext(0, IfNotExistsContext);
    }
    public createCustomSerdeExternalNoSortElement(): CreateCustomSerdeExternalNoSortElementContext[];
    public createCustomSerdeExternalNoSortElement(i: number): CreateCustomSerdeExternalNoSortElementContext | null;
    public createCustomSerdeExternalNoSortElement(i?: number): CreateCustomSerdeExternalNoSortElementContext[] | CreateCustomSerdeExternalNoSortElementContext | null {
        if (i === undefined) {
            return this.getRuleContexts(CreateCustomSerdeExternalNoSortElementContext);
        }

        return this.getRuleContext(i, CreateCustomSerdeExternalNoSortElementContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_createCustomSerdeExternal;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterCreateCustomSerdeExternal) {
             listener.enterCreateCustomSerdeExternal(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitCreateCustomSerdeExternal) {
             listener.exitCreateCustomSerdeExternal(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitCreateCustomSerdeExternal) {
            return visitor.visitCreateCustomSerdeExternal(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class CreateCustomSerdeExternalNoSortElementContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public commentSpec(): CommentSpecContext | null {
        return this.getRuleContext(0, CommentSpecContext);
    }
    public partitionDefinition(): PartitionDefinitionContext | null {
        return this.getRuleContext(0, PartitionDefinitionContext);
    }
    public withOption(): WithOptionContext | null {
        return this.getRuleContext(0, WithOptionContext);
    }
    public likeDefinition(): LikeDefinitionContext | null {
        return this.getRuleContext(0, LikeDefinitionContext);
    }
    public distribution(): DistributionContext | null {
        return this.getRuleContext(0, DistributionContext);
    }
    public tblProperties(): TblPropertiesContext | null {
        return this.getRuleContext(0, TblPropertiesContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_createCustomSerdeExternalNoSortElement;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterCreateCustomSerdeExternalNoSortElement) {
             listener.enterCreateCustomSerdeExternalNoSortElement(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitCreateCustomSerdeExternalNoSortElement) {
             listener.exitCreateCustomSerdeExternalNoSortElement(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitCreateCustomSerdeExternalNoSortElement) {
            return visitor.visitCreateCustomSerdeExternalNoSortElement(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class CreateTableAsSelectContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_CREATE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_CREATE, 0)!;
    }
    public KW_TABLE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_TABLE, 0)!;
    }
    public tablePathCreate(): TablePathCreateContext {
        return this.getRuleContext(0, TablePathCreateContext)!;
    }
    public withOption(): WithOptionContext {
        return this.getRuleContext(0, WithOptionContext)!;
    }
    public ifNotExists(): IfNotExistsContext | null {
        return this.getRuleContext(0, IfNotExistsContext);
    }
    public KW_AS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_AS, 0);
    }
    public queryStatement(): QueryStatementContext | null {
        return this.getRuleContext(0, QueryStatementContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_createTableAsSelect;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterCreateTableAsSelect) {
             listener.enterCreateTableAsSelect(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitCreateTableAsSelect) {
             listener.exitCreateTableAsSelect(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitCreateTableAsSelect) {
            return visitor.visitCreateTableAsSelect(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class CreateMaterializedTableAsSelectContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_CREATE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_CREATE, 0)!;
    }
    public KW_MATERIALIZED(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_MATERIALIZED, 0)!;
    }
    public KW_TABLE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_TABLE, 0)!;
    }
    public tablePathCreate(): TablePathCreateContext {
        return this.getRuleContext(0, TablePathCreateContext)!;
    }
    public LR_BRACKET(): antlr.TerminalNode[];
    public LR_BRACKET(i: number): antlr.TerminalNode | null;
    public LR_BRACKET(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.LR_BRACKET);
    	} else {
    		return this.getToken(SparkSQLParser.LR_BRACKET, i);
    	}
    }
    public KW_PRIMARY(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_PRIMARY, 0)!;
    }
    public KW_KEY(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_KEY, 0)!;
    }
    public identifier(): IdentifierContext[];
    public identifier(i: number): IdentifierContext | null;
    public identifier(i?: number): IdentifierContext[] | IdentifierContext | null {
        if (i === undefined) {
            return this.getRuleContexts(IdentifierContext);
        }

        return this.getRuleContext(i, IdentifierContext);
    }
    public RR_BRACKET(): antlr.TerminalNode[];
    public RR_BRACKET(i: number): antlr.TerminalNode | null;
    public RR_BRACKET(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.RR_BRACKET);
    	} else {
    		return this.getToken(SparkSQLParser.RR_BRACKET, i);
    	}
    }
    public KW_FRESHNESS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FRESHNESS, 0);
    }
    public EQUAL_SYMBOL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.EQUAL_SYMBOL, 0);
    }
    public KW_INTERVAL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_INTERVAL, 0);
    }
    public createMaterializedTableAsSelectNoSortElement(): CreateMaterializedTableAsSelectNoSortElementContext[];
    public createMaterializedTableAsSelectNoSortElement(i: number): CreateMaterializedTableAsSelectNoSortElementContext | null;
    public createMaterializedTableAsSelectNoSortElement(i?: number): CreateMaterializedTableAsSelectNoSortElementContext[] | CreateMaterializedTableAsSelectNoSortElementContext | null {
        if (i === undefined) {
            return this.getRuleContexts(CreateMaterializedTableAsSelectNoSortElementContext);
        }

        return this.getRuleContext(i, CreateMaterializedTableAsSelectNoSortElementContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public KW_NOT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NOT, 0);
    }
    public KW_ENFORCED(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ENFORCED, 0);
    }
    public KW_SECOND(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SECOND, 0);
    }
    public KW_MINUTE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MINUTE, 0);
    }
    public KW_HOUR(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_HOUR, 0);
    }
    public KW_DAY(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DAY, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_createMaterializedTableAsSelect;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterCreateMaterializedTableAsSelect) {
             listener.enterCreateMaterializedTableAsSelect(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitCreateMaterializedTableAsSelect) {
             listener.exitCreateMaterializedTableAsSelect(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitCreateMaterializedTableAsSelect) {
            return visitor.visitCreateMaterializedTableAsSelect(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class CreateMaterializedTableAsSelectNoSortElementContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public partitionDefinition(): PartitionDefinitionContext | null {
        return this.getRuleContext(0, PartitionDefinitionContext);
    }
    public withOption(): WithOptionContext | null {
        return this.getRuleContext(0, WithOptionContext);
    }
    public KW_REFRESH_MODE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_REFRESH_MODE, 0);
    }
    public EQUAL_SYMBOL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.EQUAL_SYMBOL, 0);
    }
    public KW_FULL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FULL, 0);
    }
    public KW_CONTINUOUS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_CONTINUOUS, 0);
    }
    public KW_AS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_AS, 0);
    }
    public queryStatement(): QueryStatementContext | null {
        return this.getRuleContext(0, QueryStatementContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_createMaterializedTableAsSelectNoSortElement;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterCreateMaterializedTableAsSelectNoSortElement) {
             listener.enterCreateMaterializedTableAsSelectNoSortElement(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitCreateMaterializedTableAsSelectNoSortElement) {
             listener.exitCreateMaterializedTableAsSelectNoSortElement(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitCreateMaterializedTableAsSelectNoSortElement) {
            return visitor.visitCreateMaterializedTableAsSelectNoSortElement(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class CreateCatalogContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_CREATE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_CREATE, 0)!;
    }
    public KW_CATALOG(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_CATALOG, 0)!;
    }
    public uid(): UidContext {
        return this.getRuleContext(0, UidContext)!;
    }
    public withOption(): WithOptionContext {
        return this.getRuleContext(0, WithOptionContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_createCatalog;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterCreateCatalog) {
             listener.enterCreateCatalog(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitCreateCatalog) {
             listener.exitCreateCatalog(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitCreateCatalog) {
            return visitor.visitCreateCatalog(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class CreateDatabaseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_CREATE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_CREATE, 0)!;
    }
    public KW_DATABASE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_DATABASE, 0)!;
    }
    public databasePathCreate(): DatabasePathCreateContext {
        return this.getRuleContext(0, DatabasePathCreateContext)!;
    }
    public ifNotExists(): IfNotExistsContext | null {
        return this.getRuleContext(0, IfNotExistsContext);
    }
    public commentSpec(): CommentSpecContext | null {
        return this.getRuleContext(0, CommentSpecContext);
    }
    public KW_LOCATION(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LOCATION, 0);
    }
    public STRING_LITERAL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.STRING_LITERAL, 0);
    }
    public withOption(): WithOptionContext | null {
        return this.getRuleContext(0, WithOptionContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_createDatabase;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterCreateDatabase) {
             listener.enterCreateDatabase(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitCreateDatabase) {
             listener.exitCreateDatabase(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitCreateDatabase) {
            return visitor.visitCreateDatabase(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class CreateViewContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_CREATE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_CREATE, 0)!;
    }
    public KW_VIEW(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_VIEW, 0)!;
    }
    public uid(): UidContext {
        return this.getRuleContext(0, UidContext)!;
    }
    public KW_AS(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_AS, 0)!;
    }
    public queryStatement(): QueryStatementContext {
        return this.getRuleContext(0, QueryStatementContext)!;
    }
    public KW_OR(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_OR, 0);
    }
    public KW_REPLACE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_REPLACE, 0);
    }
    public KW_TEMPORARY(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TEMPORARY, 0);
    }
    public ifNotExists(): IfNotExistsContext | null {
        return this.getRuleContext(0, IfNotExistsContext);
    }
    public columnNameList(): ColumnNameListContext | null {
        return this.getRuleContext(0, ColumnNameListContext);
    }
    public commentSpec(): CommentSpecContext | null {
        return this.getRuleContext(0, CommentSpecContext);
    }
    public KW_GLOBAL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_GLOBAL, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_createView;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterCreateView) {
             listener.enterCreateView(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitCreateView) {
             listener.exitCreateView(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitCreateView) {
            return visitor.visitCreateView(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class CreateFunctionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_CREATE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_CREATE, 0)!;
    }
    public KW_FUNCTION(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_FUNCTION, 0)!;
    }
    public functionName(): FunctionNameContext {
        return this.getRuleContext(0, FunctionNameContext)!;
    }
    public KW_AS(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_AS, 0)!;
    }
    public identifier(): IdentifierContext {
        return this.getRuleContext(0, IdentifierContext)!;
    }
    public KW_OR(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_OR, 0);
    }
    public KW_REPLACE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_REPLACE, 0);
    }
    public KW_TEMPORARY(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TEMPORARY, 0);
    }
    public KW_SYSTEM(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SYSTEM, 0);
    }
    public ifNotExists(): IfNotExistsContext | null {
        return this.getRuleContext(0, IfNotExistsContext);
    }
    public KW_USING(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_USING, 0);
    }
    public KW_JAR(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_JAR, 0);
    }
    public jarFileName(): JarFileNameContext | null {
        return this.getRuleContext(0, JarFileNameContext);
    }
    public usingClause(): UsingClauseContext | null {
        return this.getRuleContext(0, UsingClauseContext);
    }
    public KW_LANGUAGE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LANGUAGE, 0);
    }
    public KW_JAVA(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_JAVA, 0);
    }
    public KW_SCALA(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SCALA, 0);
    }
    public KW_PYTHON(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PYTHON, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_createFunction;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterCreateFunction) {
             listener.enterCreateFunction(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitCreateFunction) {
             listener.exitCreateFunction(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitCreateFunction) {
            return visitor.visitCreateFunction(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class UsingClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_USING(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_USING, 0)!;
    }
    public KW_JAR(): antlr.TerminalNode[];
    public KW_JAR(i: number): antlr.TerminalNode | null;
    public KW_JAR(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.KW_JAR);
    	} else {
    		return this.getToken(SparkSQLParser.KW_JAR, i);
    	}
    }
    public jarFileName(): JarFileNameContext[];
    public jarFileName(i: number): JarFileNameContext | null;
    public jarFileName(i?: number): JarFileNameContext[] | JarFileNameContext | null {
        if (i === undefined) {
            return this.getRuleContexts(JarFileNameContext);
        }

        return this.getRuleContext(i, JarFileNameContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_usingClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterUsingClause) {
             listener.enterUsingClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitUsingClause) {
             listener.exitUsingClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitUsingClause) {
            return visitor.visitUsingClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class JarFileNameContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public filePath(): FilePathContext {
        return this.getRuleContext(0, FilePathContext)!;
    }
    public DOT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.DOT, 0);
    }
    public KW_JAR(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_JAR, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_jarFileName;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterJarFileName) {
             listener.enterJarFileName(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitJarFileName) {
             listener.exitJarFileName(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitJarFileName) {
            return visitor.visitJarFileName(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class FilePathContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public STRING_LITERAL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.STRING_LITERAL, 0);
    }
    public SLASH_SIGN(): antlr.TerminalNode[];
    public SLASH_SIGN(i: number): antlr.TerminalNode | null;
    public SLASH_SIGN(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.SLASH_SIGN);
    	} else {
    		return this.getToken(SparkSQLParser.SLASH_SIGN, i);
    	}
    }
    public ID_LITERAL(): antlr.TerminalNode[];
    public ID_LITERAL(i: number): antlr.TerminalNode | null;
    public ID_LITERAL(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.ID_LITERAL);
    	} else {
    		return this.getToken(SparkSQLParser.ID_LITERAL, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_filePath;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterFilePath) {
             listener.enterFilePath(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitFilePath) {
             listener.exitFilePath(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitFilePath) {
            return visitor.visitFilePath(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ColumnPositionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_FIRST(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FIRST, 0);
    }
    public KW_LAST(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LAST, 0);
    }
    public uid(): UidContext | null {
        return this.getRuleContext(0, UidContext);
    }
    public KW_BEFORE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_BEFORE, 0);
    }
    public KW_AFTER(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_AFTER, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_columnPosition;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterColumnPosition) {
             listener.enterColumnPosition(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitColumnPosition) {
             listener.exitColumnPosition(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitColumnPosition) {
            return visitor.visitColumnPosition(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class RenameDefinitionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_RENAME(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_RENAME, 0)!;
    }
    public KW_TO(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_TO, 0)!;
    }
    public uid(): UidContext[];
    public uid(i: number): UidContext | null;
    public uid(i?: number): UidContext[] | UidContext | null {
        if (i === undefined) {
            return this.getRuleContexts(UidContext);
        }

        return this.getRuleContext(i, UidContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_renameDefinition;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterRenameDefinition) {
             listener.enterRenameDefinition(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitRenameDefinition) {
             listener.exitRenameDefinition(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitRenameDefinition) {
            return visitor.visitRenameDefinition(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class SetKeyValueDefinitionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_SET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_SET, 0)!;
    }
    public tablePropertyList(): TablePropertyListContext {
        return this.getRuleContext(0, TablePropertyListContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_setKeyValueDefinition;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterSetKeyValueDefinition) {
             listener.enterSetKeyValueDefinition(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitSetKeyValueDefinition) {
             listener.exitSetKeyValueDefinition(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitSetKeyValueDefinition) {
            return visitor.visitSetKeyValueDefinition(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class AddConstraintContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_ADD(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_ADD, 0)!;
    }
    public KW_CONSTRAINT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_CONSTRAINT, 0)!;
    }
    public constraintName(): ConstraintNameContext {
        return this.getRuleContext(0, ConstraintNameContext)!;
    }
    public KW_PRIMARY(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_PRIMARY, 0)!;
    }
    public KW_KEY(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_KEY, 0)!;
    }
    public columnNameList(): ColumnNameListContext {
        return this.getRuleContext(0, ColumnNameListContext)!;
    }
    public notForced(): NotForcedContext | null {
        return this.getRuleContext(0, NotForcedContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_addConstraint;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterAddConstraint) {
             listener.enterAddConstraint(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitAddConstraint) {
             listener.exitAddConstraint(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitAddConstraint) {
            return visitor.visitAddConstraint(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class DropConstraintContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_DROP(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_DROP, 0)!;
    }
    public KW_CONSTRAINT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_CONSTRAINT, 0)!;
    }
    public constraintName(): ConstraintNameContext {
        return this.getRuleContext(0, ConstraintNameContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_dropConstraint;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterDropConstraint) {
             listener.enterDropConstraint(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitDropConstraint) {
             listener.exitDropConstraint(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitDropConstraint) {
            return visitor.visitDropConstraint(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class AddUniqueContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_ADD(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_ADD, 0)!;
    }
    public KW_UNIQUE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_UNIQUE, 0)!;
    }
    public columnNameList(): ColumnNameListContext {
        return this.getRuleContext(0, ColumnNameListContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_addUnique;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterAddUnique) {
             listener.enterAddUnique(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitAddUnique) {
             listener.exitAddUnique(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitAddUnique) {
            return visitor.visitAddUnique(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class NotForcedContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_NOT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_NOT, 0)!;
    }
    public KW_ENFORCED(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_ENFORCED, 0)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_notForced;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterNotForced) {
             listener.enterNotForced(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitNotForced) {
             listener.exitNotForced(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitNotForced) {
            return visitor.visitNotForced(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class InsertStatementContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public insertSimpleStatement(): InsertSimpleStatementContext | null {
        return this.getRuleContext(0, InsertSimpleStatementContext);
    }
    public insertSparkDirectoryStatement(): InsertSparkDirectoryStatementContext | null {
        return this.getRuleContext(0, InsertSparkDirectoryStatementContext);
    }
    public insertHiveDirectoryStatement(): InsertHiveDirectoryStatementContext | null {
        return this.getRuleContext(0, InsertHiveDirectoryStatementContext);
    }
    public insertFromTable(): InsertFromTableContext | null {
        return this.getRuleContext(0, InsertFromTableContext);
    }
    public KW_EXECUTE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_EXECUTE, 0);
    }
    public insertMulStatementCompatibility(): InsertMulStatementCompatibilityContext | null {
        return this.getRuleContext(0, InsertMulStatementCompatibilityContext);
    }
    public insertMulStatement(): InsertMulStatementContext | null {
        return this.getRuleContext(0, InsertMulStatementContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_insertStatement;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterInsertStatement) {
             listener.enterInsertStatement(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitInsertStatement) {
             listener.exitInsertStatement(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitInsertStatement) {
            return visitor.visitInsertStatement(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class InsertSimpleStatementContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_INSERT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_INSERT, 0)!;
    }
    public tablePath(): TablePathContext[];
    public tablePath(i: number): TablePathContext | null;
    public tablePath(i?: number): TablePathContext[] | TablePathContext | null {
        if (i === undefined) {
            return this.getRuleContexts(TablePathContext);
        }

        return this.getRuleContext(i, TablePathContext);
    }
    public KW_INTO(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_INTO, 0);
    }
    public KW_OVERWRITE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_OVERWRITE, 0);
    }
    public queryStatement(): QueryStatementContext | null {
        return this.getRuleContext(0, QueryStatementContext);
    }
    public valuesDefinition(): ValuesDefinitionContext | null {
        return this.getRuleContext(0, ValuesDefinitionContext);
    }
    public insertPartitionDefinition(): InsertPartitionDefinitionContext | null {
        return this.getRuleContext(0, InsertPartitionDefinitionContext);
    }
    public columnNameList(): ColumnNameListContext | null {
        return this.getRuleContext(0, ColumnNameListContext);
    }
    public KW_REPLACE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_REPLACE, 0);
    }
    public whereClause(): WhereClauseContext | null {
        return this.getRuleContext(0, WhereClauseContext);
    }
    public selectStatement(): SelectStatementContext | null {
        return this.getRuleContext(0, SelectStatementContext);
    }
    public KW_TABLE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TABLE, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_insertSimpleStatement;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterInsertSimpleStatement) {
             listener.enterInsertSimpleStatement(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitInsertSimpleStatement) {
             listener.exitInsertSimpleStatement(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitInsertSimpleStatement) {
            return visitor.visitInsertSimpleStatement(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class InsertFromTableContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_INSERT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_INSERT, 0)!;
    }
    public tablePath(): TablePathContext[];
    public tablePath(i: number): TablePathContext | null;
    public tablePath(i?: number): TablePathContext[] | TablePathContext | null {
        if (i === undefined) {
            return this.getRuleContexts(TablePathContext);
        }

        return this.getRuleContext(i, TablePathContext);
    }
    public KW_TABLE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_TABLE, 0)!;
    }
    public KW_INTO(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_INTO, 0);
    }
    public KW_OVERWRITE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_OVERWRITE, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_insertFromTable;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterInsertFromTable) {
             listener.enterInsertFromTable(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitInsertFromTable) {
             listener.exitInsertFromTable(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitInsertFromTable) {
            return visitor.visitInsertFromTable(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class InsertSparkDirectoryStatementContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_INSERT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_INSERT, 0)!;
    }
    public KW_OVERWRITE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_OVERWRITE, 0)!;
    }
    public KW_DIRECTORY(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_DIRECTORY, 0)!;
    }
    public insertSparkDirectoryBody(): InsertSparkDirectoryBodyContext {
        return this.getRuleContext(0, InsertSparkDirectoryBodyContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_insertSparkDirectoryStatement;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterInsertSparkDirectoryStatement) {
             listener.enterInsertSparkDirectoryStatement(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitInsertSparkDirectoryStatement) {
             listener.exitInsertSparkDirectoryStatement(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitInsertSparkDirectoryStatement) {
            return visitor.visitInsertSparkDirectoryStatement(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class InsertSparkDirectoryBodyContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_USING(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_USING, 0);
    }
    public ID_LITERAL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.ID_LITERAL, 0);
    }
    public KW_OPTIONS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_OPTIONS, 0);
    }
    public LR_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0);
    }
    public columnName(): ColumnNameContext[];
    public columnName(i: number): ColumnNameContext | null;
    public columnName(i?: number): ColumnNameContext[] | ColumnNameContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ColumnNameContext);
        }

        return this.getRuleContext(i, ColumnNameContext);
    }
    public RR_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0);
    }
    public queryStatement(): QueryStatementContext | null {
        return this.getRuleContext(0, QueryStatementContext);
    }
    public filePath(): FilePathContext | null {
        return this.getRuleContext(0, FilePathContext);
    }
    public constant(): ConstantContext[];
    public constant(i: number): ConstantContext | null;
    public constant(i?: number): ConstantContext[] | ConstantContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ConstantContext);
        }

        return this.getRuleContext(i, ConstantContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public STRING_LITERAL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.STRING_LITERAL, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_insertSparkDirectoryBody;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterInsertSparkDirectoryBody) {
             listener.enterInsertSparkDirectoryBody(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitInsertSparkDirectoryBody) {
             listener.exitInsertSparkDirectoryBody(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitInsertSparkDirectoryBody) {
            return visitor.visitInsertSparkDirectoryBody(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class InsertHiveDirectoryStatementContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_INSERT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_INSERT, 0)!;
    }
    public KW_OVERWRITE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_OVERWRITE, 0)!;
    }
    public KW_LOCAL(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_LOCAL, 0)!;
    }
    public KW_DIRECTORY(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_DIRECTORY, 0)!;
    }
    public filePath(): FilePathContext {
        return this.getRuleContext(0, FilePathContext)!;
    }
    public queryStatement(): QueryStatementContext {
        return this.getRuleContext(0, QueryStatementContext)!;
    }
    public storedAs(): StoredAsContext | null {
        return this.getRuleContext(0, StoredAsContext);
    }
    public hiveRowFormatPart(): HiveRowFormatPartContext | null {
        return this.getRuleContext(0, HiveRowFormatPartContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_insertHiveDirectoryStatement;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterInsertHiveDirectoryStatement) {
             listener.enterInsertHiveDirectoryStatement(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitInsertHiveDirectoryStatement) {
             listener.exitInsertHiveDirectoryStatement(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitInsertHiveDirectoryStatement) {
            return visitor.visitInsertHiveDirectoryStatement(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class HiveRowFormatPartContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public rowFormatDelimted(): RowFormatDelimtedContext {
        return this.getRuleContext(0, RowFormatDelimtedContext)!;
    }
    public fieldsTerminatedBy(): FieldsTerminatedByContext {
        return this.getRuleContext(0, FieldsTerminatedByContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_hiveRowFormatPart;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterHiveRowFormatPart) {
             listener.enterHiveRowFormatPart(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitHiveRowFormatPart) {
             listener.exitHiveRowFormatPart(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitHiveRowFormatPart) {
            return visitor.visitHiveRowFormatPart(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class InsertPartitionDefinitionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_PARTITION(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_PARTITION, 0)!;
    }
    public tablePropertyList(): TablePropertyListContext {
        return this.getRuleContext(0, TablePropertyListContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_insertPartitionDefinition;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterInsertPartitionDefinition) {
             listener.enterInsertPartitionDefinition(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitInsertPartitionDefinition) {
             listener.exitInsertPartitionDefinition(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitInsertPartitionDefinition) {
            return visitor.visitInsertPartitionDefinition(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class InsertMulStatementCompatibilityContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_BEGIN(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_BEGIN, 0)!;
    }
    public KW_STATEMENT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_STATEMENT, 0)!;
    }
    public KW_SET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_SET, 0)!;
    }
    public SEMICOLON(): antlr.TerminalNode[];
    public SEMICOLON(i: number): antlr.TerminalNode | null;
    public SEMICOLON(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.SEMICOLON);
    	} else {
    		return this.getToken(SparkSQLParser.SEMICOLON, i);
    	}
    }
    public KW_END(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_END, 0)!;
    }
    public insertSimpleStatement(): InsertSimpleStatementContext[];
    public insertSimpleStatement(i: number): InsertSimpleStatementContext | null;
    public insertSimpleStatement(i?: number): InsertSimpleStatementContext[] | InsertSimpleStatementContext | null {
        if (i === undefined) {
            return this.getRuleContexts(InsertSimpleStatementContext);
        }

        return this.getRuleContext(i, InsertSimpleStatementContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_insertMulStatementCompatibility;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterInsertMulStatementCompatibility) {
             listener.enterInsertMulStatementCompatibility(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitInsertMulStatementCompatibility) {
             listener.exitInsertMulStatementCompatibility(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitInsertMulStatementCompatibility) {
            return visitor.visitInsertMulStatementCompatibility(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class InsertMulStatementContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_STATEMENT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_STATEMENT, 0)!;
    }
    public KW_SET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_SET, 0)!;
    }
    public KW_BEGIN(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_BEGIN, 0)!;
    }
    public KW_END(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_END, 0)!;
    }
    public insertSimpleStatement(): InsertSimpleStatementContext[];
    public insertSimpleStatement(i: number): InsertSimpleStatementContext | null;
    public insertSimpleStatement(i?: number): InsertSimpleStatementContext[] | InsertSimpleStatementContext | null {
        if (i === undefined) {
            return this.getRuleContexts(InsertSimpleStatementContext);
        }

        return this.getRuleContext(i, InsertSimpleStatementContext);
    }
    public SEMICOLON(): antlr.TerminalNode[];
    public SEMICOLON(i: number): antlr.TerminalNode | null;
    public SEMICOLON(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.SEMICOLON);
    	} else {
    		return this.getToken(SparkSQLParser.SEMICOLON, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_insertMulStatement;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterInsertMulStatement) {
             listener.enterInsertMulStatement(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitInsertMulStatement) {
             listener.exitInsertMulStatement(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitInsertMulStatement) {
            return visitor.visitInsertMulStatement(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class QueryStatementContext extends antlr.ParserRuleContext {
    public _left?: QueryStatementContext;
    public _operator?: Token | null;
    public _right?: QueryStatementContext;
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public withClause(): WithClauseContext | null {
        return this.getRuleContext(0, WithClauseContext);
    }
    public queryStatement(): QueryStatementContext[];
    public queryStatement(i: number): QueryStatementContext | null;
    public queryStatement(i?: number): QueryStatementContext[] | QueryStatementContext | null {
        if (i === undefined) {
            return this.getRuleContexts(QueryStatementContext);
        }

        return this.getRuleContext(i, QueryStatementContext);
    }
    public LR_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0);
    }
    public RR_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0);
    }
    public selectClause(): SelectClauseContext | null {
        return this.getRuleContext(0, SelectClauseContext);
    }
    public selectStatement(): SelectStatementContext | null {
        return this.getRuleContext(0, SelectStatementContext);
    }
    public sortByCaluse(): SortByCaluseContext | null {
        return this.getRuleContext(0, SortByCaluseContext);
    }
    public orderByCaluse(): OrderByCaluseContext | null {
        return this.getRuleContext(0, OrderByCaluseContext);
    }
    public limitClause(): LimitClauseContext | null {
        return this.getRuleContext(0, LimitClauseContext);
    }
    public offsetClause(): OffsetClauseContext | null {
        return this.getRuleContext(0, OffsetClauseContext);
    }
    public KW_INTERSECT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_INTERSECT, 0);
    }
    public KW_UNION(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_UNION, 0);
    }
    public KW_EXCEPT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_EXCEPT, 0);
    }
    public KW_MINUS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MINUS, 0);
    }
    public KW_ALL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ALL, 0);
    }
    public KW_DISTINCT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DISTINCT, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_queryStatement;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterQueryStatement) {
             listener.enterQueryStatement(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitQueryStatement) {
             listener.exitQueryStatement(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitQueryStatement) {
            return visitor.visitQueryStatement(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ValuesCaluseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_VALUES(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_VALUES, 0);
    }
    public inlineBody(): InlineBodyContext[];
    public inlineBody(i: number): InlineBodyContext | null;
    public inlineBody(i?: number): InlineBodyContext[] | InlineBodyContext | null {
        if (i === undefined) {
            return this.getRuleContexts(InlineBodyContext);
        }

        return this.getRuleContext(i, InlineBodyContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public tableAlias(): TableAliasContext[];
    public tableAlias(i: number): TableAliasContext | null;
    public tableAlias(i?: number): TableAliasContext[] | TableAliasContext | null {
        if (i === undefined) {
            return this.getRuleContexts(TableAliasContext);
        }

        return this.getRuleContext(i, TableAliasContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_valuesCaluse;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterValuesCaluse) {
             listener.enterValuesCaluse(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitValuesCaluse) {
             listener.exitValuesCaluse(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitValuesCaluse) {
            return visitor.visitValuesCaluse(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class InlineBodyContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public expression(): ExpressionContext[];
    public expression(i: number): ExpressionContext | null;
    public expression(i?: number): ExpressionContext[] | ExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ExpressionContext);
        }

        return this.getRuleContext(i, ExpressionContext);
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_inlineBody;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterInlineBody) {
             listener.enterInlineBody(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitInlineBody) {
             listener.exitInlineBody(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitInlineBody) {
            return visitor.visitInlineBody(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class WithClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_WITH(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_WITH, 0)!;
    }
    public withItem(): WithItemContext[];
    public withItem(i: number): WithItemContext | null;
    public withItem(i?: number): WithItemContext[] | WithItemContext | null {
        if (i === undefined) {
            return this.getRuleContexts(WithItemContext);
        }

        return this.getRuleContext(i, WithItemContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_withClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterWithClause) {
             listener.enterWithClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitWithClause) {
             listener.exitWithClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitWithClause) {
            return visitor.visitWithClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class WithItemContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public withItemName(): WithItemNameContext {
        return this.getRuleContext(0, WithItemNameContext)!;
    }
    public KW_AS(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_AS, 0)!;
    }
    public LR_BRACKET(): antlr.TerminalNode[];
    public LR_BRACKET(i: number): antlr.TerminalNode | null;
    public LR_BRACKET(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.LR_BRACKET);
    	} else {
    		return this.getToken(SparkSQLParser.LR_BRACKET, i);
    	}
    }
    public queryStatement(): QueryStatementContext {
        return this.getRuleContext(0, QueryStatementContext)!;
    }
    public RR_BRACKET(): antlr.TerminalNode[];
    public RR_BRACKET(i: number): antlr.TerminalNode | null;
    public RR_BRACKET(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.RR_BRACKET);
    	} else {
    		return this.getToken(SparkSQLParser.RR_BRACKET, i);
    	}
    }
    public columnName(): ColumnNameContext[];
    public columnName(i: number): ColumnNameContext | null;
    public columnName(i?: number): ColumnNameContext[] | ColumnNameContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ColumnNameContext);
        }

        return this.getRuleContext(i, ColumnNameContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_withItem;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterWithItem) {
             listener.enterWithItem(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitWithItem) {
             listener.exitWithItem(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitWithItem) {
            return visitor.visitWithItem(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class WithItemNameContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public identifier(): IdentifierContext {
        return this.getRuleContext(0, IdentifierContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_withItemName;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterWithItemName) {
             listener.enterWithItemName(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitWithItemName) {
             listener.exitWithItemName(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitWithItemName) {
            return visitor.visitWithItemName(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class SelectStatementContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_selectStatement;
    }
    public override copyFrom(ctx: SelectStatementContext): void {
        super.copyFrom(ctx);
    }
}
export class TableSampleContext extends SelectStatementContext {
    public constructor(ctx: SelectStatementContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public selectClause(): SelectClauseContext {
        return this.getRuleContext(0, SelectClauseContext)!;
    }
    public fromClause(): FromClauseContext {
        return this.getRuleContext(0, FromClauseContext)!;
    }
    public samplingQueries(): SamplingQueriesContext {
        return this.getRuleContext(0, SamplingQueriesContext)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterTableSample) {
             listener.enterTableSample(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitTableSample) {
             listener.exitTableSample(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitTableSample) {
            return visitor.visitTableSample(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class SparkStyleSelectContext extends SelectStatementContext {
    public constructor(ctx: SelectStatementContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public fromClause(): FromClauseContext {
        return this.getRuleContext(0, FromClauseContext)!;
    }
    public selectClause(): SelectClauseContext {
        return this.getRuleContext(0, SelectClauseContext)!;
    }
    public whereClause(): WhereClauseContext | null {
        return this.getRuleContext(0, WhereClauseContext);
    }
    public someByClause(): SomeByClauseContext | null {
        return this.getRuleContext(0, SomeByClauseContext);
    }
    public havingClause(): HavingClauseContext | null {
        return this.getRuleContext(0, HavingClauseContext);
    }
    public windowClause(): WindowClauseContext | null {
        return this.getRuleContext(0, WindowClauseContext);
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterSparkStyleSelect) {
             listener.enterSparkStyleSelect(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitSparkStyleSelect) {
             listener.exitSparkStyleSelect(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitSparkStyleSelect) {
            return visitor.visitSparkStyleSelect(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class TvfQueryContext extends SelectStatementContext {
    public constructor(ctx: SelectStatementContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public selectClause(): SelectClauseContext {
        return this.getRuleContext(0, SelectClauseContext)!;
    }
    public tvfClause(): TvfClauseContext {
        return this.getRuleContext(0, TvfClauseContext)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterTvfQuery) {
             listener.enterTvfQuery(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitTvfQuery) {
             listener.exitTvfQuery(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitTvfQuery) {
            return visitor.visitTvfQuery(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class TransformQueryContext extends SelectStatementContext {
    public constructor(ctx: SelectStatementContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public KW_SELECT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_SELECT, 0)!;
    }
    public transformClause(): TransformClauseContext {
        return this.getRuleContext(0, TransformClauseContext)!;
    }
    public fromClause(): FromClauseContext {
        return this.getRuleContext(0, FromClauseContext)!;
    }
    public whereClause(): WhereClauseContext | null {
        return this.getRuleContext(0, WhereClauseContext);
    }
    public someByClause(): SomeByClauseContext | null {
        return this.getRuleContext(0, SomeByClauseContext);
    }
    public havingClause(): HavingClauseContext | null {
        return this.getRuleContext(0, HavingClauseContext);
    }
    public windowClause(): WindowClauseContext | null {
        return this.getRuleContext(0, WindowClauseContext);
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterTransformQuery) {
             listener.enterTransformQuery(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitTransformQuery) {
             listener.exitTransformQuery(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitTransformQuery) {
            return visitor.visitTransformQuery(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class MatchRecognizeSelectContext extends SelectStatementContext {
    public constructor(ctx: SelectStatementContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public selectClause(): SelectClauseContext {
        return this.getRuleContext(0, SelectClauseContext)!;
    }
    public fromClause(): FromClauseContext {
        return this.getRuleContext(0, FromClauseContext)!;
    }
    public matchRecognizeClause(): MatchRecognizeClauseContext {
        return this.getRuleContext(0, MatchRecognizeClauseContext)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterMatchRecognizeSelect) {
             listener.enterMatchRecognizeSelect(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitMatchRecognizeSelect) {
             listener.exitMatchRecognizeSelect(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitMatchRecognizeSelect) {
            return visitor.visitMatchRecognizeSelect(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class CommonSelectContext extends SelectStatementContext {
    public constructor(ctx: SelectStatementContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public selectClause(): SelectClauseContext {
        return this.getRuleContext(0, SelectClauseContext)!;
    }
    public fromClause(): FromClauseContext {
        return this.getRuleContext(0, FromClauseContext)!;
    }
    public whereClause(): WhereClauseContext | null {
        return this.getRuleContext(0, WhereClauseContext);
    }
    public someByClause(): SomeByClauseContext | null {
        return this.getRuleContext(0, SomeByClauseContext);
    }
    public havingClause(): HavingClauseContext | null {
        return this.getRuleContext(0, HavingClauseContext);
    }
    public windowClause(): WindowClauseContext | null {
        return this.getRuleContext(0, WindowClauseContext);
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterCommonSelect) {
             listener.enterCommonSelect(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitCommonSelect) {
             listener.exitCommonSelect(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitCommonSelect) {
            return visitor.visitCommonSelect(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class InlineTableContext extends SelectStatementContext {
    public constructor(ctx: SelectStatementContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public KW_SELECT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_SELECT, 0)!;
    }
    public inlineTableClause(): InlineTableClauseContext {
        return this.getRuleContext(0, InlineTableClauseContext)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterInlineTable) {
             listener.enterInlineTable(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitInlineTable) {
             listener.exitInlineTable(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitInlineTable) {
            return visitor.visitInlineTable(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class SelectClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_SELECT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_SELECT, 0)!;
    }
    public ASTERISK_SIGN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.ASTERISK_SIGN, 0);
    }
    public projectItemDefinition(): ProjectItemDefinitionContext[];
    public projectItemDefinition(i: number): ProjectItemDefinitionContext | null;
    public projectItemDefinition(i?: number): ProjectItemDefinitionContext[] | ProjectItemDefinitionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ProjectItemDefinitionContext);
        }

        return this.getRuleContext(i, ProjectItemDefinitionContext);
    }
    public setQuantifier(): SetQuantifierContext | null {
        return this.getRuleContext(0, SetQuantifierContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_selectClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterSelectClause) {
             listener.enterSelectClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitSelectClause) {
             listener.exitSelectClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitSelectClause) {
            return visitor.visitSelectClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ProjectItemDefinitionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_projectItemDefinition;
    }
    public override copyFrom(ctx: ProjectItemDefinitionContext): void {
        super.copyFrom(ctx);
    }
}
export class AggregateFunctionsContext extends ProjectItemDefinitionContext {
    public constructor(ctx: ProjectItemDefinitionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public funtionBody(): FuntionBodyContext {
        return this.getRuleContext(0, FuntionBodyContext)!;
    }
    public filterPart(): FilterPartContext {
        return this.getRuleContext(0, FilterPartContext)!;
    }
    public identifier(): IdentifierContext | null {
        return this.getRuleContext(0, IdentifierContext);
    }
    public KW_AS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_AS, 0);
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterAggregateFunctions) {
             listener.enterAggregateFunctions(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitAggregateFunctions) {
             listener.exitAggregateFunctions(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitAggregateFunctions) {
            return visitor.visitAggregateFunctions(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class OrderSetAggregateFunctionsContext extends ProjectItemDefinitionContext {
    public constructor(ctx: ProjectItemDefinitionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public funtionBody(): FuntionBodyContext {
        return this.getRuleContext(0, FuntionBodyContext)!;
    }
    public KW_WITHIN(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_WITHIN, 0)!;
    }
    public KW_GROUP(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_GROUP, 0)!;
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public orderByCaluse(): OrderByCaluseContext {
        return this.getRuleContext(0, OrderByCaluseContext)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public filterPart(): FilterPartContext | null {
        return this.getRuleContext(0, FilterPartContext);
    }
    public identifier(): IdentifierContext | null {
        return this.getRuleContext(0, IdentifierContext);
    }
    public KW_AS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_AS, 0);
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterOrderSetAggregateFunctions) {
             listener.enterOrderSetAggregateFunctions(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitOrderSetAggregateFunctions) {
             listener.exitOrderSetAggregateFunctions(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitOrderSetAggregateFunctions) {
            return visitor.visitOrderSetAggregateFunctions(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class WindowsProrjectItemContext extends ProjectItemDefinitionContext {
    public constructor(ctx: ProjectItemDefinitionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public overWindowItem(): OverWindowItemContext | null {
        return this.getRuleContext(0, OverWindowItemContext);
    }
    public identifier(): IdentifierContext | null {
        return this.getRuleContext(0, IdentifierContext);
    }
    public KW_AS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_AS, 0);
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterWindowsProrjectItem) {
             listener.enterWindowsProrjectItem(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitWindowsProrjectItem) {
             listener.exitWindowsProrjectItem(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitWindowsProrjectItem) {
            return visitor.visitWindowsProrjectItem(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class ExpressionProjectItemContext extends ProjectItemDefinitionContext {
    public constructor(ctx: ProjectItemDefinitionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public expression(): ExpressionContext[];
    public expression(i: number): ExpressionContext | null;
    public expression(i?: number): ExpressionContext[] | ExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ExpressionContext);
        }

        return this.getRuleContext(i, ExpressionContext);
    }
    public KW_AS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_AS, 0);
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterExpressionProjectItem) {
             listener.enterExpressionProjectItem(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitExpressionProjectItem) {
             listener.exitExpressionProjectItem(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitExpressionProjectItem) {
            return visitor.visitExpressionProjectItem(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class FilterPartContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_FILTER(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_FILTER, 0)!;
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public whereClause(): WhereClauseContext {
        return this.getRuleContext(0, WhereClauseContext)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_filterPart;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterFilterPart) {
             listener.enterFilterPart(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitFilterPart) {
             listener.exitFilterPart(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitFilterPart) {
            return visitor.visitFilterPart(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class OverWindowItemContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public windowFunctioPart(): WindowFunctioPartContext {
        return this.getRuleContext(0, WindowFunctioPartContext)!;
    }
    public KW_OVER(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_OVER, 0)!;
    }
    public KW_NULLS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NULLS, 0);
    }
    public anonymousWindowsName(): AnonymousWindowsNameContext | null {
        return this.getRuleContext(0, AnonymousWindowsNameContext);
    }
    public LR_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0);
    }
    public byClause(): ByClauseContext[];
    public byClause(i: number): ByClauseContext | null;
    public byClause(i?: number): ByClauseContext[] | ByClauseContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ByClauseContext);
        }

        return this.getRuleContext(i, ByClauseContext);
    }
    public RR_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0);
    }
    public KW_IGNORE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_IGNORE, 0);
    }
    public KW_RESPECT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_RESPECT, 0);
    }
    public overClause(): OverClauseContext | null {
        return this.getRuleContext(0, OverClauseContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public windowFrameForWindowsQuery(): WindowFrameForWindowsQueryContext | null {
        return this.getRuleContext(0, WindowFrameForWindowsQueryContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_overWindowItem;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterOverWindowItem) {
             listener.enterOverWindowItem(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitOverWindowItem) {
             listener.exitOverWindowItem(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitOverWindowItem) {
            return visitor.visitOverWindowItem(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class OverClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_BY(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_BY, 0)!;
    }
    public columnName(): ColumnNameContext {
        return this.getRuleContext(0, ColumnNameContext)!;
    }
    public KW_PARTITION(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PARTITION, 0);
    }
    public KW_DISTRIBUTE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DISTRIBUTE, 0);
    }
    public EQUAL_SYMBOL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.EQUAL_SYMBOL, 0);
    }
    public expression(): ExpressionContext | null {
        return this.getRuleContext(0, ExpressionContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_overClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterOverClause) {
             listener.enterOverClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitOverClause) {
             listener.exitOverClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitOverClause) {
            return visitor.visitOverClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ByClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_BY(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_BY, 0)!;
    }
    public columnName(): ColumnNameContext {
        return this.getRuleContext(0, ColumnNameContext)!;
    }
    public KW_ORDER(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ORDER, 0);
    }
    public KW_SORT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SORT, 0);
    }
    public KW_NULLS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NULLS, 0);
    }
    public KW_ASC(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ASC, 0);
    }
    public KW_DESC(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DESC, 0);
    }
    public KW_FIRST(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FIRST, 0);
    }
    public KW_LAST(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LAST, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_byClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterByClause) {
             listener.enterByClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitByClause) {
             listener.exitByClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitByClause) {
            return visitor.visitByClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class WindowFunctioPartContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public windowFunctionName(): WindowFunctionNameContext | null {
        return this.getRuleContext(0, WindowFunctionNameContext);
    }
    public LR_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0);
    }
    public RR_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0);
    }
    public functionParam(): FunctionParamContext[];
    public functionParam(i: number): FunctionParamContext | null;
    public functionParam(i?: number): FunctionParamContext[] | FunctionParamContext | null {
        if (i === undefined) {
            return this.getRuleContexts(FunctionParamContext);
        }

        return this.getRuleContext(i, FunctionParamContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public primaryExpression(): PrimaryExpressionContext | null {
        return this.getRuleContext(0, PrimaryExpressionContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_windowFunctioPart;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterWindowFunctioPart) {
             listener.enterWindowFunctioPart(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitWindowFunctioPart) {
             listener.exitWindowFunctioPart(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitWindowFunctioPart) {
            return visitor.visitWindowFunctioPart(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class WindowFunctionNameContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public rangkingFunction(): RangkingFunctionContext | null {
        return this.getRuleContext(0, RangkingFunctionContext);
    }
    public analyticFunction(): AnalyticFunctionContext | null {
        return this.getRuleContext(0, AnalyticFunctionContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_windowFunctionName;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterWindowFunctionName) {
             listener.enterWindowFunctionName(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitWindowFunctionName) {
             listener.exitWindowFunctionName(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitWindowFunctionName) {
            return visitor.visitWindowFunctionName(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class AnalyticFunctionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_CUME_DIST(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_CUME_DIST, 0);
    }
    public KW_LAG(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LAG, 0);
    }
    public KW_LEAD(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LEAD, 0);
    }
    public KW_NTH_VALUE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NTH_VALUE, 0);
    }
    public KW_FIRST_VALUE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FIRST_VALUE, 0);
    }
    public KW_LAST_VALUE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LAST_VALUE, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_analyticFunction;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterAnalyticFunction) {
             listener.enterAnalyticFunction(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitAnalyticFunction) {
             listener.exitAnalyticFunction(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitAnalyticFunction) {
            return visitor.visitAnalyticFunction(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class RangkingFunctionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_RANK(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_RANK, 0);
    }
    public KW_DENSE_RANK(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DENSE_RANK, 0);
    }
    public KW_PERCENT_RANK(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PERCENT_RANK, 0);
    }
    public KW_NTILE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NTILE, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_rangkingFunction;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterRangkingFunction) {
             listener.enterRangkingFunction(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitRangkingFunction) {
             listener.exitRangkingFunction(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitRangkingFunction) {
            return visitor.visitRangkingFunction(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class FromClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_FROM(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_FROM, 0)!;
    }
    public tableExpression(): TableExpressionContext {
        return this.getRuleContext(0, TableExpressionContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_fromClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterFromClause) {
             listener.enterFromClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitFromClause) {
             listener.exitFromClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitFromClause) {
            return visitor.visitFromClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class WindowFrameForWindowsQueryContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_RANGE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_RANGE, 0);
    }
    public KW_ROWS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ROWS, 0);
    }
    public frameExpession(): FrameExpessionContext[];
    public frameExpession(i: number): FrameExpessionContext | null;
    public frameExpession(i?: number): FrameExpessionContext[] | FrameExpessionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(FrameExpessionContext);
        }

        return this.getRuleContext(i, FrameExpessionContext);
    }
    public KW_BETWEEN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_BETWEEN, 0);
    }
    public KW_AND(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_AND, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_windowFrameForWindowsQuery;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterWindowFrameForWindowsQuery) {
             listener.enterWindowFrameForWindowsQuery(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitWindowFrameForWindowsQuery) {
             listener.exitWindowFrameForWindowsQuery(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitWindowFrameForWindowsQuery) {
            return visitor.visitWindowFrameForWindowsQuery(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class FrameExpessionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_UNBOUNDED(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_UNBOUNDED, 0);
    }
    public KW_PRECEDING(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PRECEDING, 0);
    }
    public expression(): ExpressionContext | null {
        return this.getRuleContext(0, ExpressionContext);
    }
    public KW_CURRENT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_CURRENT, 0);
    }
    public KW_ROW(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ROW, 0);
    }
    public KW_FOLLOWING(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FOLLOWING, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_frameExpession;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterFrameExpession) {
             listener.enterFrameExpession(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitFrameExpession) {
             listener.exitFrameExpession(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitFrameExpession) {
            return visitor.visitFrameExpession(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class TableExpressionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public tableReference(): TableReferenceContext[];
    public tableReference(i: number): TableReferenceContext | null;
    public tableReference(i?: number): TableReferenceContext[] | TableReferenceContext | null {
        if (i === undefined) {
            return this.getRuleContexts(TableReferenceContext);
        }

        return this.getRuleContext(i, TableReferenceContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public valuesCaluse(): ValuesCaluseContext | null {
        return this.getRuleContext(0, ValuesCaluseContext);
    }
    public tvfClause(): TvfClauseContext | null {
        return this.getRuleContext(0, TvfClauseContext);
    }
    public tableAlias(): TableAliasContext | null {
        return this.getRuleContext(0, TableAliasContext);
    }
    public windowTVFClause(): WindowTVFClauseContext | null {
        return this.getRuleContext(0, WindowTVFClauseContext);
    }
    public tableExpression(): TableExpressionContext[];
    public tableExpression(i: number): TableExpressionContext | null;
    public tableExpression(i?: number): TableExpressionContext[] | TableExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(TableExpressionContext);
        }

        return this.getRuleContext(i, TableExpressionContext);
    }
    public KW_CROSS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_CROSS, 0);
    }
    public KW_JOIN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_JOIN, 0);
    }
    public KW_NATURAL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NATURAL, 0);
    }
    public KW_OUTER(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_OUTER, 0);
    }
    public joinCondition(): JoinConditionContext | null {
        return this.getRuleContext(0, JoinConditionContext);
    }
    public KW_LEFT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LEFT, 0);
    }
    public KW_RIGHT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_RIGHT, 0);
    }
    public KW_FULL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FULL, 0);
    }
    public KW_INNER(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_INNER, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_tableExpression;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterTableExpression) {
             listener.enterTableExpression(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitTableExpression) {
             listener.exitTableExpression(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitTableExpression) {
            return visitor.visitTableExpression(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class TableReferenceContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public tablePrimary(): TablePrimaryContext {
        return this.getRuleContext(0, TablePrimaryContext)!;
    }
    public tableAlias(): TableAliasContext | null {
        return this.getRuleContext(0, TableAliasContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_tableReference;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterTableReference) {
             listener.enterTableReference(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitTableReference) {
             listener.exitTableReference(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitTableReference) {
            return visitor.visitTableReference(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class TablePrimaryContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public tablePath(): TablePathContext | null {
        return this.getRuleContext(0, TablePathContext);
    }
    public KW_TABLE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TABLE, 0);
    }
    public systemTimePeriod(): SystemTimePeriodContext | null {
        return this.getRuleContext(0, SystemTimePeriodContext);
    }
    public correlationName(): CorrelationNameContext | null {
        return this.getRuleContext(0, CorrelationNameContext);
    }
    public KW_AS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_AS, 0);
    }
    public KW_LATERAL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LATERAL, 0);
    }
    public funtionBody(): FuntionBodyContext | null {
        return this.getRuleContext(0, FuntionBodyContext);
    }
    public complexDataTypeExpression(): ComplexDataTypeExpressionContext | null {
        return this.getRuleContext(0, ComplexDataTypeExpressionContext);
    }
    public KW_EXPLODE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_EXPLODE, 0);
    }
    public LR_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0);
    }
    public RR_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0);
    }
    public queryStatement(): QueryStatementContext | null {
        return this.getRuleContext(0, QueryStatementContext);
    }
    public KW_VIEW(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_VIEW, 0);
    }
    public columnAlias(): ColumnAliasContext[];
    public columnAlias(i: number): ColumnAliasContext | null;
    public columnAlias(i?: number): ColumnAliasContext[] | ColumnAliasContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ColumnAliasContext);
        }

        return this.getRuleContext(i, ColumnAliasContext);
    }
    public KW_OUTER(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_OUTER, 0);
    }
    public tableAlias(): TableAliasContext | null {
        return this.getRuleContext(0, TableAliasContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public KW_UNSET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_UNSET, 0);
    }
    public expression(): ExpressionContext | null {
        return this.getRuleContext(0, ExpressionContext);
    }
    public KW_PIVOT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PIVOT, 0);
    }
    public pivotBody(): PivotBodyContext | null {
        return this.getRuleContext(0, PivotBodyContext);
    }
    public KW_UNPIVOT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_UNPIVOT, 0);
    }
    public unpivotBody(): UnpivotBodyContext | null {
        return this.getRuleContext(0, UnpivotBodyContext);
    }
    public KW_NULLS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NULLS, 0);
    }
    public KW_INCLUDE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_INCLUDE, 0);
    }
    public KW_EXCLUDE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_EXCLUDE, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_tablePrimary;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterTablePrimary) {
             listener.enterTablePrimary(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitTablePrimary) {
             listener.exitTablePrimary(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitTablePrimary) {
            return visitor.visitTablePrimary(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class FuntionBodyContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public functionName(): FunctionNameContext {
        return this.getRuleContext(0, FunctionNameContext)!;
    }
    public LR_BRACKET(): antlr.TerminalNode[];
    public LR_BRACKET(i: number): antlr.TerminalNode | null;
    public LR_BRACKET(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.LR_BRACKET);
    	} else {
    		return this.getToken(SparkSQLParser.LR_BRACKET, i);
    	}
    }
    public RR_BRACKET(): antlr.TerminalNode[];
    public RR_BRACKET(i: number): antlr.TerminalNode | null;
    public RR_BRACKET(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.RR_BRACKET);
    	} else {
    		return this.getToken(SparkSQLParser.RR_BRACKET, i);
    	}
    }
    public funtionBody(): FuntionBodyContext[];
    public funtionBody(i: number): FuntionBodyContext | null;
    public funtionBody(i?: number): FuntionBodyContext[] | FuntionBodyContext | null {
        if (i === undefined) {
            return this.getRuleContexts(FuntionBodyContext);
        }

        return this.getRuleContext(i, FuntionBodyContext);
    }
    public functionParam(): FunctionParamContext[];
    public functionParam(i: number): FunctionParamContext | null;
    public functionParam(i?: number): FunctionParamContext[] | FunctionParamContext | null {
        if (i === undefined) {
            return this.getRuleContexts(FunctionParamContext);
        }

        return this.getRuleContext(i, FunctionParamContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public KW_AS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_AS, 0);
    }
    public tableAlias(): TableAliasContext | null {
        return this.getRuleContext(0, TableAliasContext);
    }
    public projectItemDefinition(): ProjectItemDefinitionContext[];
    public projectItemDefinition(i: number): ProjectItemDefinitionContext | null;
    public projectItemDefinition(i?: number): ProjectItemDefinitionContext[] | ProjectItemDefinitionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ProjectItemDefinitionContext);
        }

        return this.getRuleContext(i, ProjectItemDefinitionContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_funtionBody;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterFuntionBody) {
             listener.enterFuntionBody(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitFuntionBody) {
             listener.exitFuntionBody(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitFuntionBody) {
            return visitor.visitFuntionBody(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class UnpivotBodyContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_FOR(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_FOR, 0)!;
    }
    public columnName(): ColumnNameContext[];
    public columnName(i: number): ColumnNameContext | null;
    public columnName(i?: number): ColumnNameContext[] | ColumnNameContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ColumnNameContext);
        }

        return this.getRuleContext(i, ColumnNameContext);
    }
    public KW_IN(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_IN, 0)!;
    }
    public expressionAsAliasList(): ExpressionAsAliasListContext {
        return this.getRuleContext(0, ExpressionAsAliasListContext)!;
    }
    public columnNameList(): ColumnNameListContext | null {
        return this.getRuleContext(0, ColumnNameListContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_unpivotBody;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterUnpivotBody) {
             listener.enterUnpivotBody(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitUnpivotBody) {
             listener.exitUnpivotBody(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitUnpivotBody) {
            return visitor.visitUnpivotBody(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class PivotBodyContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public expressionAsAlias(): ExpressionAsAliasContext[];
    public expressionAsAlias(i: number): ExpressionAsAliasContext | null;
    public expressionAsAlias(i?: number): ExpressionAsAliasContext[] | ExpressionAsAliasContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ExpressionAsAliasContext);
        }

        return this.getRuleContext(i, ExpressionAsAliasContext);
    }
    public KW_FOR(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_FOR, 0)!;
    }
    public KW_IN(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_IN, 0)!;
    }
    public expressionAsAliasList(): ExpressionAsAliasListContext {
        return this.getRuleContext(0, ExpressionAsAliasListContext)!;
    }
    public COMMA(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.COMMA, 0);
    }
    public columnName(): ColumnNameContext | null {
        return this.getRuleContext(0, ColumnNameContext);
    }
    public columnNameList(): ColumnNameListContext | null {
        return this.getRuleContext(0, ColumnNameListContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_pivotBody;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterPivotBody) {
             listener.enterPivotBody(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitPivotBody) {
             listener.exitPivotBody(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitPivotBody) {
            return visitor.visitPivotBody(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ExpressionAsAliasContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public expression(): ExpressionContext {
        return this.getRuleContext(0, ExpressionContext)!;
    }
    public KW_AS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_AS, 0);
    }
    public columnAlias(): ColumnAliasContext | null {
        return this.getRuleContext(0, ColumnAliasContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_expressionAsAlias;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterExpressionAsAlias) {
             listener.enterExpressionAsAlias(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitExpressionAsAlias) {
             listener.exitExpressionAsAlias(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitExpressionAsAlias) {
            return visitor.visitExpressionAsAlias(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ExpressionAsAliasListContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public expressionAsAlias(): ExpressionAsAliasContext[];
    public expressionAsAlias(i: number): ExpressionAsAliasContext | null;
    public expressionAsAlias(i?: number): ExpressionAsAliasContext[] | ExpressionAsAliasContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ExpressionAsAliasContext);
        }

        return this.getRuleContext(i, ExpressionAsAliasContext);
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_expressionAsAliasList;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterExpressionAsAliasList) {
             listener.enterExpressionAsAliasList(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitExpressionAsAliasList) {
             listener.exitExpressionAsAliasList(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitExpressionAsAliasList) {
            return visitor.visitExpressionAsAliasList(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class SystemTimePeriodContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_FOR(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_FOR, 0)!;
    }
    public KW_SYSTEM_TIME(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_SYSTEM_TIME, 0)!;
    }
    public KW_AS(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_AS, 0)!;
    }
    public KW_OF(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_OF, 0)!;
    }
    public dateTimeExpression(): DateTimeExpressionContext {
        return this.getRuleContext(0, DateTimeExpressionContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_systemTimePeriod;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterSystemTimePeriod) {
             listener.enterSystemTimePeriod(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitSystemTimePeriod) {
             listener.exitSystemTimePeriod(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitSystemTimePeriod) {
            return visitor.visitSystemTimePeriod(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class DateTimeExpressionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public expression(): ExpressionContext {
        return this.getRuleContext(0, ExpressionContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_dateTimeExpression;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterDateTimeExpression) {
             listener.enterDateTimeExpression(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitDateTimeExpression) {
             listener.exitDateTimeExpression(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitDateTimeExpression) {
            return visitor.visitDateTimeExpression(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class InlineDataValueClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public expression(): ExpressionContext[];
    public expression(i: number): ExpressionContext | null;
    public expression(i?: number): ExpressionContext[] | ExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ExpressionContext);
        }

        return this.getRuleContext(i, ExpressionContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public tableAlias(): TableAliasContext | null {
        return this.getRuleContext(0, TableAliasContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_inlineDataValueClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterInlineDataValueClause) {
             listener.enterInlineDataValueClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitInlineDataValueClause) {
             listener.exitInlineDataValueClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitInlineDataValueClause) {
            return visitor.visitInlineDataValueClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class WindowTVFClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_TABLE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_TABLE, 0)!;
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public windowTVFExpression(): WindowTVFExpressionContext {
        return this.getRuleContext(0, WindowTVFExpressionContext)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_windowTVFClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterWindowTVFClause) {
             listener.enterWindowTVFClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitWindowTVFClause) {
             listener.exitWindowTVFClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitWindowTVFClause) {
            return visitor.visitWindowTVFClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class TvfClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_tvfClause;
    }
    public override copyFrom(ctx: TvfClauseContext): void {
        super.copyFrom(ctx);
    }
}
export class RangeContext extends TvfClauseContext {
    public constructor(ctx: TvfClauseContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public rangeClause(): RangeClauseContext {
        return this.getRuleContext(0, RangeClauseContext)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterRange) {
             listener.enterRange(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitRange) {
             listener.exitRange(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitRange) {
            return visitor.visitRange(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class InlineTableClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_inlineTableClause;
    }
    public override copyFrom(ctx: InlineTableClauseContext): void {
        super.copyFrom(ctx);
    }
}
export class Parse_urlContext extends InlineTableClauseContext {
    public constructor(ctx: InlineTableClauseContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public KW_PARSE_URL(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_PARSE_URL, 0)!;
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public stringLiteral(): StringLiteralContext[];
    public stringLiteral(i: number): StringLiteralContext | null;
    public stringLiteral(i?: number): StringLiteralContext[] | StringLiteralContext | null {
        if (i === undefined) {
            return this.getRuleContexts(StringLiteralContext);
        }

        return this.getRuleContext(i, StringLiteralContext);
    }
    public COMMA(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.COMMA, 0)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterParse_url) {
             listener.enterParse_url(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitParse_url) {
             listener.exitParse_url(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitParse_url) {
            return visitor.visitParse_url(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class StackContext extends InlineTableClauseContext {
    public constructor(ctx: InlineTableClauseContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public KW_STACK(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_STACK, 0)!;
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public constant(): ConstantContext {
        return this.getRuleContext(0, ConstantContext)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public expression(): ExpressionContext[];
    public expression(i: number): ExpressionContext | null;
    public expression(i?: number): ExpressionContext[] | ExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ExpressionContext);
        }

        return this.getRuleContext(i, ExpressionContext);
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterStack) {
             listener.enterStack(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitStack) {
             listener.exitStack(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitStack) {
            return visitor.visitStack(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class OneExpresionContext extends InlineTableClauseContext {
    public constructor(ctx: InlineTableClauseContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public expression(): ExpressionContext {
        return this.getRuleContext(0, ExpressionContext)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public KW_EXPLODE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_EXPLODE, 0);
    }
    public KW_EXPLODE_OUTER(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_EXPLODE_OUTER, 0);
    }
    public KW_INLINE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_INLINE, 0);
    }
    public KW_INLINE_OUTER(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_INLINE_OUTER, 0);
    }
    public KW_POSEXPLODE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_POSEXPLODE, 0);
    }
    public KW_POSEXPLODE_OUTER(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_POSEXPLODE_OUTER, 0);
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterOneExpresion) {
             listener.enterOneExpresion(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitOneExpresion) {
             listener.exitOneExpresion(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitOneExpresion) {
            return visitor.visitOneExpresion(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class Json_tupleContext extends InlineTableClauseContext {
    public constructor(ctx: InlineTableClauseContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public KW_JSON_TUPLE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_JSON_TUPLE, 0)!;
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public stringLiteral(): StringLiteralContext {
        return this.getRuleContext(0, StringLiteralContext)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public expression(): ExpressionContext[];
    public expression(i: number): ExpressionContext | null;
    public expression(i?: number): ExpressionContext[] | ExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ExpressionContext);
        }

        return this.getRuleContext(i, ExpressionContext);
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterJson_tuple) {
             listener.enterJson_tuple(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitJson_tuple) {
             listener.exitJson_tuple(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitJson_tuple) {
            return visitor.visitJson_tuple(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class RangeClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_RANGE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_RANGE, 0)!;
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public expression(): ExpressionContext[];
    public expression(i: number): ExpressionContext | null;
    public expression(i?: number): ExpressionContext[] | ExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ExpressionContext);
        }

        return this.getRuleContext(i, ExpressionContext);
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_rangeClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterRangeClause) {
             listener.enterRangeClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitRangeClause) {
             listener.exitRangeClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitRangeClause) {
            return visitor.visitRangeClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class WindowTVFExpressionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public windowTVFName(): WindowTVFNameContext {
        return this.getRuleContext(0, WindowTVFNameContext)!;
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public windowTVFParam(): WindowTVFParamContext[];
    public windowTVFParam(i: number): WindowTVFParamContext | null;
    public windowTVFParam(i?: number): WindowTVFParamContext[] | WindowTVFParamContext | null {
        if (i === undefined) {
            return this.getRuleContexts(WindowTVFParamContext);
        }

        return this.getRuleContext(i, WindowTVFParamContext);
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_windowTVFExpression;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterWindowTVFExpression) {
             listener.enterWindowTVFExpression(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitWindowTVFExpression) {
             listener.exitWindowTVFExpression(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitWindowTVFExpression) {
            return visitor.visitWindowTVFExpression(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class WindowTVFNameContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_TUMBLE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TUMBLE, 0);
    }
    public KW_HOP(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_HOP, 0);
    }
    public KW_CUMULATE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_CUMULATE, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_windowTVFName;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterWindowTVFName) {
             listener.enterWindowTVFName(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitWindowTVFName) {
             listener.exitWindowTVFName(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitWindowTVFName) {
            return visitor.visitWindowTVFName(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class TransformClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_TRANSFORM(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_TRANSFORM, 0)!;
    }
    public columnNameList(): ColumnNameListContext[];
    public columnNameList(i: number): ColumnNameListContext | null;
    public columnNameList(i?: number): ColumnNameListContext[] | ColumnNameListContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ColumnNameListContext);
        }

        return this.getRuleContext(i, ColumnNameListContext);
    }
    public rowFormatDelimited(): RowFormatDelimitedContext | null {
        return this.getRuleContext(0, RowFormatDelimitedContext);
    }
    public hiveSerde(): HiveSerdeContext | null {
        return this.getRuleContext(0, HiveSerdeContext);
    }
    public KW_USING(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_USING, 0);
    }
    public stringLiteral(): StringLiteralContext | null {
        return this.getRuleContext(0, StringLiteralContext);
    }
    public KW_AS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_AS, 0);
    }
    public physicalColumnDefinitionList(): PhysicalColumnDefinitionListContext | null {
        return this.getRuleContext(0, PhysicalColumnDefinitionListContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_transformClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterTransformClause) {
             listener.enterTransformClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitTransformClause) {
             listener.exitTransformClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitTransformClause) {
            return visitor.visitTransformClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class RowFormatDelimitedContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public sparkRecordWriterPart(): SparkRecordWriterPartContext[];
    public sparkRecordWriterPart(i: number): SparkRecordWriterPartContext | null;
    public sparkRecordWriterPart(i?: number): SparkRecordWriterPartContext[] | SparkRecordWriterPartContext | null {
        if (i === undefined) {
            return this.getRuleContexts(SparkRecordWriterPartContext);
        }

        return this.getRuleContext(i, SparkRecordWriterPartContext);
    }
    public usingAsColumnPart(): UsingAsColumnPartContext {
        return this.getRuleContext(0, UsingAsColumnPartContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_rowFormatDelimited;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterRowFormatDelimited) {
             listener.enterRowFormatDelimited(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitRowFormatDelimited) {
             listener.exitRowFormatDelimited(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitRowFormatDelimited) {
            return visitor.visitRowFormatDelimited(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class HiveSerdeContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public hiveSerdePart(): HiveSerdePartContext[];
    public hiveSerdePart(i: number): HiveSerdePartContext | null;
    public hiveSerdePart(i?: number): HiveSerdePartContext[] | HiveSerdePartContext | null {
        if (i === undefined) {
            return this.getRuleContexts(HiveSerdePartContext);
        }

        return this.getRuleContext(i, HiveSerdePartContext);
    }
    public usingAsColumnPart(): UsingAsColumnPartContext {
        return this.getRuleContext(0, UsingAsColumnPartContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_hiveSerde;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterHiveSerde) {
             listener.enterHiveSerde(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitHiveSerde) {
             listener.exitHiveSerde(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitHiveSerde) {
            return visitor.visitHiveSerde(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class UsingAsColumnPartContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_USING(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_USING, 0)!;
    }
    public stringLiteral(): StringLiteralContext {
        return this.getRuleContext(0, StringLiteralContext)!;
    }
    public KW_AS(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_AS, 0)!;
    }
    public columnNameList(): ColumnNameListContext | null {
        return this.getRuleContext(0, ColumnNameListContext);
    }
    public physicalColumnDefinitionList(): PhysicalColumnDefinitionListContext | null {
        return this.getRuleContext(0, PhysicalColumnDefinitionListContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_usingAsColumnPart;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterUsingAsColumnPart) {
             listener.enterUsingAsColumnPart(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitUsingAsColumnPart) {
             listener.exitUsingAsColumnPart(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitUsingAsColumnPart) {
            return visitor.visitUsingAsColumnPart(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class HiveSerdePartContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_ROW(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ROW, 0);
    }
    public KW_FORMAT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FORMAT, 0);
    }
    public KW_SERDE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SERDE, 0);
    }
    public stringLiteral(): StringLiteralContext | null {
        return this.getRuleContext(0, StringLiteralContext);
    }
    public KW_WITH(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_WITH, 0);
    }
    public KW_SERDEPROPERTIES(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SERDEPROPERTIES, 0);
    }
    public tableCanHasKeyPropertyList(): TableCanHasKeyPropertyListContext | null {
        return this.getRuleContext(0, TableCanHasKeyPropertyListContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_hiveSerdePart;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterHiveSerdePart) {
             listener.enterHiveSerdePart(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitHiveSerdePart) {
             listener.exitHiveSerdePart(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitHiveSerdePart) {
            return visitor.visitHiveSerdePart(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class SparkRecordWriterPartContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public rowFormatDelimted(): RowFormatDelimtedContext | null {
        return this.getRuleContext(0, RowFormatDelimtedContext);
    }
    public fieldsTerminatedBy(): FieldsTerminatedByContext | null {
        return this.getRuleContext(0, FieldsTerminatedByContext);
    }
    public KW_LINES(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LINES, 0);
    }
    public KW_TERMINATED(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TERMINATED, 0);
    }
    public KW_BY(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_BY, 0);
    }
    public stringLiteral(): StringLiteralContext[];
    public stringLiteral(i: number): StringLiteralContext | null;
    public stringLiteral(i?: number): StringLiteralContext[] | StringLiteralContext | null {
        if (i === undefined) {
            return this.getRuleContexts(StringLiteralContext);
        }

        return this.getRuleContext(i, StringLiteralContext);
    }
    public KW_NULL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NULL, 0);
    }
    public KW_DEFINED(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DEFINED, 0);
    }
    public KW_AS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_AS, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_sparkRecordWriterPart;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterSparkRecordWriterPart) {
             listener.enterSparkRecordWriterPart(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitSparkRecordWriterPart) {
             listener.exitSparkRecordWriterPart(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitSparkRecordWriterPart) {
            return visitor.visitSparkRecordWriterPart(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class WindowTVFParamContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_TABLE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TABLE, 0);
    }
    public timeAttrColumn(): TimeAttrColumnContext | null {
        return this.getRuleContext(0, TimeAttrColumnContext);
    }
    public columnDescriptor(): ColumnDescriptorContext | null {
        return this.getRuleContext(0, ColumnDescriptorContext);
    }
    public timeIntervalExpression(): TimeIntervalExpressionContext | null {
        return this.getRuleContext(0, TimeIntervalExpressionContext);
    }
    public KW_DATA(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DATA, 0);
    }
    public DOUBLE_RIGHT_ARROW(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.DOUBLE_RIGHT_ARROW, 0);
    }
    public KW_TIMECOL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TIMECOL, 0);
    }
    public timeIntervalParamName(): TimeIntervalParamNameContext | null {
        return this.getRuleContext(0, TimeIntervalParamNameContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_windowTVFParam;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterWindowTVFParam) {
             listener.enterWindowTVFParam(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitWindowTVFParam) {
             listener.exitWindowTVFParam(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitWindowTVFParam) {
            return visitor.visitWindowTVFParam(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class TimeIntervalParamNameContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_DATA(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DATA, 0);
    }
    public KW_TIMECOL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TIMECOL, 0);
    }
    public KW_SIZE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SIZE, 0);
    }
    public KW_OFFSET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_OFFSET, 0);
    }
    public KW_STEP(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_STEP, 0);
    }
    public KW_SLIDE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SLIDE, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_timeIntervalParamName;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterTimeIntervalParamName) {
             listener.enterTimeIntervalParamName(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitTimeIntervalParamName) {
             listener.exitTimeIntervalParamName(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitTimeIntervalParamName) {
            return visitor.visitTimeIntervalParamName(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ColumnDescriptorContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_DESCRIPTOR(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_DESCRIPTOR, 0)!;
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public uid(): UidContext {
        return this.getRuleContext(0, UidContext)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_columnDescriptor;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterColumnDescriptor) {
             listener.enterColumnDescriptor(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitColumnDescriptor) {
             listener.exitColumnDescriptor(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitColumnDescriptor) {
            return visitor.visitColumnDescriptor(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class JoinConditionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_ON(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ON, 0);
    }
    public booleanExpression(): BooleanExpressionContext | null {
        return this.getRuleContext(0, BooleanExpressionContext);
    }
    public KW_USING(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_USING, 0);
    }
    public LR_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0);
    }
    public uid(): UidContext[];
    public uid(i: number): UidContext | null;
    public uid(i?: number): UidContext[] | UidContext | null {
        if (i === undefined) {
            return this.getRuleContexts(UidContext);
        }

        return this.getRuleContext(i, UidContext);
    }
    public RR_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_joinCondition;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterJoinCondition) {
             listener.enterJoinCondition(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitJoinCondition) {
             listener.exitJoinCondition(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitJoinCondition) {
            return visitor.visitJoinCondition(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class WhereClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_WHERE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_WHERE, 0)!;
    }
    public booleanExpression(): BooleanExpressionContext {
        return this.getRuleContext(0, BooleanExpressionContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_whereClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterWhereClause) {
             listener.enterWhereClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitWhereClause) {
             listener.exitWhereClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitWhereClause) {
            return visitor.visitWhereClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class SamplingQueriesContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_TABLESAMPLE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_TABLESAMPLE, 0)!;
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public KW_PERCENT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PERCENT, 0);
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public decimalLiteral(): DecimalLiteralContext | null {
        return this.getRuleContext(0, DecimalLiteralContext);
    }
    public DIG_LITERAL(): antlr.TerminalNode[];
    public DIG_LITERAL(i: number): antlr.TerminalNode | null;
    public DIG_LITERAL(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.DIG_LITERAL);
    	} else {
    		return this.getToken(SparkSQLParser.DIG_LITERAL, i);
    	}
    }
    public expression(): ExpressionContext[];
    public expression(i: number): ExpressionContext | null;
    public expression(i?: number): ExpressionContext[] | ExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ExpressionContext);
        }

        return this.getRuleContext(i, ExpressionContext);
    }
    public KW_ROWS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ROWS, 0);
    }
    public KW_BUCKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_BUCKET, 0);
    }
    public KW_OUT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_OUT, 0);
    }
    public KW_OF(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_OF, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_samplingQueries;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterSamplingQueries) {
             listener.enterSamplingQueries(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitSamplingQueries) {
             listener.exitSamplingQueries(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitSamplingQueries) {
            return visitor.visitSamplingQueries(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class SomeByClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public clusteredByClause(): ClusteredByClauseContext | null {
        return this.getRuleContext(0, ClusteredByClauseContext);
    }
    public clusterByClause(): ClusterByClauseContext | null {
        return this.getRuleContext(0, ClusterByClauseContext);
    }
    public distributeByClause(): DistributeByClauseContext | null {
        return this.getRuleContext(0, DistributeByClauseContext);
    }
    public groupByClause(): GroupByClauseContext | null {
        return this.getRuleContext(0, GroupByClauseContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_someByClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterSomeByClause) {
             listener.enterSomeByClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitSomeByClause) {
             listener.exitSomeByClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitSomeByClause) {
            return visitor.visitSomeByClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ClusterByClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_CLUSTER(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_CLUSTER, 0)!;
    }
    public KW_BY(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_BY, 0)!;
    }
    public groupItemDefinition(): GroupItemDefinitionContext[];
    public groupItemDefinition(i: number): GroupItemDefinitionContext | null;
    public groupItemDefinition(i?: number): GroupItemDefinitionContext[] | GroupItemDefinitionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(GroupItemDefinitionContext);
        }

        return this.getRuleContext(i, GroupItemDefinitionContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_clusterByClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterClusterByClause) {
             listener.enterClusterByClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitClusterByClause) {
             listener.exitClusterByClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitClusterByClause) {
            return visitor.visitClusterByClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ClusteredByClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_CLUSTERED(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_CLUSTERED, 0)!;
    }
    public KW_BY(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_BY, 0)!;
    }
    public groupItemDefinition(): GroupItemDefinitionContext[];
    public groupItemDefinition(i: number): GroupItemDefinitionContext | null;
    public groupItemDefinition(i?: number): GroupItemDefinitionContext[] | GroupItemDefinitionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(GroupItemDefinitionContext);
        }

        return this.getRuleContext(i, GroupItemDefinitionContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_clusteredByClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterClusteredByClause) {
             listener.enterClusteredByClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitClusteredByClause) {
             listener.exitClusteredByClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitClusteredByClause) {
            return visitor.visitClusteredByClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class DistributeByClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_DISTRIBUTE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_DISTRIBUTE, 0)!;
    }
    public KW_BY(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_BY, 0)!;
    }
    public groupItemDefinition(): GroupItemDefinitionContext[];
    public groupItemDefinition(i: number): GroupItemDefinitionContext | null;
    public groupItemDefinition(i?: number): GroupItemDefinitionContext[] | GroupItemDefinitionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(GroupItemDefinitionContext);
        }

        return this.getRuleContext(i, GroupItemDefinitionContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_distributeByClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterDistributeByClause) {
             listener.enterDistributeByClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitDistributeByClause) {
             listener.exitDistributeByClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitDistributeByClause) {
            return visitor.visitDistributeByClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class GroupByClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_GROUP(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_GROUP, 0)!;
    }
    public KW_BY(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_BY, 0)!;
    }
    public groupItemDefinition(): GroupItemDefinitionContext[];
    public groupItemDefinition(i: number): GroupItemDefinitionContext | null;
    public groupItemDefinition(i?: number): GroupItemDefinitionContext[] | GroupItemDefinitionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(GroupItemDefinitionContext);
        }

        return this.getRuleContext(i, GroupItemDefinitionContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public KW_WITH(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_WITH, 0);
    }
    public groupingSetsNotionName(): GroupingSetsNotionNameContext | null {
        return this.getRuleContext(0, GroupingSetsNotionNameContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_groupByClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterGroupByClause) {
             listener.enterGroupByClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitGroupByClause) {
             listener.exitGroupByClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitGroupByClause) {
            return visitor.visitGroupByClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class GroupItemDefinitionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public expression(): ExpressionContext[];
    public expression(i: number): ExpressionContext | null;
    public expression(i?: number): ExpressionContext[] | ExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ExpressionContext);
        }

        return this.getRuleContext(i, ExpressionContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public groupWindowFunction(): GroupWindowFunctionContext | null {
        return this.getRuleContext(0, GroupWindowFunctionContext);
    }
    public LR_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0);
    }
    public RR_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0);
    }
    public groupingSetsNotionName(): GroupingSetsNotionNameContext | null {
        return this.getRuleContext(0, GroupingSetsNotionNameContext);
    }
    public groupingSets(): GroupingSetsContext | null {
        return this.getRuleContext(0, GroupingSetsContext);
    }
    public groupItemDefinition(): GroupItemDefinitionContext[];
    public groupItemDefinition(i: number): GroupItemDefinitionContext | null;
    public groupItemDefinition(i?: number): GroupItemDefinitionContext[] | GroupItemDefinitionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(GroupItemDefinitionContext);
        }

        return this.getRuleContext(i, GroupItemDefinitionContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_groupItemDefinition;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterGroupItemDefinition) {
             listener.enterGroupItemDefinition(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitGroupItemDefinition) {
             listener.exitGroupItemDefinition(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitGroupItemDefinition) {
            return visitor.visitGroupItemDefinition(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class GroupingSetsContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_GROUPING(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_GROUPING, 0)!;
    }
    public KW_SETS(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_SETS, 0)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_groupingSets;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterGroupingSets) {
             listener.enterGroupingSets(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitGroupingSets) {
             listener.exitGroupingSets(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitGroupingSets) {
            return visitor.visitGroupingSets(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class GroupingSetsNotionNameContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_CUBE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_CUBE, 0);
    }
    public KW_ROLLUP(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ROLLUP, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_groupingSetsNotionName;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterGroupingSetsNotionName) {
             listener.enterGroupingSetsNotionName(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitGroupingSetsNotionName) {
             listener.exitGroupingSetsNotionName(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitGroupingSetsNotionName) {
            return visitor.visitGroupingSetsNotionName(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class GroupWindowFunctionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public groupWindowFunctionName(): GroupWindowFunctionNameContext {
        return this.getRuleContext(0, GroupWindowFunctionNameContext)!;
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public timeAttrColumn(): TimeAttrColumnContext {
        return this.getRuleContext(0, TimeAttrColumnContext)!;
    }
    public COMMA(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.COMMA, 0)!;
    }
    public timeIntervalExpression(): TimeIntervalExpressionContext {
        return this.getRuleContext(0, TimeIntervalExpressionContext)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_groupWindowFunction;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterGroupWindowFunction) {
             listener.enterGroupWindowFunction(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitGroupWindowFunction) {
             listener.exitGroupWindowFunction(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitGroupWindowFunction) {
            return visitor.visitGroupWindowFunction(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class GroupWindowFunctionNameContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_TUMBLE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TUMBLE, 0);
    }
    public KW_HOP(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_HOP, 0);
    }
    public KW_SESSION(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SESSION, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_groupWindowFunctionName;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterGroupWindowFunctionName) {
             listener.enterGroupWindowFunctionName(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitGroupWindowFunctionName) {
             listener.exitGroupWindowFunctionName(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitGroupWindowFunctionName) {
            return visitor.visitGroupWindowFunctionName(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class TimeAttrColumnContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public uid(): UidContext {
        return this.getRuleContext(0, UidContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_timeAttrColumn;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterTimeAttrColumn) {
             listener.enterTimeAttrColumn(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitTimeAttrColumn) {
             listener.exitTimeAttrColumn(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitTimeAttrColumn) {
            return visitor.visitTimeAttrColumn(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class HavingClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_HAVING(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_HAVING, 0)!;
    }
    public booleanExpression(): BooleanExpressionContext {
        return this.getRuleContext(0, BooleanExpressionContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_havingClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterHavingClause) {
             listener.enterHavingClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitHavingClause) {
             listener.exitHavingClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitHavingClause) {
            return visitor.visitHavingClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class WindowClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_WINDOW(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_WINDOW, 0)!;
    }
    public namedWindow(): NamedWindowContext[];
    public namedWindow(i: number): NamedWindowContext | null;
    public namedWindow(i?: number): NamedWindowContext[] | NamedWindowContext | null {
        if (i === undefined) {
            return this.getRuleContexts(NamedWindowContext);
        }

        return this.getRuleContext(i, NamedWindowContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_windowClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterWindowClause) {
             listener.enterWindowClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitWindowClause) {
             listener.exitWindowClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitWindowClause) {
            return visitor.visitWindowClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class NamedWindowContext extends antlr.ParserRuleContext {
    public _name?: ErrorCapturingIdentifierContext;
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_AS(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_AS, 0)!;
    }
    public windowSpec(): WindowSpecContext {
        return this.getRuleContext(0, WindowSpecContext)!;
    }
    public errorCapturingIdentifier(): ErrorCapturingIdentifierContext {
        return this.getRuleContext(0, ErrorCapturingIdentifierContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_namedWindow;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterNamedWindow) {
             listener.enterNamedWindow(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitNamedWindow) {
             listener.exitNamedWindow(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitNamedWindow) {
            return visitor.visitNamedWindow(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class WindowSpecContext extends antlr.ParserRuleContext {
    public _name?: ErrorCapturingIdentifierContext;
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public partitionByClause(): PartitionByClauseContext | null {
        return this.getRuleContext(0, PartitionByClauseContext);
    }
    public sortByCaluse(): SortByCaluseContext | null {
        return this.getRuleContext(0, SortByCaluseContext);
    }
    public orderByCaluse(): OrderByCaluseContext | null {
        return this.getRuleContext(0, OrderByCaluseContext);
    }
    public windowFrame(): WindowFrameContext | null {
        return this.getRuleContext(0, WindowFrameContext);
    }
    public errorCapturingIdentifier(): ErrorCapturingIdentifierContext | null {
        return this.getRuleContext(0, ErrorCapturingIdentifierContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_windowSpec;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterWindowSpec) {
             listener.enterWindowSpec(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitWindowSpec) {
             listener.exitWindowSpec(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitWindowSpec) {
            return visitor.visitWindowSpec(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class MatchRecognizeClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_MATCH_RECOGNIZE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_MATCH_RECOGNIZE, 0)!;
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public patternVariablesDefinition(): PatternVariablesDefinitionContext {
        return this.getRuleContext(0, PatternVariablesDefinitionContext)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public partitionByClause(): PartitionByClauseContext | null {
        return this.getRuleContext(0, PartitionByClauseContext);
    }
    public sortByCaluse(): SortByCaluseContext | null {
        return this.getRuleContext(0, SortByCaluseContext);
    }
    public orderByCaluse(): OrderByCaluseContext | null {
        return this.getRuleContext(0, OrderByCaluseContext);
    }
    public measuresClause(): MeasuresClauseContext | null {
        return this.getRuleContext(0, MeasuresClauseContext);
    }
    public outputMode(): OutputModeContext | null {
        return this.getRuleContext(0, OutputModeContext);
    }
    public afterMatchStrategy(): AfterMatchStrategyContext | null {
        return this.getRuleContext(0, AfterMatchStrategyContext);
    }
    public patternDefinition(): PatternDefinitionContext | null {
        return this.getRuleContext(0, PatternDefinitionContext);
    }
    public identifier(): IdentifierContext | null {
        return this.getRuleContext(0, IdentifierContext);
    }
    public KW_AS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_AS, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_matchRecognizeClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterMatchRecognizeClause) {
             listener.enterMatchRecognizeClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitMatchRecognizeClause) {
             listener.exitMatchRecognizeClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitMatchRecognizeClause) {
            return visitor.visitMatchRecognizeClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class OrderByCaluseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_ORDER(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_ORDER, 0)!;
    }
    public KW_BY(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_BY, 0)!;
    }
    public orderItemDefinition(): OrderItemDefinitionContext[];
    public orderItemDefinition(i: number): OrderItemDefinitionContext | null;
    public orderItemDefinition(i?: number): OrderItemDefinitionContext[] | OrderItemDefinitionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(OrderItemDefinitionContext);
        }

        return this.getRuleContext(i, OrderItemDefinitionContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_orderByCaluse;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterOrderByCaluse) {
             listener.enterOrderByCaluse(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitOrderByCaluse) {
             listener.exitOrderByCaluse(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitOrderByCaluse) {
            return visitor.visitOrderByCaluse(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class SortByCaluseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_SORT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_SORT, 0)!;
    }
    public KW_BY(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_BY, 0)!;
    }
    public orderItemDefinition(): OrderItemDefinitionContext[];
    public orderItemDefinition(i: number): OrderItemDefinitionContext | null;
    public orderItemDefinition(i?: number): OrderItemDefinitionContext[] | OrderItemDefinitionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(OrderItemDefinitionContext);
        }

        return this.getRuleContext(i, OrderItemDefinitionContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_sortByCaluse;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterSortByCaluse) {
             listener.enterSortByCaluse(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitSortByCaluse) {
             listener.exitSortByCaluse(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitSortByCaluse) {
            return visitor.visitSortByCaluse(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class OrderItemDefinitionContext extends antlr.ParserRuleContext {
    public _ordering?: Token | null;
    public _nullOrder?: Token | null;
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public expression(): ExpressionContext {
        return this.getRuleContext(0, ExpressionContext)!;
    }
    public KW_NULLS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NULLS, 0);
    }
    public KW_ASC(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ASC, 0);
    }
    public KW_DESC(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DESC, 0);
    }
    public KW_LAST(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LAST, 0);
    }
    public KW_FIRST(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FIRST, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_orderItemDefinition;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterOrderItemDefinition) {
             listener.enterOrderItemDefinition(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitOrderItemDefinition) {
             listener.exitOrderItemDefinition(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitOrderItemDefinition) {
            return visitor.visitOrderItemDefinition(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class LimitClauseContext extends antlr.ParserRuleContext {
    public _limit?: ExpressionContext;
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_LIMIT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_LIMIT, 0)!;
    }
    public KW_ALL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ALL, 0);
    }
    public expression(): ExpressionContext | null {
        return this.getRuleContext(0, ExpressionContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_limitClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterLimitClause) {
             listener.enterLimitClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitLimitClause) {
             listener.exitLimitClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitLimitClause) {
            return visitor.visitLimitClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class OffsetClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_OFFSET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_OFFSET, 0)!;
    }
    public DIG_LITERAL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.DIG_LITERAL, 0);
    }
    public expression(): ExpressionContext | null {
        return this.getRuleContext(0, ExpressionContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_offsetClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterOffsetClause) {
             listener.enterOffsetClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitOffsetClause) {
             listener.exitOffsetClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitOffsetClause) {
            return visitor.visitOffsetClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class PartitionByClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_PARTITION(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_PARTITION, 0)!;
    }
    public KW_BY(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_BY, 0)!;
    }
    public expression(): ExpressionContext[];
    public expression(i: number): ExpressionContext | null;
    public expression(i?: number): ExpressionContext[] | ExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ExpressionContext);
        }

        return this.getRuleContext(i, ExpressionContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_partitionByClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterPartitionByClause) {
             listener.enterPartitionByClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitPartitionByClause) {
             listener.exitPartitionByClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitPartitionByClause) {
            return visitor.visitPartitionByClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class QuantifiersContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public ASTERISK_SIGN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.ASTERISK_SIGN, 0);
    }
    public ADD_SIGN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.ADD_SIGN, 0);
    }
    public QUESTION_MARK_SIGN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.QUESTION_MARK_SIGN, 0);
    }
    public LB_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.LB_BRACKET, 0);
    }
    public DIG_LITERAL(): antlr.TerminalNode[];
    public DIG_LITERAL(i: number): antlr.TerminalNode | null;
    public DIG_LITERAL(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.DIG_LITERAL);
    	} else {
    		return this.getToken(SparkSQLParser.DIG_LITERAL, i);
    	}
    }
    public COMMA(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.COMMA, 0);
    }
    public RB_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.RB_BRACKET, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_quantifiers;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterQuantifiers) {
             listener.enterQuantifiers(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitQuantifiers) {
             listener.exitQuantifiers(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitQuantifiers) {
            return visitor.visitQuantifiers(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class MeasuresClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_MEASURES(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_MEASURES, 0)!;
    }
    public projectItemDefinition(): ProjectItemDefinitionContext[];
    public projectItemDefinition(i: number): ProjectItemDefinitionContext | null;
    public projectItemDefinition(i?: number): ProjectItemDefinitionContext[] | ProjectItemDefinitionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ProjectItemDefinitionContext);
        }

        return this.getRuleContext(i, ProjectItemDefinitionContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_measuresClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterMeasuresClause) {
             listener.enterMeasuresClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitMeasuresClause) {
             listener.exitMeasuresClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitMeasuresClause) {
            return visitor.visitMeasuresClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class PatternDefinitionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_PATTERN(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_PATTERN, 0)!;
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public patternVariable(): PatternVariableContext[];
    public patternVariable(i: number): PatternVariableContext | null;
    public patternVariable(i?: number): PatternVariableContext[] | PatternVariableContext | null {
        if (i === undefined) {
            return this.getRuleContexts(PatternVariableContext);
        }

        return this.getRuleContext(i, PatternVariableContext);
    }
    public withinClause(): WithinClauseContext | null {
        return this.getRuleContext(0, WithinClauseContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_patternDefinition;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterPatternDefinition) {
             listener.enterPatternDefinition(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitPatternDefinition) {
             listener.exitPatternDefinition(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitPatternDefinition) {
            return visitor.visitPatternDefinition(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class PatternVariableContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public unquotedIdentifier(): UnquotedIdentifierContext {
        return this.getRuleContext(0, UnquotedIdentifierContext)!;
    }
    public quantifiers(): QuantifiersContext | null {
        return this.getRuleContext(0, QuantifiersContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_patternVariable;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterPatternVariable) {
             listener.enterPatternVariable(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitPatternVariable) {
             listener.exitPatternVariable(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitPatternVariable) {
            return visitor.visitPatternVariable(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class OutputModeContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_ALL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ALL, 0);
    }
    public KW_ROWS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ROWS, 0);
    }
    public KW_PER(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_PER, 0)!;
    }
    public KW_MATCH(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_MATCH, 0)!;
    }
    public KW_ONE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ONE, 0);
    }
    public KW_ROW(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ROW, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_outputMode;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterOutputMode) {
             listener.enterOutputMode(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitOutputMode) {
             listener.exitOutputMode(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitOutputMode) {
            return visitor.visitOutputMode(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class AfterMatchStrategyContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_AFTER(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_AFTER, 0)!;
    }
    public KW_MATCH(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_MATCH, 0)!;
    }
    public KW_SKIP(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_SKIP, 0)!;
    }
    public KW_PAST(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PAST, 0);
    }
    public KW_LAST(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LAST, 0);
    }
    public KW_ROW(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ROW, 0);
    }
    public KW_TO(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TO, 0);
    }
    public KW_NEXT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NEXT, 0);
    }
    public unquotedIdentifier(): UnquotedIdentifierContext | null {
        return this.getRuleContext(0, UnquotedIdentifierContext);
    }
    public KW_FIRST(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FIRST, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_afterMatchStrategy;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterAfterMatchStrategy) {
             listener.enterAfterMatchStrategy(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitAfterMatchStrategy) {
             listener.exitAfterMatchStrategy(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitAfterMatchStrategy) {
            return visitor.visitAfterMatchStrategy(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class PatternVariablesDefinitionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_DEFINE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_DEFINE, 0)!;
    }
    public projectItemDefinition(): ProjectItemDefinitionContext[];
    public projectItemDefinition(i: number): ProjectItemDefinitionContext | null;
    public projectItemDefinition(i?: number): ProjectItemDefinitionContext[] | ProjectItemDefinitionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ProjectItemDefinitionContext);
        }

        return this.getRuleContext(i, ProjectItemDefinitionContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_patternVariablesDefinition;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterPatternVariablesDefinition) {
             listener.enterPatternVariablesDefinition(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitPatternVariablesDefinition) {
             listener.exitPatternVariablesDefinition(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitPatternVariablesDefinition) {
            return visitor.visitPatternVariablesDefinition(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class WindowFrameContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_RANGE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_RANGE, 0);
    }
    public KW_BETWEEN(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_BETWEEN, 0)!;
    }
    public timeIntervalExpression(): TimeIntervalExpressionContext | null {
        return this.getRuleContext(0, TimeIntervalExpressionContext);
    }
    public frameBound(): FrameBoundContext {
        return this.getRuleContext(0, FrameBoundContext)!;
    }
    public KW_ROWS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ROWS, 0);
    }
    public DIG_LITERAL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.DIG_LITERAL, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_windowFrame;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterWindowFrame) {
             listener.enterWindowFrame(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitWindowFrame) {
             listener.exitWindowFrame(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitWindowFrame) {
            return visitor.visitWindowFrame(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class FrameBoundContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_PRECEDING(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_PRECEDING, 0)!;
    }
    public KW_AND(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_AND, 0)!;
    }
    public KW_CURRENT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_CURRENT, 0)!;
    }
    public KW_ROW(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_ROW, 0)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_frameBound;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterFrameBound) {
             listener.enterFrameBound(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitFrameBound) {
             listener.exitFrameBound(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitFrameBound) {
            return visitor.visitFrameBound(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class WithinClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_WITHIN(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_WITHIN, 0)!;
    }
    public timeIntervalExpression(): TimeIntervalExpressionContext {
        return this.getRuleContext(0, TimeIntervalExpressionContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_withinClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterWithinClause) {
             listener.enterWithinClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitWithinClause) {
             listener.exitWithinClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitWithinClause) {
            return visitor.visitWithinClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class SelfDefinitionClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_PERIOD(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_PERIOD, 0)!;
    }
    public KW_FOR(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_FOR, 0)!;
    }
    public KW_SYSTEM_TIME(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_SYSTEM_TIME, 0)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_selfDefinitionClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterSelfDefinitionClause) {
             listener.enterSelfDefinitionClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitSelfDefinitionClause) {
             listener.exitSelfDefinitionClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitSelfDefinitionClause) {
            return visitor.visitSelfDefinitionClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class PartitionDefinitionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_PARTITIONED(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_PARTITIONED, 0)!;
    }
    public KW_BY(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_BY, 0)!;
    }
    public transformList(): TransformListContext {
        return this.getRuleContext(0, TransformListContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_partitionDefinition;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterPartitionDefinition) {
             listener.enterPartitionDefinition(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitPartitionDefinition) {
             listener.exitPartitionDefinition(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitPartitionDefinition) {
            return visitor.visitPartitionDefinition(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class TransformListContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public transform(): TransformContext[];
    public transform(i: number): TransformContext | null;
    public transform(i?: number): TransformContext[] | TransformContext | null {
        if (i === undefined) {
            return this.getRuleContexts(TransformContext);
        }

        return this.getRuleContext(i, TransformContext);
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public dataTypeExpression(): DataTypeExpressionContext[];
    public dataTypeExpression(i: number): DataTypeExpressionContext | null;
    public dataTypeExpression(i?: number): DataTypeExpressionContext[] | DataTypeExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(DataTypeExpressionContext);
        }

        return this.getRuleContext(i, DataTypeExpressionContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_transformList;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterTransformList) {
             listener.enterTransformList(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitTransformList) {
             listener.exitTransformList(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitTransformList) {
            return visitor.visitTransformList(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class TransformContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_transform;
    }
    public override copyFrom(ctx: TransformContext): void {
        super.copyFrom(ctx);
    }
}
export class IdentityTransformContext extends TransformContext {
    public constructor(ctx: TransformContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public qualifiedName(): QualifiedNameContext {
        return this.getRuleContext(0, QualifiedNameContext)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterIdentityTransform) {
             listener.enterIdentityTransform(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitIdentityTransform) {
             listener.exitIdentityTransform(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitIdentityTransform) {
            return visitor.visitIdentityTransform(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class ApplyTransformContext extends TransformContext {
    public _transformName?: IdentifierContext;
    public constructor(ctx: TransformContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public transformArgument(): TransformArgumentContext[];
    public transformArgument(i: number): TransformArgumentContext | null;
    public transformArgument(i?: number): TransformArgumentContext[] | TransformArgumentContext | null {
        if (i === undefined) {
            return this.getRuleContexts(TransformArgumentContext);
        }

        return this.getRuleContext(i, TransformArgumentContext);
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public identifier(): IdentifierContext {
        return this.getRuleContext(0, IdentifierContext)!;
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterApplyTransform) {
             listener.enterApplyTransform(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitApplyTransform) {
             listener.exitApplyTransform(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitApplyTransform) {
            return visitor.visitApplyTransform(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class TransformArgumentContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public qualifiedName(): QualifiedNameContext | null {
        return this.getRuleContext(0, QualifiedNameContext);
    }
    public constant(): ConstantContext | null {
        return this.getRuleContext(0, ConstantContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_transformArgument;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterTransformArgument) {
             listener.enterTransformArgument(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitTransformArgument) {
             listener.exitTransformArgument(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitTransformArgument) {
            return visitor.visitTransformArgument(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class LikeDefinitionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_LIKE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_LIKE, 0)!;
    }
    public tablePath(): TablePathContext {
        return this.getRuleContext(0, TablePathContext)!;
    }
    public LR_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0);
    }
    public RR_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0);
    }
    public likeOption(): LikeOptionContext[];
    public likeOption(i: number): LikeOptionContext | null;
    public likeOption(i?: number): LikeOptionContext[] | LikeOptionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(LikeOptionContext);
        }

        return this.getRuleContext(i, LikeOptionContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_likeDefinition;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterLikeDefinition) {
             listener.enterLikeDefinition(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitLikeDefinition) {
             listener.exitLikeDefinition(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitLikeDefinition) {
            return visitor.visitLikeDefinition(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class DistributionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_DISTRIBUTED(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_DISTRIBUTED, 0)!;
    }
    public KW_BY(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_BY, 0);
    }
    public LR_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0);
    }
    public identifier(): IdentifierContext | null {
        return this.getRuleContext(0, IdentifierContext);
    }
    public RR_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0);
    }
    public intoBuckets(): IntoBucketsContext | null {
        return this.getRuleContext(0, IntoBucketsContext);
    }
    public KW_HASH(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_HASH, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_distribution;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterDistribution) {
             listener.enterDistribution(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitDistribution) {
             listener.exitDistribution(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitDistribution) {
            return visitor.visitDistribution(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class UsingContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_USING(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_USING, 0)!;
    }
    public ID_LITERAL(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.ID_LITERAL, 0)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_using;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterUsing) {
             listener.enterUsing(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitUsing) {
             listener.exitUsing(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitUsing) {
            return visitor.visitUsing(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class LikeOptionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_INCLUDING(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_INCLUDING, 0);
    }
    public KW_EXCLUDING(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_EXCLUDING, 0);
    }
    public KW_ALL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ALL, 0);
    }
    public KW_CONSTRAINTS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_CONSTRAINTS, 0);
    }
    public KW_PARTITIONS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PARTITIONS, 0);
    }
    public KW_OVERWRITING(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_OVERWRITING, 0);
    }
    public KW_GENERATED(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_GENERATED, 0);
    }
    public KW_OPTIONS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_OPTIONS, 0);
    }
    public KW_WATERMARKS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_WATERMARKS, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_likeOption;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterLikeOption) {
             listener.enterLikeOption(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitLikeOption) {
             listener.exitLikeOption(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitLikeOption) {
            return visitor.visitLikeOption(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ColumnOptionDefinitionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public physicalColumnDefinition(): PhysicalColumnDefinitionContext | null {
        return this.getRuleContext(0, PhysicalColumnDefinitionContext);
    }
    public metadataColumnDefinition(): MetadataColumnDefinitionContext | null {
        return this.getRuleContext(0, MetadataColumnDefinitionContext);
    }
    public computedColumnDefinition(): ComputedColumnDefinitionContext | null {
        return this.getRuleContext(0, ComputedColumnDefinitionContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_columnOptionDefinition;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterColumnOptionDefinition) {
             listener.enterColumnOptionDefinition(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitColumnOptionDefinition) {
             listener.exitColumnOptionDefinition(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitColumnOptionDefinition) {
            return visitor.visitColumnOptionDefinition(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class PhysicalColumnDefinitionListContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public physicalColumnDefinition(): PhysicalColumnDefinitionContext[];
    public physicalColumnDefinition(i: number): PhysicalColumnDefinitionContext | null;
    public physicalColumnDefinition(i?: number): PhysicalColumnDefinitionContext[] | PhysicalColumnDefinitionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(PhysicalColumnDefinitionContext);
        }

        return this.getRuleContext(i, PhysicalColumnDefinitionContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_physicalColumnDefinitionList;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterPhysicalColumnDefinitionList) {
             listener.enterPhysicalColumnDefinitionList(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitPhysicalColumnDefinitionList) {
             listener.exitPhysicalColumnDefinitionList(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitPhysicalColumnDefinitionList) {
            return visitor.visitPhysicalColumnDefinitionList(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class PhysicalColumnDefinitionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public columnName(): ColumnNameContext {
        return this.getRuleContext(0, ColumnNameContext)!;
    }
    public columnType(): ColumnTypeContext {
        return this.getRuleContext(0, ColumnTypeContext)!;
    }
    public columnConstraint(): ColumnConstraintContext | null {
        return this.getRuleContext(0, ColumnConstraintContext);
    }
    public commentSpec(): CommentSpecContext | null {
        return this.getRuleContext(0, CommentSpecContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_physicalColumnDefinition;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterPhysicalColumnDefinition) {
             listener.enterPhysicalColumnDefinition(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitPhysicalColumnDefinition) {
             listener.exitPhysicalColumnDefinition(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitPhysicalColumnDefinition) {
            return visitor.visitPhysicalColumnDefinition(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ComputedColumnExpressionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public expression(): ExpressionContext {
        return this.getRuleContext(0, ExpressionContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_computedColumnExpression;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterComputedColumnExpression) {
             listener.enterComputedColumnExpression(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitComputedColumnExpression) {
             listener.exitComputedColumnExpression(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitComputedColumnExpression) {
            return visitor.visitComputedColumnExpression(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class WatermarkDefinitionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_WATERMARK(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_WATERMARK, 0)!;
    }
    public KW_FOR(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_FOR, 0)!;
    }
    public expression(): ExpressionContext[];
    public expression(i: number): ExpressionContext | null;
    public expression(i?: number): ExpressionContext[] | ExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ExpressionContext);
        }

        return this.getRuleContext(i, ExpressionContext);
    }
    public KW_AS(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_AS, 0)!;
    }
    public uid(): UidContext[];
    public uid(i: number): UidContext | null;
    public uid(i?: number): UidContext[] | UidContext | null {
        if (i === undefined) {
            return this.getRuleContexts(UidContext);
        }

        return this.getRuleContext(i, UidContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_watermarkDefinition;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterWatermarkDefinition) {
             listener.enterWatermarkDefinition(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitWatermarkDefinition) {
             listener.exitWatermarkDefinition(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitWatermarkDefinition) {
            return visitor.visitWatermarkDefinition(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class TableConstraintContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_PRIMARY(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_PRIMARY, 0)!;
    }
    public KW_KEY(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_KEY, 0)!;
    }
    public columnNameList(): ColumnNameListContext {
        return this.getRuleContext(0, ColumnNameListContext)!;
    }
    public KW_NOT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_NOT, 0)!;
    }
    public KW_ENFORCED(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_ENFORCED, 0)!;
    }
    public KW_CONSTRAINT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_CONSTRAINT, 0);
    }
    public constraintName(): ConstraintNameContext | null {
        return this.getRuleContext(0, ConstraintNameContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_tableConstraint;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterTableConstraint) {
             listener.enterTableConstraint(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitTableConstraint) {
             listener.exitTableConstraint(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitTableConstraint) {
            return visitor.visitTableConstraint(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ConstraintNameContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public identifier(): IdentifierContext {
        return this.getRuleContext(0, IdentifierContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_constraintName;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterConstraintName) {
             listener.enterConstraintName(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitConstraintName) {
             listener.exitConstraintName(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitConstraintName) {
            return visitor.visitConstraintName(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ValuesDefinitionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_VALUES(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_VALUES, 0)!;
    }
    public valuesRowDefinition(): ValuesRowDefinitionContext[];
    public valuesRowDefinition(i: number): ValuesRowDefinitionContext | null;
    public valuesRowDefinition(i?: number): ValuesRowDefinitionContext[] | ValuesRowDefinitionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ValuesRowDefinitionContext);
        }

        return this.getRuleContext(i, ValuesRowDefinitionContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_valuesDefinition;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterValuesDefinition) {
             listener.enterValuesDefinition(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitValuesDefinition) {
             listener.exitValuesDefinition(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitValuesDefinition) {
            return visitor.visitValuesDefinition(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ValuesRowDefinitionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public constant(): ConstantContext[];
    public constant(i: number): ConstantContext | null;
    public constant(i?: number): ConstantContext[] | ConstantContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ConstantContext);
        }

        return this.getRuleContext(i, ConstantContext);
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_valuesRowDefinition;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterValuesRowDefinition) {
             listener.enterValuesRowDefinition(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitValuesRowDefinition) {
             listener.exitValuesRowDefinition(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitValuesRowDefinition) {
            return visitor.visitValuesRowDefinition(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class LengthOneDimensionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public decimalLiteral(): DecimalLiteralContext {
        return this.getRuleContext(0, DecimalLiteralContext)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_lengthOneDimension;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterLengthOneDimension) {
             listener.enterLengthOneDimension(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitLengthOneDimension) {
             listener.exitLengthOneDimension(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitLengthOneDimension) {
            return visitor.visitLengthOneDimension(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class LengthTwoOptionalDimensionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public decimalLiteral(): DecimalLiteralContext[];
    public decimalLiteral(i: number): DecimalLiteralContext | null;
    public decimalLiteral(i?: number): DecimalLiteralContext[] | DecimalLiteralContext | null {
        if (i === undefined) {
            return this.getRuleContexts(DecimalLiteralContext);
        }

        return this.getRuleContext(i, DecimalLiteralContext);
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public COMMA(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.COMMA, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_lengthTwoOptionalDimension;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterLengthTwoOptionalDimension) {
             listener.enterLengthTwoOptionalDimension(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitLengthTwoOptionalDimension) {
             listener.exitLengthTwoOptionalDimension(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitLengthTwoOptionalDimension) {
            return visitor.visitLengthTwoOptionalDimension(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class LengthTwoStringDimensionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public stringLiteral(): StringLiteralContext[];
    public stringLiteral(i: number): StringLiteralContext | null;
    public stringLiteral(i?: number): StringLiteralContext[] | StringLiteralContext | null {
        if (i === undefined) {
            return this.getRuleContexts(StringLiteralContext);
        }

        return this.getRuleContext(i, StringLiteralContext);
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public COMMA(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.COMMA, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_lengthTwoStringDimension;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterLengthTwoStringDimension) {
             listener.enterLengthTwoStringDimension(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitLengthTwoStringDimension) {
             listener.exitLengthTwoStringDimension(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitLengthTwoStringDimension) {
            return visitor.visitLengthTwoStringDimension(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class LengthOneTypeDimensionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_lengthOneTypeDimension;
    }
    public override copyFrom(ctx: LengthOneTypeDimensionContext): void {
        super.copyFrom(ctx);
    }
}
export class LengthSymbolsTypeDimensionContext extends LengthOneTypeDimensionContext {
    public constructor(ctx: LengthOneTypeDimensionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public LESS_SYMBOL(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LESS_SYMBOL, 0)!;
    }
    public columnType(): ColumnTypeContext[];
    public columnType(i: number): ColumnTypeContext | null;
    public columnType(i?: number): ColumnTypeContext[] | ColumnTypeContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ColumnTypeContext);
        }

        return this.getRuleContext(i, ColumnTypeContext);
    }
    public GREATER_SYMBOL(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.GREATER_SYMBOL, 0)!;
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterLengthSymbolsTypeDimension) {
             listener.enterLengthSymbolsTypeDimension(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitLengthSymbolsTypeDimension) {
             listener.exitLengthSymbolsTypeDimension(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitLengthSymbolsTypeDimension) {
            return visitor.visitLengthSymbolsTypeDimension(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class MapTypeDimensionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public LESS_SYMBOL(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LESS_SYMBOL, 0)!;
    }
    public columnType(): ColumnTypeContext[];
    public columnType(i: number): ColumnTypeContext | null;
    public columnType(i?: number): ColumnTypeContext[] | ColumnTypeContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ColumnTypeContext);
        }

        return this.getRuleContext(i, ColumnTypeContext);
    }
    public GREATER_SYMBOL(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.GREATER_SYMBOL, 0)!;
    }
    public COMMA(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.COMMA, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_mapTypeDimension;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterMapTypeDimension) {
             listener.enterMapTypeDimension(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitMapTypeDimension) {
             listener.exitMapTypeDimension(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitMapTypeDimension) {
            return visitor.visitMapTypeDimension(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class RowTypeDimensionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_rowTypeDimension;
    }
    public override copyFrom(ctx: RowTypeDimensionContext): void {
        super.copyFrom(ctx);
    }
}
export class RowSymbolsTypeDimensionContext extends RowTypeDimensionContext {
    public constructor(ctx: RowTypeDimensionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public LESS_SYMBOL(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LESS_SYMBOL, 0)!;
    }
    public columnName(): ColumnNameContext[];
    public columnName(i: number): ColumnNameContext | null;
    public columnName(i?: number): ColumnNameContext[] | ColumnNameContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ColumnNameContext);
        }

        return this.getRuleContext(i, ColumnNameContext);
    }
    public columnType(): ColumnTypeContext[];
    public columnType(i: number): ColumnTypeContext | null;
    public columnType(i?: number): ColumnTypeContext[] | ColumnTypeContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ColumnTypeContext);
        }

        return this.getRuleContext(i, ColumnTypeContext);
    }
    public GREATER_SYMBOL(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.GREATER_SYMBOL, 0)!;
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterRowSymbolsTypeDimension) {
             listener.enterRowSymbolsTypeDimension(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitRowSymbolsTypeDimension) {
             listener.exitRowSymbolsTypeDimension(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitRowSymbolsTypeDimension) {
            return visitor.visitRowSymbolsTypeDimension(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class StructTypeDimensionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_structTypeDimension;
    }
    public override copyFrom(ctx: StructTypeDimensionContext): void {
        super.copyFrom(ctx);
    }
}
export class StructSymbolsTypeDimensionContext extends StructTypeDimensionContext {
    public constructor(ctx: StructTypeDimensionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public LESS_SYMBOL(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LESS_SYMBOL, 0)!;
    }
    public columnName(): ColumnNameContext[];
    public columnName(i: number): ColumnNameContext | null;
    public columnName(i?: number): ColumnNameContext[] | ColumnNameContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ColumnNameContext);
        }

        return this.getRuleContext(i, ColumnNameContext);
    }
    public COLON_SYMB(): antlr.TerminalNode[];
    public COLON_SYMB(i: number): antlr.TerminalNode | null;
    public COLON_SYMB(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COLON_SYMB);
    	} else {
    		return this.getToken(SparkSQLParser.COLON_SYMB, i);
    	}
    }
    public columnType(): ColumnTypeContext[];
    public columnType(i: number): ColumnTypeContext | null;
    public columnType(i?: number): ColumnTypeContext[] | ColumnTypeContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ColumnTypeContext);
        }

        return this.getRuleContext(i, ColumnTypeContext);
    }
    public GREATER_SYMBOL(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.GREATER_SYMBOL, 0)!;
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterStructSymbolsTypeDimension) {
             listener.enterStructSymbolsTypeDimension(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitStructSymbolsTypeDimension) {
             listener.exitStructSymbolsTypeDimension(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitStructSymbolsTypeDimension) {
            return visitor.visitStructSymbolsTypeDimension(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ColumnConstraintContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_PRIMARY(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PRIMARY, 0);
    }
    public KW_KEY(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_KEY, 0);
    }
    public KW_CONSTRAINT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_CONSTRAINT, 0);
    }
    public constraintName(): ConstraintNameContext | null {
        return this.getRuleContext(0, ConstraintNameContext);
    }
    public KW_NOT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NOT, 0);
    }
    public KW_ENFORCED(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ENFORCED, 0);
    }
    public KW_NULL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NULL, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_columnConstraint;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterColumnConstraint) {
             listener.enterColumnConstraint(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitColumnConstraint) {
             listener.exitColumnConstraint(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitColumnConstraint) {
            return visitor.visitColumnConstraint(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class CommentSpecContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_COMMENT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_COMMENT, 0)!;
    }
    public propertyName(): PropertyNameContext {
        return this.getRuleContext(0, PropertyNameContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_commentSpec;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterCommentSpec) {
             listener.enterCommentSpec(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitCommentSpec) {
             listener.exitCommentSpec(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitCommentSpec) {
            return visitor.visitCommentSpec(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class MetadataColumnDefinitionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public columnName(): ColumnNameContext {
        return this.getRuleContext(0, ColumnNameContext)!;
    }
    public columnType(): ColumnTypeContext {
        return this.getRuleContext(0, ColumnTypeContext)!;
    }
    public KW_METADATA(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_METADATA, 0)!;
    }
    public KW_FROM(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FROM, 0);
    }
    public metadataKey(): MetadataKeyContext | null {
        return this.getRuleContext(0, MetadataKeyContext);
    }
    public KW_VIRTUAL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_VIRTUAL, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_metadataColumnDefinition;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterMetadataColumnDefinition) {
             listener.enterMetadataColumnDefinition(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitMetadataColumnDefinition) {
             listener.exitMetadataColumnDefinition(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitMetadataColumnDefinition) {
            return visitor.visitMetadataColumnDefinition(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class MetadataKeyContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public STRING_LITERAL(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.STRING_LITERAL, 0)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_metadataKey;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterMetadataKey) {
             listener.enterMetadataKey(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitMetadataKey) {
             listener.exitMetadataKey(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitMetadataKey) {
            return visitor.visitMetadataKey(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ComputedColumnDefinitionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public columnName(): ColumnNameContext {
        return this.getRuleContext(0, ColumnNameContext)!;
    }
    public KW_AS(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_AS, 0)!;
    }
    public computedColumnExpression(): ComputedColumnExpressionContext {
        return this.getRuleContext(0, ComputedColumnExpressionContext)!;
    }
    public commentSpec(): CommentSpecContext | null {
        return this.getRuleContext(0, CommentSpecContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_computedColumnDefinition;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterComputedColumnDefinition) {
             listener.enterComputedColumnDefinition(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitComputedColumnDefinition) {
             listener.exitComputedColumnDefinition(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitComputedColumnDefinition) {
            return visitor.visitComputedColumnDefinition(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ColumnNameContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public uid(): UidContext | null {
        return this.getRuleContext(0, UidContext);
    }
    public expression(): ExpressionContext | null {
        return this.getRuleContext(0, ExpressionContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_columnName;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterColumnName) {
             listener.enterColumnName(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitColumnName) {
             listener.exitColumnName(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitColumnName) {
            return visitor.visitColumnName(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ColumnNameListContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public columnName(): ColumnNameContext[];
    public columnName(i: number): ColumnNameContext | null;
    public columnName(i?: number): ColumnNameContext[] | ColumnNameContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ColumnNameContext);
        }

        return this.getRuleContext(i, ColumnNameContext);
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public commentSpec(): CommentSpecContext[];
    public commentSpec(i: number): CommentSpecContext | null;
    public commentSpec(i?: number): CommentSpecContext[] | CommentSpecContext | null {
        if (i === undefined) {
            return this.getRuleContexts(CommentSpecContext);
        }

        return this.getRuleContext(i, CommentSpecContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_columnNameList;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterColumnNameList) {
             listener.enterColumnNameList(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitColumnNameList) {
             listener.exitColumnNameList(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitColumnNameList) {
            return visitor.visitColumnNameList(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ColumnTypeContext extends antlr.ParserRuleContext {
    public _typeName?: Token | null;
    public _type_?: Token | null;
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_DATE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DATE, 0);
    }
    public KW_BOOLEAN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_BOOLEAN, 0);
    }
    public KW_NULL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NULL, 0);
    }
    public KW_CHAR(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_CHAR, 0);
    }
    public KW_VARCHAR(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_VARCHAR, 0);
    }
    public KW_STRING(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_STRING, 0);
    }
    public KW_BINARY(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_BINARY, 0);
    }
    public KW_VARBINARY(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_VARBINARY, 0);
    }
    public KW_BYTES(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_BYTES, 0);
    }
    public KW_TINYINT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TINYINT, 0);
    }
    public KW_SMALLINT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SMALLINT, 0);
    }
    public KW_INT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_INT, 0);
    }
    public KW_INTEGER(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_INTEGER, 0);
    }
    public KW_BIGINT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_BIGINT, 0);
    }
    public KW_TIME(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TIME, 0);
    }
    public KW_TIMESTAMP_LTZ(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TIMESTAMP_LTZ, 0);
    }
    public KW_DATETIME(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DATETIME, 0);
    }
    public lengthOneDimension(): LengthOneDimensionContext | null {
        return this.getRuleContext(0, LengthOneDimensionContext);
    }
    public KW_TIMESTAMP(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TIMESTAMP, 0);
    }
    public KW_ZONE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ZONE, 0);
    }
    public KW_WITHOUT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_WITHOUT, 0);
    }
    public KW_WITH(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_WITH, 0);
    }
    public KW_LOCAL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LOCAL, 0);
    }
    public KW_TIMESTAMP_3(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TIMESTAMP_3, 0);
    }
    public KW_TIMESTAMP_6(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TIMESTAMP_6, 0);
    }
    public KW_TIMESTAMP_9(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TIMESTAMP_9, 0);
    }
    public KW_DECIMAL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DECIMAL, 0);
    }
    public KW_DEC(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DEC, 0);
    }
    public KW_NUMERIC(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NUMERIC, 0);
    }
    public KW_FLOAT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FLOAT, 0);
    }
    public KW_DOUBLE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DOUBLE, 0);
    }
    public lengthTwoOptionalDimension(): LengthTwoOptionalDimensionContext | null {
        return this.getRuleContext(0, LengthTwoOptionalDimensionContext);
    }
    public KW_ARRAY(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ARRAY, 0);
    }
    public KW_MULTISET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MULTISET, 0);
    }
    public lengthOneTypeDimension(): LengthOneTypeDimensionContext | null {
        return this.getRuleContext(0, LengthOneTypeDimensionContext);
    }
    public KW_MAP(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MAP, 0);
    }
    public mapTypeDimension(): MapTypeDimensionContext | null {
        return this.getRuleContext(0, MapTypeDimensionContext);
    }
    public KW_ROW(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ROW, 0);
    }
    public rowTypeDimension(): RowTypeDimensionContext | null {
        return this.getRuleContext(0, RowTypeDimensionContext);
    }
    public structTypeDimension(): StructTypeDimensionContext | null {
        return this.getRuleContext(0, StructTypeDimensionContext);
    }
    public KW_STRUCT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_STRUCT, 0);
    }
    public KW_RAW(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_RAW, 0);
    }
    public lengthTwoStringDimension(): LengthTwoStringDimensionContext | null {
        return this.getRuleContext(0, LengthTwoStringDimensionContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_columnType;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterColumnType) {
             listener.enterColumnType(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitColumnType) {
             listener.exitColumnType(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitColumnType) {
            return visitor.visitColumnType(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ExpressionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public booleanExpression(): BooleanExpressionContext {
        return this.getRuleContext(0, BooleanExpressionContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_expression;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterExpression) {
             listener.enterExpression(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitExpression) {
             listener.exitExpression(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitExpression) {
            return visitor.visitExpression(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class BooleanExpressionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_booleanExpression;
    }
    public override copyFrom(ctx: BooleanExpressionContext): void {
        super.copyFrom(ctx);
    }
}
export class LogicalNotContext extends BooleanExpressionContext {
    public constructor(ctx: BooleanExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public KW_NOT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_NOT, 0)!;
    }
    public booleanExpression(): BooleanExpressionContext {
        return this.getRuleContext(0, BooleanExpressionContext)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterLogicalNot) {
             listener.enterLogicalNot(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitLogicalNot) {
             listener.exitLogicalNot(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitLogicalNot) {
            return visitor.visitLogicalNot(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class PredicatedContext extends BooleanExpressionContext {
    public constructor(ctx: BooleanExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public valueExpression(): ValueExpressionContext {
        return this.getRuleContext(0, ValueExpressionContext)!;
    }
    public predicate(): PredicateContext | null {
        return this.getRuleContext(0, PredicateContext);
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterPredicated) {
             listener.enterPredicated(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitPredicated) {
             listener.exitPredicated(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitPredicated) {
            return visitor.visitPredicated(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class ExistsContext extends BooleanExpressionContext {
    public constructor(ctx: BooleanExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public KW_EXISTS(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_EXISTS, 0)!;
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public queryStatement(): QueryStatementContext {
        return this.getRuleContext(0, QueryStatementContext)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterExists) {
             listener.enterExists(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitExists) {
             listener.exitExists(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitExists) {
            return visitor.visitExists(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class LogicalNestedContext extends BooleanExpressionContext {
    public _kind?: Token | null;
    public constructor(ctx: BooleanExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public booleanExpression(): BooleanExpressionContext {
        return this.getRuleContext(0, BooleanExpressionContext)!;
    }
    public KW_IS(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_IS, 0)!;
    }
    public KW_TRUE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TRUE, 0);
    }
    public KW_FALSE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FALSE, 0);
    }
    public KW_UNKNOWN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_UNKNOWN, 0);
    }
    public KW_NULL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NULL, 0);
    }
    public KW_NOT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NOT, 0);
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterLogicalNested) {
             listener.enterLogicalNested(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitLogicalNested) {
             listener.exitLogicalNested(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitLogicalNested) {
            return visitor.visitLogicalNested(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class LogicalBinaryContext extends BooleanExpressionContext {
    public _left?: BooleanExpressionContext;
    public _operator?: Token | null;
    public _right?: BooleanExpressionContext;
    public constructor(ctx: BooleanExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public booleanExpression(): BooleanExpressionContext[];
    public booleanExpression(i: number): BooleanExpressionContext | null;
    public booleanExpression(i?: number): BooleanExpressionContext[] | BooleanExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(BooleanExpressionContext);
        }

        return this.getRuleContext(i, BooleanExpressionContext);
    }
    public KW_AND(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_AND, 0);
    }
    public KW_OR(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_OR, 0);
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterLogicalBinary) {
             listener.enterLogicalBinary(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitLogicalBinary) {
             listener.exitLogicalBinary(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitLogicalBinary) {
            return visitor.visitLogicalBinary(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class PredicateContext extends antlr.ParserRuleContext {
    public _kind?: Token | null;
    public _lower?: ValueExpressionContext;
    public _upper?: ValueExpressionContext;
    public _pattern?: ValueExpressionContext;
    public _right?: ValueExpressionContext;
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_AND(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_AND, 0);
    }
    public KW_BETWEEN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_BETWEEN, 0);
    }
    public valueExpression(): ValueExpressionContext[];
    public valueExpression(i: number): ValueExpressionContext | null;
    public valueExpression(i?: number): ValueExpressionContext[] | ValueExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ValueExpressionContext);
        }

        return this.getRuleContext(i, ValueExpressionContext);
    }
    public KW_NOT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NOT, 0);
    }
    public KW_ASYMMETRIC(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ASYMMETRIC, 0);
    }
    public KW_SYMMETRIC(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SYMMETRIC, 0);
    }
    public LR_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0);
    }
    public expression(): ExpressionContext[];
    public expression(i: number): ExpressionContext | null;
    public expression(i?: number): ExpressionContext[] | ExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ExpressionContext);
        }

        return this.getRuleContext(i, ExpressionContext);
    }
    public RR_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0);
    }
    public KW_IN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_IN, 0);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public queryStatement(): QueryStatementContext | null {
        return this.getRuleContext(0, QueryStatementContext);
    }
    public KW_EXISTS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_EXISTS, 0);
    }
    public KW_RLIKE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_RLIKE, 0);
    }
    public likePredicate(): LikePredicateContext | null {
        return this.getRuleContext(0, LikePredicateContext);
    }
    public KW_IS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_IS, 0);
    }
    public KW_TRUE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TRUE, 0);
    }
    public KW_FALSE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FALSE, 0);
    }
    public KW_UNKNOWN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_UNKNOWN, 0);
    }
    public KW_NULL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NULL, 0);
    }
    public KW_FROM(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FROM, 0);
    }
    public KW_DISTINCT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DISTINCT, 0);
    }
    public KW_TO(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TO, 0);
    }
    public KW_SIMILAR(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SIMILAR, 0);
    }
    public KW_ESCAPE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ESCAPE, 0);
    }
    public stringLiteral(): StringLiteralContext | null {
        return this.getRuleContext(0, StringLiteralContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_predicate;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterPredicate) {
             listener.enterPredicate(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitPredicate) {
             listener.exitPredicate(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitPredicate) {
            return visitor.visitPredicate(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class LikePredicateContext extends antlr.ParserRuleContext {
    public _kind?: Token | null;
    public _quantifier?: Token | null;
    public _pattern?: ValueExpressionContext;
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_LIKE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LIKE, 0);
    }
    public KW_ANY(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ANY, 0);
    }
    public KW_ALL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ALL, 0);
    }
    public LR_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0);
    }
    public RR_BRACKET(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0);
    }
    public expression(): ExpressionContext[];
    public expression(i: number): ExpressionContext | null;
    public expression(i?: number): ExpressionContext[] | ExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ExpressionContext);
        }

        return this.getRuleContext(i, ExpressionContext);
    }
    public KW_NOT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NOT, 0);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public valueExpression(): ValueExpressionContext | null {
        return this.getRuleContext(0, ValueExpressionContext);
    }
    public KW_RLIKE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_RLIKE, 0);
    }
    public KW_ESCAPE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ESCAPE, 0);
    }
    public stringLiteral(): StringLiteralContext[];
    public stringLiteral(i: number): StringLiteralContext | null;
    public stringLiteral(i?: number): StringLiteralContext[] | StringLiteralContext | null {
        if (i === undefined) {
            return this.getRuleContexts(StringLiteralContext);
        }

        return this.getRuleContext(i, StringLiteralContext);
    }
    public KW_REGEXP(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_REGEXP, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_likePredicate;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterLikePredicate) {
             listener.enterLikePredicate(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitLikePredicate) {
             listener.exitLikePredicate(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitLikePredicate) {
            return visitor.visitLikePredicate(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ValueExpressionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_valueExpression;
    }
    public override copyFrom(ctx: ValueExpressionContext): void {
        super.copyFrom(ctx);
    }
}
export class ValueExpressionDefaultContext extends ValueExpressionContext {
    public constructor(ctx: ValueExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public primaryExpression(): PrimaryExpressionContext {
        return this.getRuleContext(0, PrimaryExpressionContext)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterValueExpressionDefault) {
             listener.enterValueExpressionDefault(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitValueExpressionDefault) {
             listener.exitValueExpressionDefault(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitValueExpressionDefault) {
            return visitor.visitValueExpressionDefault(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class OrContext extends ValueExpressionContext {
    public _left?: ValueExpressionContext;
    public _operator?: Token | null;
    public _right?: ValueExpressionContext;
    public constructor(ctx: ValueExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public valueExpression(): ValueExpressionContext[];
    public valueExpression(i: number): ValueExpressionContext | null;
    public valueExpression(i?: number): ValueExpressionContext[] | ValueExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ValueExpressionContext);
        }

        return this.getRuleContext(i, ValueExpressionContext);
    }
    public BIT_OR_OP(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.BIT_OR_OP, 0)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterOr) {
             listener.enterOr(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitOr) {
             listener.exitOr(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitOr) {
            return visitor.visitOr(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class ComparisonContext extends ValueExpressionContext {
    public _left?: ValueExpressionContext;
    public _operator?: ComparisonOperatorContext;
    public _right?: ValueExpressionContext;
    public constructor(ctx: ValueExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public valueExpression(): ValueExpressionContext[];
    public valueExpression(i: number): ValueExpressionContext | null;
    public valueExpression(i?: number): ValueExpressionContext[] | ValueExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ValueExpressionContext);
        }

        return this.getRuleContext(i, ValueExpressionContext);
    }
    public comparisonOperator(): ComparisonOperatorContext {
        return this.getRuleContext(0, ComparisonOperatorContext)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterComparison) {
             listener.enterComparison(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitComparison) {
             listener.exitComparison(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitComparison) {
            return visitor.visitComparison(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class ArithmeticBinaryContext extends ValueExpressionContext {
    public _left?: ValueExpressionContext;
    public _operator?: Token | null;
    public _right?: ValueExpressionContext;
    public constructor(ctx: ValueExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public valueExpression(): ValueExpressionContext[];
    public valueExpression(i: number): ValueExpressionContext | null;
    public valueExpression(i?: number): ValueExpressionContext[] | ValueExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ValueExpressionContext);
        }

        return this.getRuleContext(i, ValueExpressionContext);
    }
    public ASTERISK_SIGN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.ASTERISK_SIGN, 0);
    }
    public SLASH_SIGN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.SLASH_SIGN, 0);
    }
    public PENCENT_SIGN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.PENCENT_SIGN, 0);
    }
    public KW_DIV(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DIV, 0);
    }
    public ADD_SIGN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.ADD_SIGN, 0);
    }
    public HYPNEN_SIGN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.HYPNEN_SIGN, 0);
    }
    public DOUBLE_VERTICAL_SIGN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.DOUBLE_VERTICAL_SIGN, 0);
    }
    public BIT_AND_OP(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.BIT_AND_OP, 0);
    }
    public BIT_XOR_OP(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.BIT_XOR_OP, 0);
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterArithmeticBinary) {
             listener.enterArithmeticBinary(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitArithmeticBinary) {
             listener.exitArithmeticBinary(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitArithmeticBinary) {
            return visitor.visitArithmeticBinary(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class ArithmeticUnaryContext extends ValueExpressionContext {
    public _operator?: Token | null;
    public constructor(ctx: ValueExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public valueExpression(): ValueExpressionContext {
        return this.getRuleContext(0, ValueExpressionContext)!;
    }
    public HYPNEN_SIGN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.HYPNEN_SIGN, 0);
    }
    public ADD_SIGN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.ADD_SIGN, 0);
    }
    public BIT_NOT_OP(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.BIT_NOT_OP, 0);
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterArithmeticUnary) {
             listener.enterArithmeticUnary(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitArithmeticUnary) {
             listener.exitArithmeticUnary(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitArithmeticUnary) {
            return visitor.visitArithmeticUnary(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class PrimaryExpressionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_primaryExpression;
    }
    public override copyFrom(ctx: PrimaryExpressionContext): void {
        super.copyFrom(ctx);
    }
}
export class DereferenceContext extends PrimaryExpressionContext {
    public constructor(ctx: PrimaryExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public dereferenceDefinition(): DereferenceDefinitionContext {
        return this.getRuleContext(0, DereferenceDefinitionContext)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterDereference) {
             listener.enterDereference(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitDereference) {
             listener.exitDereference(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitDereference) {
            return visitor.visitDereference(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class SimpleCaseContext extends PrimaryExpressionContext {
    public _value?: ExpressionContext;
    public _elseExpression?: ExpressionContext;
    public constructor(ctx: PrimaryExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public KW_CASE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_CASE, 0)!;
    }
    public KW_END(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_END, 0)!;
    }
    public expression(): ExpressionContext[];
    public expression(i: number): ExpressionContext | null;
    public expression(i?: number): ExpressionContext[] | ExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ExpressionContext);
        }

        return this.getRuleContext(i, ExpressionContext);
    }
    public whenClause(): WhenClauseContext[];
    public whenClause(i: number): WhenClauseContext | null;
    public whenClause(i?: number): WhenClauseContext[] | WhenClauseContext | null {
        if (i === undefined) {
            return this.getRuleContexts(WhenClauseContext);
        }

        return this.getRuleContext(i, WhenClauseContext);
    }
    public KW_ELSE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ELSE, 0);
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterSimpleCase) {
             listener.enterSimpleCase(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitSimpleCase) {
             listener.exitSimpleCase(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitSimpleCase) {
            return visitor.visitSimpleCase(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class ColumnReferenceContext extends PrimaryExpressionContext {
    public constructor(ctx: PrimaryExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public identifier(): IdentifierContext {
        return this.getRuleContext(0, IdentifierContext)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterColumnReference) {
             listener.enterColumnReference(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitColumnReference) {
             listener.exitColumnReference(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitColumnReference) {
            return visitor.visitColumnReference(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class LastContext extends PrimaryExpressionContext {
    public constructor(ctx: PrimaryExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public KW_LAST(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_LAST, 0)!;
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public expression(): ExpressionContext {
        return this.getRuleContext(0, ExpressionContext)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public KW_IGNORE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_IGNORE, 0);
    }
    public KW_NULLS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NULLS, 0);
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterLast) {
             listener.enterLast(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitLast) {
             listener.exitLast(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitLast) {
            return visitor.visitLast(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class StarContext extends PrimaryExpressionContext {
    public constructor(ctx: PrimaryExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public ASTERISK_SIGN(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.ASTERISK_SIGN, 0)!;
    }
    public uid(): UidContext | null {
        return this.getRuleContext(0, UidContext);
    }
    public DOT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.DOT, 0);
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterStar) {
             listener.enterStar(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitStar) {
             listener.exitStar(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitStar) {
            return visitor.visitStar(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class SubscriptContext extends PrimaryExpressionContext {
    public _value?: PrimaryExpressionContext;
    public _index?: ValueExpressionContext;
    public constructor(ctx: PrimaryExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public LS_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LS_BRACKET, 0)!;
    }
    public RS_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RS_BRACKET, 0)!;
    }
    public primaryExpression(): PrimaryExpressionContext {
        return this.getRuleContext(0, PrimaryExpressionContext)!;
    }
    public valueExpression(): ValueExpressionContext {
        return this.getRuleContext(0, ValueExpressionContext)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterSubscript) {
             listener.enterSubscript(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitSubscript) {
             listener.exitSubscript(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitSubscript) {
            return visitor.visitSubscript(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class ValuesContext extends PrimaryExpressionContext {
    public constructor(ctx: PrimaryExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public functionParam(): FunctionParamContext[];
    public functionParam(i: number): FunctionParamContext | null;
    public functionParam(i?: number): FunctionParamContext[] | FunctionParamContext | null {
        if (i === undefined) {
            return this.getRuleContexts(FunctionParamContext);
        }

        return this.getRuleContext(i, FunctionParamContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterValues) {
             listener.enterValues(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitValues) {
             listener.exitValues(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitValues) {
            return visitor.visitValues(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class FunctionCallFilterContext extends PrimaryExpressionContext {
    public constructor(ctx: PrimaryExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public functionName(): FunctionNameContext {
        return this.getRuleContext(0, FunctionNameContext)!;
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public functionParam(): FunctionParamContext {
        return this.getRuleContext(0, FunctionParamContext)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public setQuantifier(): SetQuantifierContext | null {
        return this.getRuleContext(0, SetQuantifierContext);
    }
    public filterClause(): FilterClauseContext | null {
        return this.getRuleContext(0, FilterClauseContext);
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterFunctionCallFilter) {
             listener.enterFunctionCallFilter(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitFunctionCallFilter) {
             listener.exitFunctionCallFilter(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitFunctionCallFilter) {
            return visitor.visitFunctionCallFilter(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class SubqueryExpressionContext extends PrimaryExpressionContext {
    public constructor(ctx: PrimaryExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public queryStatement(): QueryStatementContext {
        return this.getRuleContext(0, QueryStatementContext)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterSubqueryExpression) {
             listener.enterSubqueryExpression(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitSubqueryExpression) {
             listener.exitSubqueryExpression(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitSubqueryExpression) {
            return visitor.visitSubqueryExpression(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class CastContext extends PrimaryExpressionContext {
    public constructor(ctx: PrimaryExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public KW_CAST(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_CAST, 0)!;
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public expression(): ExpressionContext {
        return this.getRuleContext(0, ExpressionContext)!;
    }
    public KW_AS(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_AS, 0)!;
    }
    public columnType(): ColumnTypeContext {
        return this.getRuleContext(0, ColumnTypeContext)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterCast) {
             listener.enterCast(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitCast) {
             listener.exitCast(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitCast) {
            return visitor.visitCast(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class ConstantDefaultContext extends PrimaryExpressionContext {
    public constructor(ctx: PrimaryExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public constant(): ConstantContext {
        return this.getRuleContext(0, ConstantContext)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterConstantDefault) {
             listener.enterConstantDefault(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitConstantDefault) {
             listener.exitConstantDefault(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitConstantDefault) {
            return visitor.visitConstantDefault(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class ParenthesizedExpressionContext extends PrimaryExpressionContext {
    public constructor(ctx: PrimaryExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public expression(): ExpressionContext {
        return this.getRuleContext(0, ExpressionContext)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterParenthesizedExpression) {
             listener.enterParenthesizedExpression(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitParenthesizedExpression) {
             listener.exitParenthesizedExpression(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitParenthesizedExpression) {
            return visitor.visitParenthesizedExpression(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class ComplexDataTypeFieldExpressionContext extends PrimaryExpressionContext {
    public constructor(ctx: PrimaryExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public complexDataTypeExpression(): ComplexDataTypeExpressionContext {
        return this.getRuleContext(0, ComplexDataTypeExpressionContext)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterComplexDataTypeFieldExpression) {
             listener.enterComplexDataTypeFieldExpression(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitComplexDataTypeFieldExpression) {
             listener.exitComplexDataTypeFieldExpression(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitComplexDataTypeFieldExpression) {
            return visitor.visitComplexDataTypeFieldExpression(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class FunctionCallContext extends PrimaryExpressionContext {
    public constructor(ctx: PrimaryExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public functionName(): FunctionNameContext {
        return this.getRuleContext(0, FunctionNameContext)!;
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public functionParam(): FunctionParamContext[];
    public functionParam(i: number): FunctionParamContext | null;
    public functionParam(i?: number): FunctionParamContext[] | FunctionParamContext | null {
        if (i === undefined) {
            return this.getRuleContexts(FunctionParamContext);
        }

        return this.getRuleContext(i, FunctionParamContext);
    }
    public setQuantifier(): SetQuantifierContext | null {
        return this.getRuleContext(0, SetQuantifierContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public KW_TO(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TO, 0);
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterFunctionCall) {
             listener.enterFunctionCall(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitFunctionCall) {
             listener.exitFunctionCall(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitFunctionCall) {
            return visitor.visitFunctionCall(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class SearchedCaseContext extends PrimaryExpressionContext {
    public _elseExpression?: ExpressionContext;
    public constructor(ctx: PrimaryExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public KW_CASE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_CASE, 0)!;
    }
    public KW_END(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_END, 0)!;
    }
    public whenClause(): WhenClauseContext[];
    public whenClause(i: number): WhenClauseContext | null;
    public whenClause(i?: number): WhenClauseContext[] | WhenClauseContext | null {
        if (i === undefined) {
            return this.getRuleContexts(WhenClauseContext);
        }

        return this.getRuleContext(i, WhenClauseContext);
    }
    public KW_ELSE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ELSE, 0);
    }
    public expression(): ExpressionContext | null {
        return this.getRuleContext(0, ExpressionContext);
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterSearchedCase) {
             listener.enterSearchedCase(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitSearchedCase) {
             listener.exitSearchedCase(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitSearchedCase) {
            return visitor.visitSearchedCase(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class PositionContext extends PrimaryExpressionContext {
    public _substr?: ValueExpressionContext;
    public _str?: ValueExpressionContext;
    public constructor(ctx: PrimaryExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public KW_POSITION(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_POSITION, 0)!;
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public KW_IN(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_IN, 0)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public valueExpression(): ValueExpressionContext[];
    public valueExpression(i: number): ValueExpressionContext | null;
    public valueExpression(i?: number): ValueExpressionContext[] | ValueExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ValueExpressionContext);
        }

        return this.getRuleContext(i, ValueExpressionContext);
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterPosition) {
             listener.enterPosition(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitPosition) {
             listener.exitPosition(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitPosition) {
            return visitor.visitPosition(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class FirstContext extends PrimaryExpressionContext {
    public constructor(ctx: PrimaryExpressionContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public KW_FIRST(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_FIRST, 0)!;
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public expression(): ExpressionContext {
        return this.getRuleContext(0, ExpressionContext)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public KW_IGNORE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_IGNORE, 0);
    }
    public KW_NULLS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NULLS, 0);
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterFirst) {
             listener.enterFirst(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitFirst) {
             listener.exitFirst(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitFirst) {
            return visitor.visitFirst(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ComplexDataTypeExpressionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public arrayExpression(): ArrayExpressionContext | null {
        return this.getRuleContext(0, ArrayExpressionContext);
    }
    public rowExpression(): RowExpressionContext | null {
        return this.getRuleContext(0, RowExpressionContext);
    }
    public mapExpression(): MapExpressionContext | null {
        return this.getRuleContext(0, MapExpressionContext);
    }
    public structExpression(): StructExpressionContext | null {
        return this.getRuleContext(0, StructExpressionContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_complexDataTypeExpression;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterComplexDataTypeExpression) {
             listener.enterComplexDataTypeExpression(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitComplexDataTypeExpression) {
             listener.exitComplexDataTypeExpression(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitComplexDataTypeExpression) {
            return visitor.visitComplexDataTypeExpression(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ArrayExpressionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_ARRAY(): antlr.TerminalNode[];
    public KW_ARRAY(i: number): antlr.TerminalNode | null;
    public KW_ARRAY(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.KW_ARRAY);
    	} else {
    		return this.getToken(SparkSQLParser.KW_ARRAY, i);
    	}
    }
    public LS_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LS_BRACKET, 0)!;
    }
    public dataTypeExpression(): DataTypeExpressionContext[];
    public dataTypeExpression(i: number): DataTypeExpressionContext | null;
    public dataTypeExpression(i?: number): DataTypeExpressionContext[] | DataTypeExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(DataTypeExpressionContext);
        }

        return this.getRuleContext(i, DataTypeExpressionContext);
    }
    public RS_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RS_BRACKET, 0)!;
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_arrayExpression;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterArrayExpression) {
             listener.enterArrayExpression(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitArrayExpression) {
             listener.exitArrayExpression(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitArrayExpression) {
            return visitor.visitArrayExpression(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class StructExpressionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_STRUCT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_STRUCT, 0)!;
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public dataTypeExpression(): DataTypeExpressionContext[];
    public dataTypeExpression(i: number): DataTypeExpressionContext | null;
    public dataTypeExpression(i?: number): DataTypeExpressionContext[] | DataTypeExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(DataTypeExpressionContext);
        }

        return this.getRuleContext(i, DataTypeExpressionContext);
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_structExpression;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterStructExpression) {
             listener.enterStructExpression(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitStructExpression) {
             listener.exitStructExpression(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitStructExpression) {
            return visitor.visitStructExpression(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class RowExpressionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_ROW(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_ROW, 0)!;
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public dataTypeExpression(): DataTypeExpressionContext[];
    public dataTypeExpression(i: number): DataTypeExpressionContext | null;
    public dataTypeExpression(i?: number): DataTypeExpressionContext[] | DataTypeExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(DataTypeExpressionContext);
        }

        return this.getRuleContext(i, DataTypeExpressionContext);
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_rowExpression;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterRowExpression) {
             listener.enterRowExpression(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitRowExpression) {
             listener.exitRowExpression(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitRowExpression) {
            return visitor.visitRowExpression(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class MapExpressionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_MAP(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_MAP, 0)!;
    }
    public LS_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LS_BRACKET, 0)!;
    }
    public dataTypeExpression(): DataTypeExpressionContext[];
    public dataTypeExpression(i: number): DataTypeExpressionContext | null;
    public dataTypeExpression(i?: number): DataTypeExpressionContext[] | DataTypeExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(DataTypeExpressionContext);
        }

        return this.getRuleContext(i, DataTypeExpressionContext);
    }
    public COMMA(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.COMMA, 0)!;
    }
    public RS_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RS_BRACKET, 0)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_mapExpression;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterMapExpression) {
             listener.enterMapExpression(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitMapExpression) {
             listener.exitMapExpression(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitMapExpression) {
            return visitor.visitMapExpression(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class DataTypeExpressionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public columnAlias(): ColumnAliasContext | null {
        return this.getRuleContext(0, ColumnAliasContext);
    }
    public constant(): ConstantContext | null {
        return this.getRuleContext(0, ConstantContext);
    }
    public complexDataTypeExpression(): ComplexDataTypeExpressionContext | null {
        return this.getRuleContext(0, ComplexDataTypeExpressionContext);
    }
    public sqlSimpleType(): SqlSimpleTypeContext | null {
        return this.getRuleContext(0, SqlSimpleTypeContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_dataTypeExpression;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterDataTypeExpression) {
             listener.enterDataTypeExpression(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitDataTypeExpression) {
             listener.exitDataTypeExpression(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitDataTypeExpression) {
            return visitor.visitDataTypeExpression(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class SqlSimpleTypeContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_BOOLEAN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_BOOLEAN, 0);
    }
    public KW_BIGINT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_BIGINT, 0);
    }
    public KW_BYTE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_BYTE, 0);
    }
    public KW_TINYINT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TINYINT, 0);
    }
    public KW_SMALLINT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SMALLINT, 0);
    }
    public KW_INT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_INT, 0);
    }
    public KW_INTEGER(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_INTEGER, 0);
    }
    public KW_FLOAT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FLOAT, 0);
    }
    public KW_DOUBLE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DOUBLE, 0);
    }
    public KW_DATE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DATE, 0);
    }
    public KW_LONG(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LONG, 0);
    }
    public KW_DECIMAL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DECIMAL, 0);
    }
    public KW_NUMERIC(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NUMERIC, 0);
    }
    public KW_TIME(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TIME, 0);
    }
    public KW_TIMESTAMP(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TIMESTAMP, 0);
    }
    public KW_TIMESTAMP_LTZ(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TIMESTAMP_LTZ, 0);
    }
    public KW_TIMESTAMP_NTZ(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TIMESTAMP_NTZ, 0);
    }
    public KW_REAL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_REAL, 0);
    }
    public KW_SHORT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SHORT, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_sqlSimpleType;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterSqlSimpleType) {
             listener.enterSqlSimpleType(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitSqlSimpleType) {
             listener.exitSqlSimpleType(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitSqlSimpleType) {
            return visitor.visitSqlSimpleType(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class FunctionNameContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public nonReservedKeywords(): NonReservedKeywordsContext | null {
        return this.getRuleContext(0, NonReservedKeywordsContext);
    }
    public uid(): UidContext | null {
        return this.getRuleContext(0, UidContext);
    }
    public reservedKeywordsUsedAsFuncName(): ReservedKeywordsUsedAsFuncNameContext | null {
        return this.getRuleContext(0, ReservedKeywordsUsedAsFuncNameContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_functionName;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterFunctionName) {
             listener.enterFunctionName(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitFunctionName) {
             listener.exitFunctionName(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitFunctionName) {
            return visitor.visitFunctionName(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class FunctionParamContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public reservedKeywordsUsedAsFuncParam(): ReservedKeywordsUsedAsFuncParamContext | null {
        return this.getRuleContext(0, ReservedKeywordsUsedAsFuncParamContext);
    }
    public timeIntervalUnit(): TimeIntervalUnitContext | null {
        return this.getRuleContext(0, TimeIntervalUnitContext);
    }
    public timePointUnit(): TimePointUnitContext | null {
        return this.getRuleContext(0, TimePointUnitContext);
    }
    public expression(): ExpressionContext | null {
        return this.getRuleContext(0, ExpressionContext);
    }
    public filterClause(): FilterClauseContext | null {
        return this.getRuleContext(0, FilterClauseContext);
    }
    public constant(): ConstantContext | null {
        return this.getRuleContext(0, ConstantContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_functionParam;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterFunctionParam) {
             listener.enterFunctionParam(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitFunctionParam) {
             listener.exitFunctionParam(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitFunctionParam) {
            return visitor.visitFunctionParam(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class FilterClauseContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_FILTER(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_FILTER, 0)!;
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public KW_WHERE(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_WHERE, 0)!;
    }
    public booleanExpression(): BooleanExpressionContext {
        return this.getRuleContext(0, BooleanExpressionContext)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_filterClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterFilterClause) {
             listener.enterFilterClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitFilterClause) {
             listener.exitFilterClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitFilterClause) {
            return visitor.visitFilterClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class DereferenceDefinitionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public uid(): UidContext {
        return this.getRuleContext(0, UidContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_dereferenceDefinition;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterDereferenceDefinition) {
             listener.enterDereferenceDefinition(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitDereferenceDefinition) {
             listener.exitDereferenceDefinition(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitDereferenceDefinition) {
            return visitor.visitDereferenceDefinition(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class CorrelationNameContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public identifier(): IdentifierContext {
        return this.getRuleContext(0, IdentifierContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_correlationName;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterCorrelationName) {
             listener.enterCorrelationName(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitCorrelationName) {
             listener.exitCorrelationName(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitCorrelationName) {
            return visitor.visitCorrelationName(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class QualifiedNameContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public identifier(): IdentifierContext | null {
        return this.getRuleContext(0, IdentifierContext);
    }
    public dereferenceDefinition(): DereferenceDefinitionContext | null {
        return this.getRuleContext(0, DereferenceDefinitionContext);
    }
    public unquotedAnyString(): UnquotedAnyStringContext | null {
        return this.getRuleContext(0, UnquotedAnyStringContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_qualifiedName;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterQualifiedName) {
             listener.enterQualifiedName(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitQualifiedName) {
             listener.exitQualifiedName(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitQualifiedName) {
            return visitor.visitQualifiedName(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class TimeIntervalExpressionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_INTERVAL(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_INTERVAL, 0)!;
    }
    public errorCapturingMultiUnitsInterval(): ErrorCapturingMultiUnitsIntervalContext | null {
        return this.getRuleContext(0, ErrorCapturingMultiUnitsIntervalContext);
    }
    public errorCapturingUnitToUnitInterval(): ErrorCapturingUnitToUnitIntervalContext | null {
        return this.getRuleContext(0, ErrorCapturingUnitToUnitIntervalContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_timeIntervalExpression;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterTimeIntervalExpression) {
             listener.enterTimeIntervalExpression(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitTimeIntervalExpression) {
             listener.exitTimeIntervalExpression(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitTimeIntervalExpression) {
            return visitor.visitTimeIntervalExpression(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ErrorCapturingMultiUnitsIntervalContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public multiUnitsInterval(): MultiUnitsIntervalContext {
        return this.getRuleContext(0, MultiUnitsIntervalContext)!;
    }
    public unitToUnitInterval(): UnitToUnitIntervalContext | null {
        return this.getRuleContext(0, UnitToUnitIntervalContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_errorCapturingMultiUnitsInterval;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterErrorCapturingMultiUnitsInterval) {
             listener.enterErrorCapturingMultiUnitsInterval(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitErrorCapturingMultiUnitsInterval) {
             listener.exitErrorCapturingMultiUnitsInterval(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitErrorCapturingMultiUnitsInterval) {
            return visitor.visitErrorCapturingMultiUnitsInterval(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class MultiUnitsIntervalContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public intervalValue(): IntervalValueContext[];
    public intervalValue(i: number): IntervalValueContext | null;
    public intervalValue(i?: number): IntervalValueContext[] | IntervalValueContext | null {
        if (i === undefined) {
            return this.getRuleContexts(IntervalValueContext);
        }

        return this.getRuleContext(i, IntervalValueContext);
    }
    public timeIntervalUnit(): TimeIntervalUnitContext[];
    public timeIntervalUnit(i: number): TimeIntervalUnitContext | null;
    public timeIntervalUnit(i?: number): TimeIntervalUnitContext[] | TimeIntervalUnitContext | null {
        if (i === undefined) {
            return this.getRuleContexts(TimeIntervalUnitContext);
        }

        return this.getRuleContext(i, TimeIntervalUnitContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_multiUnitsInterval;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterMultiUnitsInterval) {
             listener.enterMultiUnitsInterval(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitMultiUnitsInterval) {
             listener.exitMultiUnitsInterval(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitMultiUnitsInterval) {
            return visitor.visitMultiUnitsInterval(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ErrorCapturingUnitToUnitIntervalContext extends antlr.ParserRuleContext {
    public _body?: UnitToUnitIntervalContext;
    public _error1?: MultiUnitsIntervalContext;
    public _error2?: UnitToUnitIntervalContext;
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public unitToUnitInterval(): UnitToUnitIntervalContext[];
    public unitToUnitInterval(i: number): UnitToUnitIntervalContext | null;
    public unitToUnitInterval(i?: number): UnitToUnitIntervalContext[] | UnitToUnitIntervalContext | null {
        if (i === undefined) {
            return this.getRuleContexts(UnitToUnitIntervalContext);
        }

        return this.getRuleContext(i, UnitToUnitIntervalContext);
    }
    public multiUnitsInterval(): MultiUnitsIntervalContext | null {
        return this.getRuleContext(0, MultiUnitsIntervalContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_errorCapturingUnitToUnitInterval;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterErrorCapturingUnitToUnitInterval) {
             listener.enterErrorCapturingUnitToUnitInterval(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitErrorCapturingUnitToUnitInterval) {
             listener.exitErrorCapturingUnitToUnitInterval(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitErrorCapturingUnitToUnitInterval) {
            return visitor.visitErrorCapturingUnitToUnitInterval(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class UnitToUnitIntervalContext extends antlr.ParserRuleContext {
    public _value?: IntervalValueContext;
    public _from_?: TimeIntervalUnitContext;
    public _to?: TimeIntervalUnitContext;
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_TO(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_TO, 0)!;
    }
    public intervalValue(): IntervalValueContext {
        return this.getRuleContext(0, IntervalValueContext)!;
    }
    public timeIntervalUnit(): TimeIntervalUnitContext[];
    public timeIntervalUnit(i: number): TimeIntervalUnitContext | null;
    public timeIntervalUnit(i?: number): TimeIntervalUnitContext[] | TimeIntervalUnitContext | null {
        if (i === undefined) {
            return this.getRuleContexts(TimeIntervalUnitContext);
        }

        return this.getRuleContext(i, TimeIntervalUnitContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_unitToUnitInterval;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterUnitToUnitInterval) {
             listener.enterUnitToUnitInterval(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitUnitToUnitInterval) {
             listener.exitUnitToUnitInterval(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitUnitToUnitInterval) {
            return visitor.visitUnitToUnitInterval(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class IntervalValueContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public DIG_LITERAL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.DIG_LITERAL, 0);
    }
    public REAL_LITERAL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.REAL_LITERAL, 0);
    }
    public ADD_SIGN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.ADD_SIGN, 0);
    }
    public HYPNEN_SIGN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.HYPNEN_SIGN, 0);
    }
    public STRING_LITERAL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.STRING_LITERAL, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_intervalValue;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterIntervalValue) {
             listener.enterIntervalValue(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitIntervalValue) {
             listener.exitIntervalValue(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitIntervalValue) {
            return visitor.visitIntervalValue(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ColumnAliasContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public identifier(): IdentifierContext {
        return this.getRuleContext(0, IdentifierContext)!;
    }
    public KW_AS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_AS, 0);
    }
    public identifierList(): IdentifierListContext | null {
        return this.getRuleContext(0, IdentifierListContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_columnAlias;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterColumnAlias) {
             listener.enterColumnAlias(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitColumnAlias) {
             listener.exitColumnAlias(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitColumnAlias) {
            return visitor.visitColumnAlias(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class TableAliasContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public identifier(): IdentifierContext {
        return this.getRuleContext(0, IdentifierContext)!;
    }
    public KW_AS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_AS, 0);
    }
    public identifierList(): IdentifierListContext | null {
        return this.getRuleContext(0, IdentifierListContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_tableAlias;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterTableAlias) {
             listener.enterTableAlias(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitTableAlias) {
             listener.exitTableAlias(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitTableAlias) {
            return visitor.visitTableAlias(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ErrorCapturingIdentifierContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public identifier(): IdentifierContext {
        return this.getRuleContext(0, IdentifierContext)!;
    }
    public errorCapturingIdentifierExtra(): ErrorCapturingIdentifierExtraContext {
        return this.getRuleContext(0, ErrorCapturingIdentifierExtraContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_errorCapturingIdentifier;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterErrorCapturingIdentifier) {
             listener.enterErrorCapturingIdentifier(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitErrorCapturingIdentifier) {
             listener.exitErrorCapturingIdentifier(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitErrorCapturingIdentifier) {
            return visitor.visitErrorCapturingIdentifier(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ErrorCapturingIdentifierExtraContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_errorCapturingIdentifierExtra;
    }
    public override copyFrom(ctx: ErrorCapturingIdentifierExtraContext): void {
        super.copyFrom(ctx);
    }
}
export class ErrorIdentContext extends ErrorCapturingIdentifierExtraContext {
    public constructor(ctx: ErrorCapturingIdentifierExtraContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public KW_MINUS(): antlr.TerminalNode[];
    public KW_MINUS(i: number): antlr.TerminalNode | null;
    public KW_MINUS(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.KW_MINUS);
    	} else {
    		return this.getToken(SparkSQLParser.KW_MINUS, i);
    	}
    }
    public identifier(): IdentifierContext[];
    public identifier(i: number): IdentifierContext | null;
    public identifier(i?: number): IdentifierContext[] | IdentifierContext | null {
        if (i === undefined) {
            return this.getRuleContexts(IdentifierContext);
        }

        return this.getRuleContext(i, IdentifierContext);
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterErrorIdent) {
             listener.enterErrorIdent(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitErrorIdent) {
             listener.exitErrorIdent(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitErrorIdent) {
            return visitor.visitErrorIdent(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class RealIdentContext extends ErrorCapturingIdentifierExtraContext {
    public constructor(ctx: ErrorCapturingIdentifierExtraContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterRealIdent) {
             listener.enterRealIdent(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitRealIdent) {
             listener.exitRealIdent(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitRealIdent) {
            return visitor.visitRealIdent(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class IdentifierListContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public identifierSeq(): IdentifierSeqContext {
        return this.getRuleContext(0, IdentifierSeqContext)!;
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_identifierList;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterIdentifierList) {
             listener.enterIdentifierList(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitIdentifierList) {
             listener.exitIdentifierList(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitIdentifierList) {
            return visitor.visitIdentifierList(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class IdentifierSeqContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public identifier(): IdentifierContext[];
    public identifier(i: number): IdentifierContext | null;
    public identifier(i?: number): IdentifierContext[] | IdentifierContext | null {
        if (i === undefined) {
            return this.getRuleContexts(IdentifierContext);
        }

        return this.getRuleContext(i, IdentifierContext);
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_identifierSeq;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterIdentifierSeq) {
             listener.enterIdentifierSeq(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitIdentifierSeq) {
             listener.exitIdentifierSeq(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitIdentifierSeq) {
            return visitor.visitIdentifierSeq(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class IdentifierContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_identifier;
    }
    public override copyFrom(ctx: IdentifierContext): void {
        super.copyFrom(ctx);
    }
}
export class QuotedIdentifierAlternativeContext extends IdentifierContext {
    public constructor(ctx: IdentifierContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public quotedIdentifier(): QuotedIdentifierContext {
        return this.getRuleContext(0, QuotedIdentifierContext)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterQuotedIdentifierAlternative) {
             listener.enterQuotedIdentifierAlternative(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitQuotedIdentifierAlternative) {
             listener.exitQuotedIdentifierAlternative(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitQuotedIdentifierAlternative) {
            return visitor.visitQuotedIdentifierAlternative(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class NonReservedKeywordsAlternativeContext extends IdentifierContext {
    public constructor(ctx: IdentifierContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public nonReservedKeywords(): NonReservedKeywordsContext {
        return this.getRuleContext(0, NonReservedKeywordsContext)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterNonReservedKeywordsAlternative) {
             listener.enterNonReservedKeywordsAlternative(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitNonReservedKeywordsAlternative) {
             listener.exitNonReservedKeywordsAlternative(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitNonReservedKeywordsAlternative) {
            return visitor.visitNonReservedKeywordsAlternative(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class UnquotedIdentifierAlternativeContext extends IdentifierContext {
    public constructor(ctx: IdentifierContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public unquotedIdentifier(): UnquotedIdentifierContext {
        return this.getRuleContext(0, UnquotedIdentifierContext)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterUnquotedIdentifierAlternative) {
             listener.enterUnquotedIdentifierAlternative(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitUnquotedIdentifierAlternative) {
             listener.exitUnquotedIdentifierAlternative(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitUnquotedIdentifierAlternative) {
            return visitor.visitUnquotedIdentifierAlternative(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
export class UrefVarAlternativeContext extends IdentifierContext {
    public constructor(ctx: IdentifierContext) {
        super(ctx.parent, ctx.invokingState);
        super.copyFrom(ctx);
    }
    public refVar(): RefVarContext {
        return this.getRuleContext(0, RefVarContext)!;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterUrefVarAlternative) {
             listener.enterUrefVarAlternative(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitUrefVarAlternative) {
             listener.exitUrefVarAlternative(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitUrefVarAlternative) {
            return visitor.visitUrefVarAlternative(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class UnquotedAnyStringContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public unquotedIdentifier(): UnquotedIdentifierContext | null {
        return this.getRuleContext(0, UnquotedIdentifierContext);
    }
    public reservedKeywordsUsedAsFuncParam(): ReservedKeywordsUsedAsFuncParamContext | null {
        return this.getRuleContext(0, ReservedKeywordsUsedAsFuncParamContext);
    }
    public nonReservedKeywords(): NonReservedKeywordsContext | null {
        return this.getRuleContext(0, NonReservedKeywordsContext);
    }
    public reservedKeywordsUsedAsFuncName(): ReservedKeywordsUsedAsFuncNameContext | null {
        return this.getRuleContext(0, ReservedKeywordsUsedAsFuncNameContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_unquotedAnyString;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterUnquotedAnyString) {
             listener.enterUnquotedAnyString(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitUnquotedAnyString) {
             listener.exitUnquotedAnyString(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitUnquotedAnyString) {
            return visitor.visitUnquotedAnyString(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class RefVarContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public DOLLAR(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.DOLLAR, 0)!;
    }
    public LB_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LB_BRACKET, 0)!;
    }
    public unquotedIdentifier(): UnquotedIdentifierContext {
        return this.getRuleContext(0, UnquotedIdentifierContext)!;
    }
    public RB_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RB_BRACKET, 0)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_refVar;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterRefVar) {
             listener.enterRefVar(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitRefVar) {
             listener.exitRefVar(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitRefVar) {
            return visitor.visitRefVar(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class UnquotedIdentifierContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public DIG_LITERAL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.DIG_LITERAL, 0);
    }
    public ID_LITERAL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.ID_LITERAL, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_unquotedIdentifier;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterUnquotedIdentifier) {
             listener.enterUnquotedIdentifier(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitUnquotedIdentifier) {
             listener.exitUnquotedIdentifier(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitUnquotedIdentifier) {
            return visitor.visitUnquotedIdentifier(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class QuotedIdentifierContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public STRING_LITERAL(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.STRING_LITERAL, 0)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_quotedIdentifier;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterQuotedIdentifier) {
             listener.enterQuotedIdentifier(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitQuotedIdentifier) {
             listener.exitQuotedIdentifier(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitQuotedIdentifier) {
            return visitor.visitQuotedIdentifier(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class WhenClauseContext extends antlr.ParserRuleContext {
    public _condition?: ExpressionContext;
    public _result?: ExpressionContext;
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_WHEN(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_WHEN, 0)!;
    }
    public KW_THEN(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_THEN, 0)!;
    }
    public expression(): ExpressionContext[];
    public expression(i: number): ExpressionContext | null;
    public expression(i?: number): ExpressionContext[] | ExpressionContext | null {
        if (i === undefined) {
            return this.getRuleContexts(ExpressionContext);
        }

        return this.getRuleContext(i, ExpressionContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_whenClause;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterWhenClause) {
             listener.enterWhenClause(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitWhenClause) {
             listener.exitWhenClause(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitWhenClause) {
            return visitor.visitWhenClause(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class CatalogPathContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public uid(): UidContext {
        return this.getRuleContext(0, UidContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_catalogPath;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterCatalogPath) {
             listener.enterCatalogPath(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitCatalogPath) {
             listener.exitCatalogPath(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitCatalogPath) {
            return visitor.visitCatalogPath(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class DatabasePathContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public uid(): UidContext {
        return this.getRuleContext(0, UidContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_databasePath;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterDatabasePath) {
             listener.enterDatabasePath(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitDatabasePath) {
             listener.exitDatabasePath(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitDatabasePath) {
            return visitor.visitDatabasePath(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class DatabasePathCreateContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public uid(): UidContext {
        return this.getRuleContext(0, UidContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_databasePathCreate;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterDatabasePathCreate) {
             listener.enterDatabasePathCreate(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitDatabasePathCreate) {
             listener.exitDatabasePathCreate(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitDatabasePathCreate) {
            return visitor.visitDatabasePathCreate(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class TablePathCreateContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public uid(): UidContext {
        return this.getRuleContext(0, UidContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_tablePathCreate;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterTablePathCreate) {
             listener.enterTablePathCreate(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitTablePathCreate) {
             listener.exitTablePathCreate(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitTablePathCreate) {
            return visitor.visitTablePathCreate(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class TablePathContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public uid(): UidContext {
        return this.getRuleContext(0, UidContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_tablePath;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterTablePath) {
             listener.enterTablePath(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitTablePath) {
             listener.exitTablePath(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitTablePath) {
            return visitor.visitTablePath(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class AnonymousWindowsNameContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public identifier(): IdentifierContext {
        return this.getRuleContext(0, IdentifierContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_anonymousWindowsName;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterAnonymousWindowsName) {
             listener.enterAnonymousWindowsName(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitAnonymousWindowsName) {
             listener.exitAnonymousWindowsName(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitAnonymousWindowsName) {
            return visitor.visitAnonymousWindowsName(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class UidContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public identifier(): IdentifierContext[];
    public identifier(i: number): IdentifierContext | null;
    public identifier(i?: number): IdentifierContext[] | IdentifierContext | null {
        if (i === undefined) {
            return this.getRuleContexts(IdentifierContext);
        }

        return this.getRuleContext(i, IdentifierContext);
    }
    public DOT(): antlr.TerminalNode[];
    public DOT(i: number): antlr.TerminalNode | null;
    public DOT(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.DOT);
    	} else {
    		return this.getToken(SparkSQLParser.DOT, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_uid;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterUid) {
             listener.enterUid(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitUid) {
             listener.exitUid(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitUid) {
            return visitor.visitUid(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class WithOptionContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_WITH(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_WITH, 0)!;
    }
    public tablePropertyList(): TablePropertyListContext {
        return this.getRuleContext(0, TablePropertyListContext)!;
    }
    public KW_DBPROPERTIES(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DBPROPERTIES, 0);
    }
    public KW_TBLPROPERTIES(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TBLPROPERTIES, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_withOption;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterWithOption) {
             listener.enterWithOption(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitWithOption) {
             listener.exitWithOption(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitWithOption) {
            return visitor.visitWithOption(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class IfNotExistsContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_IF(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_IF, 0)!;
    }
    public KW_NOT(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_NOT, 0)!;
    }
    public KW_EXISTS(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_EXISTS, 0)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_ifNotExists;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterIfNotExists) {
             listener.enterIfNotExists(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitIfNotExists) {
             listener.exitIfNotExists(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitIfNotExists) {
            return visitor.visitIfNotExists(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class IfExistsContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_IF(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_IF, 0)!;
    }
    public KW_EXISTS(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.KW_EXISTS, 0)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_ifExists;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterIfExists) {
             listener.enterIfExists(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitIfExists) {
             listener.exitIfExists(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitIfExists) {
            return visitor.visitIfExists(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class TablePropertyListContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public LR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.LR_BRACKET, 0)!;
    }
    public tableProperty(): TablePropertyContext[];
    public tableProperty(i: number): TablePropertyContext | null;
    public tableProperty(i?: number): TablePropertyContext[] | TablePropertyContext | null {
        if (i === undefined) {
            return this.getRuleContexts(TablePropertyContext);
        }

        return this.getRuleContext(i, TablePropertyContext);
    }
    public RR_BRACKET(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.RR_BRACKET, 0)!;
    }
    public COMMA(): antlr.TerminalNode[];
    public COMMA(i: number): antlr.TerminalNode | null;
    public COMMA(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.COMMA);
    	} else {
    		return this.getToken(SparkSQLParser.COMMA, i);
    	}
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_tablePropertyList;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterTablePropertyList) {
             listener.enterTablePropertyList(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitTablePropertyList) {
             listener.exitTablePropertyList(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitTablePropertyList) {
            return visitor.visitTablePropertyList(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class TablePropertyContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public tablePropertyKey(): TablePropertyKeyContext {
        return this.getRuleContext(0, TablePropertyKeyContext)!;
    }
    public EQUAL_SYMBOL(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.EQUAL_SYMBOL, 0)!;
    }
    public tablePropertyValue(): TablePropertyValueContext {
        return this.getRuleContext(0, TablePropertyValueContext)!;
    }
    public KW_DATE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DATE, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_tableProperty;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterTableProperty) {
             listener.enterTableProperty(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitTableProperty) {
             listener.exitTableProperty(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitTableProperty) {
            return visitor.visitTableProperty(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class TablePropertyKeyContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public identifier(): IdentifierContext | null {
        return this.getRuleContext(0, IdentifierContext);
    }
    public dereferenceDefinition(): DereferenceDefinitionContext | null {
        return this.getRuleContext(0, DereferenceDefinitionContext);
    }
    public stringLiteral(): StringLiteralContext | null {
        return this.getRuleContext(0, StringLiteralContext);
    }
    public functionParam(): FunctionParamContext | null {
        return this.getRuleContext(0, FunctionParamContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_tablePropertyKey;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterTablePropertyKey) {
             listener.enterTablePropertyKey(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitTablePropertyKey) {
             listener.exitTablePropertyKey(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitTablePropertyKey) {
            return visitor.visitTablePropertyKey(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class PropertyNameContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public SINGLE_QUOTE_SYMB(): antlr.TerminalNode[];
    public SINGLE_QUOTE_SYMB(i: number): antlr.TerminalNode | null;
    public SINGLE_QUOTE_SYMB(i?: number): antlr.TerminalNode | null | antlr.TerminalNode[] {
    	if (i === undefined) {
    		return this.getTokens(SparkSQLParser.SINGLE_QUOTE_SYMB);
    	} else {
    		return this.getToken(SparkSQLParser.SINGLE_QUOTE_SYMB, i);
    	}
    }
    public constant(): ConstantContext {
        return this.getRuleContext(0, ConstantContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_propertyName;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterPropertyName) {
             listener.enterPropertyName(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitPropertyName) {
             listener.exitPropertyName(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitPropertyName) {
            return visitor.visitPropertyName(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class TablePropertyValueContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public DIG_LITERAL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.DIG_LITERAL, 0);
    }
    public REAL_LITERAL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.REAL_LITERAL, 0);
    }
    public booleanLiteral(): BooleanLiteralContext | null {
        return this.getRuleContext(0, BooleanLiteralContext);
    }
    public uid(): UidContext | null {
        return this.getRuleContext(0, UidContext);
    }
    public constant(): ConstantContext | null {
        return this.getRuleContext(0, ConstantContext);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_tablePropertyValue;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterTablePropertyValue) {
             listener.enterTablePropertyValue(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitTablePropertyValue) {
             listener.exitTablePropertyValue(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitTablePropertyValue) {
            return visitor.visitTablePropertyValue(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ComparisonOperatorContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public EQUAL_SYMBOL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.EQUAL_SYMBOL, 0);
    }
    public GREATER_SYMBOL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.GREATER_SYMBOL, 0);
    }
    public LESS_SYMBOL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.LESS_SYMBOL, 0);
    }
    public EXCLAMATION_SYMBOL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.EXCLAMATION_SYMBOL, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_comparisonOperator;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterComparisonOperator) {
             listener.enterComparisonOperator(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitComparisonOperator) {
             listener.exitComparisonOperator(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitComparisonOperator) {
            return visitor.visitComparisonOperator(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ConstantContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public timeIntervalExpression(): TimeIntervalExpressionContext | null {
        return this.getRuleContext(0, TimeIntervalExpressionContext);
    }
    public timePointLiteral(): TimePointLiteralContext | null {
        return this.getRuleContext(0, TimePointLiteralContext);
    }
    public stringLiteral(): StringLiteralContext | null {
        return this.getRuleContext(0, StringLiteralContext);
    }
    public decimalLiteral(): DecimalLiteralContext | null {
        return this.getRuleContext(0, DecimalLiteralContext);
    }
    public HYPNEN_SIGN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.HYPNEN_SIGN, 0);
    }
    public booleanLiteral(): BooleanLiteralContext | null {
        return this.getRuleContext(0, BooleanLiteralContext);
    }
    public REAL_LITERAL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.REAL_LITERAL, 0);
    }
    public KW_NULL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NULL, 0);
    }
    public KW_NOT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NOT, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_constant;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterConstant) {
             listener.enterConstant(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitConstant) {
             listener.exitConstant(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitConstant) {
            return visitor.visitConstant(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class TimePointLiteralContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public timePointUnit(): TimePointUnitContext {
        return this.getRuleContext(0, TimePointUnitContext)!;
    }
    public stringLiteral(): StringLiteralContext {
        return this.getRuleContext(0, StringLiteralContext)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_timePointLiteral;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterTimePointLiteral) {
             listener.enterTimePointLiteral(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitTimePointLiteral) {
             listener.exitTimePointLiteral(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitTimePointLiteral) {
            return visitor.visitTimePointLiteral(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class AnyStringLiteralContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public STRING_LITERAL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.STRING_LITERAL, 0);
    }
    public ID_LITERAL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.ID_LITERAL, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_anyStringLiteral;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterAnyStringLiteral) {
             listener.enterAnyStringLiteral(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitAnyStringLiteral) {
             listener.exitAnyStringLiteral(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitAnyStringLiteral) {
            return visitor.visitAnyStringLiteral(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class StringLiteralContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public STRING_LITERAL(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.STRING_LITERAL, 0)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_stringLiteral;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterStringLiteral) {
             listener.enterStringLiteral(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitStringLiteral) {
             listener.exitStringLiteral(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitStringLiteral) {
            return visitor.visitStringLiteral(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class DecimalLiteralContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public DIG_LITERAL(): antlr.TerminalNode {
        return this.getToken(SparkSQLParser.DIG_LITERAL, 0)!;
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_decimalLiteral;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterDecimalLiteral) {
             listener.enterDecimalLiteral(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitDecimalLiteral) {
             listener.exitDecimalLiteral(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitDecimalLiteral) {
            return visitor.visitDecimalLiteral(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class BooleanLiteralContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_TRUE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TRUE, 0);
    }
    public KW_FALSE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FALSE, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_booleanLiteral;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterBooleanLiteral) {
             listener.enterBooleanLiteral(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitBooleanLiteral) {
             listener.exitBooleanLiteral(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitBooleanLiteral) {
            return visitor.visitBooleanLiteral(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class SetQuantifierContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_DISTINCT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DISTINCT, 0);
    }
    public KW_ALL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ALL, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_setQuantifier;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterSetQuantifier) {
             listener.enterSetQuantifier(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitSetQuantifier) {
             listener.exitSetQuantifier(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitSetQuantifier) {
            return visitor.visitSetQuantifier(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class TimePointUnitContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_YEAR(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_YEAR, 0);
    }
    public KW_QUARTER(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_QUARTER, 0);
    }
    public KW_MONTH(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MONTH, 0);
    }
    public KW_WEEK(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_WEEK, 0);
    }
    public KW_DAY(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DAY, 0);
    }
    public KW_HOUR(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_HOUR, 0);
    }
    public KW_MINUTE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MINUTE, 0);
    }
    public KW_SECOND(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SECOND, 0);
    }
    public KW_MILLISECOND(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MILLISECOND, 0);
    }
    public KW_MICROSECOND(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MICROSECOND, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_timePointUnit;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterTimePointUnit) {
             listener.enterTimePointUnit(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitTimePointUnit) {
             listener.exitTimePointUnit(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitTimePointUnit) {
            return visitor.visitTimePointUnit(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class TimeIntervalUnitContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_MILLENNIUM(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MILLENNIUM, 0);
    }
    public KW_CENTURY(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_CENTURY, 0);
    }
    public KW_DECADE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DECADE, 0);
    }
    public KW_YEAR(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_YEAR, 0);
    }
    public KW_YEARS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_YEARS, 0);
    }
    public KW_QUARTER(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_QUARTER, 0);
    }
    public KW_MONTH(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MONTH, 0);
    }
    public KW_MONTHS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MONTHS, 0);
    }
    public KW_WEEK(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_WEEK, 0);
    }
    public KW_WEEKS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_WEEKS, 0);
    }
    public KW_DAY(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DAY, 0);
    }
    public KW_DAYS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DAYS, 0);
    }
    public KW_HOUR(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_HOUR, 0);
    }
    public KW_HOURS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_HOURS, 0);
    }
    public KW_MINUTE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MINUTE, 0);
    }
    public KW_MINUTES(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MINUTES, 0);
    }
    public KW_SECOND(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SECOND, 0);
    }
    public KW_SECONDS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SECONDS, 0);
    }
    public KW_MILLISECOND(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MILLISECOND, 0);
    }
    public KW_MICROSECOND(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MICROSECOND, 0);
    }
    public KW_NANOSECOND(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NANOSECOND, 0);
    }
    public KW_EPOCH(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_EPOCH, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_timeIntervalUnit;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterTimeIntervalUnit) {
             listener.enterTimeIntervalUnit(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitTimeIntervalUnit) {
             listener.exitTimeIntervalUnit(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitTimeIntervalUnit) {
            return visitor.visitTimeIntervalUnit(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ReservedKeywordsUsedAsFuncParamContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_LEADING(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LEADING, 0);
    }
    public KW_TRAILING(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TRAILING, 0);
    }
    public KW_BOTH(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_BOTH, 0);
    }
    public KW_ALL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ALL, 0);
    }
    public KW_DISTINCT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DISTINCT, 0);
    }
    public ASTERISK_SIGN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.ASTERISK_SIGN, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_reservedKeywordsUsedAsFuncParam;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterReservedKeywordsUsedAsFuncParam) {
             listener.enterReservedKeywordsUsedAsFuncParam(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitReservedKeywordsUsedAsFuncParam) {
             listener.exitReservedKeywordsUsedAsFuncParam(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitReservedKeywordsUsedAsFuncParam) {
            return visitor.visitReservedKeywordsUsedAsFuncParam(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class ReservedKeywordsUsedAsFuncNameContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_ABS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ABS, 0);
    }
    public KW_ARRAY(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ARRAY, 0);
    }
    public KW_AVG(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_AVG, 0);
    }
    public KW_CAST(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_CAST, 0);
    }
    public KW_CEIL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_CEIL, 0);
    }
    public KW_COALESCE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_COALESCE, 0);
    }
    public KW_COLLECT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_COLLECT, 0);
    }
    public KW_COUNT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_COUNT, 0);
    }
    public KW_DATE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DATE, 0);
    }
    public KW_EXPLODE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_EXPLODE, 0);
    }
    public KW_FIRST_VALUE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FIRST_VALUE, 0);
    }
    public KW_FROM_UNIXTIME(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FROM_UNIXTIME, 0);
    }
    public KW_GROUPING(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_GROUPING, 0);
    }
    public KW_HOUR(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_HOUR, 0);
    }
    public KW_IF(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_IF, 0);
    }
    public KW_LEAD(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LEAD, 0);
    }
    public KW_LAG(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LAG, 0);
    }
    public KW_LAST_VALUE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LAST_VALUE, 0);
    }
    public KW_LEFT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LEFT, 0);
    }
    public KW_NTILE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NTILE, 0);
    }
    public KW_MAP(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MAP, 0);
    }
    public KW_MINUTE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MINUTE, 0);
    }
    public KW_MONTH(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MONTH, 0);
    }
    public KW_OVERLAY(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_OVERLAY, 0);
    }
    public KW_POSITION(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_POSITION, 0);
    }
    public KW_PERCENT_RANK(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PERCENT_RANK, 0);
    }
    public KW_PERCENTILE_CONT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PERCENTILE_CONT, 0);
    }
    public KW_PERCENTILE_DISC(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PERCENTILE_DISC, 0);
    }
    public KW_POWER(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_POWER, 0);
    }
    public KW_QUARTER(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_QUARTER, 0);
    }
    public KW_RANK(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_RANK, 0);
    }
    public KW_ROW_NUMBER(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ROW_NUMBER, 0);
    }
    public KW_RANGE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_RANGE, 0);
    }
    public KW_RIGHT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_RIGHT, 0);
    }
    public KW_SECOND(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SECOND, 0);
    }
    public KW_SUBSTRING(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SUBSTRING, 0);
    }
    public KW_SUM(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SUM, 0);
    }
    public KW_TIME(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TIME, 0);
    }
    public KW_TIMESTAMP(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TIMESTAMP, 0);
    }
    public KW_TIMESTAMP_3(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TIMESTAMP_3, 0);
    }
    public KW_TIMESTAMP_6(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TIMESTAMP_6, 0);
    }
    public KW_TIMESTAMP_9(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TIMESTAMP_9, 0);
    }
    public KW_TRUNCATE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TRUNCATE, 0);
    }
    public KW_UPPER(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_UPPER, 0);
    }
    public KW_WEEK(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_WEEK, 0);
    }
    public KW_YEAR(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_YEAR, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_reservedKeywordsUsedAsFuncName;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterReservedKeywordsUsedAsFuncName) {
             listener.enterReservedKeywordsUsedAsFuncName(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitReservedKeywordsUsedAsFuncName) {
             listener.exitReservedKeywordsUsedAsFuncName(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitReservedKeywordsUsedAsFuncName) {
            return visitor.visitReservedKeywordsUsedAsFuncName(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}


export class NonReservedKeywordsContext extends antlr.ParserRuleContext {
    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {
        super(parent, invokingState);
    }
    public KW_ADD(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ADD, 0);
    }
    public KW_ADMIN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ADMIN, 0);
    }
    public KW_AFTER(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_AFTER, 0);
    }
    public KW_ANALYZE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ANALYZE, 0);
    }
    public KW_ASC(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ASC, 0);
    }
    public KW_BEFORE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_BEFORE, 0);
    }
    public KW_BYTES(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_BYTES, 0);
    }
    public KW_CASCADE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_CASCADE, 0);
    }
    public KW_CATALOG(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_CATALOG, 0);
    }
    public KW_CATALOGS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_CATALOGS, 0);
    }
    public KW_CENTURY(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_CENTURY, 0);
    }
    public KW_CHAIN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_CHAIN, 0);
    }
    public KW_CHANGELOG_MODE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_CHANGELOG_MODE, 0);
    }
    public KW_CHARACTERS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_CHARACTERS, 0);
    }
    public KW_COMMENT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_COMMENT, 0);
    }
    public KW_COMPACT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_COMPACT, 0);
    }
    public KW_COMPUTE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_COMPUTE, 0);
    }
    public KW_COLUMNS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_COLUMNS, 0);
    }
    public KW_CONSTRAINTS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_CONSTRAINTS, 0);
    }
    public KW_CONSTRUCTOR(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_CONSTRUCTOR, 0);
    }
    public KW_CUMULATE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_CUMULATE, 0);
    }
    public KW_DATA(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DATA, 0);
    }
    public KW_DATABASE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DATABASE, 0);
    }
    public KW_DATABASES(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DATABASES, 0);
    }
    public KW_DAYS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DAYS, 0);
    }
    public KW_DECADE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DECADE, 0);
    }
    public KW_DEFINED(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DEFINED, 0);
    }
    public KW_DESC(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DESC, 0);
    }
    public KW_DESCRIPTOR(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DESCRIPTOR, 0);
    }
    public KW_DIV(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_DIV, 0);
    }
    public KW_ENCODING(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ENCODING, 0);
    }
    public KW_ENFORCED(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ENFORCED, 0);
    }
    public KW_ENGINE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ENGINE, 0);
    }
    public KW_ERROR(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ERROR, 0);
    }
    public KW_ESTIMATED_COST(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ESTIMATED_COST, 0);
    }
    public KW_EXCEPTION(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_EXCEPTION, 0);
    }
    public KW_EXCLUDE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_EXCLUDE, 0);
    }
    public KW_EXCLUDING(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_EXCLUDING, 0);
    }
    public KW_EXTENDED(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_EXTENDED, 0);
    }
    public KW_FILE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FILE, 0);
    }
    public KW_FINAL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FINAL, 0);
    }
    public KW_FIRST(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FIRST, 0);
    }
    public KW_FOLLOWING(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FOLLOWING, 0);
    }
    public KW_FORMAT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FORMAT, 0);
    }
    public KW_FORTRAN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FORTRAN, 0);
    }
    public KW_FOUND(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FOUND, 0);
    }
    public KW_FRAC_SECOND(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FRAC_SECOND, 0);
    }
    public KW_FUNCTIONS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FUNCTIONS, 0);
    }
    public KW_GENERAL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_GENERAL, 0);
    }
    public KW_GENERATED(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_GENERATED, 0);
    }
    public KW_GO(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_GO, 0);
    }
    public KW_GOTO(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_GOTO, 0);
    }
    public KW_GRANTED(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_GRANTED, 0);
    }
    public KW_HOP(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_HOP, 0);
    }
    public KW_HOURS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_HOURS, 0);
    }
    public KW_IF(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_IF, 0);
    }
    public KW_IGNORE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_IGNORE, 0);
    }
    public KW_INCREMENT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_INCREMENT, 0);
    }
    public KW_INPUT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_INPUT, 0);
    }
    public KW_INVOKER(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_INVOKER, 0);
    }
    public KW_JAR(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_JAR, 0);
    }
    public KW_JARS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_JARS, 0);
    }
    public KW_JAVA(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_JAVA, 0);
    }
    public KW_JSON(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_JSON, 0);
    }
    public KW_JSON_EXECUTION_PLAN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_JSON_EXECUTION_PLAN, 0);
    }
    public KW_KEY(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_KEY, 0);
    }
    public KW_KEY_MEMBER(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_KEY_MEMBER, 0);
    }
    public KW_KEY_TYPE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_KEY_TYPE, 0);
    }
    public KW_LABEL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LABEL, 0);
    }
    public KW_LAST(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LAST, 0);
    }
    public KW_LENGTH(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LENGTH, 0);
    }
    public KW_LEVEL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LEVEL, 0);
    }
    public KW_LOAD(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LOAD, 0);
    }
    public KW_LOCALTIMESTAMP(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_LOCALTIMESTAMP, 0);
    }
    public KW_MAP(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MAP, 0);
    }
    public KW_MICROSECOND(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MICROSECOND, 0);
    }
    public KW_MILLENNIUM(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MILLENNIUM, 0);
    }
    public KW_MILLISECOND(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MILLISECOND, 0);
    }
    public KW_MINUTES(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MINUTES, 0);
    }
    public KW_MINVALUE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MINVALUE, 0);
    }
    public KW_MODIFY(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MODIFY, 0);
    }
    public KW_MODULES(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MODULES, 0);
    }
    public KW_MONTHS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_MONTHS, 0);
    }
    public KW_NANOSECOND(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NANOSECOND, 0);
    }
    public KW_NULLS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NULLS, 0);
    }
    public KW_NUMBER(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_NUMBER, 0);
    }
    public KW_OPTION(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_OPTION, 0);
    }
    public KW_OPTIONS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_OPTIONS, 0);
    }
    public KW_ORDERING(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ORDERING, 0);
    }
    public KW_OUTPUT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_OUTPUT, 0);
    }
    public KW_OVERWRITE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_OVERWRITE, 0);
    }
    public KW_OVERWRITING(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_OVERWRITING, 0);
    }
    public KW_PARTITIONED(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PARTITIONED, 0);
    }
    public KW_PARTITIONS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PARTITIONS, 0);
    }
    public KW_PASSING(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PASSING, 0);
    }
    public KW_PAST(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PAST, 0);
    }
    public KW_PATH(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PATH, 0);
    }
    public KW_PLACING(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PLACING, 0);
    }
    public KW_PLAN(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PLAN, 0);
    }
    public KW_PRECEDING(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PRECEDING, 0);
    }
    public KW_PRESERVE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PRESERVE, 0);
    }
    public KW_PRIOR(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PRIOR, 0);
    }
    public KW_PRIVILEGES(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PRIVILEGES, 0);
    }
    public KW_PUBLIC(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PUBLIC, 0);
    }
    public KW_PYTHON(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PYTHON, 0);
    }
    public KW_PYTHON_FILES(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PYTHON_FILES, 0);
    }
    public KW_PYTHON_REQUIREMENTS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PYTHON_REQUIREMENTS, 0);
    }
    public KW_PYTHON_DEPENDENCIES(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PYTHON_DEPENDENCIES, 0);
    }
    public KW_PYTHON_JAR(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PYTHON_JAR, 0);
    }
    public KW_PYTHON_ARCHIVES(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PYTHON_ARCHIVES, 0);
    }
    public KW_PYTHON_PARAMETER(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_PYTHON_PARAMETER, 0);
    }
    public KW_QUARTER(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_QUARTER, 0);
    }
    public KW_RAW(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_RAW, 0);
    }
    public KW_READ(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_READ, 0);
    }
    public KW_RELATIVE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_RELATIVE, 0);
    }
    public KW_REMOVE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_REMOVE, 0);
    }
    public KW_RENAME(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_RENAME, 0);
    }
    public KW_REPLACE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_REPLACE, 0);
    }
    public KW_RESPECT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_RESPECT, 0);
    }
    public KW_RESTART(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_RESTART, 0);
    }
    public KW_RESTRICT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_RESTRICT, 0);
    }
    public KW_ROLE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ROLE, 0);
    }
    public KW_ROW_COUNT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ROW_COUNT, 0);
    }
    public KW_SCALA(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SCALA, 0);
    }
    public KW_SCALAR(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SCALAR, 0);
    }
    public KW_SCALE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SCALE, 0);
    }
    public KW_SCHEMA(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SCHEMA, 0);
    }
    public KW_SECONDS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SECONDS, 0);
    }
    public KW_SECTION(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SECTION, 0);
    }
    public KW_SECURITY(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SECURITY, 0);
    }
    public KW_SELF(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SELF, 0);
    }
    public KW_SERVER(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SERVER, 0);
    }
    public KW_SERVER_NAME(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SERVER_NAME, 0);
    }
    public KW_SESSION(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SESSION, 0);
    }
    public KW_SETS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SETS, 0);
    }
    public KW_SIMPLE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SIMPLE, 0);
    }
    public KW_SIZE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SIZE, 0);
    }
    public KW_SLIDE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SLIDE, 0);
    }
    public KW_SOURCE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SOURCE, 0);
    }
    public KW_SPACE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_SPACE, 0);
    }
    public KW_STATE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_STATE, 0);
    }
    public KW_STATEMENT(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_STATEMENT, 0);
    }
    public KW_STEP(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_STEP, 0);
    }
    public KW_STRING(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_STRING, 0);
    }
    public KW_STRUCTURE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_STRUCTURE, 0);
    }
    public KW_STYLE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_STYLE, 0);
    }
    public KW_TABLES(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TABLES, 0);
    }
    public KW_TEMPORARY(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TEMPORARY, 0);
    }
    public KW_TIMECOL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TIMECOL, 0);
    }
    public KW_FLOOR(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_FLOOR, 0);
    }
    public KW_TIMESTAMP_LTZ(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TIMESTAMP_LTZ, 0);
    }
    public KW_TIMESTAMPADD(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TIMESTAMPADD, 0);
    }
    public KW_TIMESTAMPDIFF(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TIMESTAMPDIFF, 0);
    }
    public KW_TOTIMESTAMP(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TOTIMESTAMP, 0);
    }
    public KW_TRANSFORM(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TRANSFORM, 0);
    }
    public KW_TUMBLE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TUMBLE, 0);
    }
    public KW_TYPE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_TYPE, 0);
    }
    public KW_UNDER(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_UNDER, 0);
    }
    public KW_UNLOAD(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_UNLOAD, 0);
    }
    public KW_USAGE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_USAGE, 0);
    }
    public KW_USE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_USE, 0);
    }
    public KW_UTF16(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_UTF16, 0);
    }
    public KW_UTF32(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_UTF32, 0);
    }
    public KW_UTF8(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_UTF8, 0);
    }
    public KW_VERSION(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_VERSION, 0);
    }
    public KW_VIEW(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_VIEW, 0);
    }
    public KW_VIEWS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_VIEWS, 0);
    }
    public KW_VIRTUAL(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_VIRTUAL, 0);
    }
    public KW_WATERMARK(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_WATERMARK, 0);
    }
    public KW_WATERMARKS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_WATERMARKS, 0);
    }
    public KW_WEEK(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_WEEK, 0);
    }
    public KW_WORK(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_WORK, 0);
    }
    public KW_WRAPPER(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_WRAPPER, 0);
    }
    public KW_YEARS(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_YEARS, 0);
    }
    public KW_ZONE(): antlr.TerminalNode | null {
        return this.getToken(SparkSQLParser.KW_ZONE, 0);
    }
    public override get ruleIndex(): number {
        return SparkSQLParser.RULE_nonReservedKeywords;
    }
    public override enterRule(listener: SparkSQLListener): void {
        if(listener.enterNonReservedKeywords) {
             listener.enterNonReservedKeywords(this);
        }
    }
    public override exitRule(listener: SparkSQLListener): void {
        if(listener.exitNonReservedKeywords) {
             listener.exitNonReservedKeywords(this);
        }
    }
    public override accept<Result>(visitor: SparkSQLVisitor<Result>): Result | null {
        if (visitor.visitNonReservedKeywords) {
            return visitor.visitNonReservedKeywords(this);
        } else {
            return visitor.visitChildren(this);
        }
    }
}
